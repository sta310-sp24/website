{
  "hash": "dbc0155d16185ad9aecfeae258250972",
  "result": {
    "markdown": "---\ntitle: \"HW 02: Multiple linear regression\" \nsubtitle: \"due Wednesday, October 19 at 11:59pm\"\neditor: visual\nexecute:\n  freeze: auto\n  echo: true\n  eval: false\n  warning: false\n  message: false\nbibliography: references.bib\n---\n\n\n# Introduction\n\nIn this analysis you will use multiple linear regression to analyze relationships between variables in three different scenarios.\n\n# Learning goals\n\nIn this assignment, you will...\n\n-   Fit and interpret multiple linear regression models\n-   Evaluate and compare multiple linear regression models\n-   Continue developing a workflow for reproducible data analysis.\n\n# Getting started\n\nThe repo for this assignment is available on GitHub at [github.com/sta210-fa22](https://github.com/sta210-fa22 \"Course GitHub organization\") and starts with the prefix **hw-02**. See [Lab 01](../labs/lab-01.qmd) for more detailed instructions on getting started.\n\n# Packages\n\nThe following packages will be used in this assignment:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels) \nlibrary(knitr) \nlibrary(palmerpenguins)\n```\n:::\n\n\n::: callout-important\nAll narrative should be written in complete sentences, and all visualizations should have informative titles and axis labels.\n:::\n\n# Part 1: Palmer Penguins\n\nData were collected and made available by [Dr. Kristen Gorman](https://www.uaf.edu/cfos/people/faculty/detail/kristen-gorman.php) and the [Palmer Station, Antarctica LTER](https://pal.lternet.edu/), a member of the [Long Term Ecological Research Network](https://lternet.edu/). [@gorman2014]\n\n\\\nThese data can be found in the **palmerpenguins** package. We're going to be working with the `penguins` dataset from this package. The dataset contains data for 344 penguins. There are 3 different species of penguins in this dataset, collected from 3 islands in the Palmer Archipelago, Antarctica. [Click here](https://allisonhorst.github.io/palmerpenguins/reference/penguins.html) to see the codebook.\n\n## Exercise 1\n\nOur first goal is to fit a model predicting body mass (which is more difficult to measure) from bill length, bill depth, flipper length, species, and sex.\n\nWe will start by preparing the data.\n\n-   Use the `drop_na()` function to remove any observations from the `penguins` data frame that has missing values. Your resulting data frame should have 333 observations.\n\n-   Split the data into training (75%) and testing (25%) sets. Use a seed of 123.\n\n## Exercise 2\n\n-   Use the training data to fit a model predicting body mass (which is more difficult to measure) from the other variables listed above. Only include main effects, i.e., no interaction terms, in this model. Fit the model in a way such that the intercept has a meaningful interpretation.\n\n    Neatly display the model using 3 digits.\n\n-   Write estimated regression equation. Use the variable names in your equation.\n\n## Exercise 3\n\n-   Interpret each slope coefficient in the context of the data.\n\n-   Interpret the intercept in the context of the data.\n\n## Exercise 4\n\n-   Calculate the residual for a male Adelie penguin that weighs 3750 grams with the following body measurements: `bill_length_mm` = 39.1, `bill_depth_mm` = 18.7, `flipper_length_mm` = 181. Does the model overpredict or underpredict this penguin's weight?\n\n-   Calculate $R^2$ of this model based on the training data and interpret this value in context of the data and the model.\n\n## Exercise 5\n\nNext, we will focus on a model using bill length and species to predict body mass.\n\nUse the training data to make a visualization of the relationship between bill length and body mass by species. Does the visualization give evidence of a potential interaction term? Briefly explain your response.\n\n## Exercise 6\n\nUse the training data to fit a model using bill length, species, and the interaction between the two variables to predict body mass. Fit the model in a way such that the intercept has a meaningful interpretation.\n\nNeatly display the model using 3 digits.\n\n::: callout-tip\nYou can use the [`step_interact()`](https://recipes.tidymodels.org/reference/step_interact.html) to add interactions in the recipe.\n:::\n\n## Exercise 7\n\nUse the test data to compare the model fit in Exercise 2 to the model fit in Exercise 6. Which model is the \"best\" for predicting body mass? Briefly explain your response showing the code and output to support your choice.\n\n# Part 2: Perceived threat of Covid-19\n\n@garbe2020 published in June 2020, aims to examine the relationship between personality traits, perceived threat of Covid-19 and stockpiling toilet paper. For this study titled [Influence of perceived threat of Covid-19 and HEXACO personality traits on toilet paper stockpiling](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0234232#abstract0), researchers conducted an online survey March 23 - 29, 2020 and used the results to fit multiple linear regression models to draw conclusions about their research questions. From their survey, they collected data on adults across 35 countries. Given the small number of responses from people outside of the United States, Canada, and Europe, only responses from people in these three locations were included in the regression analysis.\n\nLet's consider their results for the model looking at the effect on **perceived threat of Covid-19**. The model can be found on page 6 of the paper. The perceived threat of Covid was quantified using the responses to the following survey question:\n\n> How threatened do you feel by Coronavirus? \\[Users select on a 10-point visual analogue scale (Not at all threatened to Extremely Threatened)\\]\n\nAs stated on page 5 of the paper \"*To ease interpretation, continuous variables were z-standardized and categorical variables were dummy-coded in all models.\"*\n\nYou are familiar with dummy-coding, i.e., creating indicator variables for categorical predictors. For the continuous variables, \"z-standardized\" means each continuous predictor was shifted by its mean and rescaled by its standard deviation. For example, if $X$ is continuous predictor, the z-standardized value of $X$ is\n\n\n$$z_X = \\frac{x - \\bar{x}}{s_X}$$\n\n\n## Exercise 8\n\n-   Interpret the coefficient of Age (0.072) in the context of the analysis.\n\n-   Interpret the coefficient of Place of residence in the context of the analysis.\n\n## Exercise 9\n\nThe model includes an interaction between Place of residence and Emotionality (capturing differential tendencies in to worry and be anxious).\n\n-   What does the coefficient for the interaction (0.101) mean in the context of the data?\n\n-   Interpret the estimated effect of Emotionality for a person who lives in the US/Canada.\n\n-   Interpret the estimated effect of Emotionality for a person who lives in Europe.\n\n# Part 3: World Bank\n\n## Exercise 10\n\nData on countries' Gross Domestic Product (GDP) and percentage of urban population was collected and made available by [The World Bank](http://data.worldbank.org/) in 2020. A description of the variables as defined by The World Bank are provided below.\n\n-   **GDP:** \"GDP per capita is gross domestic product divided by midyear population. GDP is the sum of gross value added by all resident producers in the economy plus any product taxes and minus any subsidies not included in the value of the products. It is calculated without making deductions for depreciation of fabricated assets or for depletion and degradation of natural resources. Data are in current U.S. dollars.\"\n\n-   **Urban Population (% of total):** \"Urban population refers to people living in urban areas as defined by national statistical offices. It is calculated using World Bank population estimates and urban ratios from the United Nations World Urbanization Prospects.\"\n\nThe linear model of the relationship between GDP and urban population is as follows\n\n\n$$\n\\widehat{\\log(GDP)} = 6.11 + 0.042 \\times urban\n$$\n\n\n-   Interpret the slope in terms of the GDP in the context of the data.\n\n-   Interpret the intercept in terms of the GDP in the context of the data.\n\n::: render-commit-push\nBefore submitting, make sure you render your document and commit (with a meaningful commit message) and push all updates.\n:::\n\n# Submission\n\n::: callout-warning\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\n\nRemember -- you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n:::\n\nTo submit your assignment:\n\n-   Go to [http://www.gradescope.com](http://www.gradescope.com/) and click *Log in* in the top right corner.\n-   Click *School Credentials* ➡️ *Duke NetID* and log in using your NetID credentials.\n-   Click on your *STA 210* course.\n-   Click on the assignment, and you'll be prompted to submit it.\n-   Mark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be \"checked\").\n-   Select the first page of your PDF submission to be associated with the *\"Workflow & formatting\"* section.\n\n# Grading (50 points)\n\n| Component             | Points |\n|-----------------------|--------|\n| Ex 1 - 10             | 47     |\n| Workflow & formatting | 3[^1]  |\n\n[^1]: The \"Workflow & formatting\" grade is to assess the reproducible workflow. This includes having at least 3 informative commit messages and updating the name and date in the YAML.\n",
    "supporting": [
      "hw-02_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}