{
  "hash": "dfbbcc3e727aa85197768e18d14737ee",
  "result": {
    "markdown": "---\ntitle: \"Review of multiple linear regression\"\nauthor: \"Prof. Maria Tackett\"\ndate: \"2024-01-17\"\ndate-format: \"MMM DD, YYYY\"\nfooter: \"[ðŸ”— STA 310 - Spring 2024](https://sta310-sp24.netlify.app)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    slide-number: true\n    multiplex: false\n    transition: fade\n    incremental: false \n    chalkboard: true\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\nexecute:\n  freeze: auto\n  echo: true\n  warning: false\n  message: false\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib\n---\n\n\n\n\n## Announcements\n\n-   HW 01 due Wed, Jan 24 at 11:59pm\n\n    -   Released Thursday morning\n\n-   Labs start Thursday\n\n-   Check [website](https://sta310-sp24.netlify.app/course-overview) for office hours schedule\n\n-   Added a Slack channel `#internships-research-opportunities` (optional)\n\n## Computing set up\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\n\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n\ncolors <- tibble::tibble(green = \"#B5BA72\")\n```\n:::\n\n\n## Topics\n\n-   Define statistical models\n\n-   Motivate generalized linear models and multilevel models\n\n-   Review multiple linear regression\n\n::: aside\nNotes based on Chapter 1 of @roback2021beyond unless noted otherwise.\n:::\n\n# Statistical models\n\n## Models and statistical models\n\nSuppose we have observations $y_1, \\ldots, y_n$\n\n::: incremental\n-   **Model**: Mathematical description of the process we think generates the observations\n\n-   **Statistical model**: Model that includes an equation describing the impact of explanatory variables (**deterministic part)** and probability distributions for parts of the process that are assumed to be random variation (**random part)**\n:::\n\n::: aside\nDefinitions adapted from @stroup2012generalized\n:::\n\n## Statistical models\n\nA statistical model must include\n\n1.  The observations\n2.  The deterministic (systematic) part of the process\n3.  The random part of the process with a statement of the presumed probability distribution\n\n::: aside\nDefinitions adapted from @stroup2012generalized\n:::\n\n## Example {.midi}\n\nSuppose we have the model for comparing two means:\n\n$$\ny_{ij} = \\mu_i + \\epsilon_{ij}\n$$\n\nwhere\n\n. . .\n\n::: incremental\n-   $i = 1, 2$: group\n\n\n```{=html}\n<!-- -->\n```\n\n-   $j = 1, \\ldots, n$: observation number\n-   $n_i$: number of observations in group $i$\n-   $\\mu_i$: mean of group $i$\n-   $y_{ij}$: $j^{th}$ observation in the $i^{th}$ group\n-   $\\epsilon_{ij}$ : random error (variation) associated with $ij^{th}$ observation\n:::\n\n::: aside\nAdapted from @stroup2012generalized\n:::\n\n## Example\n\n$$\ny_{ij} = \\mu_i + \\epsilon_{ij}\n$$\n\n::: incremental\n-   $y_{ij}$: the observations\n\n-   $\\mu_i$: deterministic part of the model, no random variability\n\n-   $e_{ij}$ : random part of the model, indicating observations vary about their mean\n\n-   Typically assume $\\epsilon_{ij}$ are independent and identically distributed (i.i.d.) $N(0, \\sigma^2)$\n:::\n\n::: aside\nAdapted from @stroup2012generalized\n:::\n\n## Practice\n\n::: question\nSuppose $y_{ij}$'s are observed outcome data and $x_i$'s are values of the explanatory variable. Assume a linear regression model can used to describe the process of generating $y_{ij}$ based on the $x_i$.\n\n1.  Write the specification of the statistical model.\n2.  Label the 3 components of the model equation (observation, deterministic part, random part)\n3.  What is $E(y_{ij})$, the expected value of the observations?\n:::\n\n# Motivating generalized linear models (GLMs) and multilevel models\n\n## Assumptions for linear regression\n\n-   <u>**L**</u>**inearity**: Linear relationship between mean response and predictor variable(s)\n\n-   <u>**I**</u>**ndependence**: Residuals are independent. There is no connection between how far any two points lie above or below regression line.\n\n-   <u>**N**</u>**ormality**: Response follows a normal distribution at each level of the predictor (or combination of predictors)\n\n-   <u>**E**</u>**qual variance**: Variability (variance or standard deviation) of the response is equal for all levels of the predictor (or combination of predictors)\n\n## Assumptions for linear regression {.midi}\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Modified from Figure 1.1. in BMLR](02-mlr-review_files/figure-revealjs/unnamed-chunk-2-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n-   **Linearity**: Linear relationship between mean of the response $Y$ and the predictor $X$\n\n-   **Independence**: No connection between how far any two points lie from regression line\n\n-   **Normality**: Response $Y$ follows a normal distribution at each level of the predictor $X$ (red curves)\n\n-   **Equal variance**: Variance of the response $Y$ is equal for all levels of the predictor $X$\n:::\n:::\n\n## Violations in assumptions\n\n*Do wealthy households tend to have fewer children compared to households with lower income?* Annual income and family size are recorded for a random sample of households.\n\n-   The response variable is number of children in the household.\n-   The predictor variable is annual income in US dollars.\n\n::: question\nWhich assumption(s) are obviously violated, if any?\n:::\n\n## Violations in assumptions\n\nMedical researchers investigated the outcome of a particular surgery for patients with comparable stages of disease but different ages. The 10 hospitals in the study had at least two surgeons performing the surgery of interest. Patients were randomly selected for each surgeon at each hospital. The surgery outcome was recorded on a scale of 1 - 10.\n\n-   The response variable is surgery outcome, 1 - 10.\n-   The predictor variable is patient age in years.\n\n::: question\nWhich assumption(s) are obviously violated, if any?\n:::\n\n## Beyond linear regression {.midi}\n\n::: incremental\n-   When drawing conclusions from linear regression models, we do so assuming LINE are all met\n\n-   **Generalized linear models** require different assumptions and can accommodate violations in LINE\n\n    -   Relationship between response and predictor(s) can be nonlinear\n    -   Response variable can be non-normal\n    -   Variance in response can differ at each level of predictor(s)\n    -   **The independence assumption still must hold!**\n\n-   **Multilevel models** are used to model data that violate the independence assumption, i.e. correlated observations\n:::\n\n# Multiple linear regression\n\n## Data: Kentucky Derby Winners {.midi}\n\nToday's data is from the Kentucky Derby, an annual 1.25-mile horse race held at the Churchill Downs race track in Louisville, KY. The data is in the file [derbyplus.csv](data/derbyplus.csv) and contains information for races 1896 - 2017.\n\n::: columns\n::: {.column width=\"50%\"}\n**Response variable**\n\n-   `speed`: Average speed of the winner in feet per second (ft/s)\n\n**Additional variable**\n\n-   `winner`: Winning horse\n:::\n\n::: {.column width=\"50%\"}\n**Predictor variables**\n\n-   `year`: Year of the race\n-   `condition`: Condition of the track (good, fast, slow)\n-   `starters`: Number of horses who raced\n:::\n:::\n\n**Goal: Understand variability in average winner speed based on characteristics of the race.**\n\n## Data\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nderby <- read_csv(\"data/derbyplus.csv\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nderby |>\n  head(5) |> kable()\n```\n\n::: {.cell-output-display}\n| year|winner        |condition | speed| starters|\n|----:|:-------------|:---------|-----:|--------:|\n| 1896|Ben Brush     |good      | 51.66|        8|\n| 1897|Typhoon II    |slow      | 49.81|        6|\n| 1898|Plaudit       |good      | 51.16|        4|\n| 1899|Manuel        |fast      | 50.00|        5|\n| 1900|Lieut. Gibson |fast      | 52.28|        7|\n:::\n:::\n\n\n## Data science workflow\n\n![Image source: @wickham2023r](images/02/data-science-cycle.png){fig-alt=\"Data science workflow cycle from R for Data Science\" fig-align=\"center\"}\n\n## Exploratory data analysis (EDA)\n\n-   Once you're ready for the statistical analysis, the first step should always be **exploratory data analysis**.\n\n-   The EDA will help you\n\n    -   begin to understand the variables and observations\n    -   identify outliers or potential data entry errors\n    -   begin to see relationships between variables\n    -   identify the appropriate model and identify a strategy\n\n-   The EDA is exploratory; formal modeling and statistical inference are used to draw conclusions.\n\n## Univariate EDA\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-mlr-review_files/figure-revealjs/univar-eda-plot-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n## Univariate EDA code\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np1 <- ggplot(data = derby, aes(x = speed)) + \n  geom_histogram(fill = colors$green, color = \"black\") + \n  labs(x = \"Winning speed (ft/s)\", y = \"Count\")\n\np2 <- ggplot(data = derby, aes(x = starters)) + \n  geom_histogram(fill = colors$green, color = \"black\",\n                 binwidth = 2) + \n  labs(x = \"Starters\", y = \"Count\")\n\np3 <- ggplot(data = derby, aes(x = condition)) +\n   geom_bar(fill = colors$green, color = \"black\", aes(x = ))\n\np1 + (p2 / p3) + \n  plot_annotation(title = \"Univariate data analysis\")\n```\n:::\n\n\n## Bivariate EDA\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-mlr-review_files/figure-revealjs/bivar-eda-plot-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n## Bivariate EDA code\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np4 <- ggplot(data = derby, aes(x = starters, y = speed)) + \n  geom_point() + \n  labs(x = \"Starters\", y = \"Speed (ft / s)\")\n\np5 <- ggplot(data = derby, aes(x = year, y = speed)) + \n  geom_point() + \n  labs(x = \"Year\", y = \"Speed (ft / s)\")\n\np6 <- ggplot(data = derby, aes(x = condition, y = speed)) + \n  geom_boxplot(fill = colors$green, color = \"black\") + \n  labs(x = \"Conditions\", y = \"Speed (ft / s)\")\n\n(p4 + p5) + p6 +\n  plot_annotation(title = \"Bivariate data analysis\")\n```\n:::\n\n\n## Scatterplot matrix\n\nA **scatterplot matrix** helps quickly visualize relationships between many variable pairs. They are particularly useful to identify potentially correlated predictors.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-mlr-review_files/figure-revealjs/scatterplot-matrix-plot-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n## Scatterplot matrix code\n\nCreate using the `ggpairs()` function in the GGally package.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(GGally)\nggpairs(data = derby, \n        columns = c(\"condition\", \"year\", \"starters\", \"speed\"))\n```\n:::\n\n\n## Multivariate EDA\n\nPlot the relationship between the response and a predictor based on levels of another predictor to assess potential interactions.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-mlr-review_files/figure-revealjs/multivar-eda-plot-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n## Multivariate EDA code\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(viridis)\nggplot(data = derby, aes(x = year, y = speed, color = condition, \n                         shape = condition, linetype = condition)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE, aes(linetype = condition)) + \n  labs(x = \"Year\", y = \"Speed (ft/s)\", color = \"Condition\",\n       title = \"Speed vs. year\", \n       subtitle = \"by track condition\") +\n  guides(lty = FALSE, shape = FALSE) +\n  scale_color_viridis_d(end = 0.9)\n```\n:::\n\n\n## Candidate models\n\nModel 1: Main effects model (`year`, `condition`, `starters`)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel1 <- lm(speed ~ starters + year + condition, data = derby)\n```\n:::\n\n\n<br>\n\n. . .\n\nModel 2: Main effects + $year^2$, the quadratic effect of `year`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel2 <- lm(speed ~ starters + year + I(year^2) + condition,\n             data = derby)\n```\n:::\n\n\n<br>\n\n. . .\n\nModel 3: Main effects + interaction between `year` and `condition`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel3 <- lm(speed ~ starters + year + condition + year * condition, \n             data = derby)\n```\n:::\n\n\n# Application exercise\n\n<!--do an interpretation activity here - 3 groups each interpreting a different variable- put guidance in the AE-->\n\n# Inference for regression \n\nUse statistical inference to\n\n-   Evaluate if predictors are statistically significant (not necessarily practically significant!)\n\n-   Quantify uncertainty in coefficient estimates\n\n-   Quantify uncertainty in model predictions\n\nIf LINE assumptions are met, we can use inferential methods based on mathematical models. If at least linearity and independence are met, we can use simulation-based inference methods.\n\n## Inference for regression  {.midi}\n\nWhen LINE assumptions are met...\n. . .\n\n::: incremental\n-   Use least squares regression to obtain the estimates for the model coefficients $\\beta_0, \\beta_1, \\ldots, \\beta_j$ and for $\\sigma^2$\n\n-   $\\hat{\\sigma}$ is the **regression standard error**\n\n    $$\n    \\hat{\\sigma} = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n - p - 1}} = \\sqrt{\\frac{\\sum_{i=1}^n e_i^2}{n-p-1}}\n    $$\n\n    where $p$ is the number of non-intercept terms in the model (e.g., $p = 1$ in simple linear regression)\n\n-   Goal is to use estimated values to draw conclusions about $\\beta_j$\n\n    -   Use $\\hat{\\sigma}$ to calculate $SE_{\\hat{\\beta}_j}$ . [Click here](https://github.com/STA210-Sp19/supplemental-notes/blob/master/regression-basics-matrix.pdf) for more detail.\n:::\n\n## Hypothesis testing for $\\beta_j$ {.small}\n\n1.  **State the hypotheses**. $H_0: \\beta_j = 0 \\text{ vs. } H_a: \\beta_j \\neq 0$, given the other variables in the model.\n\n. . .\n\n2.  **Calculate the test statistic.**\n\n$$\nt = \\frac{\\hat{\\beta}_j - 0}{SE_{\\hat{\\beta}_j}}\n$$. . .\n\n3.  **Calculate the p-value.** The p-value is calculated from a $t$ distribution with $n - p - 1$ degrees of freedom.\n\n    $$\n    \\text{p-value} = 2P(T > |t|) \\hspace{4mm} T \\sim t_{n-p-1}\n    $$\n\n. . .\n\n43. **State the conclusion in context of the data.**\n    -   Reject $H_0$ if p-value is sufficiently small.\n\n## Confidence interval for $\\beta_j$ \n\nThe $C\\%$ confidence confidence interval for $\\beta_j$ is\n\n$$\\hat{\\beta}_j \\pm t^* \\times SE_{\\hat{\\beta}_j}$$\n\nwhere the critical value $t^* \\sim t_{n-p-1}$\n\n<br>\n\n. . .\n\n**General interpretation for the confidence interval \\[LB, UB\\]**:\n\nWe are $C\\%$ confident that for every one unit increase in $x_j$, the response is expected to change by LB to UB units, holding all else constant.\n\n# Application exercise\n\n## Measures of model performance\n\n-   $R^2$: Proportion of variability in the response explained by the model\n\n    -   Will always increase as predictors are added, so it shouldn't be used to compare models\n\n-   $Adj. R^2$: Similar to $R^2$ with a penalty for extra terms\n\n-   $AIC$: Likelihood-based approach balancing model performance and complexity\n\n-   $BIC$: Similar to AIC with stronger penalty for extra terms\n\n## Model summary statistics\n\nUse the `glance()` function to get model summary statistics\n\n<br>\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|model  | r.squared| adj.r.squared|     AIC|     BIC|\n|:------|---------:|-------------:|-------:|-------:|\n|Model1 |     0.730|         0.721| 259.478| 276.302|\n|Model2 |     0.827|         0.819| 207.429| 227.057|\n|Model3 |     0.751|         0.738| 253.584| 276.016|\n:::\n:::\n\n\n. . .\n\n::: question\nWhich model do you choose based on these statistics?\n:::\n\n## Characteristics of a \"good\" final model {.midi}\n\n-   Model can be used to answer primary research questions\n\n-   Predictor variables control for important covariates\n\n-   Potential interactions have been investigated\n\n-   Variables are centered, as needed, for more meaningful interpretations\n\n-   Unnecessary terms are removed\n\n-   Assumptions are met and influential points have been addressed\n\n-   Model tells a \"persuasive story parsimoniously\"\n\n::: aside\nList from Section 1.6.7 of @roback2021beyond\n:::\n\n## Next class \n\n-   Using likelihoods\n\n-   See [Prepare for Jan 22](../prepare/jan-22.html) lecture\n\n# References\n",
    "supporting": [
      "02-mlr-review_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}