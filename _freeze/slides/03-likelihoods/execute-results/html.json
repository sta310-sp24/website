{
  "hash": "a308d64eb7fc6faebfc990a2f7ff3730",
  "result": {
    "markdown": "---\ntitle: \"Inference review + <br> using likelihoods\"\nauthor: \"Prof. Maria Tackett\"\ndate: \"2024-01-22\"\ndate-format: \"MMM DD, YYYY\"\nfooter: \"[🔗 STA 310 - Spring 2024](https://sta310-sp24.netlify.app)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    slide-number: true\n    multiplex: false\n    transition: fade\n    incremental: false \n    chalkboard: true\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\nexecute:\n  freeze: auto\n  echo: true\n  warning: false\n  message: false\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib\n---\n\n\n\n\n## Announcements\n\n-   HW 01 due Thursday at 6am\n    -   Your access to the repo will be removed at the deadline. If you wish to submit the HW late, please email me and I will extend your access to the repo.\n    -   You will have access to your HW repo again when grades are returned.\n\n## Computing set up\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)\n\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\ncolors <- tibble::tibble(green = \"#B5BA72\")\n```\n:::\n\n\n## Topics\n\n-   Review inference for multiple linear regression\n\n-   Using likelihoods\n\n::: aside\nNotes based on Chapter 1 and 2 of @roback2021beyond unless noted otherwise.\n:::\n\n# Inference for multiple linear regression\n\n## Data: Kentucky Derby Winners {.midi}\n\nToday's data is from the Kentucky Derby, an annual 1.25-mile horse race held at the Churchill Downs race track in Louisville, KY. The data is in the file [derbyplus.csv](data/derbyplus.csv) and contains information for races 1896 - 2017.\n\n::: columns\n::: {.column width=\"50%\"}\n**Response variable**\n\n-   `speed`: Average speed of the winner in feet per second (ft/s)\n\n**Additional variable**\n\n-   `winner`: Winning horse\n:::\n\n::: {.column width=\"50%\"}\n**Predictor variables**\n\n-   `year`: Year of the race\n-   `condition`: Condition of the track (good, fast, slow)\n-   `starters`: Number of horses who raced\n:::\n:::\n\n**Goal: Understand variability in average winner speed based on characteristics of the race.**\n\n## Data\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nderby <- read_csv(\"data/derbyplus.csv\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nderby |>\n  head(5) |> kable()\n```\n\n::: {.cell-output-display}\n| year|winner        |condition | speed| starters|\n|----:|:-------------|:---------|-----:|--------:|\n| 1896|Ben Brush     |good      | 51.66|        8|\n| 1897|Typhoon II    |slow      | 49.81|        6|\n| 1898|Plaudit       |good      | 51.16|        4|\n| 1899|Manuel        |fast      | 50.00|        5|\n| 1900|Lieut. Gibson |fast      | 52.28|        7|\n:::\n:::\n\n\n## Candidate models\n\nModel 1: Main effects model (`year`, `condition`, `starters`)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel1 <- lm(speed ~ starters + year + condition, data = derby)\n```\n:::\n\n\n<br>\n\n. . .\n\nModel 2: Main effects + $year^2$, the quadratic effect of `year`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel2 <- lm(speed ~ starters + year + I(year^2) + condition,\n             data = derby)\n```\n:::\n\n\n<br>\n\n. . .\n\nModel 3: Main effects + interaction between `year` and `condition`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel3 <- lm(speed ~ starters + year + condition + year * condition, \n             data = derby)\n```\n:::\n\n\n## Inference for regression\n\nUse statistical inference to\n\n-   Evaluate if predictors are statistically significant (not necessarily practically significant!)\n\n-   Quantify uncertainty in coefficient estimates\n\n-   Quantify uncertainty in model predictions\n\nIf LINE assumptions are met, we can use inferential methods based on mathematical models. If at least linearity and independence are met, we can use simulation-based inference methods.\n\n## Inference for regression {.midi}\n\nWhen LINE assumptions are met... . . .\n\n::: incremental\n-   Use least squares regression to obtain the estimates for the model coefficients $\\beta_0, \\beta_1, \\ldots, \\beta_j$ and for $\\sigma^2$\n\n-   $\\hat{\\sigma}$ is the **regression standard error**\n\n    $$\n    \\hat{\\sigma} = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n - p - 1}} = \\sqrt{\\frac{\\sum_{i=1}^n e_i^2}{n-p-1}}\n    $$\n\n    where $p$ is the number of non-intercept terms in the model (e.g., $p = 1$ in simple linear regression)\n\n-   Goal is to use estimated values to draw conclusions about $\\beta_j$\n\n    -   Use $\\hat{\\sigma}$ to calculate $SE_{\\hat{\\beta}_j}$ . [Click here](https://github.com/STA210-Sp19/supplemental-notes/blob/master/regression-basics-matrix.pdf) for more detail.\n:::\n\n## Hypothesis testing for $\\beta_j$ {.small}\n\n1.  **State the hypotheses**. $H_0: \\beta_j = 0 \\text{ vs. } H_a: \\beta_j \\neq 0$, given the other variables in the model.\n\n. . .\n\n2.  **Calculate the test statistic.**\n\n$$\nt = \\frac{\\hat{\\beta}_j - 0}{SE_{\\hat{\\beta}_j}}\n$$\n\n. . .\n\n**Calculate the p-value.** The p-value is calculated from a $t$ distribution with $n - p - 1$ degrees of freedom.\n\n$$\n\\text{p-value} = 2P(T > |t|) \\hspace{8mm} T \\sim t_{n-p-1}\n$$\n\n. . .\n\n4.  **State the conclusion in context of the data.**\n    -   Reject $H_0$ if p-value is sufficiently small.\n\n## Confidence interval for $\\beta_j$\n\nThe $C\\%$ confidence confidence interval for $\\beta_j$ is\n\n$$\\hat{\\beta}_j \\pm t^* \\times SE_{\\hat{\\beta}_j}$$\n\nwhere the critical value $t^* \\sim t_{n-p-1}$\n\n<br>\n\n. . .\n\n**General interpretation for the confidence interval \\[LB, UB\\]**:\n\nWe are $C\\%$ confident that for every one unit increase in $x_j$, the response is expected to change by LB to UB units, holding all else constant.\n\n# Application exercise\n\n::: appex\n📋 [sta310-sp24.netlify.app/ae/ae-02-mlr-review](../ae/ae-02-mlr-review.html)\n:::\n\n## Measures of model performance\n\n-   $R^2$: Proportion of variability in the response explained by the model\n\n    -   Will always increase as predictors are added, so it shouldn't be used to compare models\n\n-   $Adj. R^2$: Similar to $R^2$ with a penalty for extra terms\n\n-   $AIC$: Likelihood-based approach balancing model performance and complexity\n\n-   $BIC$: Similar to AIC with stronger penalty for extra terms\n\n## Model summary statistics\n\nUse the `glance()` function to get model summary statistics\n\n<br>\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|model  | r.squared| adj.r.squared|     AIC|     BIC|\n|:------|---------:|-------------:|-------:|-------:|\n|Model1 |     0.730|         0.721| 259.478| 276.302|\n|Model2 |     0.827|         0.819| 207.429| 227.057|\n|Model3 |     0.751|         0.738| 253.584| 276.016|\n:::\n:::\n\n\n. . .\n\n::: question\nWhich model do you choose based on these statistics?\n:::\n\n## Characteristics of a \"good\" final model {.midi}\n\n-   Model can be used to answer primary research questions\n\n-   Predictor variables control for important covariates\n\n-   Potential interactions have been investigated\n\n-   Variables are centered, as needed, for more meaningful interpretations\n\n-   Unnecessary terms are removed\n\n-   Assumptions are met and influential points have been addressed\n\n-   Model tells a \"persuasive story parsimoniously\"\n\n::: aside\nList from Section 1.6.7 of @roback2021beyond\n:::\n\n# Using likelihoods\n\n## Learning goals\n\n-   Describe the concept of a likelihood\n\n-   Construct the likelihood for a simple model\n\n-   Define the Maximum Likelihood Estimate (MLE) and use it to answer an analysis question\n\n-   Identify three ways to calculate or approximate the MLE and apply these methods to find the MLE for a simple model\n\n## What is the likelihood?\n\nA **likelihood** is a function that tells us how likely we are to observe our data for a given parameter value (or values).\n\n-   Unlike with Ordinary Least Squares (OLS) estimates, they do not require the responses be independent, identically distributed, and normal\n\n-   They are <u>not</u> the same as probability functions\n\n## Probability function vs. likelihood {.incremental}\n\n::: incremental\n-   **Probability function:** Fixed parameter value(s) + input possible outcomes $\\Rightarrow$ probability of seeing the different outcomes given the parameter value(s)\n\n-   **Likelihood:** Fixed data + input possible parameter values $\\Rightarrow$ probability of seeing the fixed data for each parameter value\n:::\n\n## Data: Fouls in college basketball games {.midi}\n\nThe data set [`04-refs.csv`](data/04-refs.csv) includes 30 randomly selected NCAA men's basketball games played in the 2009 - 2010 season.[^1]\n\n[^1]: The dataset was derived from `basektball0910.csv` used in [BMLR Section 11.2](https://bookdown.org/roback/bookdown-BeyondMLR/ch-GLMM.html#cs:refs)\n\nWe will focus on the variables `foul1`, `foul2`, and `foul3`, which indicate which team had a foul called them for the 1st, 2nd, and 3rd fouls, respectively.\n\n-   `H`: Foul was called on the home team\n-   `V`: Foul was called on the visiting team\n\nWe are focusing on the first three fouls for this analysis, but this could easily be extended to include all fouls in a game.\n\n------------------------------------------------------------------------\n\n## Fouls in college basketball games\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrefs <- read_csv(\"data/04-refs.csv\")\nrefs |> slice(1:5) |> kable()\n```\n\n::: {.cell-output-display}\n| game|     date|visitor |hometeam |foul1 |foul2 |foul3 |\n|----:|--------:|:-------|:--------|:-----|:-----|:-----|\n|  166| 20100126|CLEM    |BC       |V     |V     |V     |\n|  224| 20100224|DEPAUL  |CIN      |H     |H     |V     |\n|  317| 20100109|MARQET  |NOVA     |H     |H     |H     |\n|  214| 20100228|MARQET  |SETON    |V     |V     |H     |\n|  278| 20100128|SETON   |SFL      |H     |V     |V     |\n:::\n:::\n\n\nWe will treat the games as independent in this analysis.\n\n## Different likelihood models\n\n**Model 1 (Unconditional Model)**:\n\n-   What is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?\n\n. . .\n\n**Model 2 (Conditional Model)**:\n\n-   Is there a tendency for the referees to call more fouls on the visiting team or home team?\n\n-   Is there a tendency for referees to call a foul on the team that already has more fouls?\n\n. . .\n\n**Ultimately we want to decide which model is better.**\n\n## Exploratory data analysis {.midi}\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrefs |>\ncount(foul1, foul2, foul3) |> kable()\n```\n\n::: {.cell-output-display}\n|foul1 |foul2 |foul3 |  n|\n|:-----|:-----|:-----|--:|\n|H     |H     |H     |  3|\n|H     |H     |V     |  2|\n|H     |V     |H     |  3|\n|H     |V     |V     |  7|\n|V     |H     |H     |  7|\n|V     |H     |V     |  1|\n|V     |V     |H     |  5|\n|V     |V     |V     |  2|\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\nThere are\n\n-   46 total fouls on the home team\n-   44 total fouls on the visiting team\n:::\n:::\n\n# Model 1: Unconditional model\n\nWhat is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?\n\n## Likelihood\n\nLet $p_H$ be the probability the referees call a foul on the home team. **The likelihood for a single observation** $$Lik(p_H) = p_H^{y_i}(1 - p_H)^{n_i - y_i}$$Where $y_i$ is the number of fouls called on the home team. (In this example, we know $n_i = 3$ for all observations.)\n\n. . .\n\n**Example**\n\nFor a single game where the first three fouls are $H, H, V$, then $$Lik(p_H) = p_H^{2}(1 - p_H)^{3 - 2} = p_H^{2}(1 - p_H)$$\n\n## Model 1: Likelihood contribution {.midi}\n\n| Foul 1 | Foul 2 | Foul 3 | n   | Likelihood contribution |\n|--------|--------|--------|-----|-------------------------|\n| H      | H      | H      | 3   | $p_H^3$                 |\n| H      | H      | V      | 2   | $p_H^2(1 - p_H)$        |\n| H      | V      | H      | 3   | $p_H^2(1 - p_H)$        |\n| H      | V      | V      | 7   | **A**                   |\n| V      | H      | H      | 7   | **B**                   |\n| V      | H      | V      | 1   | $p_H(1 - p_H)^2$        |\n| V      | V      | H      | 5   | $p_H(1 - p_H)^2$        |\n| V      | V      | V      | 2   | $(1 - p_H)^3$           |\n\n::: question\nFill in **A** and **B**.\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_9968e596\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;margin:5%;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">02</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n## Model 1: Likelihood function\n\nBecause the observations (the games) are independent, the **likelihood** is\n\n$$Lik(p_H) = \\prod_{i=1}^{n}p_H^{y_i}(1 - p_H)^{3 - y_i}$$\n\n. . .\n\nWe will use this function to find the **maximum likelihood estimate (MLE)**. The MLE is the value between 0 and 1 where we are most likely to see the observed data.\n\n## Visualizing the likelihood\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-likelihoods_files/figure-revealjs/unnamed-chunk-11-1.png){fig-align='center' width=90%}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np <- seq(0,1, length.out = 100) #sequence of 100 values between 0 and 100\nlik <- p^46 *(1 -p)^44\nx <- tibble(p = p, lik = lik)\nggplot(data = x, aes(x = p, y = lik)) + \n  geom_point() + \n  geom_line() +\n  labs(y = \"Likelihood\",\n       title = \"Likelihood of p_H\")\n```\n:::\n\n:::\n:::\n\n------------------------------------------------------------------------\n\n::: question\nWhat is your best guess for the MLE, $\\hat{p}_H$?\n\na.  0.489\nb.  0.500\nc.  0.511\nd.  0.556\n:::\n\n------------------------------------------------------------------------\n\n## Finding the maximum likelihood estimate\n\nThere are three primary ways to find the MLE\n\n✅ Approximate using a graph\n\n✅ Numerical approximation\n\n✅ Using calculus\n\n------------------------------------------------------------------------\n\n## Approximate MLE from a graph\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-likelihoods_files/figure-revealjs/unnamed-chunk-13-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## MLE using numerical approximation\n\nSpecify a finite set of possible values the for $p_H$ and calculate the likelihood for each value\n\n. . .\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# write an R function for the likelihood\nref_lik <- function(ph) {\n  ph^46 *(1 - ph)^44\n}\n\n# search possible values for p and return max\nnGrid = 1000\nph <- seq(0, 1, length = nGrid)\nlik <- ref_lik(ph)\nph[lik == max(lik)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5115115\n```\n:::\n:::\n\n\n## Find MLE using calculus\n\n-   Find the MLE by taking the first derivative of the likelihood function.\n\n-   This can be tricky because of the Product Rule, so we can maximize the **log(Likelihood)** instead. The same value maximizes the likelihood and log(Likelihood)\n\n. . .\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-likelihoods_files/figure-revealjs/unnamed-chunk-15-1.png){fig-align='center' width=90%}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-likelihoods_files/figure-revealjs/unnamed-chunk-16-1.png){fig-align='center' width=90%}\n:::\n:::\n\n:::\n:::\n\n## Find MLE using calculus\n\n$$Lik(p_H) = \\prod_{i=1}^{n}p_H^{y_i}(1 - p_H)^{3 - y_i}$$\n\n. . .\n\n$$\n\\begin{aligned}\\log(Lik(p_H)) &= \\sum_{i=1}^{n}y_i\\log(p_H) + (3 - y_i)\\log(1 - p_H)\\\\[10pt] &= 46\\log(p_H) + 44\\log(1 - p_H)\\end{aligned}\n$$\n\n## Find MLE using calculus\n\n$$\\frac{d}{d p_H} \\log(Lik(p_H)) = \\frac{46}{p_H} - \\frac{44}{1-p_H} = 0$$\n\n. . .\n\n$$\\Rightarrow \\frac{46}{p_H} = \\frac{44}{1-p_H}$$\n\n. . .\n\n$$\\Rightarrow 46(1-p_H) = 44p_H$$\n\n. . .\n\n$$\\Rightarrow 46 = 90p_H$$\n\n. . .\n\n$$\n\\hat{p}_H = \\frac{46}{90} = 0.511\n$$\n\n. . .\n\n<center>😐</center>\n\n# Model 2: Conditional model\n\nIs there a tendency for referees to call more fouls on the visiting team or home team?\n\nIs there a tendency for referees to call a foul on the team that already has more fouls?\n\n## Model 2: Conditional model {.midi}\n\nNow let's assume fouls are <u>not</u> independent within each game. We will specify this dependence using conditional probabilities.\n\n-   **Conditional probability**: $P(A|B) =$ Probability of $A$ given $B$ has occurred\n\n. . .\n\nDefine new parameters:\n\n::: incremental\n-   $p_{H|N}$: Probability referees call foul on home team given there are equal numbers of fouls on the home and visiting teams\n-   $p_{H|H Bias}$: Probability referees call foul on home team given there are more prior fouls on the home team\n-   $p_{H|V Bias}$: Probability referees call foul on home team given there are more prior fouls on the visiting team\n:::\n\n## Model 2: Likelihood contributions {.small}\n\n+--------+--------+--------+-----+---------------------------------------------------------------------------------------------------------------------------------------------+\n| Foul 1 | Foul 2 | Foul 3 | n   | Likelihood contribution                                                                                                                     |\n+========+========+========+=====+=============================================================================================================================================+\n| H      | H      | H      | 3   | | $(p_{H\\vert N})(p_{H\\vert H Bias})(p_{H\\vert H Bias}) = (p_{H\\vert N})(p_{H\\vert H Bias})^2$                                              |\n+--------+--------+--------+-----+---------------------------------------------------------------------------------------------------------------------------------------------+\n| H      | H      | V      | 2   | | $(p_{H\\vert N})(p_{H\\vert H Bias})(1-p_{H\\vert H Bias})$                                                                                  |\n+--------+--------+--------+-----+---------------------------------------------------------------------------------------------------------------------------------------------+\n| H      | V      | H      | 3   | $(p_{H\\vert N})(1 - p_{H \\vert HBias})(p_{H \\vert N}) = (p_{H \\vert N})^2(1 - p_{H \\vert HBias})$                                           |\n+--------+--------+--------+-----+---------------------------------------------------------------------------------------------------------------------------------------------+\n| H      | V      | V      | 7   | **A**                                                                                                                                       |\n+--------+--------+--------+-----+---------------------------------------------------------------------------------------------------------------------------------------------+\n| V      | H      | H      | 7   | **B**                                                                                                                                       |\n+--------+--------+--------+-----+---------------------------------------------------------------------------------------------------------------------------------------------+\n| V      | H      | V      | 1   | | $(1 - p_{H\\vert N})(p_{H\\vert V Bias})(1 - p_{H\\vert N}) = (1 - p_{H\\vert N})^2(p_{H\\vert V Bias})$                                       |\n+--------+--------+--------+-----+---------------------------------------------------------------------------------------------------------------------------------------------+\n| V      | V      | H      | 5   | | $(1 - p_{H\\vert N})(1-p_{H\\vert V Bias})(p_{H\\vert V Bias})$                                                                              |\n+--------+--------+--------+-----+---------------------------------------------------------------------------------------------------------------------------------------------+\n| V      | V      | V      | 2   | | $\\begin{aligned}&(1 - p_{H\\vert N})(1-p_{H\\vert V Bias})(1-p_{H\\vert V Bias})\\\\ &=(1 - p_{H\\vert N})(1-p_{H\\vert V Bias})^2\\end{aligned}$ |\n+--------+--------+--------+-----+---------------------------------------------------------------------------------------------------------------------------------------------+\n\n::: footer\n:::\n\n## Likelihood function {.midi}\n\n$$\\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\\\ &(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\\end{aligned}$$\n\n**(Note: The exponents sum to 90, the total number of fouls in the data)**\n\n<br>\n\n. . .\n\n$$\\begin{aligned}\\log (Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias})) &= 25 \\log(p_{H| N}) + 23 \\log(1 - p_{H|N}) \\\\ & + 8 \\log(p_{H| H Bias}) + 12 \\log(1 - p_{H| H Bias})\\\\ &+ 13 \\log(p_{H| V Bias}) + 9 \\log(1-p_{H|V Bias})\\end{aligned}$$\n\n------------------------------------------------------------------------\n\n::: question\nIf fouls within a game are independent, how would you expect $\\hat{p}_H$, $\\hat{p}_{H\\vert H Bias}$ and $\\hat{p}_{H\\vert V Bias}$ to compare?\n\na.  $\\hat{p}_H$ is greater than $\\hat{p}_{H\\vert H Bias}$ and $\\hat{p}_{H \\vert V Bias}$\n\nb.  $\\hat{p}_{H\\vert H Bias}$ is greater than $\\hat{p}_H$ and $\\hat{p}_{H \\vert V Bias}$\n\nc.  $\\hat{p}_{H\\vert V Bias}$ is greater than $\\hat{p}_H$ and $\\hat{p}_{H \\vert V Bias}$\n\nd.  They are all approximately equal.\n:::\n\n## MLEs for Model 2\n\n[Click here](03-model2-mle.html) for details on finding MLEs for Model2.\n\n## Next time\n\n-   Poisson regression\n\n## References\n",
    "supporting": [
      "03-likelihoods_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/countdown-0.4.0/countdown.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/countdown-0.4.0/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}