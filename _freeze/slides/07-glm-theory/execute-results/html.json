{
  "hash": "1e4fc56e4666b1fb68741f130a5943d6",
  "result": {
    "markdown": "---\ntitle: \"Unifying theory of GLMs\"\nauthor: \"Prof. Maria Tackett\"\ndate: \"February 5, 2024\"\ndate-format: \"MMM DD, YYYY\"\nfooter: \"[üîó STA 310 - Spring 2024](https://sta310-sp24.netlify.app)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    slide-number: true\n    multiplex: false\n    transition: fade\n    incremental: false \n    chalkboard: true\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\nexecute:\n  freeze: auto\n  echo: true\n  warning: false\n  message: false\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n## Announcements\n\n-   HW 02 due Wed, Feb 07 at 11:59pm\n\n-   Project 01 presentations in class Wed, Feb 14\n\n## Topics\n\n-   Identify the components common to all generalized linear models\n\n-   Find the canonical link based on the distribution of the response variable\n\n-   Explain how coefficients are estimated using iteratively reweighted least squares (IRLS) and Newton Raphson\n\n# Unifying theory of GLMs\n\n## Many models; one family\n\nWe have studied models for a variety of response variables\n\n-   Least squares (Normal)\n-   Logistic (Bernoulli, Binomial, Multinomial)\n-   Log-linear (Poisson, Negative Binomial)\n\nThese models are all examples of **generalized linear models**.\n\nGLMs have a similar structure for their likelihoods, MLEs, variances, so we can use a generalized approach to find the model estimates and associated uncertainty.\n\n## Components of a GLM\n\n@nelder1972generalized defines a broad class of models called **generalized linear models** that generalizes multiple linear regression. GLMs are characterized by three components:\n\n<br>\n\n. . .\n\n1Ô∏è‚É£ Response variable with parameter $\\theta$ whose probability function can be written in exponential family form (**random component**)\n\n<br>\n\n. . .\n\n2Ô∏è‚É£ A linear combination of predictors, $\\eta = \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p$ (**systematic component**)\n\n<br>\n\n. . .\n\n3Ô∏è‚É£ A **link** function $g(\\theta)$ that connects $\\theta$ to $\\eta$\n\n## Exponential family form\n\nSuppose a probability (mass or density) function has a parameter $\\theta$. It is said to have a **one-parameter exponential family form** if\n\n<br>\n\n‚úÖ The support (set of possible values) does not depend on $\\theta$, and\n\n‚úÖ The probability function can be written in the following form\n\n$$f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}$$\n\n## Mean and variance\n\n**Exponential family form**\n\n$$f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}$$\n\nUsing this form:\n\n. . .\n\n$$E(Y) = -\\frac{c'(\\theta)}{b'(\\theta)} \\hspace{20mm} Var(Y) = \\frac{b''(\\theta)c'(\\theta) - c''(\\theta)b'(\\theta)}{[b'(\\theta)]^3}$$\n\n## Poisson in exponential family form {.midi}\n\n$$P(Y = y) = \\frac{e^{-\\lambda}\\lambda^y}{y!} \\hspace{10mm} y = 0, 1, 2, \\ldots, \\infty$$\n\n. . .\n\n$$\\begin{aligned}P(Y = y) &= e^{-\\lambda}e^{y\\log(\\lambda)}e^{-\\log(y!)}\\\\\n& = e^{y\\log(\\lambda) - \\lambda - \\log(y!)}\\end{aligned}$$\n\n. . .\n\nRecall the form: $f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}$, where the parameter $\\theta = \\lambda$ for the Poisson distribution\n\n. . .\n\n-   $a(y) = y$\n-   $b(\\lambda) = \\log(\\lambda)$\n-   $c(\\lambda) = -\\lambda$\n-   $d(y) = -\\log(y!)$\n\n## Poisson in exponential family form\n\n‚úÖ The support for the Poisson distribution is $y = 0, 1, 2, \\ldots, \\infty$. This does not depend on the parameter $\\lambda$.\n\n. . .\n\n‚úÖ The probability mass function can be written in the form $f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}$\n\n<br>\n\n. . .\n\n**The Poisson distribution can be written in one-parameter exponential family form.**\n\n## Canonical link\n\nSuppose there is a response variable $Y$ from a distribution with parameter $\\theta$ and a set of predictors that can be written as a linear combination $\\eta = \\beta_0 + \\sum_{j=1}^{p}\\beta_jx_j = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p$\n\n<br>\n\n-   A **link function**, $g()$, is a monotonic and differentiable function that connects $\\theta$ to $\\eta$\n\n-   The **canonical link** is a link function such that\n\n    -   When working with a member of the one-parameter exponential family, the canonical link is $b(\\theta)$\n\n## Canonical link for Poisson\n\nRecall the exponential family form:\n\n$$P(Y = y) = e^{y\\log(\\lambda) - \\lambda - \\log(y!)}$$\n\n<br>\n\n. . .\n\nthen the canonical link is $b(\\lambda) = \\log(\\lambda)$\n\n## GLM framework: Poisson response variable {.midi}\n\n1Ô∏è‚É£ Response variable with parameter $\\theta$ whose probability function can be written in exponential family form\n\n$$P(Y = y) = e^{y\\log(\\lambda) - \\lambda - \\log(y!)}$$\n\n<br>\n\n2Ô∏è‚É£ A linear combination of predictors, $$\\eta = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p$$\n\n<br>\n\n3Ô∏è‚É£ A function $g(\\lambda)$ that connects $\\lambda$ and $\\eta$\n\n$$\\log(\\lambda) = \\eta =  \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p$$\n\n## Activity: Generalized linear models\n\nUPDATE INSTRUCTIONS!!\n\n::: question\nFor your group's distribution\n\n-   Describe an example of a setting where this random variable may be used.\n\n-   Identify the parameter.\n\n-   Write the pmf or pdf in one-parameter exponential form.\n\n-   Identify the canonical link function\n\n-   Find the mean and variance\n:::\n\n## Activity: Generalized linear models\n\n::: question\n**Distributions**\n\n1.  Exponential\n2.  Gamma (with fixed $r$)\n3.  Geometric\n4.  Normal (with fixed $\\sigma$)\n:::\n\n-   If your group finishes early, try identifying the canonical link for the other distributions.\n\n-   See [BMLR - Section 3.6](https://bookdown.org/roback/bookdown-BeyondMLR/ch-distthry.html#additional-resources) for details on the distributions.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_55b88274\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;margin:5%;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">10</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n# Iteratively reweighted least squares (IWLS)\n\n## Data: Noisy Miners\n\nThe dataset [`nminer`](data/nminer.csv) contains information about the number of noisy miners (small Australian bird) detected in two woodland patches within the Wimmera Plains of Victoria, Australia. It was obtained from the **GLMsdata** R package. We will use the following variables:\n\n-   **`Minerab`**: The number of noisy miners (abundance) observed in three 20 minute surveys\n-   **`Eucs`**: The number of eucalyptus trees in each 2 hectare area (about 4.94 acres)\n\n## Noisy Miner Model\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n| Eucs| Minerab|\n|----:|-------:|\n|    2|       0|\n|   10|       0|\n|   16|       3|\n|   20|       2|\n|   19|       8|\n:::\n:::\n\n\nOur goal is to use a Poisson regression model to predict the number of noisy miners observed in three 20 minute surveys based on the number of eucalyptus trees.\n\n$$\\log(\\lambda_{Minearab}) = \\beta_0 + \\beta_1 ~ Euc$$ .center\\[ **What are the best estimates of** $\\beta_0$ and $\\beta_1$?\\]\n\n## Iteratively reweighted least squares (IWLS)\n\n-   The estimates of $\\beta_0$ and $\\beta_1$ are found using maximum likelihood estimation.\n\n-   **Iteratively reweighted least-squares (IWLS)** is used to find the MLEs\n\n    -   Nelder and Wedderburn (1972) show that under certain specifications of the weights and a modified response variable, the estimates found using IWLS are equivalent to the MLEs.\n\n## IWLS Set up\n\n**Working response**: Modified response variable at each step of the iteration.\n\n$$z_i = g(\\theta) + g'(\\theta)(y_i - \\theta_i)$$\n\nFor Poisson regression, this is\n\n$$z_i = \\log(\\lambda) + \\frac{(y_i - \\lambda_i)}{\\lambda_i}$$\n\n. . .\n\n**Working Weights:** Weights applied to the observations at each step of the iteration\n\n$$W_i = \\frac{\\theta^2}{Var(Y)} \\hspace{5mm} \\Rightarrow \\hspace{5mm}  W_i = \\frac{\\lambda^2}{\\lambda} =  \\lambda \\text{ for Poisson regression}$$\n\n## IWLS procedure\n\n1.  Find initial starting values $\\hat{\\theta}_i$.\n\n2.  Calculate the working response values $z_i$.\n\n3.  Calculate the working weights $W_i$.\n\n4.  Find the coefficient estimates of the weighted least squares model.\n\n$$z_i = \\beta_0 + \\beta_1 x \\hspace{5mm} \\text{ with weights }W_i$$\n\nThe estimates $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$ are the estimates for the model coefficients.\n\n. . .\n\nUse $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$ to calculate updated values of $\\hat{\\theta}_i$ and repeat steps 2 - 4 until convergence.\n\n# Demo in `lecture-11` repo\n\n## Newton Raphson\n\n## Acknowledgements\n\nThese slides are based on content in\n\n-   [BMLR: Chapter 5 - Generalized Linear Models: A Unifying Theory](https://bookdown.org/roback/bookdown-BeyondMLR/ch-glms.html)\n-   Nelder, J. A., & Wedderburn, R. W. (1972). Generalized linear models. Journal of the Royal Statistical Society: Series A (General), 135(3), 370-384.\n-   Generalized Linear Models with Examples in R\n    -   Chapter 5 - Generalized Linear Models: Structure\n    -   Chapter 6 - Generalized Linear Models: Estimation\n\n# References\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/countdown-0.4.0/countdown.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/countdown-0.4.0/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}