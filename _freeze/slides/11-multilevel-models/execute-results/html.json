{
  "hash": "b5d0111d4634696d1dff8b04d78aa140",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Multilevel models\"\ndate: \"February 21, 2024\"\ndate-format: \"MMM DD, YYYY\"\nauthor: \"Prof. Maria Tackett\"\nfooter: \"[üîó STA 310 - Spring 2024](https://sta310-sp24.netlify.app)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    slide-number: true\n    multiplex: false\n    transition: fade\n    incremental: false \n    chalkboard: true\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\nexecute:\n  freeze: auto\n  echo: true\n  warning: false\n  message: false\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n## Announcements\n\n-   Quiz 02: **due Thu, Feb 22, 12pm (noon)**\n\n    -   Covers readings & lectures: Jan 24 - Feb 12\n\n    -   Poisson regression, unifying framework for GLMs, logistic regression, proportional odds models, probit regression\n\n-   HW 02 returned\n\n    -   Close issue in your GitHub after you've reviewed feedback\n\n-   HW 03 released tomorrow and due Wed, Feb 28\n\n-   Read Sadler and Miller (2010) as part of [Feb 26 prepare](../prepare/feb-26.html) assignment\n\n## Topics\n\n-   Understand how multilevel models can be used to take correlation into account\n\n-   Conduct univariate and bivariate EDA for multilevel models\n\n-   Write multilevel model, including assumptions about variance components\n\n    -   In by-level and composite forms\n\n-   Interpret the model parameters, fixed effects, and variance components\n\n::: aside\nNotes based on Chapter 8 of @roback2021beyond unless noted otherwise.\n:::\n\n# Correlated observations\n\n## Multilevel data\n\n-   We can think of correlated data as a multilevel structure\n\n    -   Population elements are aggregated into groups\n    -   There are observational units and measurements at each level\n\n-   For now we will focus on data with two levels:\n\n    -   **Level one**: Most basic level of observation\n    -   **Level two**: Groups formed from aggregated level-one observations\n\n## Two types of effects\n\n-   **Fixed effects**: Effects that are of interest in the study\n    -   Can think of these as effects whose interpretations would be included in a write up of the study\n\n. . .\n\n-   **Random effects**: Not interested in studying effects of specific values in the data but we want to understand the variability\n    -   Can think of these as effects whose interpretations would not necessarily be included in a write up of the study\n\n# Multilevel models\n\n## Data: Music performance anxiety {.midi}\n\nThe data [`musicdata.csv`](data/musicdata.csv) come from the study by @sadler2010performance of the emotional state of musicians before performances. The dataset contains information collected from 37 undergraduate music majors who completed the Positive Affect Negative Affect Schedule (PANAS), an instrument produces a measure of anxiety (negative affect) and a measure of happiness (positive affect). This analysis will focus on negative affect as a measure of performance anxiety.\n\n. . .\n\nThe primary variables we'll use are\n\n-   **`na`**: negative affect score on PANAS (the response variable)\n\n-   **`perform_type`**: type of performance (Solo, Large Ensemble, Small Ensemble)\n\n-   **`instrument`**: type of instrument (Voice, Orchestral, Piano)\n\n## Look at data {.midi}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n| id| diary|perform_type   | na|gender |instrument            |\n|--:|-----:|:--------------|--:|:------|:---------------------|\n|  1|     1|Solo           | 11|Female |voice                 |\n|  1|     2|Large Ensemble | 19|Female |voice                 |\n|  1|     3|Large Ensemble | 14|Female |voice                 |\n| 12|     1|Solo           | 23|Female |orchestral instrument |\n| 12|     2|Solo           | 17|Female |orchestral instrument |\n| 12|     3|Small Ensemble | 25|Female |orchestral instrument |\n\n\n:::\n:::\n\n\n::: question\n-   What are the Level One and Level Two observational units?\n-   What variables are measured at each level?\n:::\n\n## Univariate exploratory data analysis {.midi}\n\n**Level One variables**\n\nTwo ways to approach univariate EDA (visualizations and summary statistics) for Level One variables:\n\n-   Use individual observations (i.e., treat observations as independent)\n\n-   Use aggregated values for each Level Two observation\n\n. . .\n\n**Level Two variables**\n\n-   Use a data set that contains one row per Level Two observation\n\n## Bivariate exploratory data analysis {.midi}\n\n**Goals**\n\n-   Explore general association between the predictor and response variable\n-   Explore whether subjects at a given level of the predictor tend to have similar mean responses\n-   Explore whether variation in response differs at different levels of a predictor\n\nThere are two ways to visualize these associations:\n\n-   One plot of individual observations (i.e., treat observations as independent)\n\n-   Separate plots of responses vs. predictor for each Level Two observation (lattice plots)\n\n# Application exercise\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_0e9a710f\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;margin:1.25%;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">06</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n# Fitting the model\n\n## Questions we want to answer {.midi}\n\nWhat is the association between performance type (large ensemble or not) and performance anxiety? Does the association differ based on instrument type (orchestral or not)?\n\n<br>\n\n. . .\n\n**What is the problem with an ordinary least squares model to draw conclusions?**\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|term                     | estimate| std.error| statistic| p.value|\n|:------------------------|--------:|---------:|---------:|-------:|\n|(Intercept)              |   15.721|     0.359|    43.778|   0.000|\n|orchestra                |    1.789|     0.552|     3.243|   0.001|\n|large_ensemble           |   -0.277|     0.791|    -0.350|   0.727|\n|orchestra:large_ensemble |   -1.709|     1.062|    -1.609|   0.108|\n\n\n:::\n:::\n\n\n## Other modeling approaches {.midi}\n\n1Ô∏è‚É£ Condense each musician's set of responses into a single outcome (e.g., mean max, last observation, etc.) and fit a linear model on these condensed observations\n\n-   Leaves few observations (37) to fit the model\n-   Ignoring a lot of information in the multiple observations for each musician\n\n. . .\n\n2Ô∏è‚É£ Fit a separate model for each musician understand the association between performance type (Level One models). Then fit a system of Level Two models to predict the fitted coefficients in the Level One model for each subject based on instrument type (Level Two model).\n\n. . .\n\n**Let's look at approach #2**\n\n## Level One model\n\nWe'll start with the Level One model to understand the association between performance type and performance anxiety for the $i^{th}$ musician and the $j^{th}$ perfromance $$na_{ij} = a_i + b_i ~ LargeEnsemble_{ij} + \\epsilon_i, \\hspace{5mm} \\epsilon_{ij} \\sim N(0,\\sigma^2)$$\n\n<br>\n\n**Why is it more meaningful to use performance type for the Level One model than instrument?**\n\n. . .\n\nFor now, estimate $a_i$ and $b_i$ using least-squares regression.\n\n## Example Level One model\n\nBelow is data for `id` #22\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n| id| diary|perform_type   |instrument            | na|\n|--:|-----:|:--------------|:---------------------|--:|\n| 22|     1|Solo           |orchestral instrument | 24|\n| 22|     2|Large Ensemble |orchestral instrument | 21|\n| 22|     3|Large Ensemble |orchestral instrument | 14|\n| 22|     4|Large Ensemble |orchestral instrument | 15|\n| 22|     5|Large Ensemble |orchestral instrument | 10|\n| 22|     6|Solo           |orchestral instrument | 24|\n| 22|     7|Solo           |orchestral instrument | 24|\n| 22|     8|Solo           |orchestral instrument | 16|\n| 22|     9|Small Ensemble |orchestral instrument | 34|\n| 22|    10|Large Ensemble |orchestral instrument | 22|\n| 22|    11|Large Ensemble |orchestral instrument | 19|\n| 22|    12|Large Ensemble |orchestral instrument | 18|\n| 22|    13|Large Ensemble |orchestral instrument | 12|\n| 22|    14|Large Ensemble |orchestral instrument | 19|\n| 22|    15|Solo           |orchestral instrument | 25|\n\n\n:::\n:::\n\n\n## Level One model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmusic |>\n  filter(id == 22) |>\n  lm(na ~ large_ensemble, data = _) |>\n  tidy() |>\n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term           | estimate| std.error| statistic| p.value|\n|:--------------|--------:|---------:|---------:|-------:|\n|(Intercept)    |   24.500|      1.96|    12.503|   0.000|\n|large_ensemble |   -7.833|      2.53|    -3.097|   0.009|\n\n\n:::\n:::\n\n\n<br>\n\n. . .\n\n::: question\n**Repeat for all 37 musicians. See Part 3: Level One Models in AE.**\n:::\n\n## Level One models \n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Recreated from BMLR Figure 8.9](11-multilevel-models_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n. . .\n\n**Now let's consider if there is an association between the estimated slopes, estimated intercepts, and the type of instrument**\n\n## Level Two Model\n\nThe slope and intercept for the $i^{th}$ musician can be modeled as $$\\begin{aligned}&a_i = \\alpha_0 + \\alpha_1 ~ Orchestra_i + u_i \\\\\n&b_i = \\beta_0 + \\beta_1 ~ Orchestra_i + v_i\\end{aligned}$$\n\nNote the response variable in the Level Two models are not observed outcomes but the (fitted) slope and intercept from each musician\n\n**See Part 4: Level Two Models in AE.**\n\n## Estimated coefficients by instrument\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](11-multilevel-models_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n## Level Two model\n\n**Model for intercepts**\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value|\n|:-----------|--------:|---------:|---------:|-------:|\n|(Intercept) |   16.283|     0.671|    24.249|   0.000|\n|orchestra   |    1.411|     0.991|     1.424|   0.163|\n\n\n:::\n:::\n\n\n<br>\n\n**Model for slopes**\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value|\n|:-----------|--------:|---------:|---------:|-------:|\n|(Intercept) |   -0.771|     0.851|    -0.906|   0.373|\n|orchestra   |   -1.406|     1.203|    -1.168|   0.253|\n\n\n:::\n:::\n\n\n## Writing out the models\n\n**Level One**\n\n$$\\hat{na}_{ij}  = \\hat{a}_i + \\hat{b}_i ~ LargeEnsemble_{ij}$$\n\n<br>\n\n. . .\n\n**Level Two**\n\n$$\\begin{aligned}&\\hat{a}_i = 16.283 + 1.441 ~ Orchestra_i \\\\\n&\\hat{b}_i = -0.771 - 1.406 ~ Orchestra_i\\end{aligned}$$\n\n## Estimated composite model {.midi}\n\n$$\n\\begin{aligned}\\hat{na}_{ij} &= 16.283 + 1.441 ~ Orchestra_i - 0.771 ~ LargeEnsemble_{ij} \\\\\n&- 1.406 ~ Orchestra:LargeEnsemble_{ij}\\end{aligned}\n$$\n\n(Note that we also have the error terms $\\epsilon_{ij}, u_i, v_i$ that we will discuss later)\n\n<br>\n\n::: question\n1.  What is the predicted average performance anxiety before solos and small ensemble performances for vocalists and keyboardists? For those who place orchestral instruments?\n\n2.  What is the predicted average performance anxiety before large ensemble performances for those who play orchestral instruments?\n:::\n\n## Disadvantages to this approach\n\n‚ö†Ô∏è Weighs each musician the same regardless of number of diary entries\n\n‚ö†Ô∏è Drops subjects who have missing values for slope (7 individuals who didn't play a large ensemble performance)\n\n‚ö†Ô∏è Does not share strength effectively across individuals (look at $R^2$ values in Part 3: Level One Models of AE)\n\n<br>\n\n. . .\n\n**We will use a unified approach that utilizes likelihood-based methods to address some of these drawbacks.**\n\n# Unified approach to modeling multilevel data\n\n## Framework {.midi}\n\nLet $Y_{ij}$ be the performance anxiety for the $i^{th}$ musician before performance $j$.\n\n**Level One**\n\n$$Y_{ij} = a_i + b_i ~ LargeEnsemble + \\epsilon_{ij}$$\n\n. . .\n\n**Level Two**\n\n$$\\begin{aligned}&a_i = \\alpha_0 + \\alpha_1 ~ Orchestra_i+ u_i\\\\\n&b_i = \\beta_0 + \\beta_1~Orchestra_i + v_i\\end{aligned}$$\n\n<br>\n\n. . .\n\nThis approach uses likelihood-based methods (instead of least squares) to address the previously mentioned disadvantages\n\n## Composite model  {.midi}\n\nPlug in the equations for $a_i$ and $b_i$ to get the **composite model** $$\\begin{aligned}Y_{ij} &= (\\alpha_0 + \\alpha_1 ~ Orchestra_i + \\beta_0 ~ LargeEnsemble_{ij} \\\\ \n&+ \\beta_1 ~ Orchestra_i:LargeEnsemble_{ij})\\\\\n&+ (u_i + v_i ~ LargeEnsemble_{ij} + \\epsilon_{ij})\\end{aligned}$$\n\n. . .\n\n-   The **fixed effects** to estimate are $\\alpha_0, \\alpha_1, \\beta_0, \\beta_1$\n-   The **error terms** are $u_i, v_i, \\epsilon_{ij}$\n    -   $u_i$ and $v_i$ are associated with student random effect\n    -   $\\epsilon_{ij}$ is what's left unexplained\n\n::: {.callout-note appearance=\"minimal\"}\nNote that we no longer need to estimate $a_i$ and $b_i$ directly as we did earlier. They conceptually connect the Level One and Level Two models.\n:::\n\n## Notation\n\n::: incremental\n-   Greek letters denote the fixed effect model parameters to be estimated\n\n    -   e.g., $\\alpha_0, \\alpha_1, \\beta_0, \\beta_1$\n\n-   Roman letters denote the preliminary fixed effects at lower levels (not directly estimated)\n\n    -   e.g. $a_i, b_i$\n\n-   $\\sigma$ and $\\rho$ denote variance components that will be estimated\n\n-   $\\epsilon_{ij}, u_i, v_i$ denote error terms (not directly estimated)\n:::\n\n## Error terms {.midi}\n\n::: incremental\n-   We generally assume that the error terms are normally distributed, e.g. error associated with each performance of a given musician is $\\epsilon_{ij} \\sim N(0, \\sigma^2)$\n-   For the Level Two models, the errors are\n    -   $u_i$: deviation of musician $i$ from the mean performance anxiety before solos and small ensembles after accounting for the instrument\n    -   $v_i$: deviance of musician $i$ from the mean difference in performance anxiety between large ensembles and other performance types after accounting for instrument\n-   Need to account for fact that $u_i$ and $v_i$ are correlated for the $i^{th}$ musician\n:::\n\n------------------------------------------------------------------------\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Recreated from Figure 8.11](11-multilevel-models_files/figure-revealjs/unnamed-chunk-12-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n::: question\n::: midi\nDescribe what we learn about the association between the slopes and intercepts based on this plot.\n:::\n:::\n\n## Distribution of Level Two errors\n\nUse a **multivariate normal** distribution for the Level Two error terms $$\\left[ \\begin{array}{c}\n            u_{i} \\\\ v_{i}\n          \\end{array}  \\right] \\sim N \\left( \\left[\n          \\begin{array}{c}\n            0 \\\\ 0\n          \\end{array} \\right], \\left[\n          \\begin{array}{cc}\n            \\sigma_{u}^{2} & \\rho_{uv}\\sigma_{u}\\sigma_v \\\\\n            \\rho_{uv}\\sigma_{u}\\sigma_v & \\sigma_{v}^{2}\n          \\end{array} \\right] \\right)$$\n\nwhere $\\sigma^2_u$ and $\\sigma^2_v$ are the variance of $u_i$'s and $v_i$'s respectively, and $\\sigma_{uv} = \\rho_{uv}\\sigma_u\\sigma_v$ is covariance between $u_i$ and $v_i$\n\n. . .\n\n-   What does it mean for $\\rho_{uv} > 0$?\n-   What does it mean for $\\rho_{uv} < 0$?\n\n## Visualizing multivariate normal distribution\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Recreated from Figure 8.12](11-multilevel-models_files/figure-revealjs/contour-boundary-1.png){fig-align='center' width=60%}\n:::\n:::\n\n\n## Fit the model\n\nFit multilevel model using the `lmer` function from the **lme4** package. Display results using the `tidy()` function from the **broom.mixed** package.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(broom.mixed)\n\nmusic_model <- lmer(na ~ orchestra + large_ensemble + \n                      orchestra:large_ensemble +\n                      (large_ensemble|id), \n                    REML = TRUE, data = music)\n\ntidy(music_model) |> kable(digits = 3)\n```\n:::\n\n\n## Fitted model\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|effect   |group    |term                            | estimate| std.error| statistic|\n|:--------|:--------|:-------------------------------|--------:|---------:|---------:|\n|fixed    |NA       |(Intercept)                     |   15.930|     0.641|    24.833|\n|fixed    |NA       |orchestra                       |    1.693|     0.945|     1.791|\n|fixed    |NA       |large_ensemble                  |   -0.911|     0.845|    -1.077|\n|fixed    |NA       |orchestra:large_ensemble        |   -1.424|     1.099|    -1.295|\n|ran_pars |id       |sd__(Intercept)                 |    2.378|        NA|        NA|\n|ran_pars |id       |cor__(Intercept).large_ensemble |   -0.635|        NA|        NA|\n|ran_pars |id       |sd__large_ensemble              |    0.672|        NA|        NA|\n|ran_pars |Residual |sd__Observation                 |    4.670|        NA|        NA|\n\n\n:::\n:::\n\n\n## Fitted model {.midi}\n\n$$\n\\begin{aligned}\n\\hat{na}_{ij} &= 15.930 + 1.693 ~ Orchestra_i - 0.911 ~ LargeEnsemble_{ij} \\\\\n&- 1.424 ~ Orchestra_i:LargeEnsemble_{ij} \\\\[30pt]&\\left[ \\begin{array}{c}\n            u_{i} \\\\ v_{i}\n          \\end{array}  \\right] \\sim N \\left( \\left[\n          \\begin{array}{c}\n            0 \\\\ 0\n          \\end{array} \\right], \\left[\n          \\begin{array}{cc}\n            2.378^{2} & -0.635 *2.378 *0.672 \\\\\n            -0.635 *2.378 *0.672 & 0.672^{2}\n          \\end{array} \\right] \\right) \\\\[30pt]\n&\\epsilon_{ij} \\sim N(0, 4.670^2)\n\\end{aligned}\n$$\n\n## References\n",
    "supporting": [
      "11-multilevel-models_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/countdown-0.4.0/countdown.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/countdown-0.4.0/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}