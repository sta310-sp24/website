{
  "hash": "5faa9f6dd52542d7223cb9d5bc067abd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Multilevel models\"\nsubtitle: \"Fitting and interpretation\"\ndate: \"February 26, 2024\"\ndate-format: \"MMM DD, YYYY\"\nauthor: \"Prof. Maria Tackett\"\nfooter: \"[üîó STA 310 - Spring 2024](https://sta310-sp24.netlify.app)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    slide-number: true\n    multiplex: false\n    transition: fade\n    incremental: false \n    chalkboard: true\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\nexecute:\n  freeze: auto\n  echo: true\n  warning: false\n  message: false\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n## Announcements\n\n-   HW 03 released tomorrow due Wed, Feb 28 at 11:59pm\n\n    -   See Slack for tips from Hun\n\n-   Read Sadler and Miller (2010) as part of [Feb 26 prepare](../prepare/feb-26.html) assignment\n\n## Topics\n\n-   Write multilevel model, including assumptions about variance components\n\n    -   In by-level and composite forms\n\n-   Fit and interpret multilevel models\n\n::: aside\nNotes based on Chapter 8 of @roback2021beyond unless noted otherwise.\n:::\n\n## Data: Music performance anxiety {.midi}\n\nToday's data come from the study by @sadler2010performance of the emotional state of musicians before performances. The data set contains information collected from 37 undergraduate music majors who completed the Positive Affect Negative Affect Schedule (PANAS), an instrument produces a measure of anxiety (negative affect) and a measure of happiness (positive affect). This analysis will focus on negative affect as a measure of performance anxiety.\n\n. . .\n\nThe primary variables we'll use are\n\n-   **`id`**: unique musician identification number\n-   **`na`**: negative affect score on PANAS (the response variable)\n-   **`perform_type`**: type of performance (Solo, Large Ensemble, Small Ensemble)\n-   **`instrument`**: type of instrument (Voice, Orchestral, Piano)\n\n## Look at data {.midi}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n| id| diary|large_ensemble | mpqnem|orchestra |\n|--:|-----:|:--------------|------:|:---------|\n|  1|     1|0              |     16|0         |\n|  1|     2|1              |     16|0         |\n|  1|     3|1              |     16|0         |\n| 43|     1|0              |     17|0         |\n| 43|     2|0              |     17|0         |\n| 43|     3|0              |     17|0         |\n\n\n:::\n:::\n\n\n::: question\n-   What are the Level One and Level Two observational units?\n-   What variables are measured at each level?\n:::\n\n# Fitting the model\n\n## Questions we want to answer {.midi}\n\nWhat is the association between performance type (large ensemble or not) and performance anxiety? Does the association differ based on instrument type (orchestral or not)?\n\n## Initial modeling approach {.midi}\n\n**Step 1**. Fit a separate model for each musician understand the association between performance type (Level One models) and anxiety.\n\n<br>\n\n**Step 2** . fit a system of Level Two models to predict the fitted coefficients in the Level One model for each subject based on instrument type (Level Two model).\n\n## Level One model\n\nWe'll start with the Level One model to understand the association between performance type and performance anxiety for the $i^{th}$ musician and the $j^{th}$ performance $$na_{ij} = a_i + b_i ~ LargeEnsemble_{ij} + \\epsilon_{ij}, \\hspace{5mm} \\epsilon_{ij} \\sim N(0,\\sigma^2)$$\n\n<br>\n\nFor now, estimate $a_i$ and $b_i$ using least-squares regression.\n\n## Example Level One model\n\nBelow is data for `id` #22\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 15 √ó 5\n      id diary perform_type   instrument               na\n   <dbl> <dbl> <chr>          <chr>                 <dbl>\n 1    22     1 Solo           orchestral instrument    24\n 2    22     2 Large Ensemble orchestral instrument    21\n 3    22     3 Large Ensemble orchestral instrument    14\n 4    22     4 Large Ensemble orchestral instrument    15\n 5    22     5 Large Ensemble orchestral instrument    10\n 6    22     6 Solo           orchestral instrument    24\n 7    22     7 Solo           orchestral instrument    24\n 8    22     8 Solo           orchestral instrument    16\n 9    22     9 Small Ensemble orchestral instrument    34\n10    22    10 Large Ensemble orchestral instrument    22\n11    22    11 Large Ensemble orchestral instrument    19\n12    22    12 Large Ensemble orchestral instrument    18\n13    22    13 Large Ensemble orchestral instrument    12\n14    22    14 Large Ensemble orchestral instrument    19\n15    22    15 Solo           orchestral instrument    25\n```\n\n\n:::\n:::\n\n\n## Level One model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmusic |>\n  filter(id == 22) |>\n  lm(na ~ large_ensemble, data = _) |>\n  tidy() |>\n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term            | estimate| std.error| statistic| p.value|\n|:---------------|--------:|---------:|---------:|-------:|\n|(Intercept)     |   24.500|      1.96|    12.503|   0.000|\n|large_ensemble1 |   -7.833|      2.53|    -3.097|   0.009|\n\n\n:::\n:::\n\n\n<br>\n\n::: question\n**Repeat for all 37 musicians.**\n:::\n\n## Level One models\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Recreated from BMLR Figure 8.9](12-multilevel-models-pt2_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n. . .\n\n**Now let's consider if there is an association between the estimated slopes, estimated intercepts, and the type of instrument**\n\n## Level Two Model\n\nThe slope and intercept for the $i^{th}$ musician can be modeled as $$\\begin{aligned}&a_i = \\alpha_0 + \\alpha_1 ~ Orchestra_i + u_i \\\\\n&b_i = \\beta_0 + \\beta_1 ~ Orchestra_i + v_i\\end{aligned}$$\n\nNote the response variable in the Level Two models are not observed outcomes but the (fitted) slope and intercept from each musician\n\n## Estimated coefficients by instrument\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](12-multilevel-models-pt2_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n## Level Two model\n\n**Model for intercepts**\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value|\n|:-----------|--------:|---------:|---------:|-------:|\n|(Intercept) |   16.283|     0.671|    24.249|   0.000|\n|orchestra1  |    1.411|     0.991|     1.424|   0.163|\n\n\n:::\n:::\n\n\n<br>\n\n**Model for slopes**\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value|\n|:-----------|--------:|---------:|---------:|-------:|\n|(Intercept) |   -0.771|     0.851|    -0.906|   0.373|\n|orchestra1  |   -1.406|     1.203|    -1.168|   0.253|\n\n\n:::\n:::\n\n\n## Estimated two-level model\n\n**Level One**\n\n$$\\hat{na}_{ij}  = \\hat{a}_i + \\hat{b}_i ~ LargeEnsemble_{ij}$$\n\n<br>\n\n. . .\n\n**Level Two**\n\n$$\\begin{aligned}&\\hat{a}_i = 16.283 + 1.411 ~ Orchestra_i \\\\\n&\\hat{b}_i = -0.771 - 1.406 ~ Orchestra_i\\end{aligned}$$\n\n## Estimated composite model {.midi}\n\n$$\n\\begin{aligned}\\hat{na}_{ij} &= 16.283 + 1.411 ~ Orchestra_i - 0.771 ~ LargeEnsemble_{ij} \\\\\n&- 1.406 ~ Orchestra_i:LargeEnsemble_{ij}\\end{aligned}\n$$\n\n(Note that we also have the error terms $\\epsilon_{ij}, u_i, v_i$ that we will discuss later)\n\n## Disadvantages to this approach\n\n‚ö†Ô∏è Weighs each musician the same regardless of number of diary entries\n\n‚ö†Ô∏è Drops subjects who have missing values for slope (7 individuals who didn't play a large ensemble performance)\n\n‚ö†Ô∏è Does not share strength effectively across individuals\n\n<br>\n\n**We will use a unified approach that utilizes likelihood-based methods to address some of these drawbacks.**\n\n# Unified approach to modeling multilevel data\n\n## Framework {.midi}\n\nLet $Y_{ij}$ be the performance anxiety for the $i^{th}$ musician before performance $j$.\n\n**Level One**\n\n$$Y_{ij} = a_i + b_i ~ LargeEnsemble_{ij} + \\epsilon_{ij}$$\n\n<br>\n\n. . .\n\n**Level Two**\n\n$$\\begin{aligned}&a_i = \\alpha_0 + \\alpha_1 ~ Orchestra_i+ u_i\\\\\n&b_i = \\beta_0 + \\beta_1~Orchestra_i + v_i\\end{aligned}$$\n\n::: callout-note\nWe will discuss the distribution of the error terms $\\epsilon_{ij}, u_i, v_i$ shortly.\n:::\n\n## Composite model {.midi}\n\nPlug in the equations for $a_i$ and $b_i$ to get the **composite model** $$\\begin{aligned}Y_{ij} &= (\\alpha_0 + \\alpha_1 ~ Orchestra_i + \\beta_0 ~ LargeEnsemble_{ij} \\\\ \n&+ \\beta_1 ~ Orchestra_i:LargeEnsemble_{ij})\\\\\n&+ (u_i + v_i ~ LargeEnsemble_{ij} + \\epsilon_{ij})\\end{aligned}$$\n\n. . .\n\n-   The **fixed effects** to estimate are $\\alpha_0, \\alpha_1, \\beta_0, \\beta_1$\n-   The **error terms** are $u_i, v_i, \\epsilon_{ij}$\n    -   $u_i$ and $v_i$ are associated with musician random effect\n    -   $\\epsilon_{ij}$ is what's left unexplained\n\n::: {.callout-note appearance=\"minimal\"}\nNote that we no longer need to estimate $a_i$ and $b_i$ directly as we did earlier. They conceptually connect the Level One and Level Two models.\n:::\n\n## Notation\n\n::: incremental\n-   Greek letters denote the fixed effect model parameters to be estimated\n\n    -   e.g., $\\alpha_0, \\alpha_1, \\beta_0, \\beta_1$\n\n-   Roman letters denote the preliminary fixed effects at lower levels (not directly estimated)\n\n    -   e.g. $a_i, b_i$\n\n-   $\\sigma$ and $\\rho$ denote variance components that will be estimated\n\n-   $\\epsilon_{ij}, u_i, v_i$ denote error terms (not directly estimated)\n:::\n\n## Error terms {.midi}\n\n::: incremental\n-   We generally assume that the error terms are normally distributed, e.g. error associated with each performance of a given musician is $\\epsilon_{ij} \\sim N(0, \\sigma^2)$\n-   For the Level Two models, the errors are\n    -   $u_i$: deviation of musician $i$ from the mean performance anxiety before solos and small ensembles after accounting for the instrument\n        -   musician-to-musician differences in the intercepts\n    -   $v_i$: deviance of musician $i$ from the mean difference in performance anxiety between large ensembles and other performance types after accounting for instrument\n        -   musician-to-musician differences in the slopes\n-   Need to account for fact that $u_i$ and $v_i$ are correlated for the $i^{th}$ musician\n:::\n\n------------------------------------------------------------------------\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Recreated from Figure 8.11](12-multilevel-models-pt2_files/figure-revealjs/unnamed-chunk-10-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n::: question\n::: midi\nDescribe what we learn about the association between the slopes and intercepts based on this plot.\n:::\n:::\n\n## Distribution of Level Two errors\n\nUse a **multivariate normal** distribution for the Level Two error terms $$\\left[ \\begin{array}{c}\n            u_{i} \\\\ v_{i}\n          \\end{array}  \\right] \\sim N \\left( \\left[\n          \\begin{array}{c}\n            0 \\\\ 0\n          \\end{array} \\right], \\left[\n          \\begin{array}{cc}\n            \\sigma_{u}^{2} & \\rho_{uv}\\sigma_{u}\\sigma_v \\\\\n            \\rho_{uv}\\sigma_{u}\\sigma_v & \\sigma_{v}^{2}\n          \\end{array} \\right] \\right)$$\n\nwhere $\\sigma^2_u$ and $\\sigma^2_v$ are the variance of $u_i$'s and $v_i$'s respectively, and $\\sigma_{uv} = \\rho_{uv}\\sigma_u\\sigma_v$ is covariance between $u_i$ and $v_i$\n\n. . .\n\n-   What does it mean for $\\rho_{uv} > 0$?\n-   What does it mean for $\\rho_{uv} < 0$?\n\n## Visualizing multivariate normal distribution\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Recreated from Figure 8.12](12-multilevel-models-pt2_files/figure-revealjs/contour-boundary-1.png){fig-align='center' width=60%}\n:::\n:::\n\n\n## Fit the model in R {.midi}\n\nFit multilevel model using the `lmer` (\"linear mixed effects in R\") function from the **lme4** package.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(lme4)\nmusic_model <- lmer(na ~ orchestra + large_ensemble +\n       orchestra:large_ensemble + (large_ensemble|id),\n       REML = TRUE, data = music)\n```\n:::\n\n\n. . .\n\n-   `na ~ orchestra + large_ensemble + orchestra:large_ensemble`: Represents the fixed effects\n\n-   `(large_ensemble|id)`: Represents the error terms and associated variance components\n\n    -   Specifies two error terms: $u_i$ corresponding to the intercepts, $v_i$ corresponding to effect of large ensemble\n\n## Tidy output\n\nDisplay results using the `tidy` function from the **broom.mixed** package.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(broom.mixed)\ntidy(music_model) \n```\n:::\n\n\n. . .\n\nGet fixed effects only\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(music_model) |> filter(effect == \"fixed\")\n```\n:::\n\n\n. . .\n\nGet errors and variance components only\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(music_model) |> filter(effect == \"ran_pars\")\n```\n:::\n\n\n## Estimated fixed effects \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(music_model) |> \n  filter(effect == \"fixed\") |> \n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|effect |group |term                       | estimate| std.error| statistic|\n|:------|:-----|:--------------------------|--------:|---------:|---------:|\n|fixed  |NA    |(Intercept)                |   15.930|     0.641|    24.833|\n|fixed  |NA    |orchestra1                 |    1.693|     0.945|     1.791|\n|fixed  |NA    |large_ensemble1            |   -0.911|     0.845|    -1.077|\n|fixed  |NA    |orchestra1:large_ensemble1 |   -1.424|     1.099|    -1.295|\n\n\n:::\n:::\n\n\n## Estimated random effects\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(music_model) |> \n  filter(effect == \"ran_pars\") |> \n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|effect   |group    |term                             | estimate| std.error| statistic|\n|:--------|:--------|:--------------------------------|--------:|---------:|---------:|\n|ran_pars |id       |sd__(Intercept)                  |    2.378|        NA|        NA|\n|ran_pars |id       |cor__(Intercept).large_ensemble1 |   -0.635|        NA|        NA|\n|ran_pars |id       |sd__large_ensemble1              |    0.672|        NA|        NA|\n|ran_pars |Residual |sd__Observation                  |    4.670|        NA|        NA|\n\n\n:::\n:::\n\n\n## Fitted model {.midi}\n\n$$\n\\begin{aligned}\n\\hat{na}_{ij} &= 15.930 + 1.693 ~ Orchestra_i - 0.911 ~ LargeEnsemble_{ij} \\\\\n&- 1.424 ~ Orchestra_i:LargeEnsemble_{ij} \\\\[30pt]&\\left[ \\begin{array}{c}\n            u_{i} \\\\ v_{i}\n          \\end{array}  \\right] \\sim N \\left( \\left[\n          \\begin{array}{c}\n            0 \\\\ 0\n          \\end{array} \\right], \\left[\n          \\begin{array}{cc}\n            2.378^{2} & -0.635 *2.378 *0.672 \\\\\n            -0.635 *2.378 *0.672 & 0.672^{2}\n          \\end{array} \\right] \\right) \\\\[30pt]\n&\\epsilon_{ij} \\sim N(0, 4.670^2)\n\\end{aligned}\n$$\n\n## Interpret the effects \n\n-   Split into 4 groups.\n\n-   Each group will write the interpretation for one main effect and one variance component. The terms on each slide do not necessarily have a direct correspondence to each other.\n\n-   One person write the group's interpretations on the slide.\n\n-   [Click here](https://docs.google.com/presentation/d/1wwL1C0pqp3FAnf9knaysx4DbgW7GJEmXxW5mhAebFR4/edit?usp=sharing) for the slides.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_222f5c49\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;margin:1.25%;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">06</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n## References\n",
    "supporting": [
      "12-multilevel-models-pt2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/countdown-0.4.0/countdown.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/countdown-0.4.0/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}