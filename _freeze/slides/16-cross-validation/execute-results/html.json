{
  "hash": "ba5f5c7b77908da9678d5de86f53233d",
  "result": {
    "markdown": "---\ntitle: \"Cross validation\"\nauthor: \"Prof. Maria Tackett\"\ndate: \"2022-10-24\"\ndate-format: \"MMM DD, YYYY\"\nfooter: \"[ğŸ”— Week 09](https://sta210-fa22.netlify.app/weeks/week-09.html)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: true\n    incremental: false \n    chalkboard: true\nexecute:\n  freeze: auto\n  echo: true\n  warning: false\n  message: false\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\n---\n\n\n\n\n## Announcements\n\n-   [Lab 05](https://sta210-fa22.netlify.app/labs/lab-05.html)\n\n    -   due TODAY, 11:59pm (Thu labs)\n\n    -   due Tuesday, 11:59pm (Fri labs)\n\n-   Office hours update:\n\n    -   Monday, 1 - 2pm: in-person only (Old Chem 118B)\n\n-   [Click here](ANOVA-table.html) for explanation about sum of squares in R ANOVA output.\n\n-   See [Week 09](https://sta210-fa22.netlify.app/weeks/week-09.html) activities.\n\n## Spring 2023 Statistics classes {.midi}\n\n-   STA 211: Mathematics of Regression\n\n    -   Pre-req: STA 210 + Math 216/218/221\n\n-   STA 240: Probability for Statistical Inference, Modeling, and Data Analysis\n\n    -   Pre-req: Calc 2\n\n-   STA 313: Advanced Data Visualization\n\n    -   Pre-req: STA 199 or STA 210\n\n-   STA 323: Statistical Computing\n\n    -   Pre-req: STA 210 and STA 230 / 240\n\n-   STA 360: Bayesian Inference and Modern Statistical Methods\n\n    -   Pre-req: STA 210, STA 230/240, CS 101, Calc 2, Math 216/218/221,\n    -   Co-req: STA 211\n\n## Topics\n\n::: nonincremental\n-   Cross validation for model evaluation\n-   Cross validation for model comparison\n:::\n\n## Computational setup\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(schrute)\n```\n:::\n\n\n## Data & goal {.smaller}\n\n::: nonincremental\n-   Data: The data come from the [**shrute**](https://bradlindblad.github.io/schrute/) package, and has been transformed using instructions from [Lab 04](../labs/lab-04.html)\n-   Goal: Predict `imdb_rating` from other variables in the dataset\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\noffice_episodes <- read_csv(here::here(\"slides/data/office_episodes.csv\"))\noffice_episodes\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 186 Ã— 14\n   season episode episode_nâ€¦Â¹ imdb_â€¦Â² totalâ€¦Â³ air_date   linesâ€¦â´ linesâ€¦âµ linesâ€¦â¶\n    <dbl>   <dbl> <chr>         <dbl>   <dbl> <date>       <dbl>   <dbl>   <dbl>\n 1      1       1 Pilot           7.6    3706 2005-03-24  0.157   0.179    0.354\n 2      1       2 Diversity â€¦     8.3    3566 2005-03-29  0.123   0.0591   0.369\n 3      1       3 Health Care     7.9    2983 2005-04-05  0.172   0.131    0.230\n 4      1       4 The Allianâ€¦     8.1    2886 2005-04-12  0.202   0.0905   0.280\n 5      1       5 Basketball      8.4    3179 2005-04-19  0.0913  0.0609   0.452\n 6      1       6 Hot Girl        7.8    2852 2005-04-26  0.159   0.130    0.306\n 7      2       1 The Dundies     8.7    3213 2005-09-20  0.125   0.160    0.375\n 8      2       2 Sexual Harâ€¦     8.2    2736 2005-09-27  0.0565  0.0954   0.353\n 9      2       3 Office Olyâ€¦     8.4    2742 2005-10-04  0.196   0.117    0.295\n10      2       4 The Fire        8.4    2713 2005-10-11  0.160   0.0690   0.216\n# â€¦ with 176 more rows, 5 more variables: lines_dwight <dbl>, halloween <chr>,\n#   valentine <chr>, christmas <chr>, michael <chr>, and abbreviated variable\n#   names Â¹â€‹episode_name, Â²â€‹imdb_rating, Â³â€‹total_votes, â´â€‹lines_jim, âµâ€‹lines_pam,\n#   â¶â€‹lines_michael\n```\n:::\n:::\n\n\n# Modeling prep\n\n## Split data into training and testing\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)\noffice_split <- initial_split(office_episodes)\noffice_train <- training(office_split)\noffice_test <- testing(office_split)\n```\n:::\n\n\n## Specify model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\noffice_spec <- linear_reg() |>\n  set_engine(\"lm\")\n\noffice_spec\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n```\n:::\n:::\n\n\n# Model 1\n\n## From Lab 04\n\nCreate a recipe that uses the newly generated variables\n\n-   Denotes `episode_name` as an ID variable and doesn't use `air_date` or `season` as predictors\n-   Create dummy variables for all nominal predictors\n-   Remove all zero variance predictors\n\n## Create recipe\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\noffice_rec1 <- recipe(imdb_rating ~ ., data = office_train) |>\n  update_role(episode_name, new_role = \"id\") |>\n  step_rm(air_date, season) |>\n  step_dummy(all_nominal_predictors()) |>\n  step_zv(all_predictors())\n\noffice_rec1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n        id          1\n   outcome          1\n predictor         12\n\nOperations:\n\nVariables removed air_date, season\nDummy variables from all_nominal_predictors()\nZero variance filter on all_predictors()\n```\n:::\n:::\n\n\n## Preview recipe\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprep(office_rec1) |>\n  bake(office_train) |>\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 139\nColumns: 12\n$ episode       <dbl> 20, 16, 8, 7, 23, 3, 16, 21, 18, 14, 27, 28, 12, 1, 23, â€¦\n$ episode_name  <fct> \"Welcome Party\", \"Moving On\", \"Performance Review\", \"Theâ€¦\n$ total_votes   <dbl> 1489, 1572, 2416, 1406, 2783, 1802, 2283, 2041, 1445, 14â€¦\n$ lines_jim     <dbl> 0.12703583, 0.05588822, 0.09523810, 0.07482993, 0.078291â€¦\n$ lines_pam     <dbl> 0.10423453, 0.10978044, 0.10989011, 0.15306122, 0.081850â€¦\n$ lines_michael <dbl> 0.0000000, 0.0000000, 0.3772894, 0.0000000, 0.3736655, 0â€¦\n$ lines_dwight  <dbl> 0.07166124, 0.08782435, 0.15384615, 0.18027211, 0.135231â€¦\n$ imdb_rating   <dbl> 7.2, 8.2, 8.2, 7.7, 9.1, 8.2, 8.3, 8.9, 8.0, 7.8, 8.7, 8â€¦\n$ halloween_yes <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦\n$ valentine_yes <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦\n$ christmas_yes <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,â€¦\n$ michael_yes   <dbl> 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,â€¦\n```\n:::\n:::\n\n\n## Create workflow\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\noffice_wflow1 <- workflow() |>\n  add_model(office_spec) |>\n  add_recipe(office_rec1)\n\noffice_wflow1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: linear_reg()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n3 Recipe Steps\n\nâ€¢ step_rm()\nâ€¢ step_dummy()\nâ€¢ step_zv()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n```\n:::\n:::\n\n\n## Fit model to training data\n\n. . .\n\n*Not so fast!*\n\n# Cross validation\n\n## Spending our data\n\n-   We have already established that the idea of data spending where the test set was recommended for obtaining an unbiased estimate of performance.\n-   However, we usually need to understand the effectiveness of the model [*before*]{.underline} *using the test set*.\n-   Typically we can't decide on *which* final model to take to the test set without making model assessments.\n-   **Remedy:** Resampling to make model assessments on training data in a way that can generalize to new data.\n\n## Resampling for model assessment\n\n**Resampling is only conducted on the** <u>**training**</u> **set**. The test set is not involved. For each iteration of resampling, the data are partitioned into two subsamples:\n\n-   The model is fit with the **analysis set**. Model fit statistics such as $R^2_{Adj}$, AIC, and BIC are calculated based on this fit.\n-   The model is evaluated with the **assessment set**.\n\n## Resampling for model assessment\n\n![](images/16/resampling.svg){fig-align=\"center\"}\n\n<br>\n\nSource: Kuhn and Silge. [Tidy modeling with R](https://www.tmwr.org/).\n\n## Analysis and assessment sets\n\n-   Analysis set is analogous to training set.\n-   Assessment set is analogous to test set.\n-   The terms *analysis* and *assessment* avoids confusion with initial split of the data.\n-   These data sets are mutually exclusive.\n\n## Cross validation\n\nMore specifically, **v-fold cross validation** -- commonly used resampling technique:\n\n-   Randomly split your **training** **data** into *v* partitions\n-   Use *v-1* partitions for analysis, and the remaining 1 partition for analysis (model fit + model fit statistics)\n-   Repeat *v* times, updating which partition is used for assessment each time\n\n. . .\n\nLet's give an example where `v = 3`...\n\n## Cross validation, step 1\n\nRandomly split your **training** **data** into 3 partitions:\n\n<br>\n\n![](images/16/three-CV.svg){fig-align=\"center\"}\n\n## Split data\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(345)\nfolds <- vfold_cv(office_train, v = 3)\nfolds\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#  3-fold cross-validation \n# A tibble: 3 Ã— 2\n  splits          id   \n  <list>          <chr>\n1 <split [92/47]> Fold1\n2 <split [93/46]> Fold2\n3 <split [93/46]> Fold3\n```\n:::\n:::\n\n\n## Cross validation, steps 2 and 3\n\n::: nonincremental\n-   Use *v-1* partitions for analysis, and the remaining 1 partition for assessment\n-   Repeat *v* times, updating which partition is used for assessment each time\n:::\n\n![](images/16/three-CV-iter.svg){fig-align=\"center\"}\n\n## Fit resamples {.midi}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Function to get Adj R-sq, AIC, BIC\ncalc_model_stats <- function(x) {\n  glance(extract_fit_parsnip(x)) |>\n    select(adj.r.squared, AIC, BIC)\n}\n\nset.seed(456)\n\n# Fit model and calculate statistics for each fold\noffice_fit_rs1 <- office_wflow1 |>\n  fit_resamples(resamples = folds, \n                control = control_resamples(extract = calc_model_stats))\n\noffice_fit_rs1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Resampling results\n# 3-fold cross-validation \n# A tibble: 3 Ã— 5\n  splits          id    .metrics         .notes           .extracts       \n  <list>          <chr> <list>           <list>           <list>          \n1 <split [92/47]> Fold1 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble [1 Ã— 2]>\n2 <split [93/46]> Fold2 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble [1 Ã— 2]>\n3 <split [93/46]> Fold3 <tibble [2 Ã— 4]> <tibble [0 Ã— 3]> <tibble [1 Ã— 2]>\n```\n:::\n:::\n\n\n## Cross validation, now what?\n\n-   We've fit a bunch of models\n-   Now it's time to use them to collect metrics (e.g., \\$R\\^2\\$, AIC, RMSE, etc. ) on each model and use them to evaluate model fit and how it varies across folds\n\n## Collect $R^2$ and RMSE from CV\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Produces summary across all CV\ncollect_metrics(office_fit_rs1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 Ã— 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   0.353     3  0.0117 Preprocessor1_Model1\n2 rsq     standard   0.539     3  0.0378 Preprocessor1_Model1\n```\n:::\n:::\n\n\n<br>\n\nNote: These are calculated using the *assessment* data\n\n## Deeper look into $R^2$ and RMSE\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncv_metrics1 <- collect_metrics(office_fit_rs1, summarize = FALSE) \n\ncv_metrics1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 Ã— 5\n  id    .metric .estimator .estimate .config             \n  <chr> <chr>   <chr>          <dbl> <chr>               \n1 Fold1 rmse    standard       0.355 Preprocessor1_Model1\n2 Fold1 rsq     standard       0.525 Preprocessor1_Model1\n3 Fold2 rmse    standard       0.373 Preprocessor1_Model1\n4 Fold2 rsq     standard       0.481 Preprocessor1_Model1\n5 Fold3 rmse    standard       0.332 Preprocessor1_Model1\n6 Fold3 rsq     standard       0.610 Preprocessor1_Model1\n```\n:::\n:::\n\n\n## Better tabulation of $R^2$ and RMSE from CV\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncv_metrics1 |>\n  mutate(.estimate = round(.estimate, 3)) |>\n  pivot_wider(id_cols = id, names_from = .metric, values_from = .estimate) |>\n  kable(col.names = c(\"Fold\", \"RMSE\", \"R-squared\"))\n```\n\n::: {.cell-output-display}\n|Fold  |  RMSE| R-squared|\n|:-----|-----:|---------:|\n|Fold1 | 0.355|     0.525|\n|Fold2 | 0.373|     0.481|\n|Fold3 | 0.332|     0.610|\n:::\n:::\n\n\n## How does RMSE compare to y? {.small}\n\n::: columns\n::: {.column width=\"50%\"}\nCross validation RMSE stats:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncv_metrics1 |>\n  filter(.metric == \"rmse\") |>\n  summarise(\n    min = min(.estimate),\n    max = max(.estimate),\n    mean = mean(.estimate),\n    sd = sd(.estimate)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 Ã— 4\n    min   max  mean     sd\n  <dbl> <dbl> <dbl>  <dbl>\n1 0.332 0.373 0.353 0.0202\n```\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\nTraining data IMDB score stats:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\noffice_episodes |>\n  \n  summarise(\n    min = min(imdb_rating),\n    max = max(imdb_rating),\n    mean = mean(imdb_rating),\n    sd = sd(imdb_rating)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 Ã— 4\n    min   max  mean    sd\n  <dbl> <dbl> <dbl> <dbl>\n1   6.7   9.7  8.25 0.535\n```\n:::\n:::\n\n:::\n:::\n\n## Collect $R^2_{Adj}$, AIC, BIC from CV\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmap_df(office_fit_rs1$.extracts, ~ .x[[1]][[1]]) |>\n  bind_cols(Fold = office_fit_rs1$id)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 Ã— 4\n  adj.r.squared   AIC   BIC Fold \n          <dbl> <dbl> <dbl> <chr>\n1         0.585  70.3 101.  Fold1\n2         0.615  63.0  93.4 Fold2\n3         0.553  77.6 108.  Fold3\n```\n:::\n:::\n\n\n<br>\n\nNote: These are based on the model fit from the *analysis* data\n\n## Cross validation jargon\n\n-   Referred to as *v-fold* or *k-fold* cross validation\n-   Also commonly abbreviated as CV\n\n## Cross validation in practice\n\n::: incremental\n-   To illustrate how CV works, we used `v = 3`:\n\n    ::: nonincremental\n    -   Analysis sets are 2/3 of the training set\n    -   Each assessment set is a distinct 1/3\n    -   The final resampling estimate of performance averages each of the 3 replicates\n    :::\n\n-   This was useful for illustrative purposes, but `v = 3` is a poor choice in practice\n\n-   Values of `v` are most often 5 or 10; we generally prefer 10-fold cross-validation as a default\n:::\n\n# Application exercise\n\n::: appex\nğŸ“‹ [AE 10: Cross validation](../ae/ae-10-cross-validation.html)\n:::\n\n## Recap\n\n::: nonincremental\n-   Cross validation for model evaluation\n-   Cross validation for model comparison\n:::\n",
    "supporting": [
      "16-cross-validation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}