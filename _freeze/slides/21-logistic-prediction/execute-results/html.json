{
  "hash": "514895d13ea51a1dd08e9898e5e855c6",
  "result": {
    "markdown": "---\ntitle: \"Logistic Regression: Prediction + classification\"\nauthor: \"Prof. Maria Tackett\"\ndate: \"2022-11-09\"\ndate-format: \"MMM DD, YYYY\"\nfooter: \"[ğŸ”— Week 11](https://sta210-fa22.netlify.app/weeks/week-11.html)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: true\n    incremental: false \n    chalkboard: true\nexecute:\n  freeze: auto\n  echo: true\n  warning: false\n  message: false\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\n---\n\n\n\n\n## Announcements\n\n-   Aaditya's office hours permanently moved to Wed 6 - 8pm\n\n    -   New time reflected on website and Sakai\n\n-   See [Week 11](../weeks/week-11.html) activities\n\n## Odds ratios practice {.small}\n\nLet's take a look at one of the models from [Lab 06](../labs/lab-06.html).\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|term            | estimate| std.error| statistic| p.value|\n|:---------------|--------:|---------:|---------:|-------:|\n|(Intercept)     |  -14.676|     1.881|    -7.804|   0.000|\n|islandDream     |   -0.892|     0.359|    -2.481|   0.013|\n|islandTorgersen |   18.132|   822.821|     0.022|   0.982|\n|bill_depth_mm   |    0.836|     0.113|     7.416|   0.000|\n:::\n:::\n\n\n::: question\n-   Interpret the coefficient of `bill_depth_mm` in terms of the **odds** a penguin is from Adelie species.\n\n-   Interpret the coefficient of `islandDream` in terms of the **odds** a penguin is from Adelie species.\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_636bb715\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n## Topics\n\n::: nonincremental\n-   Building predictive logistic regression models\n-   Sensitivity and specificity\n-   Making classification decisions\n:::\n\n## Computational setup\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))\n```\n:::\n\n\n# Data\n\n## `openintro::email`\n\nThese data represent incoming emails for the first three months of 2012 for an email account.\n\n::: nonincremental\n-   Outcome: `spam` - Indicator for whether the email was spam.\n-   Predictors: `spam`, `to_multiple`, `from`, `cc`, `sent_email`, `time`, `image`, `attach`, `dollar`, `winner`, `inherit`, `viagra`, `password`, `num_char`, `line_breaks`, `format`, `re_subj`, `exclaim_subj`, `urgent_subj`, `exclaim_mess`, `number`.\n:::\n\nClick [here](http://openintrostat.github.io/openintro/reference/email.html) for more detailed information on the variables.\n\n## Training and testing split\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Fix random numbers by setting the seed \n# Enables analysis to be reproducible when random numbers are used \nset.seed(1109)\n\n# Put 75% of the data into the training set \nemail_split <- initial_split(email)\n\n# Create data frames for the two sets\nemail_train <- training(email_split)\nemail_test  <- testing(email_split)\n```\n:::\n\n\n## Exploratory data analysis\n\nThe sample is **unbalanced** with respect to `spam`.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](21-logistic-prediction_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n## Reminder: Modeling workflow\n\n-   Create a recipe for feature engineering steps to be applied to the training data\n\n-   Fit the model to the training data after these steps have been applied\n\n    -   Use cross-validation if deciding between multiple models\n\n-   Using the model estimates from the training data, predict outcomes for the test data\n\n-   Evaluate the performance of the model on the test data\n\n# Start with a recipe\n\n## Initiate a recipe {.midi}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemail_rec <- recipe(\n  spam ~ .,          # formula\n  data = email_train  # data to use for cataloging names and types of variables\n  )\nsummary(email_rec)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 21 Ã— 4\n   variable     type    role      source  \n   <chr>        <chr>   <chr>     <chr>   \n 1 to_multiple  nominal predictor original\n 2 from         nominal predictor original\n 3 cc           numeric predictor original\n 4 sent_email   nominal predictor original\n 5 time         date    predictor original\n 6 image        numeric predictor original\n 7 attach       numeric predictor original\n 8 dollar       numeric predictor original\n 9 winner       nominal predictor original\n10 inherit      numeric predictor original\n11 viagra       numeric predictor original\n12 password     numeric predictor original\n13 num_char     numeric predictor original\n14 line_breaks  numeric predictor original\n15 format       nominal predictor original\n16 re_subj      nominal predictor original\n17 exclaim_subj numeric predictor original\n18 urgent_subj  nominal predictor original\n19 exclaim_mess numeric predictor original\n20 number       nominal predictor original\n21 spam         nominal outcome   original\n```\n:::\n:::\n\n\n## Remove certain variables\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemail_rec <- email_rec |>\n  step_rm(from, sent_email)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor         20\n\nOperations:\n\nVariables removed from, sent_email\n```\n:::\n:::\n\n\n## Feature engineer date\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemail_rec <- email_rec |>\n  step_date(time, features = c(\"dow\", \"month\")) |>\n  step_rm(time)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor         20\n\nOperations:\n\nVariables removed from, sent_email\nDate features from time\nVariables removed time\n```\n:::\n:::\n\n\n## Discretize numeric variables\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemail_rec <- email_rec |>\n  step_cut(cc, attach, dollar, breaks = c(0, 1))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor         20\n\nOperations:\n\nVariables removed from, sent_email\nDate features from time\nVariables removed time\nCut numeric for cc, attach, dollar\n```\n:::\n:::\n\n\n## Create dummy variables\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemail_rec <- email_rec |>\n  step_dummy(all_nominal(), -all_outcomes())\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor         20\n\nOperations:\n\nVariables removed from, sent_email\nDate features from time\nVariables removed time\nCut numeric for cc, attach, dollar\nDummy variables from all_nominal(), -all_outcomes()\n```\n:::\n:::\n\n\n## Remove zero variance variables\n\nVariables that contain only a single value\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemail_rec <- email_rec |>\n  step_zv(all_predictors())\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor         20\n\nOperations:\n\nVariables removed from, sent_email\nDate features from time\nVariables removed time\nCut numeric for cc, attach, dollar\nDummy variables from all_nominal(), -all_outcomes()\nZero variance filter on all_predictors()\n```\n:::\n:::\n\n\n## Recipe: All in one place\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemail_rec <- recipe(spam ~ ., data = email_train) |>\n  step_rm(from, sent_email) |>\n  step_date(time, features = c(\"dow\", \"month\")) |>               \n  step_rm(time) |>\n  step_cut(cc, attach, dollar, breaks = c(0, 1)) |>\n  step_dummy(all_nominal_predictors()) |>\n  step_zv(all_predictors())\n```\n:::\n\n\n# Build a workflow\n\n## Define model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemail_spec <- logistic_reg() |> \n  set_engine(\"glm\")\nemail_spec\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n```\n:::\n:::\n\n\n## Define workflow {.midi}\n\n**Remember:** Workflows bring together models and recipes so that they can be easily applied to both the training and test data.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemail_wflow <- workflow() |> \n  add_model(email_spec) |> \n  add_recipe(email_rec)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: logistic_reg()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n6 Recipe Steps\n\nâ€¢ step_rm()\nâ€¢ step_date()\nâ€¢ step_rm()\nâ€¢ step_cut()\nâ€¢ step_dummy()\nâ€¢ step_zv()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n```\n:::\n:::\n\n\n## Fit model to training data {.midi}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemail_fit <- email_wflow |> \n  fit(data = email_train)\n\ntidy(email_fit) |> print(n = 31)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 27 Ã— 5\n   term           estimate std.error statistic  p.value\n   <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n 1 (Intercept)    -1.24      0.274     -4.51   6.43e- 6\n 2 image          -1.36      0.679     -2.00   4.59e- 2\n 3 inherit         0.352     0.185      1.90   5.69e- 2\n 4 viagra          1.96     40.6        0.0482 9.62e- 1\n 5 password       -0.941     0.387     -2.43   1.51e- 2\n 6 num_char        0.0572    0.0257     2.23   2.58e- 2\n 7 line_breaks    -0.00554   0.00147   -3.77   1.66e- 4\n 8 exclaim_subj   -0.245     0.303     -0.807  4.19e- 1\n 9 exclaim_mess    0.00916   0.00195    4.69   2.67e- 6\n10 to_multiple_X1 -2.91      0.388     -7.50   6.37e-14\n11 cc_X.1.68.     -0.105     0.446     -0.236  8.14e- 1\n12 attach_X.1.21.  2.33      0.385      6.06   1.37e- 9\n13 dollar_X.1.64.  0.0136    0.241      0.0565 9.55e- 1\n14 winner_yes      2.46      0.480      5.12   3.02e- 7\n15 format_X1      -1.02      0.173     -5.88   4.07e- 9\n16 re_subj_X1     -2.93      0.436     -6.72   1.81e-11\n17 urgent_subj_X1  4.37      1.25       3.51   4.54e- 4\n18 number_small   -0.728     0.178     -4.08   4.45e- 5\n19 number_big      0.261     0.255      1.03   3.05e- 1\n20 time_dow_Mon    0.123     0.320      0.386  7.00e- 1\n21 time_dow_Tue    0.309     0.294      1.05   2.94e- 1\n22 time_dow_Wed   -0.133     0.297     -0.447  6.55e- 1\n23 time_dow_Thu    0.104     0.303      0.343  7.32e- 1\n24 time_dow_Fri    0.280     0.292      0.960  3.37e- 1\n25 time_dow_Sat    0.439     0.323      1.36   1.74e- 1\n26 time_month_Feb  1.06      0.192      5.54   3.06e- 8\n27 time_month_Mar  0.575     0.198      2.91   3.60e- 3\n```\n:::\n:::\n\n\n# Make predictions\n\n## Make predictions for test data\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemail_pred <- predict(email_fit, email_test, type = \"prob\") |> \n  bind_cols(email_test) \nemail_pred\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 981 Ã— 23\n   .pred_0  .pred_1 spam  to_mulâ€¦Â¹ from     cc sent_â€¦Â² time                image\n     <dbl>    <dbl> <fct> <fct>    <fct> <int> <fct>   <dttm>              <dbl>\n 1   0.921 0.0786   0     0        1         0 0       2012-01-01 01:16:41     0\n 2   0.961 0.0391   0     0        1         0 0       2012-01-01 05:00:01     0\n 3   0.999 0.000988 0     0        1         1 1       2012-01-01 14:38:32     0\n 4   0.999 0.000591 0     0        1         1 1       2012-01-01 18:40:14     0\n 5   0.991 0.00878  0     0        1         0 0       2012-01-02 00:42:16     0\n 6   0.910 0.0902   0     0        1         0 0       2012-01-01 21:05:45     0\n 7   1.00  0.000108 0     1        1         3 0       2012-01-02 08:41:11     0\n 8   0.975 0.0248   0     0        1         0 0       2012-01-02 20:07:17     0\n 9   0.952 0.0477   0     0        1         0 0       2012-01-02 23:31:03     0\n10   0.992 0.00819  0     1        1         0 0       2012-01-03 08:36:16     0\n# â€¦ with 971 more rows, 14 more variables: attach <dbl>, dollar <dbl>,\n#   winner <fct>, inherit <dbl>, viagra <dbl>, password <dbl>, num_char <dbl>,\n#   line_breaks <int>, format <fct>, re_subj <fct>, exclaim_subj <dbl>,\n#   urgent_subj <fct>, exclaim_mess <dbl>, number <fct>, and abbreviated\n#   variable names Â¹â€‹to_multiple, Â²â€‹sent_email\n```\n:::\n:::\n\n\n## A closer look at predictions\n\n::: question\nWhich of the following 10 emails will be misclassified?\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemail_pred |>\n  arrange(desc(.pred_1)) |>\n  select(contains(\"pred\"), spam) |> slice(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 Ã— 3\n   .pred_0 .pred_1 spam \n     <dbl>   <dbl> <fct>\n 1  0.0750   0.925 0    \n 2  0.110    0.890 0    \n 3  0.116    0.884 1    \n 4  0.127    0.873 1    \n 5  0.170    0.830 1    \n 6  0.189    0.811 1    \n 7  0.204    0.796 1    \n 8  0.208    0.792 1    \n 9  0.224    0.776 1    \n10  0.295    0.705 1    \n```\n:::\n:::\n\n\n# Sensitivity and specificity\n\n## False positive and negative {.midi}\n\n|                              | Email is spam                   | Email is not spam               |\n|-----------------------|-------------------------|-------------------------|\n| Email classified as spam     | True positive                   | False positive (*Type 1 error*) |\n| Email classified as not spam | False negative (*Type 2 error*) | True negative                   |\n\n<br>\n\n. . .\n\n-   False negative rate = P(classified as not spam \\| Email spam) = FN / (TP + FN)\n\n-   False positive rate = P(classified as spam \\| Email not spam) = FP / (FP + TN)\n\n## Sensitivity and specificity {.midi}\n\n|                              | Email is spam                   | Email is not spam               |\n|-----------------------|-------------------------|-------------------------|\n| Email classified as spam     | True positive                   | False positive (*Type 1 error*) |\n| Email classified as not spam | False negative (*Type 2 error*) | True negative                   |\n\n<br>\n\n. . .\n\n-   Sensitivity = P(classified as spam \\| Email spam) = TP / (TP + FN)\n    -   **Sensitivity = 1 âˆ’ False negative rate**\n-   Specificity = P(classified as not spam \\| Email not spam) = TN / (FP + TN)\n    -   **Specificity = 1 âˆ’ False positive rate**\n\n. . .\n\n::: question\nIf you were designing a spam filter, would you want sensitivity and specificity to be high or low? What are the trade-offs associated with each decision?\n:::\n\n## Evaluate the performance\n\n**Receiver operating characteristic (ROC) curve**<sup>+</sup> plots the true positive rate (sensitivity) vs. false positive rate (1 - specificity).\n\n::: aside\n<sup>+</sup> Originally developed for operators of military radar receivers, hence the name.\n:::\n\n::: columns\n::: {.column width=\"40%\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemail_pred |>\n  roc_curve(\n    truth = spam,\n    .pred_1,\n    event_level = \"second\"\n  ) |>\n  autoplot()\n```\n:::\n\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](21-logistic-prediction_files/figure-revealjs/unnamed-chunk-26-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n:::\n\n## ROC curve, under the hood\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemail_pred |>\n  roc_curve(\n    truth = spam,\n    .pred_1,\n    event_level = \"second\"\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 978 Ã— 3\n    .threshold specificity sensitivity\n         <dbl>       <dbl>       <dbl>\n 1 -Inf            0                 1\n 2    3.36e-10     0                 1\n 3    2.27e- 9     0.00226           1\n 4    8.69e- 7     0.00339           1\n 5    9.89e- 7     0.00452           1\n 6    1.43e- 6     0.00565           1\n 7    9.16e- 6     0.00678           1\n 8    1.03e- 5     0.00791           1\n 9    2.58e- 5     0.00904           1\n10    3.35e- 5     0.0102            1\n# â€¦ with 968 more rows\n```\n:::\n:::\n\n\n## ROC curve\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](21-logistic-prediction_files/figure-revealjs/unnamed-chunk-28-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n## Evaluate the performance: AUC\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemail_pred |>\n  roc_auc(\n    truth = spam,\n    .pred_1,\n    event_level = \"second\"\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 Ã— 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.836\n```\n:::\n:::\n\n\n. . .\n\nThe **area under the curve (AUC)** can be used to assess how well the logistic model fits the data\n\n-   AUC=0.5: model is a very bad fit (no better than a coin flip)\n\n-   AUC close to 1: model is a good fit\n\n# Make decisions\n\n## Cutoff probability: 0.5 {.midi}\n\n::: panel-tabset\n## Output\n\nSuppose we decide to label an email as spam if the model predicts the probability of spam to be **more than 0.5**.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|                             | Email is not spam| Email is spam|\n|:----------------------------|-----------------:|-------------:|\n|Email classified as not spam |               877|            82|\n|Email classified as spam     |                 8|            14|\n:::\n:::\n\n\n## Code\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncutoff_prob <- 0.5\nemail_pred |>\n  mutate(\n    spam_pred = as_factor(if_else(.pred_1 >= cutoff_prob, 1, 0)),\n    spam      = if_else(spam == 1, \"Email is spam\", \"Email is not spam\"),\n    spam_pred = if_else(spam_pred == 1, \"Email classified as spam\", \"Email classified as not spam\")\n    ) |>\n  count(spam_pred, spam) |>\n  pivot_wider(names_from = spam, values_from = n) |>\n  kable(col.names = c(\"\", \"Email is not spam\", \"Email is spam\"))\n```\n:::\n\n:::\n\n## Confusion matrix\n\nCross-tabulation of observed and predicted classes:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncutoff_prob <- 0.5\nemail_pred |>\n  mutate(spam_predicted = as_factor(if_else(.pred_1 >= cutoff_prob, 1, 0))) |>\n  conf_mat(truth = spam, estimate = spam_predicted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Truth\nPrediction   0   1\n         0 877  82\n         1   8  14\n```\n:::\n:::\n\n\n## Classification\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](21-logistic-prediction_files/figure-revealjs/unnamed-chunk-33-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n## Cutoff probability: 0.25 {.midi}\n\n::: panel-tabset\n## Output\n\nSuppose we decide to label an email as spam if the model predicts the probability of spam to be **more than 0.25**.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|                             | Email is not spam| Email is spam|\n|:----------------------------|-----------------:|-------------:|\n|Email classified as not spam |               830|            52|\n|Email classified as spam     |                55|            44|\n:::\n:::\n\n\n## Code\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncutoff_prob <- 0.25\nemail_pred |>\n  mutate(\n    spam_pred = as_factor(if_else(.pred_1 >= cutoff_prob, 1, 0)),\n    spam      = if_else(spam == 1, \"Email is spam\", \"Email is not spam\"),\n    spam_pred = if_else(spam_pred == 1, \"Email classified as spam\", \"Email classified as not spam\")\n    ) |>\n  count(spam_pred, spam) |>\n  pivot_wider(names_from = spam, values_from = n) |>\n  kable(col.names = c(\"\", \"Email is not spam\", \"Email is spam\"))\n```\n:::\n\n:::\n\n## Classification\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](21-logistic-prediction_files/figure-revealjs/unnamed-chunk-35-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n## Cutoff probability: 0.75 {.midi}\n\n::: panel-tabset\n## Output\n\nSuppose we decide to label an email as spam if the model predicts the probability of spam to be **more than 0.75**.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|                             | Email is not spam| Email is spam|\n|:----------------------------|-----------------:|-------------:|\n|Email classified as not spam |               883|            89|\n|Email classified as spam     |                 2|             7|\n:::\n:::\n\n\n## Code\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncutoff_prob <- 0.75\nemail_pred |>\n  mutate(\n    spam_pred = as_factor(if_else(.pred_1 >= cutoff_prob, 1, 0)),\n    spam      = if_else(spam == 1, \"Email is spam\", \"Email is not spam\"),\n    spam_pred = if_else(spam_pred == 1, \"Email classified as spam\", \"Email classified as not spam\")\n    ) |>\n  count(spam_pred, spam) |>\n  pivot_wider(names_from = spam, values_from = n) |>\n  kable(col.names = c(\"\", \"Email is not spam\", \"Email is spam\"))\n```\n:::\n\n:::\n\n## Classification\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](21-logistic-prediction_files/figure-revealjs/unnamed-chunk-37-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n## Use ROC curve\n\nUse the ROC curve to determine the best cutoff probability\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](21-logistic-prediction_files/figure-revealjs/unnamed-chunk-38-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 Ã— 3\n   .threshold specificity sensitivity\n        <dbl>       <dbl>       <dbl>\n 1     0.0769       0.736       0.792\n 2     0.0770       0.736       0.781\n 3     0.0780       0.737       0.781\n 4     0.0785       0.737       0.771\n 5     0.0786       0.738       0.771\n 6     0.0787       0.739       0.771\n 7     0.0789       0.739       0.760\n 8     0.0802       0.740       0.760\n 9     0.0802       0.741       0.760\n10     0.0805       0.742       0.760\n```\n:::\n:::\n\n:::\n:::\n",
    "supporting": [
      "21-logistic-prediction_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/countdown-0.3.5/countdown.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/countdown-0.3.5/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}