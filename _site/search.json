[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Role\nName\nOffice hours\nLocation\n\n\n\n\nInstructor\nProf. Maria Tackett\nMon 10:30 - 11:30am\nWed 1:30 - 2:30pm\nOld Chem 118B\n\n\n\n\nor by appointment\nOld Chem 118B or Zoom\n\n\nTeaching Assistant\nHun Kang\nTue 3 - 5pm\nOld Chem 203B",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#teaching-team-office-hours",
    "href": "syllabus.html#teaching-team-office-hours",
    "title": "Syllabus",
    "section": "",
    "text": "Role\nName\nOffice hours\nLocation\n\n\n\n\nInstructor\nProf. Maria Tackett\nMon 10:30 - 11:30am\nWed 1:30 - 2:30pm\nOld Chem 118B\n\n\n\n\nor by appointment\nOld Chem 118B or Zoom\n\n\nTeaching Assistant\nHun Kang\nTue 3 - 5pm\nOld Chem 203B",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-info",
    "href": "syllabus.html#course-info",
    "title": "Syllabus",
    "section": "Course info",
    "text": "Course info\n\n\n\n\nDay\nTime\nLocation\n\n\n\n\nLectures\nMon & Wed\n3:05 - 4:20pm\nPhysics 205\n\n\nLab 01\nThu\n3:05 - 4:20pm\nPerkins 071 (Link #5)\n\n\nLab 02\nThu\n4:40 - 5:55pm\nPerkins 087 (Link #3)",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#textbooks",
    "href": "syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nAll books are freely available online. Print copies are also available for purchase.\n\n\n\nBeyond Multiple Linear Regression\nRoback, Legler\nCRC Press, 1st edition, 2020\n\n\nR for Data Science\nWickham, Cetinkaya-Rundel, Grolemund\nO’Reilly, 2nd edition, 2023\n\n\nTidy Modeling with R\nKuhn, Silge\nO’Reilly, 1st edition, 2022",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus",
    "section": "Course description",
    "text": "Course description\nSTA 310 builds upon the content in STA 210: Regression Analysis. In STA 310 students will be introduced to generalized linear models (GLMs), a broad modeling framework that includes linear and logistic models, among others. Students will learn the basic theory of GLMs and how they can used to model a variety of response variables with non-normal distributions. Students will also learn an extension of GLMs that can be applied to modeling data with correlated observations, such as data with repeated measures.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#prerequisites",
    "href": "syllabus.html#prerequisites",
    "title": "Syllabus",
    "section": "Prerequisites",
    "text": "Prerequisites\nThe prerequisites for the course are STA 210 and one of STA 230/STA 231/STA 240. This course assumes students have some familiarity with linear regression, analyzing data using RStudio, using version control with Git and collaborating using GitHub. The semester will start with a short review of linear regression and computing.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-learning-objectives",
    "href": "syllabus.html#course-learning-objectives",
    "title": "Syllabus",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to …\n\ndescribe generalized linear models (GLMs) as a unified framework.\nexplain how specific models fit into the GLM framework, including extensions for correlated data.\nidentify the appropriate model given the data and analysis objective.\nanalyze real-world data by fitting and interpreting GLMs.\nuse R for analysis, Quarto to write reports, git for version control, and GitHub for collaboration.\neffectively communicate results from statistical analyses to a general audience in writing and oral presentations.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-community",
    "href": "syllabus.html#course-community",
    "title": "Syllabus",
    "section": "Course community",
    "text": "Course community\n\nDuke Community Standard\nAs a student in this course, you have agreed to uphold the Duke Community Standard as well as the practices specific to this course.\n\n\n\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know! You’ll be able to note this in the Getting to know you survey.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nPronouns\nPronouns are meaningful tools to communicate identities and experiences, and using pronouns supports a campus environment where all community members can thrive. Please update your gender pronouns in Duke Hub. You can learn more at the Center for Sexual and Gender Diversity’s website.\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website, sta310-sp24.netlify.app\nAnnouncements will be sent through Canvas and email. Please check your email regularly to ensure you have the latest announcements for the course.\n\n\nWhere to get help\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours1 to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the course Slack. There is a chance another student has already asked a similar question, so please check the other posts on Slack before adding a new question. If you know the answer to a question posted on Slack, I encourage you to respond!\n\nCheck out the Support page for more resources.\n\n\nEmail\nIf there is a question that’s not appropriate for Slack, please email directly with “STA 310” in the subject line. Barring extenuating circumstances, I will respond to STA 310 emails within 48 hours Monday - Thursday. Response time may be slower for emails received Friday - Sunday.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#activities-assessment",
    "href": "syllabus.html#activities-assessment",
    "title": "Syllabus",
    "section": "Activities & Assessment",
    "text": "Activities & Assessment\nThe activities and assessments in this course are designed to help you successfully achieve the course learning objectives. Each activity and assessment is part of the prepare, practice, perform cycle for each topic.\n\nPrepare: Includes reading assignments and occasional videos to introduce new concepts and ensure a basic comprehension of the material.\nPractice: Includes in-class activities and application exercises to explore the topics new topics in more depth. These activities will be completed during lecture. As they are intended for practice, they will not be graded.\nPerform: Includes homework, quizzes, and the projects. These assignments are an opportunity for you to demonstrate your understanding of the course material and how it is applied to the analysis of real-world data.\n\n\nReadings\nThere will be reading assignments to accompany each topic. Readings will primarily come from the course textbook Beyond Multiple Linear Regression, but they may periodically include articles and other resources. It is strongly recommended that you complete the readings before lectures, so you have an introduction to the topic before class.\n\n\nLectures\nLectures will be interactive with a mix of presenting lecture notes, short in-class activities, and application exercises. The activities and application exercises will give you an opportunity to explore concepts in more depth and get practice applying them to real-world data.\n\n\nHomework\nThere will be 6 homework assignments during the semester. In these assignments, you will apply what you’ve learned as you answer conceptual questions and complete guided and open-ended analyses. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Homework will be submitted in your private GitHub repo.\nThe lowest homework grade is dropped.\n\n\nQuizzes\nThere will be 6 quizzes during the semester. Quizzes will cover the readings, lecture notes and activities, and any assignments since the previous quiz.\nThe lowest quiz grade is dropped.\n\n\nProjects\nThere will be 2 short group projects and 1 final individual project in this course. Teams will be randomly assigned for each of the mini projects. More details about each project will be available as they are assigned.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n40%\n\n\nProject 01\n10%\n\n\nProject 02\n10%\n\n\nFinal project\n20%\n\n\nQuizzes\n20%\n\n\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n&gt;= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n&lt; 60\n\n\n\nThese are upper bounds for grade cutoffs, depending on the class performance the cutoffs may be lowered but they won’t be increased.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nAcademic honesty\nBy participating in this course, you agree to abide by the following when completing assignments:\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what’s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the teaching assistants.\nYou may not discuss or otherwise work with others on quizzes. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved.\nFor the projects collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project across teams.\nReusing code: Unless explicitly stated otherwise, you may make use of online resources (e.g. StackOverflow) for coding examples on assignments. If you directly use code from an outside source (or use it as inspiration), you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nUse of artificial intelligence (AI): You should treat AI tools, such as ChatGPT, the same as other online resources. There are two guiding principles that govern how you can use AI in this course:2 (1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning. (2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\nAI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. You may use these guidelines for citing AI-generated content.\nNo AI tools for narrative: Unless instructed otherwise, AI is not permitted for writing narrative on assignments. In general, you may use AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content.\n\n\nIf you are unsure if the use of a particular resource complies with the academic honesty policy, please ask me or a teaching assistant.\nRegardless of course delivery format, it is the responsibility of all students to understand and follow all Duke policies, including academic integrity (e.g., completing one’s own work, following proper citation of sources, adhering to guidance around group work projects,and more). Ignoring these requirements is a violation of the Duke Community Standard. Any questions and/or concerns regarding academic integrity can be directed to the Office of Student Conduct and Community Standards at conduct@duke.edu.\nAny violations in academic honesty standards as outlined in the Duke Community Standard and those specific to this course will automatically result in a 0 for the assignment and will be reported to the Office of Student Conduct for further action.\n\n\nLate work & extensions\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback within a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline.\n\nHomework will be accepted up to 48 hours after the deadline. There will be a 5% deduction for each 24-hour period the assignment is late.\nNo late work is accepted on quizzes, and there are no makeups for missed quizzes.\nLate policy for the projects:\n\nPresentation: Late presentations are not accepted and there are no make ups for missed presentations.\nWrite up: GitHub repositories will be closed to contributions at the deadline. If you need to submit your work late, please send me a message via Slack or email to reopen your repository. There will be a 5% deduction for write ups submitted late but the same day (by 11:59pm). There will be a 10% deduction for write ups submitted the next day (by 11:59pm). There will be a 15% deduction for write ups submitted two days late (by 11:59pm). No credit given for write ups submitted more than 2 days after the deadline.\nPeer evaluation: No late work is accepted on peer evaluations. If you do not turn in your peer evaluation, you get 0 points for your own peer score as well, regardless of how your teammates have evaluated you. There are no make ups for peer evaluations.\n\n\n\n\nLate waiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a homework assignment by the deadline, you may email me before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used for once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let me know if you need help contacting your academic dean.\n\n\nRegrade requests\nRegrade requests must be submitted via email to me within a week of when an assignment is returned. Regrade requests will only be considered if points were tallied incorrectly or a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. If a regrade request is submitted, the entire question will be regraded, so your score could increase, decrease, or remain unchanged.\n\n\nAttendance\nYou are expected to attend all lectures and labs with a fully-charged laptop or tablet with access to RStudio. We understand there may be times when you are unable to attend a class meeting; in such instances it is your responsibility to make up the missed material. Labs will primarily be used to work on homework and the projects. If you miss a lab meeting dedicated to group work, please communicate with your teammates to make a plan to contribute to the assignment. Click here for more information on the Trinity attendance policies.\n\n\nAttendance Policy Related to COVID Symptoms, Exposure, or Infection\nStudent health, safety, and well-being are the university’s top priorities. To help ensure your well-being and the well-being of those around you, please do not come to class if you have tested positive for COVID-19 or have possible symptoms and have not yet been tested. If any of these situations apply to you, you must follow university guidance related to the ongoing COVID-19 pandemic and current health and safety protocols. If you are experiencing any COVID-19 symptoms, contact student health (dshcheckin@duke.edu, 919-681-9355). Learn more about current university policy related to COVID-19 at coronavirus.duke.edu.\nTo keep the university community as safe and healthy as possible, you will be expected to follow these guidelines. Please reach out to me and your academic dean as soon as possible if you need to quarantine or isolate so that we can discuss arrangements for your continued participation in class.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#accommodations",
    "href": "syllabus.html#accommodations",
    "title": "Syllabus",
    "section": "Accommodations",
    "text": "Accommodations\n\nAcademic accommodations\nIf you are a student with a disability and need accommodations for this class, it is your responsibility to register with the Student Disability Access Office (SDAO) and provide them with documentation of your disability. SDAO will work with you to determine what accommodations are appropriate for your situation. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu.\n\n\nReligious accommodations\nStudents are permitted by university policy to be absent from class to observe a religious holiday. Accordingly, Trinity College of Arts & Sciences and the Pratt School of Engineering have established procedures to be followed by students for notifying their instructors of an absence necessitated by the observance of a religious holiday. Please submit requests for religious accommodations at the beginning of the semester so that we can work to make suitable arrangements well ahead of time. You can find the policy and relevant notification form here: trinity.duke.edu/undergraduate/academic-policies/religious-holidays",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#additional-support",
    "href": "syllabus.html#additional-support",
    "title": "Syllabus",
    "section": "Additional support",
    "text": "Additional support\n\nAcademic Resource Center\nThe Academic Resource Center (the ARC) offers services to support students academically during their undergraduate careers at Duke. The ARC can provide support with time management, academic skills and strategies, unique learning styles, peer tutoring, learning consultations, learning communities, and more. ARC services are available free to any Duke undergraduate student, in any year, studying in any discipline.\nContact ARC@duke.edu, 919-684-5917.\n\n\nMental health and wellness resources\nStudent mental health and wellness is of primary importance at Duke, and the university offers resources to support students in managing daily stress and self-care. Duke offers several resources for students to seek assistance on coursework and to nurture daily habits that support overall well-being, some of which are listed below\n\nDuWell: (919) 681-8421, provides Moments of Mindfulness (stress management and resilience building) and Koru (meditation) programming to assist students in developing a daily emotional well-being practice. Click here to see schedules for programs please see. All are welcome and no experience necessary. duwell@studentaffairs.duke.edu, or studentaffairs.duke.edu/duwell\n\nIf your mental health concerns and/or stressful events negatively affect your daily emotional state, academic performance, or ability to participate in your daily activities, many resources are available to help you through difficult times. Duke encourages all students to access these resources.\n\nDukeReach: Provides comprehensive outreach services to identify and support students in managing all aspects of well-being. If you have concerns about a student’s behavior or health visit the website for resources and assistance. studentaffairs.duke.edu/dukereach\nCounseling and Psychological Services (CAPS): CAPS services include individual, group, and couples counseling services, health coaching, psychiatric services, and workshops and discussions. CAPS also provides referral to off-campus resources for specialized care. (919) 660-1000. studentaffairs.duke.edu/caps\nBlue Devils Care: A convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling. bluedevilscare.duke.edu\nTwo-Click Support: Duke Student Government and DukeReach partnership that connects students to help in just two clicks. bit.ly/TwoClickSupport\n\n\n\nTechnology Accommodations\nStudents with demonstrated high financial need who have limited access to computers may request assistance in the form of loaner laptops. For new Spring 2024 technology assistance requests, please go here. Please note that supplies are limited.\nSee the Support page for a more comprehensive list of academic and mental health wellness resources.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#important-dates",
    "href": "syllabus.html#important-dates",
    "title": "Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nJan 10: Classes begin\nJan 15: Martin Luther King, Jr. Holiday - No classes\nJan 24: Drop/add ends\nMar 11 - 15: Spring break - No classes\nMar 27 :Last day to withdraw with W\nApr 24: LDOC\nApr 25 - 28: Reading period\nApr 19 - May 04: Final exams\n\nClick here for the full academic calendar.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "Syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOffice hours are times the teaching team set aside each week to meet with students. Click here to learn more about how to effectively use office hours.↩︎",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "computing.html",
    "href": "computing.html",
    "title": "Computing",
    "section": "",
    "text": "You will need access to R/ RStudio and git for this course. There are two options to access the software:",
    "crumbs": [
      "Course information",
      "Computing"
    ]
  },
  {
    "objectID": "computing.html#step-1-install-rrstudio-and-git",
    "href": "computing.html#step-1-install-rrstudio-and-git",
    "title": "Computing",
    "section": "Step 1: Install R/RStudio and git",
    "text": "Step 1: Install R/RStudio and git\nYou can install R/RStudio on your local machine and configure it to work with git and GitHub. The text Happy Git and GitHub for the useR is a great resource for working with RStudio and git. The steps are outlined below. Click on each link for more detail.\n\nInstall R and RStudio Desktop: posit.co/download/rstudio-desktop\n\nI recommend installing the desktop version not the preview release of RStudio\n\nInstall git: happygitwithr.com/install-git",
    "crumbs": [
      "Course information",
      "Computing"
    ]
  },
  {
    "objectID": "computing.html#step-2-install-r-packages",
    "href": "computing.html#step-2-install-r-packages",
    "title": "Computing",
    "section": "Step 2: Install R packages",
    "text": "Step 2: Install R packages\nBelow is a set of R packages we will use throughout the semester. This list is just to get you started; we will let you know as new R packages are required.\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"knitr\")\ninstall.packages(\"lme4\")\ninstall.packages(\"tidymodels\")\ninstall.packages(\"usethis\")\ninstall.packages(\"credentials\")",
    "crumbs": [
      "Course information",
      "Computing"
    ]
  },
  {
    "objectID": "computing.html#step-3-install-quarto",
    "href": "computing.html#step-3-install-quarto",
    "title": "Computing",
    "section": "Step 3: Install Quarto",
    "text": "Step 3: Install Quarto\nWe will use Quarto (similar to R Markdown) to write up analyses. Download and install Quarto at quarto.org/docs/get-started",
    "crumbs": [
      "Course information",
      "Computing"
    ]
  },
  {
    "objectID": "computing.html#step-4-set-up-git-authentication",
    "href": "computing.html#step-4-set-up-git-authentication",
    "title": "Computing",
    "section": "Step 4: Set up git authentication",
    "text": "Step 4: Set up git authentication\nYou will authenticate GitHub using SSH.\n\nType credentials::ssh_setup_github() into your console.\nR will ask “No SSH key found. Generate one now?” Click 1 for yes.\nYou will generate a key. It will begin with “ssh-rsa….” R will then ask “Would you like to open a browser now?” Click 1 for yes.\nYou may be asked to provide your username and password to log into GitHub. This would be the ones associated with your account that you set up. After entering this information, paste the key in and give it a name. You might name it in a way that indicates where the key will be used, e.g., sta310)\n\nYou can find more detailed instructions here if you’re interested.",
    "crumbs": [
      "Course information",
      "Computing"
    ]
  },
  {
    "objectID": "computing.html#step-5-configure-git",
    "href": "computing.html#step-5-configure-git",
    "title": "Computing",
    "section": "Step 5: Configure git",
    "text": "Step 5: Configure git\nWe need to configure your git so that RStudio can communicate with GitHub. This requires two pieces of information: your name and email address.\nTo do so, you will use the use_git_config() function from the usethis package.\nType the following lines of code in the console in RStudio filling in your name and the email address associated with your GitHub account.\n\nusethis::use_git_config(\n  user.name = \"Your name\", \n  user.email = \"Email associated with your GitHub account\")\n\nFor example, mine would be\n\nusethis::use_git_config(\n  user.name = \"Maria Tackett\",\n  user.email = \"maria.tackett@duke.edu\")\n\nYou are now ready to conduct reproducible data analyses!",
    "crumbs": [
      "Course information",
      "Computing"
    ]
  },
  {
    "objectID": "slides/02-mlr-review.html#announcements",
    "href": "slides/02-mlr-review.html#announcements",
    "title": "Review of multiple linear regression",
    "section": "Announcements",
    "text": "Announcements\n\nHW 01 due Wed, Jan 24 at 11:59pm\n\nReleased Thursday morning\n\nLabs start Thursday\nCheck website for office hours schedule\nAdded a Slack channel #internships-research-opportunities (optional)"
  },
  {
    "objectID": "slides/02-mlr-review.html#computing-set-up",
    "href": "slides/02-mlr-review.html#computing-set-up",
    "title": "Review of multiple linear regression",
    "section": "Computing set up",
    "text": "Computing set up\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\n\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n\ncolors &lt;- tibble::tibble(green = \"#B5BA72\")"
  },
  {
    "objectID": "slides/02-mlr-review.html#topics",
    "href": "slides/02-mlr-review.html#topics",
    "title": "Review of multiple linear regression",
    "section": "Topics",
    "text": "Topics\n\nDefine statistical models\nMotivate generalized linear models and multilevel models\nReview multiple linear regression\n\n\n\nNotes based on Chapter 1 of Roback and Legler (2021) unless noted otherwise."
  },
  {
    "objectID": "slides/02-mlr-review.html#models-and-statistical-models",
    "href": "slides/02-mlr-review.html#models-and-statistical-models",
    "title": "Review of multiple linear regression",
    "section": "Models and statistical models",
    "text": "Models and statistical models\nSuppose we have observations \\(y_1, \\ldots, y_n\\)\n\n\nModel: Mathematical description of the process we think generates the observations\nStatistical model: Model that includes an equation describing the impact of explanatory variables (deterministic part) and probability distributions for parts of the process that are assumed to be random variation (random part)\n\n\n\n\nDefinitions adapted from Stroup (2012)"
  },
  {
    "objectID": "slides/02-mlr-review.html#statistical-models-1",
    "href": "slides/02-mlr-review.html#statistical-models-1",
    "title": "Review of multiple linear regression",
    "section": "Statistical models",
    "text": "Statistical models\nA statistical model must include\n\nThe observations\nThe deterministic (systematic) part of the process\nThe random part of the process with a statement of the presumed probability distribution\n\n\n\nDefinitions adapted from Stroup (2012)"
  },
  {
    "objectID": "slides/02-mlr-review.html#example",
    "href": "slides/02-mlr-review.html#example",
    "title": "Review of multiple linear regression",
    "section": "Example",
    "text": "Example\nSuppose we have the model for comparing two means:\n\\[\ny_{ij} = \\mu_i + \\epsilon_{ij}\n\\]\nwhere\n\n\n\n\\(i = 1, 2\\): group\n\n\n\n\\(j = 1, \\ldots, n\\): observation number\n\\(n_i\\): number of observations in group \\(i\\)\n\\(\\mu_i\\): mean of group \\(i\\)\n\\(y_{ij}\\): \\(j^{th}\\) observation in the \\(i^{th}\\) group\n\\(\\epsilon_{ij}\\) : random error (variation) associated with \\(ij^{th}\\) observation\n\n\n\n\n\nAdapted from Stroup (2012)"
  },
  {
    "objectID": "slides/02-mlr-review.html#example-1",
    "href": "slides/02-mlr-review.html#example-1",
    "title": "Review of multiple linear regression",
    "section": "Example",
    "text": "Example\n\\[\ny_{ij} = \\mu_i + \\epsilon_{ij}\n\\]\n\n\n\\(y_{ij}\\): the observations\n\\(\\mu_i\\): deterministic part of the model, no random variability\n\\(e_{ij}\\) : random part of the model, indicating observations vary about their mean\nTypically assume \\(\\epsilon_{ij}\\) are independent and identically distributed (i.i.d.) \\(N(0, \\sigma^2)\\)\n\n\n\n\nAdapted from Stroup (2012)"
  },
  {
    "objectID": "slides/02-mlr-review.html#practice",
    "href": "slides/02-mlr-review.html#practice",
    "title": "Review of multiple linear regression",
    "section": "Practice",
    "text": "Practice\n\nSuppose \\(y_{ij}\\)’s are observed outcome data and \\(x_i\\)’s are values of the explanatory variable. Assume a linear regression model can used to describe the process of generating \\(y_{ij}\\) based on the \\(x_i\\).\n\nWrite the specification of the statistical model.\nLabel the 3 components of the model equation (observation, deterministic part, random part)\nWhat is \\(E(y_{ij})\\), the expected value of the observations?"
  },
  {
    "objectID": "slides/02-mlr-review.html#assumptions-for-linear-regression",
    "href": "slides/02-mlr-review.html#assumptions-for-linear-regression",
    "title": "Review of multiple linear regression",
    "section": "Assumptions for linear regression",
    "text": "Assumptions for linear regression\n\nLinearity: Linear relationship between mean response and predictor variable(s)\nIndependence: Residuals are independent. There is no connection between how far any two points lie above or below regression line.\nNormality: Response follows a normal distribution at each level of the predictor (or combination of predictors)\nEqual variance: Variability (variance or standard deviation) of the response is equal for all levels of the predictor (or combination of predictors)"
  },
  {
    "objectID": "slides/02-mlr-review.html#assumptions-for-linear-regression-1",
    "href": "slides/02-mlr-review.html#assumptions-for-linear-regression-1",
    "title": "Review of multiple linear regression",
    "section": "Assumptions for linear regression",
    "text": "Assumptions for linear regression\n\n\n\n\n\n\n\nModified from Figure 1.1. in BMLR\n\n\n\n\n\n\nLinearity: Linear relationship between mean of the response \\(Y\\) and the predictor \\(X\\)\nIndependence: No connection between how far any two points lie from regression line\nNormality: Response \\(Y\\) follows a normal distribution at each level of the predictor \\(X\\) (red curves)\nEqual variance: Variance of the response \\(Y\\) is equal for all levels of the predictor \\(X\\)"
  },
  {
    "objectID": "slides/02-mlr-review.html#violations-in-assumptions",
    "href": "slides/02-mlr-review.html#violations-in-assumptions",
    "title": "Review of multiple linear regression",
    "section": "Violations in assumptions",
    "text": "Violations in assumptions\nDo wealthy households tend to have fewer children compared to households with lower income? Annual income and family size are recorded for a random sample of households.\n\nThe response variable is number of children in the household.\nThe predictor variable is annual income in US dollars.\n\n\nWhich assumption(s) are obviously violated, if any?"
  },
  {
    "objectID": "slides/02-mlr-review.html#violations-in-assumptions-1",
    "href": "slides/02-mlr-review.html#violations-in-assumptions-1",
    "title": "Review of multiple linear regression",
    "section": "Violations in assumptions",
    "text": "Violations in assumptions\nMedical researchers investigated the outcome of a particular surgery for patients with comparable stages of disease but different ages. The 10 hospitals in the study had at least two surgeons performing the surgery of interest. Patients were randomly selected for each surgeon at each hospital. The surgery outcome was recorded on a scale of 1 - 10.\n\nThe response variable is surgery outcome, 1 - 10.\nThe predictor variable is patient age in years.\n\n\nWhich assumption(s) are obviously violated, if any?"
  },
  {
    "objectID": "slides/02-mlr-review.html#beyond-linear-regression",
    "href": "slides/02-mlr-review.html#beyond-linear-regression",
    "title": "Review of multiple linear regression",
    "section": "Beyond linear regression",
    "text": "Beyond linear regression\n\n\nWhen drawing conclusions from linear regression models, we do so assuming LINE are all met\nGeneralized linear models require different assumptions and can accommodate violations in LINE\n\nRelationship between response and predictor(s) can be nonlinear\nResponse variable can be non-normal\nVariance in response can differ at each level of predictor(s)\nThe independence assumption still must hold!\n\nMultilevel models are used to model data that violate the independence assumption, i.e. correlated observations"
  },
  {
    "objectID": "slides/02-mlr-review.html#data-kentucky-derby-winners",
    "href": "slides/02-mlr-review.html#data-kentucky-derby-winners",
    "title": "Review of multiple linear regression",
    "section": "Data: Kentucky Derby Winners",
    "text": "Data: Kentucky Derby Winners\nToday’s data is from the Kentucky Derby, an annual 1.25-mile horse race held at the Churchill Downs race track in Louisville, KY. The data is in the file derbyplus.csv and contains information for races 1896 - 2017.\n\n\nResponse variable\n\nspeed: Average speed of the winner in feet per second (ft/s)\n\nAdditional variable\n\nwinner: Winning horse\n\n\nPredictor variables\n\nyear: Year of the race\ncondition: Condition of the track (good, fast, slow)\nstarters: Number of horses who raced\n\n\n\nGoal: Understand variability in average winner speed based on characteristics of the race."
  },
  {
    "objectID": "slides/02-mlr-review.html#data",
    "href": "slides/02-mlr-review.html#data",
    "title": "Review of multiple linear regression",
    "section": "Data",
    "text": "Data\n\nderby &lt;- read_csv(\"data/derbyplus.csv\")\n\n\nderby |&gt;\n  head(5) |&gt; kable()\n\n\n\n\nyear\nwinner\ncondition\nspeed\nstarters\n\n\n\n\n1896\nBen Brush\ngood\n51.66\n8\n\n\n1897\nTyphoon II\nslow\n49.81\n6\n\n\n1898\nPlaudit\ngood\n51.16\n4\n\n\n1899\nManuel\nfast\n50.00\n5\n\n\n1900\nLieut. Gibson\nfast\n52.28\n7"
  },
  {
    "objectID": "slides/02-mlr-review.html#data-science-workflow",
    "href": "slides/02-mlr-review.html#data-science-workflow",
    "title": "Review of multiple linear regression",
    "section": "Data science workflow",
    "text": "Data science workflow\n\nImage source: Wickham, Çetinkaya-Rundel, and Grolemund (2023)"
  },
  {
    "objectID": "slides/02-mlr-review.html#exploratory-data-analysis-eda",
    "href": "slides/02-mlr-review.html#exploratory-data-analysis-eda",
    "title": "Review of multiple linear regression",
    "section": "Exploratory data analysis (EDA)",
    "text": "Exploratory data analysis (EDA)\n\nOnce you’re ready for the statistical analysis, the first step should always be exploratory data analysis.\nThe EDA will help you\n\nbegin to understand the variables and observations\nidentify outliers or potential data entry errors\nbegin to see relationships between variables\nidentify the appropriate model and identify a strategy\n\nThe EDA is exploratory; formal modeling and statistical inference are used to draw conclusions."
  },
  {
    "objectID": "slides/02-mlr-review.html#univariate-eda",
    "href": "slides/02-mlr-review.html#univariate-eda",
    "title": "Review of multiple linear regression",
    "section": "Univariate EDA",
    "text": "Univariate EDA"
  },
  {
    "objectID": "slides/02-mlr-review.html#univariate-eda-code",
    "href": "slides/02-mlr-review.html#univariate-eda-code",
    "title": "Review of multiple linear regression",
    "section": "Univariate EDA code",
    "text": "Univariate EDA code\n\np1 &lt;- ggplot(data = derby, aes(x = speed)) + \n  geom_histogram(fill = colors$green, color = \"black\") + \n  labs(x = \"Winning speed (ft/s)\", y = \"Count\")\n\np2 &lt;- ggplot(data = derby, aes(x = starters)) + \n  geom_histogram(fill = colors$green, color = \"black\",\n                 binwidth = 2) + \n  labs(x = \"Starters\", y = \"Count\")\n\np3 &lt;- ggplot(data = derby, aes(x = condition)) +\n   geom_bar(fill = colors$green, color = \"black\", aes(x = ))\n\np1 + (p2 / p3) + \n  plot_annotation(title = \"Univariate data analysis\")"
  },
  {
    "objectID": "slides/02-mlr-review.html#bivariate-eda",
    "href": "slides/02-mlr-review.html#bivariate-eda",
    "title": "Review of multiple linear regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA"
  },
  {
    "objectID": "slides/02-mlr-review.html#bivariate-eda-code",
    "href": "slides/02-mlr-review.html#bivariate-eda-code",
    "title": "Review of multiple linear regression",
    "section": "Bivariate EDA code",
    "text": "Bivariate EDA code\n\np4 &lt;- ggplot(data = derby, aes(x = starters, y = speed)) + \n  geom_point() + \n  labs(x = \"Starters\", y = \"Speed (ft / s)\")\n\np5 &lt;- ggplot(data = derby, aes(x = year, y = speed)) + \n  geom_point() + \n  labs(x = \"Year\", y = \"Speed (ft / s)\")\n\np6 &lt;- ggplot(data = derby, aes(x = condition, y = speed)) + \n  geom_boxplot(fill = colors$green, color = \"black\") + \n  labs(x = \"Conditions\", y = \"Speed (ft / s)\")\n\n(p4 + p5) + p6 +\n  plot_annotation(title = \"Bivariate data analysis\")"
  },
  {
    "objectID": "slides/02-mlr-review.html#scatterplot-matrix",
    "href": "slides/02-mlr-review.html#scatterplot-matrix",
    "title": "Review of multiple linear regression",
    "section": "Scatterplot matrix",
    "text": "Scatterplot matrix\nA scatterplot matrix helps quickly visualize relationships between many variable pairs. They are particularly useful to identify potentially correlated predictors."
  },
  {
    "objectID": "slides/02-mlr-review.html#scatterplot-matrix-code",
    "href": "slides/02-mlr-review.html#scatterplot-matrix-code",
    "title": "Review of multiple linear regression",
    "section": "Scatterplot matrix code",
    "text": "Scatterplot matrix code\nCreate using the ggpairs() function in the GGally package.\n\nlibrary(GGally)\nggpairs(data = derby, \n        columns = c(\"condition\", \"year\", \"starters\", \"speed\"))"
  },
  {
    "objectID": "slides/02-mlr-review.html#multivariate-eda",
    "href": "slides/02-mlr-review.html#multivariate-eda",
    "title": "Review of multiple linear regression",
    "section": "Multivariate EDA",
    "text": "Multivariate EDA\nPlot the relationship between the response and a predictor based on levels of another predictor to assess potential interactions."
  },
  {
    "objectID": "slides/02-mlr-review.html#multivariate-eda-code",
    "href": "slides/02-mlr-review.html#multivariate-eda-code",
    "title": "Review of multiple linear regression",
    "section": "Multivariate EDA code",
    "text": "Multivariate EDA code\n\nlibrary(viridis)\nggplot(data = derby, aes(x = year, y = speed, color = condition, \n                         shape = condition, linetype = condition)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE, aes(linetype = condition)) + \n  labs(x = \"Year\", y = \"Speed (ft/s)\", color = \"Condition\",\n       title = \"Speed vs. year\", \n       subtitle = \"by track condition\") +\n  guides(lty = FALSE, shape = FALSE) +\n  scale_color_viridis_d(end = 0.9)"
  },
  {
    "objectID": "slides/02-mlr-review.html#candidate-models",
    "href": "slides/02-mlr-review.html#candidate-models",
    "title": "Review of multiple linear regression",
    "section": "Candidate models",
    "text": "Candidate models\nModel 1: Main effects model (year, condition, starters)\n\nmodel1 &lt;- lm(speed ~ starters + year + condition, data = derby)\n\n\n\nModel 2: Main effects + \\(year^2\\), the quadratic effect of year\n\nmodel2 &lt;- lm(speed ~ starters + year + I(year^2) + condition,\n             data = derby)\n\n\n\n\nModel 3: Main effects + interaction between year and condition\n\nmodel3 &lt;- lm(speed ~ starters + year + condition + year * condition, \n             data = derby)"
  },
  {
    "objectID": "slides/02-mlr-review.html#inference-for-regression-1",
    "href": "slides/02-mlr-review.html#inference-for-regression-1",
    "title": "Review of multiple linear regression",
    "section": "Inference for regression",
    "text": "Inference for regression\nWhen LINE assumptions are met… . . .\n\n\nUse least squares regression to obtain the estimates for the model coefficients \\(\\beta_0, \\beta_1, \\ldots, \\beta_j\\) and for \\(\\sigma^2\\)\n\\(\\hat{\\sigma}\\) is the regression standard error\n\\[\n\\hat{\\sigma} = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n - p - 1}} = \\sqrt{\\frac{\\sum_{i=1}^n e_i^2}{n-p-1}}\n\\]\nwhere \\(p\\) is the number of non-intercept terms in the model (e.g., \\(p = 1\\) in simple linear regression)\nGoal is to use estimated values to draw conclusions about \\(\\beta_j\\)\n\nUse \\(\\hat{\\sigma}\\) to calculate \\(SE_{\\hat{\\beta}_j}\\) . Click here for more detail."
  },
  {
    "objectID": "slides/02-mlr-review.html#hypothesis-testing-for-beta_j",
    "href": "slides/02-mlr-review.html#hypothesis-testing-for-beta_j",
    "title": "Review of multiple linear regression",
    "section": "Hypothesis testing for \\(\\beta_j\\)",
    "text": "Hypothesis testing for \\(\\beta_j\\)\n\nState the hypotheses. \\(H_0: \\beta_j = 0 \\text{ vs. } H_a: \\beta_j \\neq 0\\), given the other variables in the model.\n\n\n\nCalculate the test statistic.\n\n\\[\nt = \\frac{\\hat{\\beta}_j - 0}{SE_{\\hat{\\beta}_j}}\n\\]\n\n\n\nCalculate the p-value. The p-value is calculated from a \\(t\\) distribution with \\(n - p - 1\\) degrees of freedom.\n\\[\n\\text{p-value} = 2P(T &gt; |t|) \\hspace{4mm} T \\sim t_{n-p-1}\n\\]\n\n\n\n\nState the conclusion in context of the data.\n\nReject \\(H_0\\) if p-value is sufficiently small."
  },
  {
    "objectID": "slides/02-mlr-review.html#confidence-interval-for-beta_j",
    "href": "slides/02-mlr-review.html#confidence-interval-for-beta_j",
    "title": "Review of multiple linear regression",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\nThe \\(C\\%\\) confidence confidence interval for \\(\\beta_j\\) is\n\\[\\hat{\\beta}_j \\pm t^* \\times SE_{\\hat{\\beta}_j}\\]\nwhere the critical value \\(t^* \\sim t_{n-p-1}\\)\n\n\nGeneral interpretation for the confidence interval [LB, UB]:\nWe are \\(C\\%\\) confident that for every one unit increase in \\(x_j\\), the response is expected to change by LB to UB units, holding all else constant."
  },
  {
    "objectID": "slides/02-mlr-review.html#measures-of-model-performance",
    "href": "slides/02-mlr-review.html#measures-of-model-performance",
    "title": "Review of multiple linear regression",
    "section": "Measures of model performance",
    "text": "Measures of model performance\n\n\\(R^2\\): Proportion of variability in the response explained by the model\n\nWill always increase as predictors are added, so it shouldn’t be used to compare models\n\n\\(Adj. R^2\\): Similar to \\(R^2\\) with a penalty for extra terms\n\\(AIC\\): Likelihood-based approach balancing model performance and complexity\n\\(BIC\\): Similar to AIC with stronger penalty for extra terms"
  },
  {
    "objectID": "slides/02-mlr-review.html#model-summary-statistics",
    "href": "slides/02-mlr-review.html#model-summary-statistics",
    "title": "Review of multiple linear regression",
    "section": "Model summary statistics",
    "text": "Model summary statistics\nUse the glance() function to get model summary statistics\n\n\n\n\n\n\nmodel\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\nModel1\n0.730\n0.721\n259.478\n276.302\n\n\nModel2\n0.827\n0.819\n207.429\n227.057\n\n\nModel3\n0.751\n0.738\n253.584\n276.016\n\n\n\n\n\n\n\nWhich model do you choose based on these statistics?"
  },
  {
    "objectID": "slides/02-mlr-review.html#characteristics-of-a-good-final-model",
    "href": "slides/02-mlr-review.html#characteristics-of-a-good-final-model",
    "title": "Review of multiple linear regression",
    "section": "Characteristics of a “good” final model",
    "text": "Characteristics of a “good” final model\n\nModel can be used to answer primary research questions\nPredictor variables control for important covariates\nPotential interactions have been investigated\nVariables are centered, as needed, for more meaningful interpretations\nUnnecessary terms are removed\nAssumptions are met and influential points have been addressed\nModel tells a “persuasive story parsimoniously”\n\n\n\nList from Section 1.6.7 of Roback and Legler (2021)"
  },
  {
    "objectID": "slides/02-mlr-review.html#next-class",
    "href": "slides/02-mlr-review.html#next-class",
    "title": "Review of multiple linear regression",
    "section": "Next class",
    "text": "Next class\n\nUsing likelihoods\nSee Prepare for Jan 22 lecture"
  },
  {
    "objectID": "slides/04-poisson.html#computing-set-up",
    "href": "slides/04-poisson.html#computing-set-up",
    "title": "Poisson Regression",
    "section": "Computing set up",
    "text": "Computing set up\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(gridExtra)\n\n\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n\ncolors &lt;- tibble::tibble(green = \"#B5BA72\")"
  },
  {
    "objectID": "slides/04-poisson.html#topics",
    "href": "slides/04-poisson.html#topics",
    "title": "Poisson Regression",
    "section": "Topics",
    "text": "Topics\n\nDescribe properties of the Poisson random variable\nWrite the mathematical equation of the Poisson regression model\nDescribe how the Poisson regression differs from least-squares regression\nInterpret the coefficients for the Poisson regression model\nCompare two Poisson regression models\n\n\n\nNotes based on Section 4.4 - 4.5, and 4.9 of Roback and Legler (2021) unless noted otherwise."
  },
  {
    "objectID": "slides/04-poisson.html#scenarios-to-use-poisson-regression",
    "href": "slides/04-poisson.html#scenarios-to-use-poisson-regression",
    "title": "Poisson Regression",
    "section": "Scenarios to use Poisson regression",
    "text": "Scenarios to use Poisson regression\n\nDoes the number of employers conducting on-campus interviews during a year differ for public and private colleges?\nDoes the daily number of asthma-related visits to an Emergency Room differ depending on air pollution indices?\nDoes the number of paint defects per square foot of wall differ based on the years of experience of the painter?"
  },
  {
    "objectID": "slides/04-poisson.html#scenarios-to-use-poisson-regression-1",
    "href": "slides/04-poisson.html#scenarios-to-use-poisson-regression-1",
    "title": "Poisson Regression",
    "section": "Scenarios to use Poisson regression",
    "text": "Scenarios to use Poisson regression\n\nDoes the number of employers conducting on-campus interviews during a year differ for public and private colleges?\nDoes the daily number of asthma-related visits to an Emergency Room differ depending on air pollution indices?\nDoes the number of paint defects per square foot of wall differ based on the years of experience of the painter?\n\n\n\nEach response variable is a count per a unit of time or space."
  },
  {
    "objectID": "slides/04-poisson.html#poisson-distribution",
    "href": "slides/04-poisson.html#poisson-distribution",
    "title": "Poisson Regression",
    "section": "Poisson distribution",
    "text": "Poisson distribution\nLet \\(Y\\) be the number of events in a given unit of time or space. Then \\(Y\\) can be modeled using a Poisson distribution\n\\[P(Y=y) = \\frac{e^{-\\lambda}\\lambda^y}{y!} \\hspace{10mm} y=0,1,2,\\ldots, \\infty\\]\n\nFeatures\n\n\\(E(Y) = Var(Y) = \\lambda\\)\nThe distribution is typically skewed right, particularly if \\(\\lambda\\) is small\nThe distribution becomes more symmetric as \\(\\lambda\\) increases\n\nIf \\(\\lambda\\) is sufficiently large, it can be approximated using a normal distribution (Click here for an example.)"
  },
  {
    "objectID": "slides/04-poisson.html#example1",
    "href": "slides/04-poisson.html#example1",
    "title": "Poisson Regression",
    "section": "Example1",
    "text": "Example1\nThe annual number of earthquakes registering at least 2.5 on the Richter Scale and having an epicenter within 40 miles of downtown Memphis follows a Poisson distribution with mean 6.5. What is the probability there will be at 3 or fewer such earthquakes next year?\n\n\\[P(Y \\leq 3) = P(Y = 0) + P(Y = 1) + P(Y = 2) + P(Y = 3)\\]\n\n\n\\[ = \\frac{e^{-6.5}6.5^0}{0!} + \\frac{e^{-6.5}6.5^1}{1!} + \\frac{e^{-6.5}6.5^2}{2!} + \\frac{e^{-6.5}6.5^3}{3!}\\]\n\\[ = 0.112\\]\n\n\n\nppois(3, 6.5)\n\n[1] 0.1118496\n\n\n\nExample adapted from Introduction to Probability Theory Example 28-2"
  },
  {
    "objectID": "slides/04-poisson.html#the-data-household-size-in-the-philippines",
    "href": "slides/04-poisson.html#the-data-household-size-in-the-philippines",
    "title": "Poisson Regression",
    "section": "The data: Household size in the Philippines",
    "text": "The data: Household size in the Philippines\nThe data fHH1.csv come from the 2015 Family Income and Expenditure Survey conducted by the Philippine Statistics Authority.\nGoal: Understand the association between household size and various characteristics of the household\nResponse:\n\ntotal: Number of people in the household other than the head\n\n\n\nPredictors:\n\nlocation: Where the house is located\nage: Age of the head of household\nroof: Type of roof on the residence (proxy for wealth)\n\n\nOther variables:\n\nnumLT5: Number in the household under 5 years old"
  },
  {
    "objectID": "slides/04-poisson.html#the-data",
    "href": "slides/04-poisson.html#the-data",
    "title": "Poisson Regression",
    "section": "The data",
    "text": "The data\n\nhh_data &lt;- read_csv(\"data/fHH1.csv\")\nhh_data |&gt; slice(1:5) |&gt; kable()\n\n\n\n\nlocation\nage\ntotal\nnumLT5\nroof\n\n\n\n\nCentralLuzon\n65\n0\n0\nPredominantly Strong Material\n\n\nMetroManila\n75\n3\n0\nPredominantly Strong Material\n\n\nDavaoRegion\n54\n4\n0\nPredominantly Strong Material\n\n\nVisayas\n49\n3\n0\nPredominantly Strong Material\n\n\nMetroManila\n74\n3\n0\nPredominantly Strong Material"
  },
  {
    "objectID": "slides/04-poisson.html#response-variable",
    "href": "slides/04-poisson.html#response-variable",
    "title": "Poisson Regression",
    "section": "Response variable",
    "text": "Response variable\n\n\n\n\n\n\nmean\nvar\n\n\n\n\n3.685\n5.534"
  },
  {
    "objectID": "slides/04-poisson.html#why-the-least-squares-model-doesnt-work",
    "href": "slides/04-poisson.html#why-the-least-squares-model-doesnt-work",
    "title": "Poisson Regression",
    "section": "Why the least-squares model doesn’t work",
    "text": "Why the least-squares model doesn’t work\nThe goal is to model \\(\\lambda\\), the expected number of people in the household (other than the head), as a function of the predictors (covariates)\n\nWe might be tempted to try a linear model \\[\\lambda_i = \\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + \\dots + \\beta_px_{ip}\\]\n\n\nThis model won’t work because…\n\nIt could produce negative values of \\(\\lambda\\) for certain values of the predictors\nThe equal variance assumption required to conduct inference for linear regression is violated."
  },
  {
    "objectID": "slides/04-poisson.html#poisson-regression-model",
    "href": "slides/04-poisson.html#poisson-regression-model",
    "title": "Poisson Regression",
    "section": "Poisson regression model",
    "text": "Poisson regression model\nIf \\(Y_i \\sim Poisson\\) with \\(\\lambda = \\lambda_i\\) for the given values \\(x_{i1}, \\ldots, x_{ip}\\), then\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_p x_{ip}\\]\n\n\nEach observation can have a different value of \\(\\lambda\\) based on its value of the predictors \\(x_1, \\ldots, x_p\\)\n\\(\\lambda\\) determines the mean and variance, so we don’t need to estimate a separate error term"
  },
  {
    "objectID": "slides/04-poisson.html#poisson-vs.-multiple-linear-regression",
    "href": "slides/04-poisson.html#poisson-vs.-multiple-linear-regression",
    "title": "Poisson Regression",
    "section": "Poisson vs. multiple linear regression",
    "text": "Poisson vs. multiple linear regression\n\n\n\n\n\nRegression models: Linear regression (left) and Poisson regression (right).\n\n\n\n\n\n\nFigures recreated from BMLR Figure 4.1"
  },
  {
    "objectID": "slides/04-poisson.html#assumptions-for-poisson-regression",
    "href": "slides/04-poisson.html#assumptions-for-poisson-regression",
    "title": "Poisson Regression",
    "section": "Assumptions for Poisson regression",
    "text": "Assumptions for Poisson regression\n\n\nPoisson response: The response variable is a count per unit of time or space, described by a Poisson distribution, at each level of the predictor(s)\nIndependence: The observations must be independent of one another\nMean = Variance: The mean must equal the variance\nLinearity: The log of the mean rate, \\(\\log(\\lambda)\\), must be a linear function of the predictor(s)"
  },
  {
    "objectID": "slides/04-poisson.html#model-1-household-vs.-age",
    "href": "slides/04-poisson.html#model-1-household-vs.-age",
    "title": "Poisson Regression",
    "section": "Model 1: Household vs. Age",
    "text": "Model 1: Household vs. Age\n\nmodel1 &lt;- glm(total ~ age, data = hh_data, family = poisson)\n\ntidy(model1) |&gt; \n  kable(digits = 4)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n1.5499\n0.0503\n30.8290\n0\n\n\nage\n-0.0047\n0.0009\n-5.0258\n0\n\n\n\n\n\n\\[\\log(\\hat{\\lambda}) = 1.5499  - 0.0047 ~ age\\]"
  },
  {
    "objectID": "slides/04-poisson.html#is-the-coefficient-of-age-statistically-significant",
    "href": "slides/04-poisson.html#is-the-coefficient-of-age-statistically-significant",
    "title": "Poisson Regression",
    "section": "Is the coefficient of age statistically significant?",
    "text": "Is the coefficient of age statistically significant?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n1.5499\n0.0503\n30.8290\n0\n1.4512\n1.6482\n\n\nage\n-0.0047\n0.0009\n-5.0258\n0\n-0.0065\n-0.0029\n\n\n\n\n\n\\[H_0: \\beta_1 = 0 \\hspace{2mm} \\text{ vs. } \\hspace{2mm} H_a: \\beta_1 \\neq 0\\]\n\nTest statistic\n\\[Z = \\frac{\\hat{\\beta}_1 - 0}{SE(\\hat{\\beta}_1)} = \\frac{-0.0047 - 0}{0.0009} = -5.026 \\text{ (using exact values)}\\]\n\n\nP-value\n\\[P(|Z| &gt; |-5.026|) = 5.01 \\times 10^{-7} \\approx 0\\]"
  },
  {
    "objectID": "slides/04-poisson.html#what-are-plausible-values-for-the-coefficient-of-age",
    "href": "slides/04-poisson.html#what-are-plausible-values-for-the-coefficient-of-age",
    "title": "Poisson Regression",
    "section": "What are plausible values for the coefficient of age?",
    "text": "What are plausible values for the coefficient of age?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n1.5499\n0.0503\n30.8290\n0\n1.4512\n1.6482\n\n\nage\n-0.0047\n0.0009\n-5.0258\n0\n-0.0065\n-0.0029\n\n\n\n\n\n95% confidence interval for the coefficient of age\n\\[\\hat{\\beta}_1 \\pm z^{*}\\times SE(\\hat{\\beta}_1)\\]\nwhere \\(z^* \\sim N(0, 1)\\) \\[-0.0047 \\pm 1.96 \\times 0.0009 = \\mathbf{(-.0065, -0.0029)}\\]\n\nInterpret the interval in terms of the change in mean household size."
  },
  {
    "objectID": "slides/04-poisson.html#which-plot-can-best-help-us-determine-whether-model-1-is-a-good-fit",
    "href": "slides/04-poisson.html#which-plot-can-best-help-us-determine-whether-model-1-is-a-good-fit",
    "title": "Poisson Regression",
    "section": "Which plot can best help us determine whether Model 1 is a good fit?",
    "text": "Which plot can best help us determine whether Model 1 is a good fit?"
  },
  {
    "objectID": "slides/04-poisson.html#model-2-add-a-quadratic-effect-for-age",
    "href": "slides/04-poisson.html#model-2-add-a-quadratic-effect-for-age",
    "title": "Poisson Regression",
    "section": "Model 2: Add a quadratic effect for age",
    "text": "Model 2: Add a quadratic effect for age\n\nhh_data &lt;- hh_data |&gt; \n  mutate(age2 = age*age)\n\nmodel2 &lt;- glm(total ~ age + age2, data = hh_data, family = poisson)\ntidy(model2, conf.int = T) |&gt; \n  kable(digits = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.3325\n0.1788\n-1.8594\n0.063\n-0.6863\n0.0148\n\n\nage\n0.0709\n0.0069\n10.2877\n0.000\n0.0575\n0.0845\n\n\nage2\n-0.0007\n0.0001\n-11.0578\n0.000\n-0.0008\n-0.0006"
  },
  {
    "objectID": "slides/04-poisson.html#model-2-add-a-quadratic-effect-for-age-1",
    "href": "slides/04-poisson.html#model-2-add-a-quadratic-effect-for-age-1",
    "title": "Poisson Regression",
    "section": "Model 2: Add a quadratic effect for age",
    "text": "Model 2: Add a quadratic effect for age\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.3325\n0.1788\n-1.8594\n0.063\n-0.6863\n0.0148\n\n\nage\n0.0709\n0.0069\n10.2877\n0.000\n0.0575\n0.0845\n\n\nage2\n-0.0007\n0.0001\n-11.0578\n0.000\n-0.0008\n-0.0006\n\n\n\n\n\nWe can determine whether to keep \\(age^2\\) in the model in two ways:\n1️⃣ Use the p-value (or confidence interval) for the coefficient (since we are adding a single term to the model)\n2️⃣ Conduct a drop-in-deviance test"
  },
  {
    "objectID": "slides/04-poisson.html#deviance",
    "href": "slides/04-poisson.html#deviance",
    "title": "Poisson Regression",
    "section": "Deviance",
    "text": "Deviance\nA deviance is a way to measure how the observed data differs (deviates) from the model predictions.\n\nIt’s a measure unexplained variability in the response variable (similar to SSE in linear regression )\nLower deviance means the model is a better fit to the data\n\n\nWe can calculate the “deviance residual” for each observation in the data (more on the formula later). Let \\((\\text{deviance residual}_i\\) be the deviance residual for the \\(i^{th}\\) observation, then\n\\[\\text{deviance} = \\sum(\\text{deviance residual})_i^2\\]\nNote: Deviance is also known as the “residual deviance”"
  },
  {
    "objectID": "slides/04-poisson.html#drop-in-deviance-test",
    "href": "slides/04-poisson.html#drop-in-deviance-test",
    "title": "Poisson Regression",
    "section": "Drop-in-Deviance Test",
    "text": "Drop-in-Deviance Test\nWe can use a drop-in-deviance test to compare two models. To conduct the test\n1️⃣ Compute the deviance for each model\n2️⃣ Calculate the drop in deviance\n\\[\\text{drop-in-deviance =  Deviance(reduced model) - Deviance(larger model)}\\]\n3️⃣ Given the reduced model is the true model \\((H_0 \\text{ true})\\), then \\[\\text{drop-in-deviance} \\sim \\chi_d^2\\]\nwhere \\(d\\) is the difference in degrees of freedom between the two models (i.e., the difference in number of terms)"
  },
  {
    "objectID": "slides/04-poisson.html#drop-in-deviance-to-compare-model1-and-model2",
    "href": "slides/04-poisson.html#drop-in-deviance-to-compare-model1-and-model2",
    "title": "Poisson Regression",
    "section": "Drop-in-deviance to compare Model1 and Model2",
    "text": "Drop-in-deviance to compare Model1 and Model2\n\nanova(model1, model2, test = \"Chisq\") |&gt;\n  kable(digits = 3)\n\n\n\n\nResid. Df\nResid. Dev\nDf\nDeviance\nPr(&gt;Chi)\n\n\n\n\n1498\n2337.089\nNA\nNA\nNA\n\n\n1497\n2200.944\n1\n136.145\n0\n\n\n\n\n\n\n\nWrite the null and alternative hypotheses.\nWhat does the value 2337.089 tell you?\nWhat does the value 1 tell you?\nWhat is your conclusion?"
  },
  {
    "objectID": "slides/04-poisson.html#add-location-to-the-model",
    "href": "slides/04-poisson.html#add-location-to-the-model",
    "title": "Poisson Regression",
    "section": "Add location to the model?",
    "text": "Add location to the model?\nSuppose we want to add location to the model, so we compare the following models:\nModel A: \\(\\lambda_i = \\beta_0 + \\beta_1 ~ age_i + \\beta_2 ~ age_i^2\\)\nModel B: \\(\\lambda_i = \\beta_0 + \\beta_1 ~ age_i + \\beta_2 ~ age_i^2 + \\beta_3 ~ Loc1_i + \\beta_4 ~ Loc2_i + \\beta_5 ~ Loc3_i + \\beta_6 ~ Loc4_i\\)\n\nWhich of the following are reliable ways to determine if location should be added to the model?\n\nDrop-in-deviance test\nUse the p-value for each coefficient\nLikelihood ratio test\nNested F Test\nBIC"
  },
  {
    "objectID": "slides/04-poisson.html#looking-ahead",
    "href": "slides/04-poisson.html#looking-ahead",
    "title": "Poisson Regression",
    "section": "Looking ahead",
    "text": "Looking ahead\n\nFor next time - Chapter 4 - Poisson Regression\n\nSections 4.6, 4.10"
  },
  {
    "objectID": "slides/04-poisson.html#references",
    "href": "slides/04-poisson.html#references",
    "title": "Poisson Regression",
    "section": "References",
    "text": "References\n\n\n\n\n🔗 STA 310 - Spring 2024\n\n\n\n\nRoback, Paul, and Julie Legler. 2021. Beyond multiple linear regression: applied generalized linear models and multilevel models in R. CRC Press."
  },
  {
    "objectID": "slides/07-glm-theory.html#announcements",
    "href": "slides/07-glm-theory.html#announcements",
    "title": "Unifying theory of GLMs",
    "section": "Announcements",
    "text": "Announcements\n\nHW 02 due Wed, Feb 07 at 11:59pm\nProject 01\n\npresentations in class Wed, Feb 14\nwrite up due Thu, Feb 15 at noon"
  },
  {
    "objectID": "slides/07-glm-theory.html#topics",
    "href": "slides/07-glm-theory.html#topics",
    "title": "Unifying theory of GLMs",
    "section": "Topics",
    "text": "Topics\n\nIdentify the components common to all generalized linear models\nFind the canonical link based on the distribution of the response variable\nProperties of GLMs\n\n\n\nNotes based on Chapter 5 Roback and Legler (2021) unless noted otherwise."
  },
  {
    "objectID": "slides/07-glm-theory.html#many-models-one-family",
    "href": "slides/07-glm-theory.html#many-models-one-family",
    "title": "Unifying theory of GLMs",
    "section": "Many models; one family",
    "text": "Many models; one family\nWe have studied models for a variety of response variables\n\nLeast squares (Normal)\nLogistic (Bernoulli, Binomial, Multinomial)\nLog-linear (Poisson, Negative Binomial)\n\nThese models are all examples of generalized linear models.\nGLMs have a similar structure for their likelihoods, MLEs, variances, so we can use a generalized approach to find the model estimates and associated uncertainty."
  },
  {
    "objectID": "slides/07-glm-theory.html#components-of-a-glm",
    "href": "slides/07-glm-theory.html#components-of-a-glm",
    "title": "Unifying theory of GLMs",
    "section": "Components of a GLM",
    "text": "Components of a GLM\nNelder and Wedderburn (1972) defines a broad class of models called generalized linear models that generalizes multiple linear regression. GLMs are characterized by three components:\n\n\n1️⃣ Response variable with parameter \\(\\theta\\) whose probability function can be written in exponential family form (random component)\n\n\n\n2️⃣ A linear combination of predictors, \\(\\eta = \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\) (systematic component)\n\n\n\n3️⃣ A link function \\(g(\\theta)\\) that connects \\(\\theta\\) to \\(\\eta\\)"
  },
  {
    "objectID": "slides/07-glm-theory.html#one-parameter-exponential-family-form",
    "href": "slides/07-glm-theory.html#one-parameter-exponential-family-form",
    "title": "Unifying theory of GLMs",
    "section": "One-parameter exponential family form",
    "text": "One-parameter exponential family form\nSuppose a probability (mass or density) function has a parameter \\(\\theta\\). It is said to have a one-parameter exponential family form if\n\n✅ The support (set of possible values) does not depend on \\(\\theta\\), and\n✅ The probability function can be written in the following form\n\\[f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}\\]"
  },
  {
    "objectID": "slides/07-glm-theory.html#mean-and-variance",
    "href": "slides/07-glm-theory.html#mean-and-variance",
    "title": "Unifying theory of GLMs",
    "section": "Mean and variance",
    "text": "Mean and variance\nOn-parameter exponential family form\n\\[f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}\\]\nUsing this form:\n\n\\[E(Y) = -\\frac{c'(\\theta)}{b'(\\theta)} \\hspace{20mm} Var(Y) = \\frac{b''(\\theta)c'(\\theta) - c''(\\theta)b'(\\theta)}{[b'(\\theta)]^3}\\]"
  },
  {
    "objectID": "slides/07-glm-theory.html#poisson-in-one-parameter-exponential-family-form",
    "href": "slides/07-glm-theory.html#poisson-in-one-parameter-exponential-family-form",
    "title": "Unifying theory of GLMs",
    "section": "Poisson in one-parameter exponential family form",
    "text": "Poisson in one-parameter exponential family form\n\\[P(Y = y) = \\frac{e^{-\\lambda}\\lambda^y}{y!} \\hspace{10mm} y = 0, 1, 2, \\ldots, \\infty\\]\n\n\\[\\begin{aligned}P(Y = y) &= e^{-\\lambda}e^{y\\log(\\lambda)}e^{-\\log(y!)}\\\\\n& = e^{y\\log(\\lambda) - \\lambda - \\log(y!)}\\end{aligned}\\]\n\n\nRecall the form: \\(f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}\\), where the parameter \\(\\theta = \\lambda\\) for the Poisson distribution\n\n\n\n\\(a(y) = y\\)\n\\(b(\\lambda) = \\log(\\lambda)\\)\n\\(c(\\lambda) = -\\lambda\\)\n\\(d(y) = -\\log(y!)\\)"
  },
  {
    "objectID": "slides/07-glm-theory.html#poisson-in-exponential-family-form",
    "href": "slides/07-glm-theory.html#poisson-in-exponential-family-form",
    "title": "Unifying theory of GLMs",
    "section": "Poisson in exponential family form",
    "text": "Poisson in exponential family form\n✅ The support for the Poisson distribution is \\(y = 0, 1, 2, \\ldots, \\infty\\). This does not depend on the parameter \\(\\lambda\\).\n\n✅ The probability mass function can be written in the form \\(f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}\\)\n\n\n\nThe Poisson distribution can be written in one-parameter exponential family form."
  },
  {
    "objectID": "slides/07-glm-theory.html#canonical-link",
    "href": "slides/07-glm-theory.html#canonical-link",
    "title": "Unifying theory of GLMs",
    "section": "Canonical link",
    "text": "Canonical link\nSuppose there is a response variable \\(Y\\) from a distribution with parameter \\(\\theta\\) and a set of predictors that can be written as a linear combination \\(\\eta = \\beta_0 + \\sum_{j=1}^{p}\\beta_jx_j = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\)\n\n\nA link function, \\(g()\\), is a monotonic and differentiable function that connects \\(\\theta\\) to \\(\\eta\\)\nWhen working with a member of the one-parameter exponential family, \\(b(\\theta)\\) is called the canonical link\n\nMost commonly used link function"
  },
  {
    "objectID": "slides/07-glm-theory.html#canonical-link-for-poisson",
    "href": "slides/07-glm-theory.html#canonical-link-for-poisson",
    "title": "Unifying theory of GLMs",
    "section": "Canonical link for Poisson",
    "text": "Canonical link for Poisson\nRecall the exponential family form:\n\\[P(Y = y) = e^{y\\log(\\lambda) - \\lambda - \\log(y!)}\\]\n\n\nthen the canonical link is \\(b(\\lambda) = \\log(\\lambda)\\)"
  },
  {
    "objectID": "slides/07-glm-theory.html#glm-framework-poisson-response-variable",
    "href": "slides/07-glm-theory.html#glm-framework-poisson-response-variable",
    "title": "Unifying theory of GLMs",
    "section": "GLM framework: Poisson response variable",
    "text": "GLM framework: Poisson response variable\n1️⃣ Response variable with parameter \\(\\theta\\) whose probability function can be written in exponential family form\n\\[P(Y = y) = e^{y\\log(\\lambda) - \\lambda - \\log(y!)}\\]\n\n2️⃣ A linear combination of predictors, \\[\\eta = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\]\n\n3️⃣ A function \\(g(\\lambda)\\) that connects \\(\\lambda\\) and \\(\\eta\\)\n\\[\\log(\\lambda) = \\eta =  \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\]"
  },
  {
    "objectID": "slides/07-glm-theory.html#activity-generalized-linear-models",
    "href": "slides/07-glm-theory.html#activity-generalized-linear-models",
    "title": "Unifying theory of GLMs",
    "section": "Activity: Generalized linear models",
    "text": "Activity: Generalized linear models\n\nFor your group’s distribution\n\nWrite the pmf or pdf in one-parameter exponential form.\nDescribe an example of a setting where this random variable may be used.\nIdentify the canonical link function."
  },
  {
    "objectID": "slides/07-glm-theory.html#activity-generalized-linear-models-1",
    "href": "slides/07-glm-theory.html#activity-generalized-linear-models-1",
    "title": "Unifying theory of GLMs",
    "section": "Activity: Generalized linear models",
    "text": "Activity: Generalized linear models\n\nDistributions\n\nExponential\nGamma (with fixed \\(r\\))\nGeometric\nBinary\n\nSee BMLR - Section 3.6 for details on the distributions.\n\nIf your group finishes early, try completing the exercise for another distribution.\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "slides/07-glm-theory.html#using-the-exponential-family-form",
    "href": "slides/07-glm-theory.html#using-the-exponential-family-form",
    "title": "Unifying theory of GLMs",
    "section": "Using the exponential family form",
    "text": "Using the exponential family form\nThe one-parameter exponential family form is utilized for\n\nCalculating MLEs of coefficients (recall iteratively reweighted least squares)\nInference for coefficients\nLikelihood ratio and drop-in-deviance tests\n\nThe specific calculations are beyond the scope of this course. See Section 4.6 of Dunn, Smyth, et al. (2018) for more detail (available at Duke library)."
  },
  {
    "objectID": "slides/07-logistic-intro.html#topics",
    "href": "slides/07-logistic-intro.html#topics",
    "title": "Logistic regression",
    "section": "Topics",
    "text": "Topics\n\nIdentify Bernoulli and binomial random variables\nWrite GLM for binomial response variable\nInterpret the coefficients for a logistic regression model\n\n\n\nNotes based on Chapter 6 Roback and Legler (2021) unless noted otherwise."
  },
  {
    "objectID": "slides/07-logistic-intro.html#bernoulli-binomial-random-variables",
    "href": "slides/07-logistic-intro.html#bernoulli-binomial-random-variables",
    "title": "Logistic regression",
    "section": "Bernoulli + Binomial random variables",
    "text": "Bernoulli + Binomial random variables\nLogistic regression is used to analyze data with two types of responses:\n\n\nBinary: These responses take on two values success \\((Y = 1)\\) or failure \\((Y = 0)\\), yes \\((Y = 1)\\) or no \\((Y = 0)\\), etc.\n\n\\[P(Y = y) = p^y(1-p)^{1-y} \\hspace{10mm} y = 0, 1\\]\n\nBinomial: Number of successes in a Bernoulli process, \\(n\\) independent trials with a constant probability of success \\(p\\).\n\n\\[P(Y = y) = {n \\choose y}p^{y}(1-p)^{n - y} \\hspace{10mm} y = 0, 1, \\ldots, n\\]\n\n\nIn both instances, the goal is to model \\(p\\) the probability of success."
  },
  {
    "objectID": "slides/07-logistic-intro.html#binary-vs.-binomial-data",
    "href": "slides/07-logistic-intro.html#binary-vs.-binomial-data",
    "title": "Logistic regression",
    "section": "Binary vs. Binomial data",
    "text": "Binary vs. Binomial data\n\nFor each example, identify if the response is a Bernoulli or Binomial response:\n\nUse median age and unemployment rate in a county to predict the percent of Obama votes in the county in the 2008 presidential election.\nUse GPA and MCAT scores to estimate the probability a student is accepted into medical school.\nUse sex, age, and smoking history to estimate the probability an individual has lung cancer.\nUse offensive and defensive statistics from the 2017-2018 NBA season to predict a team’s winning percentage.\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/07-logistic-intro.html#logistic-regression-model",
    "href": "slides/07-logistic-intro.html#logistic-regression-model",
    "title": "Logistic regression",
    "section": "Logistic regression model",
    "text": "Logistic regression model\n\\[\n\\log\\Big(\\frac{p}{1-p}\\Big) = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_px_p\n\\]\n\n\nThe response variable, \\(\\log\\Big(\\frac{p}{1-p}\\Big)\\), is the log(odds) of success, i.e. the logit\n\n\n\n\nUse the model to calculate the probability of success \\[\\hat{p} = \\frac{e^{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_px_p}}{1 + e^{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_px_p}}\\]\n\n\n\n\nWhen the response is a Bernoulli random variable, the probabilities can be used to classify each observation as a success or failure"
  },
  {
    "objectID": "slides/07-logistic-intro.html#logistic-vs-linear-regression-model",
    "href": "slides/07-logistic-intro.html#logistic-vs-linear-regression-model",
    "title": "Logistic regression",
    "section": "Logistic vs linear regression model",
    "text": "Logistic vs linear regression model\n\nGraph from BMLR Chapter 6"
  },
  {
    "objectID": "slides/07-logistic-intro.html#logit-link",
    "href": "slides/07-logistic-intro.html#logit-link",
    "title": "Logistic regression",
    "section": "Logit link",
    "text": "Logit link\nBernoulli and Binomial random variables can be written in one-parameter exponential family form, \\(f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}\\)\nBernoulli\n\\[f(y;p) = e^{y\\log(\\frac{p}{1-p}) + \\log(1-p)}\\]\nBinomial\n\\[f(y;n,p) = e^{y\\log(\\frac{p}{1-p}) + n\\log(1-p) + \\log{n \\choose y}}\\]\n\nThey have the same canonical link \\(b(p) = \\log\\big(\\frac{p}{1-p}\\big)\\)"
  },
  {
    "objectID": "slides/07-logistic-intro.html#assumptions-for-logistic-regression",
    "href": "slides/07-logistic-intro.html#assumptions-for-logistic-regression",
    "title": "Logistic regression",
    "section": "Assumptions for logistic regression",
    "text": "Assumptions for logistic regression\nThe following assumptions need to be satisfied to use logistic regression to make inferences\n1️⃣ \\(\\hspace{0.5mm}\\) Binary response: The response is dichotomous (has two possible outcomes) or is the sum of dichotomous responses\n\n\n2️⃣ \\(\\hspace{0.5mm}\\) Independence: The observations must be independent of one another\n\n\n\n3️⃣ \\(\\hspace{0.5mm}\\) Variance structure: Variance of a binomial random variable is \\(np(1-p)\\) \\((n = 1 \\text{ for Bernoulli})\\) , so the variability is highest when \\(p = 0.5\\)\n\n\n\n4️⃣ \\(\\hspace{0.5mm}\\) Linearity: The log of the odds ratio, \\(\\log\\big(\\frac{p}{1-p}\\big)\\), must be a linear function of the predictors \\(x_1, \\ldots, x_p\\)"
  },
  {
    "objectID": "slides/07-logistic-intro.html#covid-19-infection-prevention-practices-at-food-establishments",
    "href": "slides/07-logistic-intro.html#covid-19-infection-prevention-practices-at-food-establishments",
    "title": "Logistic regression",
    "section": "COVID-19 infection prevention practices at food establishments",
    "text": "COVID-19 infection prevention practices at food establishments\nResearchers at Wollo Univeristy in Ethiopia conducted a study in July and August 2020 to understand factors associated with good COVID-19 infection prevention practices at food establishments. Their study is published in Andualem et al. (2022) .\n\nThey were particularly interested in the understanding implementation of prevention practices at food establishments, given the workers’ increased risk due to daily contact with customers."
  },
  {
    "objectID": "slides/07-logistic-intro.html#the-data",
    "href": "slides/07-logistic-intro.html#the-data",
    "title": "Logistic regression",
    "section": "The data",
    "text": "The data\n“An institution-based cross-sectional study was conducted among 422 food handlers in Dessie City and Kombolcha Town food and drink establishments in July and August 2020. The study participants were selected using a simple random sampling technique. Data were collected by trained data collectors using a pretested structured questionnaire and an on-the-spot observational checklist.”"
  },
  {
    "objectID": "slides/07-logistic-intro.html#response-variable",
    "href": "slides/07-logistic-intro.html#response-variable",
    "title": "Logistic regression",
    "section": "Response variable",
    "text": "Response variable\n“The outcome variable of this study was the good or poor practices of COVID-19 infection prevention among food handlers. Nine yes/no questions, one observational checklist and five multiple choice infection prevention practices questions were asked with a minimum score of 1 and maximum score of 25. Good infection prevention practice (the variable of interest) was determined for food handlers who scored 75% or above, whereas poor infection prevention practices refers to those food handlers who scored below 75% on the practice questions.”"
  },
  {
    "objectID": "slides/07-logistic-intro.html#results",
    "href": "slides/07-logistic-intro.html#results",
    "title": "Logistic regression",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "slides/07-logistic-intro.html#interpreting-the-results",
    "href": "slides/07-logistic-intro.html#interpreting-the-results",
    "title": "Logistic regression",
    "section": "Interpreting the results",
    "text": "Interpreting the results\n\n\nIs the response a Bernoulli or Binomial?\nWhat is the strongest predictor of having good COVID-19 infection prevention practices?\n\nIt’s often unreliable to look answer this question just based on the model output. Why are we able to answer this question based on the model output in this case?\n\nDescribe the effect (coefficient interpretation and inference) of having COVID-19 infection prevention policies available at the food establishment.\nThe intercept describes what group of food handlers?\n\n\n\n\n\n−+\n04:30"
  },
  {
    "objectID": "slides/07-logistic-intro.html#references",
    "href": "slides/07-logistic-intro.html#references",
    "title": "Logistic regression",
    "section": "References",
    "text": "References\n\n\n\n\n🔗 STA 310 - Spring 2024\n\n\n\n\nAndualem, Atsedemariam, Belachew Tegegne, Sewunet Ademe, Tarikuwa Natnael, Gete Berihun, Masresha Abebe, Yeshiwork Alemnew, et al. 2022. “COVID-19 Infection Prevention Practices Among a Sample of Food Handlers of Food and Drink Establishments in Ethiopia.” PLoS One 17 (1): e0259851.\n\n\nRoback, Paul, and Julie Legler. 2021. Beyond multiple linear regression: applied generalized linear models and multilevel models in R. CRC Press."
  },
  {
    "objectID": "slides/01-welcome.html#teaching-team",
    "href": "slides/01-welcome.html#teaching-team",
    "title": "Welcome to STA 310!",
    "section": "Teaching Team",
    "text": "Teaching Team\n\n\nInstructor:\nProfessor Maria Tackett\nOld Chem 118B\nmaria.tackett@duke.edu\n\nTeaching assistant\nHun Kang\nPhD student in statistics"
  },
  {
    "objectID": "slides/01-welcome.html#course-logistics",
    "href": "slides/01-welcome.html#course-logistics",
    "title": "Welcome to STA 310!",
    "section": "Course logistics",
    "text": "Course logistics\nLectures\nMondays and Wednesdays, 3:05 - 4:20pm, Physics 205\n\nLabs\nLab 01: Thursdays, 3:05 - 4:20pm, Link #5\nLab 02: Thursdays, 4:45- 5:55pm, Link #5"
  },
  {
    "objectID": "slides/01-welcome.html#generalized-linear-models",
    "href": "slides/01-welcome.html#generalized-linear-models",
    "title": "Welcome to STA 310!",
    "section": "Generalized Linear Models",
    "text": "Generalized Linear Models\nIn statistics, a generalized linear model (GLM) is a flexible generalization of ordinary linear regression. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.1\n\nExample: Logistic regression\n\\[\\begin{aligned}\\pi = P(y = 1 | x) \\hspace{2mm} &\\Rightarrow \\hspace{2mm} \\text{Link function: } \\log\\big(\\frac{\\pi}{1-\\pi}\\big) \\\\\n&\\Rightarrow \\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1~x\\end{aligned}\\]\n\nSouce: Generalized linear model"
  },
  {
    "objectID": "slides/01-welcome.html#course-learning-objectives",
    "href": "slides/01-welcome.html#course-learning-objectives",
    "title": "Welcome to STA 310!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to …\n\n\ndescribe generalized linear models (GLMs) as a unified framework.\nexplain how specific models fit into the GLM framework, including extensions for correlated data.\nidentify the appropriate model given the data and analysis objective.\nanalyze real-world data by fitting and interpreting GLMs.\nuse R for analysis, Quarto to write reports, git for version control, and GitHub for collaboration.\neffectively communicate results from statistical analyses to a general audience in writing and oral presentations."
  },
  {
    "objectID": "slides/01-welcome.html#course-topics",
    "href": "slides/01-welcome.html#course-topics",
    "title": "Welcome to STA 310!",
    "section": "Course topics",
    "text": "Course topics\nGeneralized Linear Models\n\nIntroduce models for non-normal response variables\nEstimation, interpretation, and inference\nMathematical details of GLMs as a unified framework\n\n\nModeling correlated data\n\nIntroduce multilevel models for correlated and longitudinal data\nEstimation, interpretation, and inference\nMathematical details, particularly diving into covariance structures"
  },
  {
    "objectID": "slides/01-welcome.html#glms-in-practice",
    "href": "slides/01-welcome.html#glms-in-practice",
    "title": "Welcome to STA 310!",
    "section": "GLMs in practice",
    "text": "GLMs in practice\n\n\n\n\n\n“…we used negative binomial regression to model the association between the number of questions produced, race, and group after adjusting for the additional covariates age and years of education. Poisson and zero-inflated Poisson regression models were also considered…the negative binomial model was a good fit for the data given the overdispersion in the distribution of number of questions asked.”1\nFannin, D. K., Elleby, J., Tackett, M., & Minga, J. (2023). Intersectionality of Race and Question-Asking in Women After Right Hemisphere Brain Damage. Journal of Speech, Language, and Hearing Research, 66(1), 314-324."
  },
  {
    "objectID": "slides/01-welcome.html#glms-in-practice-1",
    "href": "slides/01-welcome.html#glms-in-practice-1",
    "title": "Welcome to STA 310!",
    "section": "GLMs in practice",
    "text": "GLMs in practice\n\n\n\n\n\n” …a logistic regression model is used to test how the likelihood of a foul is affected by which team is the home team, the foul differential, and the score differential…The logistic regression was run under several specifications … using clustered observation standard errors, with each game as a cluster. This is done as an attempt to adjust for the fact that observations may not be independent as required under the logistic specification.1\n\n\n\n\nAnderson, K. J., & Pierce, D. A. (2009). Officiating bias: The effect of foul differential on foul calls in NCAA basketball. Journal of sports sciences, 27(7), 687-694."
  },
  {
    "objectID": "slides/01-welcome.html#meet-your-classmates-1",
    "href": "slides/01-welcome.html#meet-your-classmates-1",
    "title": "Welcome to STA 310!",
    "section": "Meet your classmates!",
    "text": "Meet your classmates!\n\nGet in groups of 2 - 3\nEach person in the group…\n\nIntroduce yourself\nShare a boring fact about yourself\n\nEveryone will introduce one person from your group to the class"
  },
  {
    "objectID": "slides/01-welcome.html#pre-reqs",
    "href": "slides/01-welcome.html#pre-reqs",
    "title": "Welcome to STA 310!",
    "section": "Pre-reqs",
    "text": "Pre-reqs\nPre-reqs\nSTA 210 and STA 230 / STA 240\n\nBackground knowledge\n\n\nStatistical methods\n\nLinear and logistic regression\nStatistical inference\nBasic understanding of random variables\n\n\nComputing\n\nUsing R for data analysis\nWriting reports using Quarto\nVersion control and collaboration using GitHub"
  },
  {
    "objectID": "slides/01-welcome.html#course-toolkit",
    "href": "slides/01-welcome.html#course-toolkit",
    "title": "Welcome to STA 310!",
    "section": "Course toolkit",
    "text": "Course toolkit\n\n\nsta310-sp24.netlify.app"
  },
  {
    "objectID": "slides/01-welcome.html#course-toolkit-1",
    "href": "slides/01-welcome.html#course-toolkit-1",
    "title": "Welcome to STA 310!",
    "section": "Course toolkit",
    "text": "Course toolkit\nCanvas: canvas.duke.edu/courses/25310\n\nAnnouncements\nGradebook\n\nGitHub: github.com/sta310-sp24\n\nHomework and projects\n\nSlack (link in Canvas)\n\nClass discussion forum"
  },
  {
    "objectID": "slides/01-welcome.html#class-meetings",
    "href": "slides/01-welcome.html#class-meetings",
    "title": "Welcome to STA 310!",
    "section": "Class Meetings",
    "text": "Class Meetings\n\n\nLectures\n\nSome traditional lecture\nShort individual and group activities\nBring fully-charged laptop / tablet to use R\n\n\nLabs (start January 18)\n\nWork on class assignments with TA support\nWork on projects with teammates\n\n\n\n\n\nAttendance is strongly expected (if you are healthy!)"
  },
  {
    "objectID": "slides/01-welcome.html#readings",
    "href": "slides/01-welcome.html#readings",
    "title": "Welcome to STA 310!",
    "section": "Readings",
    "text": "Readings\n\n\n\n\n\n\n\n\n\nPrimary textbook: Beyond Multiple Linear Regression by Roback and Legler\nOther texts:\n\nR for Data Science (2nd edition) by Wickham, Çetinkaya-Rundel, and Grolemund\nTidy Modeling with R by Kuhn and Silge\n\nArticles and videos periodically assigned"
  },
  {
    "objectID": "slides/01-welcome.html#r-and-rstudio",
    "href": "slides/01-welcome.html#r-and-rstudio",
    "title": "Welcome to STA 310!",
    "section": "R and RStudio",
    "text": "R and RStudio\n1️⃣ Install R and RStudio on your laptop\n\nClick here for instructions to install RStudio and configure git\n\n\nor\n\n2️⃣ Access RStudio through Docker container provided by Duke OIT\n\nReserve a generic RStudio container (there is no course specific container)"
  },
  {
    "objectID": "slides/01-welcome.html#github",
    "href": "slides/01-welcome.html#github",
    "title": "Welcome to STA 310!",
    "section": "GitHub",
    "text": "GitHub\n\nGitHub course organization: github.com/sta310-sp24\nWill receive and submit assignments through a private GitHub repo in the course Github organization\nWill receive assignment feedback as a GitHub issue. Final grades on each assignment will be available in Canvas\nAll work and feedback are private"
  },
  {
    "objectID": "slides/01-welcome.html#slack",
    "href": "slides/01-welcome.html#slack",
    "title": "Welcome to STA 310!",
    "section": "Slack",
    "text": "Slack\n\nOnline discussion forum (like Piazza, Ed Discussion, etc.)\nPlatform to ask questions about course content, logistics, assignments, etc.\nContent organized by channels. Before posting, please browse previous posts to see if your question has already been answered. If not, please post your question in the relevant channel.\nQuestions about grades, absences, and other private matters should be emailed to me with “STA 310” in the subject line."
  },
  {
    "objectID": "slides/01-welcome.html#homework-40",
    "href": "slides/01-welcome.html#homework-40",
    "title": "Welcome to STA 310!",
    "section": "Homework (40%)",
    "text": "Homework (40%)\n\n6 individual assignments\nCombination of conceptual questions, guided analyses, and open-ended analyses\nWill be submitted in your private GitHub repo\nLowest homework grade is dropped"
  },
  {
    "objectID": "slides/01-welcome.html#quizzes-20",
    "href": "slides/01-welcome.html#quizzes-20",
    "title": "Welcome to STA 310!",
    "section": "Quizzes (20%)",
    "text": "Quizzes (20%)\n\n6 individual online quizzes\nCovers content since the previous quiz, including readings, lecture notes, in-class activities, and homework\nLowest quiz grade is dropped"
  },
  {
    "objectID": "slides/01-welcome.html#projects",
    "href": "slides/01-welcome.html#projects",
    "title": "Welcome to STA 310!",
    "section": "Projects",
    "text": "Projects\n\nProject 01 (Team project, 10%)\n\nTeam project to read and evaluate academic article that includes model for non-normal response variable\nIncludes in-class presentation and short write up\n\nProject 02 (Team project, 10%)\n\nTeam project to evaluate article and conduct analysis focused on models for correlated data\nIncludes in-class presentation and short write up\n\nFinal project (20%)\n\nIndividual project to apply what you’ve learned to analyze correlated data\nIncludes write up"
  },
  {
    "objectID": "slides/01-welcome.html#grading",
    "href": "slides/01-welcome.html#grading",
    "title": "Welcome to STA 310!",
    "section": "Grading",
    "text": "Grading\nFinal grades will be calculated as follows\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n40%\n\n\nProject 01\n10%\n\n\nProject 02\n10%\n\n\nFinal project\n20%\n\n\nQuizzes\n20%\n\n\n\n\nSee syllabus for letter grade thresholds."
  },
  {
    "objectID": "slides/01-welcome.html#course-community-1",
    "href": "slides/01-welcome.html#course-community-1",
    "title": "Welcome to STA 310!",
    "section": "Course community",
    "text": "Course community\n\nUphold the Duke Community Standard:\n\n\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors;\nI will act if the Standard is compromised.\n\n\n\n\n\n\nCommit to respect, honor, and celebrate our diverse community\nCommit to being part of a learning environment that is welcoming and accessible to everyone"
  },
  {
    "objectID": "slides/01-welcome.html#accessibility",
    "href": "slides/01-welcome.html#accessibility",
    "title": "Welcome to STA 310!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nIf you have documented accommodations from SDAO, please send the documentation as soon as possible.\nI am committed to making all course activities and materials accessible. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "slides/01-welcome.html#support",
    "href": "slides/01-welcome.html#support",
    "title": "Welcome to STA 310!",
    "section": "Support",
    "text": "Support\n\nOffice hours to meet with a member of the teaching team.\n\nFind the schedule in the syllabus and course webpage\nOffice hours begin January 16\nPlease email me if you’d like to meet before then\n\nSlack for questions about course logistics, content, and assignments\nEmail for questions not appropriate for Slack, e.g., regarding personal matters or grades\n\nPlease put STA 310 in the subject line\n\n\nSee the syllabus and support page for additional academic and mental health and wellness resources"
  },
  {
    "objectID": "slides/01-welcome.html#covid-19-and-other-illness",
    "href": "slides/01-welcome.html#covid-19-and-other-illness",
    "title": "Welcome to STA 310!",
    "section": "COVID-19 and other illness",
    "text": "COVID-19 and other illness\n\nPlease do not come to class if you have tested positive for COVID-19, have possible symptoms and have not yet been tested, or have other illness.\nRead and follow the university guidelines regarding COVID-19 at coronavirus.duke.edu."
  },
  {
    "objectID": "slides/01-welcome.html#late-work",
    "href": "slides/01-welcome.html#late-work",
    "title": "Welcome to STA 310!",
    "section": "Late work",
    "text": "Late work\n\nHomework will be accepted up to 48 hours after the deadline. There will be a 5% deduction for each 24-hour period the assignment is late.\nNo late work is accepted on quizzes, and there are no makeups for missed quizzes.\nLate policy for projects:\n\nPresentation: Late presentations are not accepted and there are no make ups for missed presentations.\nWrite up: There will be a 5% deduction for write ups submitted late but the same day, a 10% deduction for write ups submitted the next day, and a 15% deduction for write ups submitted two days late (by 11:59pm). No credit given for write ups submitted more than 2 days after the deadline.\nPeer evaluation: No late work is accepted on peer evaluations."
  },
  {
    "objectID": "slides/01-welcome.html#academic-integrity-and-collaboration",
    "href": "slides/01-welcome.html#academic-integrity-and-collaboration",
    "title": "Welcome to STA 310!",
    "section": "Academic integrity and collaboration",
    "text": "Academic integrity and collaboration\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level.\nYou may not discuss or otherwise work with others on quizzes.\nFor the projects collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project across teams.\nReusing code: Unless explicitly stated otherwise, you may make use of online resources (e.g. StackOverflow) for coding examples on assignments. If you directly use code from an outside source (or use it as inspiration), you must explicitly cite where you obtained the code."
  },
  {
    "objectID": "slides/01-welcome.html#use-of-artificial-intelligence-ai",
    "href": "slides/01-welcome.html#use-of-artificial-intelligence-ai",
    "title": "Welcome to STA 310!",
    "section": "Use of artificial intelligence (AI)",
    "text": "Use of artificial intelligence (AI)\n\nYou should treat AI tools, such as ChatGPT, the same as other online resources.\nThere are two guiding principles that govern how you can use AI in this course:1\n\n(1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning.\n(2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\n\nThese guiding principles are based on Course Policies related to ChatGPT and other AI Tools developed by Joel Gladd, Ph.D.↩︎"
  },
  {
    "objectID": "slides/01-welcome.html#use-of-artificial-intelligence-ai-1",
    "href": "slides/01-welcome.html#use-of-artificial-intelligence-ai-1",
    "title": "Welcome to STA 310!",
    "section": "Use of artificial intelligence (AI)",
    "text": "Use of artificial intelligence (AI)\n✅ AI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code.\n❌ No AI tools for narrative: Unless instructed otherwise, AI is not permitted for writing narrative on assignments.\n\n\n\n\n\n\n\nImportant\n\n\nIn general, you may use AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content."
  },
  {
    "objectID": "slides/01-welcome.html#set-up-course-toolkit",
    "href": "slides/01-welcome.html#set-up-course-toolkit",
    "title": "Welcome to STA 310!",
    "section": "Set up course toolkit",
    "text": "Set up course toolkit\nSee announcement on Canvas and complete the following:\n\nSign up for Slack\nComplete STA 310 Student Survey\n\nNeed to provide GitHub username. If you do not have a GitHub username, go to github.com to sign up and click here for advice on making a username."
  },
  {
    "objectID": "slides/01-welcome.html#next-class",
    "href": "slides/01-welcome.html#next-class",
    "title": "Welcome to STA 310!",
    "section": "Next Class",
    "text": "Next Class\n(Wednesday, January 17)\n\nUnderstand statistical models\nReview multiple linear regression"
  },
  {
    "objectID": "slides/01-welcome.html#to-do-before-next-time",
    "href": "slides/01-welcome.html#to-do-before-next-time",
    "title": "Welcome to STA 310!",
    "section": "To do before next time",
    "text": "To do before next time\n\nInstall RStudio and configure git (or reserve container). See computing page for instructions.\n\nWill do application exercise next class\n\nRead syllabus and let me know if you have any questions\nSee Prepare for Jan 17 lecture\n\n\n\n\n\n🔗 STA 310 - Spring 2024"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html",
    "href": "slides/03-mlr-review-pt2.html",
    "title": "Review of multiple linear regression",
    "section": "",
    "text": "class: middle, center\n##Click for PDF of slides"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#announcements",
    "href": "slides/03-mlr-review-pt2.html#announcements",
    "title": "Review of multiple linear regression",
    "section": "Announcements",
    "text": "Announcements\n\nLab starts Thu 3:30 - 4:45pm online\n\nFind Zoom link in Sakai\n\nOffice hours this week:\n\nThu 2 - 3pm & Fri 1 - 2pm online (links in Sakai)\nFull office hours schedule starts Tue, Jan 19\n\nWeek 02 reading: BMLR: Chapter 2- Beyond Least Squares: Using Likelihoods\n\n\nclass: middle"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#questions",
    "href": "slides/03-mlr-review-pt2.html#questions",
    "title": "Review of multiple linear regression",
    "section": "Questions?",
    "text": "Questions?\n\nclass: middle, inverse"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#recap",
    "href": "slides/03-mlr-review-pt2.html#recap",
    "title": "Review of multiple linear regression",
    "section": "Recap",
    "text": "Recap"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#data-kentucky-derby-winners",
    "href": "slides/03-mlr-review-pt2.html#data-kentucky-derby-winners",
    "title": "Review of multiple linear regression",
    "section": "Data: Kentucky Derby Winners",
    "text": "Data: Kentucky Derby Winners\n.midi[ Today’s data is from the Kentucky Derby, an annual 1.25-mile horse race held at the Churchill Downs race track in Louisville, KY. The data is in the file derbyplus.csv and contains information for races 1896 - 2017. ]\n.pull-left[\n.midi[Response variable]\n\n.midi[speed: Average speed of the winner in feet per second (ft/s)]\n\n.midi[Additional variable] .midi[- winner: Winning horse] ]\n.pull-right[ .midi[Predictor variables] - .midi[year: Year of the race] - .midi[condition: Condition of the track (good, fast, slow)] - .midi[starters: Number of horses who raced]]"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#data",
    "href": "slides/03-mlr-review-pt2.html#data",
    "title": "Review of multiple linear regression",
    "section": "Data",
    "text": "Data\n\nderby &lt;- read_csv(\"data/derbyplus.csv\") %&gt;%\n  mutate(yearnew = year - 1896)\n\n\nderby %&gt;%\n  head(5) %&gt;% kable()\n\n\n\n\nyear\nwinner\ncondition\nspeed\nstarters\nyearnew\n\n\n\n\n1896\nBen Brush\ngood\n51.66\n8\n0\n\n\n1897\nTyphoon II\nslow\n49.81\n6\n1\n\n\n1898\nPlaudit\ngood\n51.16\n4\n2\n\n\n1899\nManuel\nfast\n50.00\n5\n3\n\n\n1900\nLieut. Gibson\nfast\n52.28\n7\n4"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#model-1-main-effects-model-with-centering",
    "href": "slides/03-mlr-review-pt2.html#model-1-main-effects-model-with-centering",
    "title": "Review of multiple linear regression",
    "section": "Model 1: Main effects model (with centering)",
    "text": "Model 1: Main effects model (with centering)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n52.175\n0.194\n269.079\n0.000\n\n\nstarters\n-0.005\n0.017\n-0.299\n0.766\n\n\nyearnew\n0.023\n0.002\n9.766\n0.000\n\n\nconditiongood\n-0.443\n0.231\n-1.921\n0.057\n\n\nconditionslow\n-1.543\n0.161\n-9.616\n0.000"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#model-2-include-quadratic-effect-for-year",
    "href": "slides/03-mlr-review-pt2.html#model-2-include-quadratic-effect-for-year",
    "title": "Review of multiple linear regression",
    "section": "Model 2: Include quadratic effect for year",
    "text": "Model 2: Include quadratic effect for year\n.midi[\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n51.4130\n0.1826\n281.5645\n0.0000\n\n\nstarters\n-0.0253\n0.0136\n-1.8588\n0.0656\n\n\nyearnew\n0.0700\n0.0061\n11.4239\n0.0000\n\n\nI(yearnew^2)\n-0.0004\n0.0000\n-8.0411\n0.0000\n\n\nconditiongood\n-0.4770\n0.1857\n-2.5689\n0.0115\n\n\nconditionslow\n-1.3927\n0.1305\n-10.6701\n0.0000\n\n\n\n\n\n]"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#model-2-check-model-assumptions",
    "href": "slides/03-mlr-review-pt2.html#model-2-check-model-assumptions",
    "title": "Review of multiple linear regression",
    "section": "Model 2: Check model assumptions",
    "text": "Model 2: Check model assumptions\n\n\n\n\n\n\n\n\n\n\nclass: middle, inverse"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#model-3",
    "href": "slides/03-mlr-review-pt2.html#model-3",
    "title": "Review of multiple linear regression",
    "section": "## Model 3",
    "text": "## Model 3"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#include-interaction-term",
    "href": "slides/03-mlr-review-pt2.html#include-interaction-term",
    "title": "Review of multiple linear regression",
    "section": "Include interaction term?",
    "text": "Include interaction term?\nRecall from the EDA…"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#model-3-include-interaction-term",
    "href": "slides/03-mlr-review-pt2.html#model-3-include-interaction-term",
    "title": "Review of multiple linear regression",
    "section": "Model 3: Include interaction term",
    "text": "Model 3: Include interaction term\n\\[\\begin{aligned}\\widehat{speed} = & 52.387 - 0.003 ~ starters + 0.020 ~ yearnew - 1.070 ~ good - 2.183 ~ slow \\\\ &+0.012 ~ yearnew \\times good + 0.012 ~ yearnew \\times slow \\end{aligned}\\]\n.panelset.sideways[ .panel[.panel-name[Output]\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n52.387\n0.200\n262.350\n0.000\n\n\nstarters\n-0.003\n0.016\n-0.189\n0.850\n\n\nyearnew\n0.020\n0.003\n7.576\n0.000\n\n\nconditiongood\n-1.070\n0.423\n-2.527\n0.013\n\n\nconditionslow\n-2.183\n0.270\n-8.097\n0.000\n\n\nyearnew:conditiongood\n0.012\n0.008\n1.598\n0.113\n\n\nyearnew:conditionslow\n0.012\n0.004\n2.866\n0.005\n\n\n\n\n\n]\n.panel[.panel-name[Code]\n\nmodel3 &lt;- lm(speed ~ starters + yearnew + condition +\n               yearnew * condition, \n             data = derby)\ntidy(model3) %&gt;% kable(digits = 4)\n\n] .panel[.panel-name[Assumptions]\n\n\n\n\n\n\n\n\n\n] ]"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#interpreting-interaction-effects",
    "href": "slides/03-mlr-review-pt2.html#interpreting-interaction-effects",
    "title": "Review of multiple linear regression",
    "section": "Interpreting interaction effects",
    "text": "Interpreting interaction effects\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n52.387\n0.200\n262.350\n0.000\n\n\nstarters\n-0.003\n0.016\n-0.189\n0.850\n\n\nyearnew\n0.020\n0.003\n7.576\n0.000\n\n\nconditiongood\n-1.070\n0.423\n-2.527\n0.013\n\n\nconditionslow\n-2.183\n0.270\n-8.097\n0.000\n\n\nyearnew:conditiongood\n0.012\n0.008\n1.598\n0.113\n\n\nyearnew:conditionslow\n0.012\n0.004\n2.866\n0.005\n\n\n\n\n\nClick here for poll\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#measures-of-model-performance",
    "href": "slides/03-mlr-review-pt2.html#measures-of-model-performance",
    "title": "Review of multiple linear regression",
    "section": "Measures of model performance",
    "text": "Measures of model performance\n\n\\(\\color{#4187aa}{R^2}\\): Proportion of variability in the response explained by the model.\n\nWill always increase as predictors are added, so it shouldn’t be used to compare models\n\n\\(\\color{#4187aa}{Adj. R^2}\\): Similar to \\(R^2\\) with a penalty for extra terms\n\n–\n\n\\(\\color{#4187aa}{AIC}\\): Likelihood-based approach balancing model performance and complexity\n\\(\\color{#4187aa}{BIC}\\): Similar to AIC with stronger penalty for extra terms\n\n–\n\nNested F Test (extra sum of squares F test): Generalization of t-test for individual coefficients to perform significance tests on nested models"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#which-model-would-you-choose",
    "href": "slides/03-mlr-review-pt2.html#which-model-would-you-choose",
    "title": "Review of multiple linear regression",
    "section": "Which model would you choose?",
    "text": "Which model would you choose?\nUse the glance function to get model statistics.\n\n\n\n\n\nmodel\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\nModel1\n0.730\n0.721\n259.478\n276.302\n\n\nModel2\n0.827\n0.819\n207.429\n227.057\n\n\nModel3\n0.751\n0.738\n253.584\n276.016"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#which-model-would-you-choose-1",
    "href": "slides/03-mlr-review-pt2.html#which-model-would-you-choose-1",
    "title": "Review of multiple linear regression",
    "section": "Which model would you choose?",
    "text": "Which model would you choose?"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#characteristics-of-a-good-final-model",
    "href": "slides/03-mlr-review-pt2.html#characteristics-of-a-good-final-model",
    "title": "Review of multiple linear regression",
    "section": "Characteristics of a “good” final model",
    "text": "Characteristics of a “good” final model\n\nModel can be used to answer primary research questions\nPredictor variables control for important covariates\nPotential interactions have been investigated\nVariables are centered, as needed, for more meaningful interpretations\nUnnecessary terms are removed\nAssumptions are met and influential points have been addressed\nModel tells a “persuasive story parsimoniously”\n\n\n.footnote[List from Section 1.6.7 of BMLR]\n\nclass: middle, inverse"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#inference-for-multiple-linear-regression",
    "href": "slides/03-mlr-review-pt2.html#inference-for-multiple-linear-regression",
    "title": "Review of multiple linear regression",
    "section": "Inference for multiple linear regression",
    "text": "Inference for multiple linear regression"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#inference-for-regression",
    "href": "slides/03-mlr-review-pt2.html#inference-for-regression",
    "title": "Review of multiple linear regression",
    "section": "Inference for regression",
    "text": "Inference for regression\nUse statistical inference to\n\nDetermine if predictors are statistically significant (not necessarily practically significant!)\nQuantify uncertainty in coefficient estimates\nQuantify uncertainty in model predictions\n\n\nIf L.I.N.E. assumptions are met, we can conduct inference using the \\(t\\) distribution and estimated standard errors"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#inference-for-regression-1",
    "href": "slides/03-mlr-review-pt2.html#inference-for-regression-1",
    "title": "Review of multiple linear regression",
    "section": "Inference for regression",
    "text": "Inference for regression\n.pull-left[\nWhen L.I.N.E. conditions are met\n\n\n\n\n\n\n\n\n\n]\n.pull-right[\n\nUse least squares regression to get the estimates \\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\), and \\(\\hat{\\sigma}^2\\)\n\\(\\hat{\\sigma}\\) is the regression standard error\n\n\\[\\hat{\\sigma} = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n - p - 1}} = \\sqrt{\\frac{\\sum_{i=1}^n e_i^2}{n-p-1}}\\]\nwhere \\(p\\) is the number of non-intercept terms in the model\n(p = 1 in simple linear regression) ]"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#inference-for-beta_j",
    "href": "slides/03-mlr-review-pt2.html#inference-for-beta_j",
    "title": "Review of multiple linear regression",
    "section": "Inference for \\(\\beta_j\\)",
    "text": "Inference for \\(\\beta_j\\)\n\nSuppose we have the following model:\n\n\\[y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\dots + \\beta_p x_{pi} + \\epsilon_i \\hspace{5mm} \\epsilon \\sim N(0, \\sigma^2)\\]\n–\n\nWe use least squares regression to get estimates for the parameters \\(\\beta_0, \\beta_1, \\ldots, \\beta_p\\) and \\(\\sigma^2\\). The regression equation is\n\n\\[\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 x_2 + \\dots + \\hat{\\beta}_p x_p\\]\n\nWhen the L.I.N.E. assumptions are met, \\(\\hat{\\beta}_j \\sim N(\\beta_j, SE_{\\hat{\\beta}_j})\\).\n\nThe objective of statistical inference is to understand \\(\\beta_j\\)\nUse \\(\\hat{\\sigma}\\) to estimate \\(SE_{\\hat{\\beta}_j}\\), the standard error of \\(\\hat{\\beta}_j\\)"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#inference-for-beta_j-1",
    "href": "slides/03-mlr-review-pt2.html#inference-for-beta_j-1",
    "title": "Review of multiple linear regression",
    "section": "Inference for \\(\\beta_j\\)",
    "text": "Inference for \\(\\beta_j\\)\n.eq[ \\[SE_{\\hat{\\beta}_j} = \\hat{\\sigma}\\sqrt{\\frac{1}{(n-1)s_{x_j}^2}}\\]]\nConduct inference for \\(\\beta_j\\) using a \\(t\\) distribution with \\(n-p-1\\) degrees of freedom (df).\n\n\\(\\hat{\\beta}_j\\) follows a \\(t\\) distribution, because \\(\\hat{\\sigma}\\) (not \\(\\sigma\\)) is used to calculate the standard error of \\(\\hat{\\beta}_j\\).\nThe distribution has \\(n-p-1\\) df because we use up \\(p + 1\\) df to calculate \\(\\hat{\\sigma}\\), so there are \\(n - p - 1\\) df left to understand variability."
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#hypothesis-test-for-beta_j",
    "href": "slides/03-mlr-review-pt2.html#hypothesis-test-for-beta_j",
    "title": "Review of multiple linear regression",
    "section": "Hypothesis test for \\(\\beta_j\\)",
    "text": "Hypothesis test for \\(\\beta_j\\)\n.pull-left[ 1️⃣ State the hypotheses\n.eq[ \\[\\small{H_0: \\beta_j = 0 \\text{ vs. }H_a: \\beta_j \\neq 0}\\]]\n\n2️⃣ Calculate the test statistic.\n.eq[ \\[\\small{t = \\frac{\\hat{\\beta}_j - 0}{SE_{\\hat{\\beta}_j}} = \\frac{\\hat{\\beta}_j - 0}{\\hat{\\sigma}\\sqrt{\\frac{1}{(n-1)s_{x_j}^2}}}}\\]] ]\n.pull-right[ 3️⃣ Calculate the p-value.\n.eq[ \\[\\text{p-value} = 2P(T &gt; |t|) \\hspace{4mm} T \\sim t_{n-p-1}\\]]\n\n4️⃣ State the conclusion in context of the data.\n.eq[ Reject \\(H_0\\) if p-value is sufficiently small.]\n]"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#confidence-intervals",
    "href": "slides/03-mlr-review-pt2.html#confidence-intervals",
    "title": "Review of multiple linear regression",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n.eq[ The \\(C\\)% confidence confidence interval for \\(\\beta_j\\) is\n\\[\\begin{align}&\\hat{\\beta}_j \\pm t^* \\times SE_{\\hat{\\beta}_j}\\\\[8pt]\n&\\hat{\\beta}_j \\pm t^* \\times \\hat{\\sigma}\\sqrt{\\frac{1}{(n-1)s_{x_{j}}^2}}\\end{align}\\] where the critical value \\(t^* \\sim t(n-p-1)\\) ]\nGeneral interpretation: We are \\(C\\)% confident that for every one unit increase in \\(x_j\\), the response is expected to change by LB to UB units, holding all else constant."
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#inference-activity-8-minutes",
    "href": "slides/03-mlr-review-pt2.html#inference-activity-8-minutes",
    "title": "Review of multiple linear regression",
    "section": "Inference Activity (~8 minutes)",
    "text": "Inference Activity (~8 minutes)\n\nUse the Model 3 output on the next slide to conduct a hypothesis test and interpret the 95% confidence interval for your assigned variable.\n\nYou do not have to do the calculations by hand.\n\nChoose one person to write your group’s response on your slide slide.\nChoose on person to share your group’s responses with the class."
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#model-3-output",
    "href": "slides/03-mlr-review-pt2.html#model-3-output",
    "title": "Review of multiple linear regression",
    "section": "Model 3 output",
    "text": "Model 3 output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n52.387\n0.200\n262.350\n0.000\n51.991\n52.782\n\n\nstarters\n-0.003\n0.016\n-0.189\n0.850\n-0.035\n0.029\n\n\nyearnew\n0.020\n0.003\n7.576\n0.000\n0.014\n0.025\n\n\nconditiongood\n-1.070\n0.423\n-2.527\n0.013\n-1.908\n-0.231\n\n\nconditionslow\n-2.183\n0.270\n-8.097\n0.000\n-2.717\n-1.649\n\n\nyearnew:conditiongood\n0.012\n0.008\n1.598\n0.113\n-0.003\n0.027\n\n\nyearnew:conditionslow\n0.012\n0.004\n2.866\n0.005\n0.004\n0.020"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#additional-review-topics",
    "href": "slides/03-mlr-review-pt2.html#additional-review-topics",
    "title": "Review of multiple linear regression",
    "section": "Additional review topics",
    "text": "Additional review topics\n\nUncertainty in predictions\nVariable transformations\nComparing models using Nested F tests"
  },
  {
    "objectID": "slides/03-mlr-review-pt2.html#acknowledgements",
    "href": "slides/03-mlr-review-pt2.html#acknowledgements",
    "title": "Review of multiple linear regression",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in BMLR: Chapter 1 - Review of Multiple Linear Regression"
  },
  {
    "objectID": "slides/lab-01.html#meet-your-ta",
    "href": "slides/lab-01.html#meet-your-ta",
    "title": "Welcome to STA 310 Labs!",
    "section": "Meet your TA!",
    "text": "Meet your TA!"
  },
  {
    "objectID": "slides/lab-01.html#what-to-expect-in-lab",
    "href": "slides/lab-01.html#what-to-expect-in-lab",
    "title": "Welcome to STA 310 Labs!",
    "section": "What to expect in lab",
    "text": "What to expect in lab\n\nIntroduction to the week’s lab\nAnswer questions about lectures and cover additional content, as needed\nWork on homework or projects"
  },
  {
    "objectID": "slides/lab-01.html#lecture-02-ae",
    "href": "slides/lab-01.html#lecture-02-ae",
    "title": "Welcome to STA 310 Labs!",
    "section": "Lecture 02 AE",
    "text": "Lecture 02 AE\n\nOpen the Lecture 02 AE from yesterday’s class.\nAre there any questions about Exercises 1 - 5?\nWe will go over Exercises 6 - 8 about Model 3 today. You will do Part 2 in Monday’s lecture."
  },
  {
    "objectID": "slides/lab-01.html#icebreaker",
    "href": "slides/lab-01.html#icebreaker",
    "title": "Welcome to STA 310 Labs!",
    "section": "Icebreaker",
    "text": "Icebreaker\n\n\nGet into groups of 3 - 5.\nIntroduce yourself if you haven’t met\nChoose a reporter\n\nNeed help choosing? Person with birthday closest to today’s date.\n\nIdentify 8 things everyone in the group has in common\n\nNot being a Duke student\nNot clothes (e.g., we’re all wearing socks)\nNot body parts (e.g., we all have a nose)\n\nReporter will share list with the class.\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/lab-01.html#todays-lab",
    "href": "slides/lab-01.html#todays-lab",
    "title": "Welcome to STA 310 Labs!",
    "section": "Today’s lab",
    "text": "Today’s lab\nThe rest of the today’s lab is focused on working on HW 01. You are encouraged to discuss homework with each other but everyone must turn in their own assignment. See the syllabus for policy on homework collaboration.\n\n🔗 sta310-sp24.netlify.app/hw/hw-01\n\n\n\n\n🔗 STA 310 - Spring 2024"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 310: Generalized Linear Models",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nweek\ndow\ndate\ntopic\nprepare\nlectures\nae\nhw\nquiz\nproject\nnotes\n\n\n\n\n1\nW\nJan 10\nWelcome\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nJan 11\nNo lab: Labs start 1/18\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\nM\nJan 15\nNo lecture: Martin Luther King Jr. Day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\nJan 17\nReview: Multiple linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nJan 18\nLab 01: Welcome + HW 01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\nM\nJan 22\nInference review + Using likelihoods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\nJan 24\nComparing models using likelihoods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 01 due\n\n\n\n\n\n\nPoisson regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nJan 25\nLab: Start Project 01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\nM\nJan 29\nPoisson: Goodness of fit + overdispersion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\nJan 31\nPoisson: offset + ZIP models\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nFeb 1\nLab: Project 01 Article Evaluation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuiz 01 due at 12pm\n\n\n5\nM\nFeb 5\nUnifying framework for GLMs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogistic regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\nFeb 7\nLogistic: Binomial responses + overdispersion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 02 due\n\n\n\nTh\nFeb 8\nLab: Project 01 Write up + Presentation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6\nM\nFeb 12\nProportional odds + Probit regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\nFeb 14\nProject 01 presentations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nFeb 15\nLab: Project 01 Write up\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject 01 write up + GitHub repo due at 9pm\n\n\n7\nM\nFeb 19\nCorrelated data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\nFeb 21\nIntroduction to multilevel models\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nFeb 22\nLab: HW 03\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuiz 02 due at 12pm\n\n\n8\nM\nFeb 26\nFixed + random effects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\nFeb 27\nMultilevel models\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 03 due\n\n\n\nTh\nFeb 28\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9\nM\nMar 4\nMultilevel models cont'd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\nMar 6\nMultilevel models cont'd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nMar 7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuiz 03 due at 12pm\n\n\n10\nM\nMar 11\nNo lecture: Spring break!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\nMar 13\nNo lecture: Spring break!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nMar 14\nNo lab: Spring break!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11\nM\nMar 18\nModeling longitudinal data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\nMar 20\nModeling longitudinal data cont'd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 04 due\n\n\n\nTh\nMar 21\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12\nM\nMar 25\nModeling longitudinal data cont'd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\nMar 27\nProject 02 presentations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nMar 28\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuiz 04 due at 12pm\n\n\n13\nM\nApr 1\nMultilevel models with 3+ levels\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\nApr 3\nMultilevel models with 3+ levels\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 05 due\n\n\n\nTh\nApr 4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14\nM\nApr 8\nNo lecture\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\nApr 10\nCovariance structures\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nApr 11\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuiz 05 due at 12pm\n\n\n15\nM\nApr 15\nMultilevel GLMs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\nApr 17\nMultilevel GLMs cont'd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 06 due\n\n\n\nTh\nApr 18\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n16\nM\nApr 22\nMultilevel GLMs cont'd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\nApr 24\nFinal project meetings\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuiz 06 due at 12pm\n\n\nExam period",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "projects/project-tips.html",
    "href": "projects/project-tips.html",
    "title": "Final project tips + resources",
    "section": "",
    "text": "Data sources\n\nSome resources that may be helpful as you find data:\n\nR Data Sources for Regression Analysis\nFiveThirtyEight data\nTidyTuesday\n\n\n\nOther data repositories\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies\n\n\n\n\nTips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your Qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works.\n\n\n\nFormatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\nAn alternative approach is to add the following code to the YAML:\n\nexecute:\n  echo: false\n  warning: false\n  message: false\n\n\n\n\nHeaders\n\nUse headers to clearly label each section. Make sure there is a space between the last # and the title, so the header renders correctly. For example, ###Section Title will not render as header, but ### Section Title will.\n\n\n\nReferences\n\nInclude all references in a section called “References” at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\n\nResize plots and figures, so you have more space for the narrative.\n\nResize individual figures: Use the code chunk header {r plot1, fig.height = 3, fig.width = 5}, replacing plot1 with a meaningful label and the height and width with values appropriate for your write up.\nResize all figures: Include the fig_width and fig_height options in your YAML header as shown below:\n\n\n\n---\ntitle: \"Your title\"\nauthor: \"Your names\"\nformat:\n  pdf:\n    fig-width: 7\n    fig-height: 5\n---\nReplace the height and width values with values appropriate for your write up.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\n\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\nIf you’re using base R function, i.e. when using the emplogit functions, put the code par(mfrow = c(rows,columns)) before the code to make the plots. For example, par(mfrow = c(2,3)) will arrange plots in a grid with 2 rows and 3 columns.\n\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\nUse coord_flip() to flip the x and y axes on the plot. This is useful if you a bar plot with an x-axis that is difficult to read due to overlapping text.\n\n❌ NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n✅ YES! Names are readable\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg |&gt;\n  count(manufacturer) |&gt;\n  mutate(manufacturer = str_to_title(manufacturer)) |&gt;\n  ggplot(aes(x = fct_reorder(manufacturer,n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  coord_flip() +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_bw() \n\n\n\n\n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel &lt;- lm(mpg ~ hp, data = mtcars)\ntidy(model) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon’t use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n❌ There is a negative linear relationship between mpg and hp.\n✅ There is a negative linear relationship between a car’s fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don’t assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the “so what”: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e. what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n❌ For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n✅ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it’s from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document.\n\n\n\n\nAdditional resources\n\nExploring RStudio’s Visual Markdown Editor\nR for Data Science\nQuarto documentation:\n\nQuarto PDF Basics\nPresentations in Quarto\n\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package",
    "crumbs": [
      "Projects",
      "Tips + resources"
    ]
  },
  {
    "objectID": "projects/project-01.html",
    "href": "projects/project-01.html",
    "title": "Project 01: Generalized Linear Models",
    "section": "",
    "text": "For this project you and your team will be reading and evaluating a scholarly article that incorporates generalized linear models (GLMs) in the analysis.\nThe learning objectives of the project are to",
    "crumbs": [
      "Projects",
      "Project 01"
    ]
  },
  {
    "objectID": "projects/project-01.html#team-assignments",
    "href": "projects/project-01.html#team-assignments",
    "title": "Project 01: Generalized Linear Models",
    "section": "Team assignments",
    "text": "Team assignments\nYou will work in small teams for this project. You will find the team assignments in the #project-01 channel in Slack.\nBefore getting started, I encourage you to discuss the following as a group:\n\nCome up with a plan to communicate and work together outside of lab.\nCome up with a plan for remote work if some team members are unable to attend lab or other in-person team meetings.",
    "crumbs": [
      "Projects",
      "Project 01"
    ]
  },
  {
    "objectID": "projects/project-01.html#workflow",
    "href": "projects/project-01.html#workflow",
    "title": "Project 01: Generalized Linear Models",
    "section": "Workflow",
    "text": "Workflow\n\nProject Week 01 (week of Mon, Jan 22): Select article and submit proposal.\nProject Week 02 (week of Mon, Jan 29): Read article and complete article evaluation.\nProject Week 03 (week of Mon, Feb 05 ): Work on draft reports and presentations.\nProject Week 04 (week of Mon, Feb 12): Presentations and submit report.",
    "crumbs": [
      "Projects",
      "Project 01"
    ]
  },
  {
    "objectID": "projects/project-01.html#due-dates",
    "href": "projects/project-01.html#due-dates",
    "title": "Project 01: Generalized Linear Models",
    "section": "Due dates",
    "text": "Due dates\n\n\n\n\n\n\nNote\n\n\n\nAll work will be submitted in your team’s project GitHub repo.\n\n\n\nProposal: due Fri, Jan 26 at noon\nArticle evaluation: due Sun, Feb 04 at noon\nPresentation: due Wed, Feb 14 at 3:05pm\nWritten report: due Thu, Feb 15 at 9pm",
    "crumbs": [
      "Projects",
      "Project 01"
    ]
  },
  {
    "objectID": "projects/project-01.html#article",
    "href": "projects/project-01.html#article",
    "title": "Project 01: Generalized Linear Models",
    "section": "Article",
    "text": "Article\nThe article for this project must be published in a scholarly journal. Please ask a member of the teaching team if you are unsure whether the article is published in a scholarly journal. The article must incorporate the use one or more generalized linear models, that is not a linear regression model, in the analysis.\n\nCommon GLMs are Poisson regression, Logistic regression, Probit regression, and Negative binomial regression.\nYou can also look for models based on the distribution of the response variable: Binary, Binomial, Poisson, Exponential, Gamma, Geometric.\nSee Section 3.6 in Beyond Multiple Linear Regression for a list of types of GLMs.\n\nThe model used in the paper does not have to be one we discuss in class. I’d encourage you to explore articles that use modeling beyond the scope of the class!\nBelow are a few useful places to search for articles:\n\nDuke Library\nPLOS One\nPubMed.gov\n\nSee the Tips on finding articles for tips on searching journal databases to find an article.",
    "crumbs": [
      "Projects",
      "Project 01"
    ]
  },
  {
    "objectID": "projects/project-01.html#proposal",
    "href": "projects/project-01.html#proposal",
    "title": "Project 01: Generalized Linear Models",
    "section": "Proposal",
    "text": "Proposal\nThe main goal of the proposal is to ensure you have an article that will set you up for a successful project. Include the following in the proposal.\n\nThe citation for the article. If you’re using a .bib file you can use the default citation format in Quarto (Chicago author-date format). Otherwise, use MLA format.\nBrief summary about why you chose this article.\nBrief summary of the article’s primary research objective.\nName of the GLM(s) used in the article and a short description of the response variable for each model.\n\nYou are only required to write the proposal for one article. Write the proposal in the file proposal.qmd, then push the .qmd and rendered PDF to the GitHub repo for submission.\n\n\n\n\n\n\nImportant\n\n\n\nThe proposal is due on Fri, Jan 25 at noon.\n\nYou will not be able to commit new work to your GitHub repo after the deadline until we have completed grading. If your group needs to submit your work late, please send me a message on Slack or email to reopen the repo.\n\n\n\nGrading criteria\nThe proposal will be graded based on the following:\n\nAll required components of the proposal are included and accurate (8 pts)\nAll team members have made meaningful contribution, as determined by Git commit history (2 pts)",
    "crumbs": [
      "Projects",
      "Project 01"
    ]
  },
  {
    "objectID": "projects/project-01.html#article-evaluation",
    "href": "projects/project-01.html#article-evaluation",
    "title": "Project 01: Generalized Linear Models",
    "section": "Article evaluation",
    "text": "Article evaluation\nThe purpose of the article evaluation is for you to begin describing and evaluating the statistical analysis and argument in the article. Write your responses to the following questions in article-evaluation.qmd. The anticipated length is about 1 - 2 pages and should be no more than 4 pages. There is no minimum page requirement, as long as each section is comprehensively addressed.\n\nAudience and purpose\n\nWho is the primary audience for this article, i.e., for what type of readers are the authors writing?\nWhat is the general purpose of the article, e.g., to persuade the reader to do something, to prove something, to inform the reader, etc.?\n\nData\n\nHow were the data generated - from an experiment, online survey, interviews, etc?\nUnder what conditions were the data collected, e.g., the time period, location, how subjects were selected, response rate / drop-out rate, etc.?\n\nGraphs and tables\n\nDescribe the types of visualizations and tables used in the article.\nHow are they primarily used - for exploratory data analysis, to support a candidate, etc.?\nWhat visualizations or tables might you add to the article? Briefly explain.\n\nGeneralized Linear Model\nIf your paper has multiple, GLMs you only have to write this section up for one model.\n\nWhat is the response variable, and what is its distribution?\nWhat are the predictor variables? Which predictor(s) are of particular interest in the research?\nWrite the statistical model in mathematical notation.\n\nOverall argument\n\nAre there limitations or difficulties with generalizing beyond the data? Briefly explain.\nWhen was the article published? Are the findings up-to-date, out-dated, or timeless? Briefly explain.\nHow does the study advance knowledge in the field?\n\n\n\nGrading criteria\nThe article evaluation will be graded based on the following\n\nAll required components of the article evaluation are included and accurate (15 pts)\nThe team has worked collaboratively using GitHub and all all team members have made a meaningful contribution, as determined by Git commit history (5 pts)\n\n\n\n\n\n\n\nImportant\n\n\n\nThe article evaluation is due on Sun, Feb 04 at noon.\n\nYou will not be able to commit new work to your GitHub repo after the deadline until we have completed grading. If your group needs to submit your work late, please send me a message on Slack or email to reopen the repo.",
    "crumbs": [
      "Projects",
      "Project 01"
    ]
  },
  {
    "objectID": "projects/project-01.html#write-up",
    "href": "projects/project-01.html#write-up",
    "title": "Project 01: Generalized Linear Models",
    "section": "Write up",
    "text": "Write up\nThe anticipated length is about 5 pages. There is no minimum or maximum page requirement as long as each section is accurately and comprehensively addressed.\n\nIntroduction\nBriefly summarize the article, the research objective and purpose, and key conclusions. Also include a description of the data used for the analysis.\n\n\nMethods\nDescribe the GLM used for the analysis. Describe the response variable and and its distribution. Describe predictor variables. Write the equation of the statistical models using mathematical notation.\n\n\nResults\nInterpret the results form the model. Write the interpretations / conclusions from the model, using estimates from the article when possible. If the article does not include estimates for some or all of the estimated effects effects, you can write general interpretations using the appropriate mathematical symbol (e.g., \\(\\hat{\\beta}_1\\)) in place of the estimated value.\n\n\nCommunication\nThe objective of this section of the written report is to assess the authors’ argument and communication. Reading and identifying how others communicate statistical results is a key way to develop your statistical writing skills. This section will include an assessment of the following:\n\nAudience: Describe the primary audience for the article.\nMethods: Consider the detail in the data and methods sections. What aspects of the analysis are mentioned in detail? What aspects are mentioned without detail? How does the level of detail correlate to the statistical background of the primary audience?\nGraphs and figures: How are the graphs, figures, and tables used to support the findings? How are they used for exploratory data analysis? How how are they used to assess or support modeling results? Would additional graphs, figures, or tables be helpful? If so, what kind?\n\nIdentify one key graph. Where is it located in the article? What message does it convey with respect to the objective and conclusion of the study? If there are no graphs in the article, describe one key graph you would include and how it would be used in the article (e.g., support conclusions, provide clarity, etc.).\n\nLimitations: Are there limitations or difficulties in generalizing beyond the data? How are these limitations noted, if at all? Do you have any other concerns about the study?\nImpact: According to the author, how does the study advance knowledge in the field? Taking into account the year the article was published, do the author’s claims seem adequately justified, overblown, or unduly cautious?\n\nYou can use these questions as a guide to shape the narrative. This section should still be written in narrative form, not as a list of questions and answers.\nThe questions in this section are adapted from Communicating with Data: The Art of Writing for Data Science by Deborah Nolan and Sara Stoudt. Click here for more details about the questions and how to read scientific articles. You can borrow a copy of the book from Duke Libraries.\n\n\nGrading criteria\nEach section will assessed on whether the components of the section are clearly, comprehensively, and accurately discussed in the report. (35 pts total)\nThe report will also be assessed based on the following:\n\nFormatting & reproducibility: 3 pts\n\nThis is an assessment of the overall presentation and formatting of the written report, along with reproducibility. This includes neatly formatted text and tables, appropriate labels on figures, suppressing all code and extraneous output, properly rendered LaTex, and being able to obtain the PDF by rendering the Quarto document.\n\nCollaboration: 3 pts\n\nThe team has worked collaboratively using GitHub and all all team members have made a meaningful contribution, as determined by Git commit history\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe written report is due on Thu, Feb 15 at 9pm.\nYou will not be able to commit new work to your GitHub repo after the deadline until we have completed grading. If your group needs to submit your work late, please send me a message on Slack or email to reopen the repo.",
    "crumbs": [
      "Projects",
      "Project 01"
    ]
  },
  {
    "objectID": "projects/project-01.html#presentation",
    "href": "projects/project-01.html#presentation",
    "title": "Project 01: Generalized Linear Models",
    "section": "Presentation",
    "text": "Presentation\nYou will present on Wed, Feb 14 during lecture. Each team will have up to 10 minutes for the presentation along with a few minutes for questions, and every team member should speak about an equal amount of time during the presentation.\nYou can make the presentation slides using the software of your choice. You can use as many slide as you wish, just be mindful of what can reasonably be presented in the time frame. A suggested outline is\n\n1 slide to introduce article\n1 - 2 slides to describe the model\n1 - 2 slides for key interpretations and results\n1 slide for key highlights about the communication and writing (e.g., what the authors did particularly well or areas of improvement)\n\nYou will be assigned two presentations to peer review. You must submit the peer review scores for both presentations to have the “Peers” scores for your team’s presentation included in your presentation grade.\nThe presentation order and peer review assignments will be given closer to the presentation date.\nThe presentation is worth 25 points. The points are broken down as follows:\n\nTeaching team grading: 18 pts\nPeer grading: 4 pts\nProviding presentation comments: 3pts\n\n\nGrading criteria - Teaching Team (18 pts)\nThis portion of the grade will the average of the scores from the members of the teaching team.\n\nProfessionalism (3 pts)\n\nWas the team prepared for the presentation? Did each team member have a meaningful contribution to the presentation?\nWas the time reasonably divided among team members? Was the presentation within the time limit?\nDid the team present a unified story?\n\nContent (10 pts): Is the content presented in a clear and accurate way? This includes clearly and accurately describing the components described in the presentation outline.\nSlides (5 pts): Are the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.?\n\n\n\nGrading criteria - Peers (4 pts)\nThis portion of the grade will the average of the scores from the peer reviewers. Peer review assignments will be posted on Slack.\n\nIntroduction (1 pt)\n\nDid the team clearly describe the primary research objective, primary takeaways, and intended audience for the article?\n\nData (1 pt)\n\nDid the team clearly describe the data used in the analysis?\n\nModel (1 pt)\n\nDid the team clearly and accurately describe the model?\n\nSlides (1 pt)\n\nAre the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.?",
    "crumbs": [
      "Projects",
      "Project 01"
    ]
  },
  {
    "objectID": "projects/project-01.html#github-repo-organization",
    "href": "projects/project-01.html#github-repo-organization",
    "title": "Project 01: Generalized Linear Models",
    "section": "GitHub repo organization",
    "text": "GitHub repo organization\nYou should have the following files and folders in the project repo. The repo and brief summary in the README should be updated by Thu, Feb 15 at pm. README.md: 3 - 5 sentence summary of the project and citation for the article.\n\nproposal.qmd\nproposal.pdf\narticle-evaluation.qmd\narticle-evaluation.pdf\nwriteup.qmd\nwriteup.pdf\n/presentation\n\n/presentation/*: Presentation file (if not linked in README)\n/presentation/README.md: Link to project (if not in presentation folder)\n\n\nOptional\n\n*.bib: BibTex file for references\n/data/: Folder containing data",
    "crumbs": [
      "Projects",
      "Project 01"
    ]
  },
  {
    "objectID": "projects/project-01.html#grading-100-points",
    "href": "projects/project-01.html#grading-100-points",
    "title": "Project 01: Generalized Linear Models",
    "section": "Grading (100 points)",
    "text": "Grading (100 points)\n\n\n\nComponent\nPoints\n\n\n\n\nProposal\n10 pts\n\n\nArticle evaluation\n20 pts\n\n\nWritten report\n35 pts\n\n\nPresentation\n25 pts\n\n\nRepo organization\n5 pts\n\n\nTeamwork evaluation (individually assessed)\n5 pts",
    "crumbs": [
      "Projects",
      "Project 01"
    ]
  },
  {
    "objectID": "projects/project-01.html#tips-on-finding-articles",
    "href": "projects/project-01.html#tips-on-finding-articles",
    "title": "Project 01: Generalized Linear Models",
    "section": "Tips on finding articles",
    "text": "Tips on finding articles\nBelow are tips to help you find articles based on information from Jodi Psoter, the former Librarian for Chemistry and Statistical Science at Duke Libraries and current Head Librarian for the Marine Lab Library.\n\nPubMed\nArticles in health-related fields\nThe PubMed heading tree lets you search by topic. The link will direct you to the results under the category of “Statistics as a Topic”.\n\nClick on the model or distribution of interest, e.g. “Logistic Models”.\nClick “Add to search builder” under the PubMed Search Builder in the top right corner. You should now see the model/analysis type you chose in the search box.\nClick “Search PubMed”, and a page of search results will appear.\nThere are options to narrow your results on the left-hand side based on your team’s interest.\n\n\n\nPsycInfo\nArticles in psychology\nPsycInfo will allow users to search by analysis type.\n\nPut the name of the model in the search bar, e.g., “Poisson Regression”. Then, in the drop down menu next to the search bar, select “DE Subjects [exact]”. Click Search.\nYou can use the options on the left-hand size to narrow down the search results.\n\n\n\nWeb of Science\nArticles on all topics\nWeb of Science Data Citation Index lets you search for data sets based on the topic of interest.\n\nUse the search bar to search based on a topic of interest. You can also search for the model or distribution name.\nOn the left-hand side, check “Data Set” under Content Type and check “Dataset” under Data Types. Click “Refine” to limit the results.\n\n3.Click on the article of interest.\n\nYou can use the options on the left-hand size to narrow down the search results.\n\n\n\nAcknowledgements\n\nGrading criteria and the repo organization for this project were adapted from Project 1 on vizdata.org.\nSome questions for the Article Evaluation adapted from “How to Evaluate Journal Articles”.\nQuestions in the “Communication” section of the Written Report are adapted from Communicating with Data: The Art of Writing for Data Science by Deborah Nolan and Sara Stoudt.",
    "crumbs": [
      "Projects",
      "Project 01"
    ]
  },
  {
    "objectID": "support.html",
    "href": "support.html",
    "title": "Course support",
    "section": "",
    "text": "We expect everyone will have questions at some point in the semester, so we want to make sure you can identify when that is and feel comfortable seeking help.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "support.html#lectures-and-labs",
    "href": "support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "support.html#office-hours",
    "href": "support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage you to take advantage of them!\nMake a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "support.html#slack",
    "href": "support.html#slack",
    "title": "Course support",
    "section": "Slack",
    "text": "Slack\nOutside of class and office hours, any general questions about course content or assignments should be posted on the classrom Slack. There is a chance another student has already asked a similar question, so please check the other posts on Slack before adding a new question. If you know the answer to a question that is posted, I encourage you to respond!",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "support.html#email",
    "href": "support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nIf you have questions about personal matters that are not appropriate for the class discussion forum (e.g. illness, accommodations, etc.), you may email Professor Tackett at maria.tackett@duke.edu. If you email me, please include “STA 310” in the subject line. Barring extenuating circumstances, I will respond to STA 310 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "support.html#academic-support",
    "href": "support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "support.html#mental-health-and-wellness",
    "href": "support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\n\nDukeReach: Provides comprehensive outreach services to identify and support students in managing all aspects of well being. If you have concerns about a student’s behavior or health visit the website for resources and assistance. Go to studentaffairs.duke.edu/dukereach\nCounseling and Psychological Services (CAPS): CAPS services include individual, group, and couples counseling services, health coaching, psychiatric services, and workshops and discussions. (919) 660-1000 or students.duke.edu/wellness/caps\nTimelyCare (formerly known as Blue Devils Care): An online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling. bluedevilscare.duke.edu",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "support.html#technology-accommodations",
    "href": "support.html#technology-accommodations",
    "title": "Course support",
    "section": "Technology accommodations",
    "text": "Technology accommodations\nHighly aided students who have limited access to computers may request loaner laptops through the DukeLIFE Technology Assistance Program. Please note that supplies are limited.\nNote that we will be using Duke’s computational resources in this course. These resources are freely available to you. As long as your computer can connect to the internet and open a browser window, you can perform the necessary computing for this course. All software we use is open-source and/or freely available.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "support.html#course-materials-costs",
    "href": "support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.).",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "ae/lec-10-correlated.html",
    "href": "ae/lec-10-correlated.html",
    "title": "Lecture 10: Correlated data",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/lec-10-correlated.html#scenario-1a",
    "href": "ae/lec-10-correlated.html#scenario-1a",
    "title": "Lecture 10: Correlated data",
    "section": "Scenario 1a",
    "text": "Scenario 1a\nBelow is the code for the binomial logistic regression model and confidence intervals calculated using the profile likelihood approach (confidence intervals calculated based on likelihood function with no assumptions on the distribution of the parameter of interest, \\(\\beta_0\\)).\n\nmodel_1a &lt;- glm(phat_1a ~ 1, family = binomial, weight = rep(10,24), \n                data = scenario_1)\n\ntidy(model_1a) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.067\n0.129\n0.516\n0.606\n\n\n\n\n\n95% CI of the odds of a pup with deformity\n\nexp(confint(model_1a))\n\n    2.5 %    97.5 % \n0.8298899 1.3778985 \n\n\nThe 95% CI of the probability of a pup with deformity\n\nexp(confint(model_1a)) / (1 + exp(confint(model_1a)))\n\n    2.5 %    97.5 % \n0.4535190 0.5794606 \n\n\nNext we fit a quasibinomial model\n\nquasi_model_1a &lt;- glm(phat_1a ~ 1, family = quasibinomial,\n                      weight = rep(10,24), data = scenario_1)\n\ntidy(quasi_model_1a)\n\n# A tibble: 1 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)   0.0667     0.122     0.546   0.590\n\n\n95% CI of the odds of a pup with deformity\n\nexp(confint(quasi_model_1a))\n\n    2.5 %    97.5 % \n0.8414573 1.3588535 \n\n\nThe 95% CI of the probability of a pup with deformity\n\nexp(confint(quasi_model_1a)) / (1 + exp(confint(quasi_model_1a)))\n\n    2.5 %    97.5 % \n0.4569518 0.5760652"
  },
  {
    "objectID": "ae/lec-10-correlated.html#scenario-1b",
    "href": "ae/lec-10-correlated.html#scenario-1b",
    "title": "Lecture 10: Correlated data",
    "section": "Scenario 1b",
    "text": "Scenario 1b\n\n\n\n\n\n\nFit models for Scenario 1b\n\n\n\n\nFit the binomial and quasibinomial models for the data generated under Scenario 1b. Calculate the 95% CI for \\(p\\) for each model.\n\n\n\n# add code here\n\n\n# add code here"
  },
  {
    "objectID": "ae/lec-10-correlated.html#questions",
    "href": "ae/lec-10-correlated.html#questions",
    "title": "Lecture 10: Correlated data",
    "section": "Questions",
    "text": "Questions\n\n\n\n\n\n\nQuestion 1\n\n\n\nHow do the quasibinomial analysis for Scenario 1b differ from the binomial analysis for Scenario 1b? Consider the coefficient estimates, standard error, predicted probabilities and associated 95% CI.\n\n\n\n\n\n\n\n\nQuestion 2\n\n\n\nWhy are differences between the quasibinomial and binomial models of Scenario 1a less noticeable than the differences in Scenario 1b?"
  },
  {
    "objectID": "ae/lec-04-poisson-estimate.html",
    "href": "ae/lec-04-poisson-estimate.html",
    "title": "Lecture 04 AE: Estimating coefficients for Poisson Regression",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\n\nhh_data &lt;- read_csv(\"data/fHH1.csv\")"
  },
  {
    "objectID": "ae/lec-04-poisson-estimate.html#step-1.-initial-estimates-of-lambda",
    "href": "ae/lec-04-poisson-estimate.html#step-1.-initial-estimates-of-lambda",
    "title": "Lecture 04 AE: Estimating coefficients for Poisson Regression",
    "section": "Step 1. Initial estimates of lambda",
    "text": "Step 1. Initial estimates of lambda\nUsing total + 0.1 instead of total as initial starting values to avoid dividing by 0 or taking the log of 0.\n\nhh_data &lt;- hh_data |&gt;\n  mutate(lambda = hh_data$total + 5)"
  },
  {
    "objectID": "ae/lec-04-poisson-estimate.html#step-2.-calculate-the-working-response-values-z_i.",
    "href": "ae/lec-04-poisson-estimate.html#step-2.-calculate-the-working-response-values-z_i.",
    "title": "Lecture 04 AE: Estimating coefficients for Poisson Regression",
    "section": "Step 2. Calculate the working response values \\(z_i\\).",
    "text": "Step 2. Calculate the working response values \\(z_i\\).\nFor Poisson regression, \\(z_i = \\log(\\lambda) + \\frac{(y_i - \\lambda_i)}{\\lambda_i}\\)\n\nhh_data &lt;- hh_data |&gt;\n  mutate(z = log(lambda) + (hh_data$total - lambda) / lambda)"
  },
  {
    "objectID": "ae/lec-04-poisson-estimate.html#step-3.-calculate-the-working-weights-w_i",
    "href": "ae/lec-04-poisson-estimate.html#step-3.-calculate-the-working-weights-w_i",
    "title": "Lecture 04 AE: Estimating coefficients for Poisson Regression",
    "section": "Step 3. Calculate the working weights \\(W_i\\)",
    "text": "Step 3. Calculate the working weights \\(W_i\\)\nFor Poisson regression, \\(W_i = \\lambda_i\\) .\n\nhh_data &lt;- hh_data |&gt;\n  mutate(w = lambda)\n\n\nhh_data |&gt;\n  select(total, lambda, z, w) |&gt;\n  slice(1:5)\n\n# A tibble: 5 × 4\n  total lambda     z     w\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0      5 0.609     5\n2     3      8 1.45      8\n3     4      9 1.64      9\n4     3      8 1.45      8\n5     3      8 1.45      8"
  },
  {
    "objectID": "ae/lec-04-poisson-estimate.html#step-4.-find-the-coefficient-estimates-of-the-weighted-least-squares-model",
    "href": "ae/lec-04-poisson-estimate.html#step-4.-find-the-coefficient-estimates-of-the-weighted-least-squares-model",
    "title": "Lecture 04 AE: Estimating coefficients for Poisson Regression",
    "section": "Step 4. Find the coefficient estimates of the weighted least squares model",
    "text": "Step 4. Find the coefficient estimates of the weighted least squares model\n\nwls &lt;- lm(z ~ age, weight = w, data = hh_data)\ntidy(wls) |&gt;\n  kable(digits = 4)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n1.7594\n0.0419\n41.9664\n0e+00\n\n\nage\n-0.0026\n0.0008\n-3.4172\n6e-04"
  },
  {
    "objectID": "ae/lec-04-poisson-estimate.html#use-this-model-to-get-new-estimates-of-lambda",
    "href": "ae/lec-04-poisson-estimate.html#use-this-model-to-get-new-estimates-of-lambda",
    "title": "Lecture 04 AE: Estimating coefficients for Poisson Regression",
    "section": "Use this model to get new estimates of lambda",
    "text": "Use this model to get new estimates of lambda\n\nhh_data &lt;- hh_data |&gt;\n  mutate(lambda = exp(predict(wls)))\n\nRepeat steps 2 - 4 until the estimates \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) converge to their respective values."
  },
  {
    "objectID": "ae/lec-04-poisson-estimate.html#irls-automated",
    "href": "ae/lec-04-poisson-estimate.html#irls-automated",
    "title": "Lecture 04 AE: Estimating coefficients for Poisson Regression",
    "section": "IRLS automated",
    "text": "IRLS automated\n\nnreps &lt;- 10\nhh_data &lt;- hh_data %&gt;%\n  mutate(lambda = hh_data$total + 5)\n\n\nbetas &lt;- tibble(beta0 = rep(0, nreps), \n                beta1 = rep(0, nreps))\n\nfor(i in 1:nreps){\n  hh_data &lt;- hh_data %&gt;%\n    mutate(z = log(lambda) + (hh_data$total - lambda)/ lambda, \n         w = lambda)\n  wls &lt;- lm(z ~ age, weight = w, data = hh_data)\n  betas$beta0[i] = tidy(wls)$estimate[1]\n  betas$beta1[i] = tidy(wls)$estimate[2]\n  \n  hh_data &lt;- hh_data %&gt;% \n    mutate(lambda = exp(predict(wls)))\n}\n  \nbetas\n\n# A tibble: 10 × 2\n   beta0    beta1\n   &lt;dbl&gt;    &lt;dbl&gt;\n 1  1.76 -0.00265\n 2  1.57 -0.00414\n 3  1.55 -0.00468\n 4  1.55 -0.00471\n 5  1.55 -0.00471\n 6  1.55 -0.00471\n 7  1.55 -0.00471\n 8  1.55 -0.00471\n 9  1.55 -0.00471\n10  1.55 -0.00471"
  },
  {
    "objectID": "ae/lec-04-poisson-estimate.html#fit-using-the-glm-function",
    "href": "ae/lec-04-poisson-estimate.html#fit-using-the-glm-function",
    "title": "Lecture 04 AE: Estimating coefficients for Poisson Regression",
    "section": "Fit using the glm function",
    "text": "Fit using the glm function\n\n## add code here"
  },
  {
    "objectID": "prepare/feb-05.html",
    "href": "prepare/feb-05.html",
    "title": "Prepare for Feb 05 lecture",
    "section": "",
    "text": "Read BMLR Section 5.1 - 5.3"
  },
  {
    "objectID": "prepare/feb-12.html",
    "href": "prepare/feb-12.html",
    "title": "Prepare for Feb 12 lecture",
    "section": "",
    "text": "Read BMLR Sections 6.1 - 6.7"
  },
  {
    "objectID": "prepare/jan-24.html",
    "href": "prepare/jan-24.html",
    "title": "Prepare for Jan 24 lecture",
    "section": "",
    "text": "Read Beyond Multiple Linear Regression (BMLR): Sections 4.1 - 4.8"
  },
  {
    "objectID": "prepare/jan-29.html",
    "href": "prepare/jan-29.html",
    "title": "Prepare for Jan 29 lecture",
    "section": "",
    "text": "Read Beyond Multiple Linear Regression (BMLR): Section 4.9"
  },
  {
    "objectID": "prepare/feb-19.html",
    "href": "prepare/feb-19.html",
    "title": "Prepare for Feb 19 lecture",
    "section": "",
    "text": "Read BMLR: Sections 7.1 - 7.8"
  },
  {
    "objectID": "prepare/feb-21.html",
    "href": "prepare/feb-21.html",
    "title": "Prepare for Feb 21 lecture",
    "section": "",
    "text": "Read BMLR: Sections 8.1 - 8.4"
  },
  {
    "objectID": "hw/hw-03.html",
    "href": "hw/hw-03.html",
    "title": "HW 03",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-04.html",
    "href": "hw/hw-04.html",
    "title": "HW 04",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-06.html",
    "href": "hw/hw-06.html",
    "title": "HW 06",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Homework",
      "HW 06"
    ]
  },
  {
    "objectID": "hw/hw-05.html",
    "href": "hw/hw-05.html",
    "title": "HW 05",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Homework",
      "HW 05"
    ]
  },
  {
    "objectID": "hw/hw-01.html",
    "href": "hw/hw-01.html",
    "title": "HW 01: Multiple linear regression",
    "section": "",
    "text": "Important\n\n\n\n\nThis assignment is due on Wednesday, January 24 at 11:59pm with a grace period (i.e., no late penalty) until Thursday, January 25 at 6am.\n\nYour access to the repo will be removed at the end of the grace period. If you wish to submit the HW late, please email me and I will extend your access to the repo.\nYou will have access to your HW repo again when grades are returned.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-1",
    "href": "hw/hw-01.html#exercise-1",
    "title": "HW 01: Multiple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nConsider the following scenario:\n\nResearchers record the number of cricket chirps per minute and temperature during that time. They use linear regression to investigate whether the number of chirps varies with temperature.\n\n\nIdentify the response and predictor variable.\nWrite the complete specification of the statistical model.\nWrite the assumptions for linear regression in the context of the problem.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-2",
    "href": "hw/hw-01.html#exercise-2",
    "title": "HW 01: Multiple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nConsider the following scenario:\n\nA randomized clinical trial investigated postnatal depression and the use of an estrogen patch. Patients were randomly assigned to either use the patch or not. Depression scores were recorded on 6 different visits.\n\n\nIdentify the response and predictor variables.\nIdentify which model assumption(s) are violated. Briefly explain your choice.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-3",
    "href": "hw/hw-01.html#exercise-3",
    "title": "HW 01: Multiple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nUse the Kentucky Derby case study in Chapter 1 of Beyond Multiple Linear Regression.\n\nConsider Equation (1.3) in Section 1.6.3. Show why we have to be sure to say “holding year constant”, “after adjusting for year”, or an equivalent statement, when interpreting \\(\\beta_2\\).\nBriefly explain why there is no error (random variation) term \\(\\epsilon_i\\) in Equation (1.4) in Section 1.6.6?",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-4",
    "href": "hw/hw-01.html#exercise-4",
    "title": "HW 01: Multiple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nThe data set kingCountyHouses.csv in the data folder contains data on over 20,000 houses sold in King County, Washington (Kaggle (2018)).\nWe will use the following variables:\n\nprice = selling price of the house\nsqft = interior square footage\n\nSee Section 1.8 of Beyond Multiple Linear Regression for the full list of variables.\n\nFit a linear regression model with price as the response variable and sqft as the predictor variable (Model 1). Interpret the slope coefficient in terms of the expected change in price when sqft increases by 100.\nFit Model 2, where logprice (the natural log of price) is now the response variable and sqft is still the predictor variable. How is the logprice expected to change when sqft increases by 100?\nRecall that \\(log(a) - log(b) = log(\\frac{a}{b})\\). Use this to derive how the price is expected to change when sqft increases by 100 based on Model 2.\nFit Model 3, where price and logsqft (the natural log of sqft) are the response and predictor variables, respectively. How is the price expected to change when sqft increases by 10%? As a hint, this is the same as multiplying sqft by 1.10.\n\n\n\n\n\n\n\nTip\n\n\n\nClick here for notes on interpreting model effects for log-transformed response and/or predictor variables.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-5",
    "href": "hw/hw-01.html#exercise-5",
    "title": "HW 01: Multiple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nThe goal of this analysis is to use characteristics of 593 colleges and universities in the United States to understand variability in the early career pay, defined as the median salary for alumni with 0 - 5 years of experience. The data was obtained from TidyTuesday College tuition, diversity, and pay, and was originaly collected from the PayScale College Salary Report.\nThe data set is located in college-data.csv in the data folder. We will focus on the following variables:\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\nname\ncharacter\nName of school\n\n\nstate_name\ncharacter\nstate name\n\n\ntype\ncharacter\nPublic or private\n\n\nearly_career_pay\ndouble\nMedian salary for alumni with 0 - 5 years experience (in US dollars)\n\n\nstem_percent\ndouble\nPercent of degrees awarded in science, technology, engineering, or math subjects\n\n\nout_of_state_total\ndouble\nTotal cost for in-state residents in USD (sum of room & board + out of state tuition)\n\n\n\n\nVisualize the distribution of the response variable early_career_pay. Write 1 - 2 observations from the plot.\nVisualize the relationship between (i) early_career_pay and type and (ii) early_career_pay and stem_percent. Write an observation from each plot.\nBelow is the specification of the statistical model for this analysis. Fit the model and neatly display the results using 3 digits. Display the 95% confidence interval for the coefficients.\n\n\\[\n\\begin{align}\nearly\\_career\\_pay_{i} = \\beta_0 &+ \\beta_1~out\\_of\\_state\\_total_{i} \\\\ &+ \\beta_2 ~ type_i\\\\&+ \\beta_3 ~ stem\\_percent_{i}\\\\ &+ \\beta_4 ~ type_i * stem\\_percent_{i} \\\\ &+ \\epsilon_{i}, \\hspace{5mm} \\text{where } \\epsilon_i \\sim N(0, \\sigma^2)\n\\end{align}\n\\]\n\nHow many degrees of freedom are there in the estimate of the regression standard error \\(\\sigma\\) for the model from part c?\nWhat is the 95% confidence interval for the amount in which the intercept for public institutions differs from private institutions?",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-6",
    "href": "hw/hw-01.html#exercise-6",
    "title": "HW 01: Multiple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nUse the analysis from the previous exercise to write a paragraph (~ 3 - 5 sentences) describing the differences in early career pay based on the institution characteristics. The summary should be consistent with the results from the previous exercise, comprehensive, answers the primary analysis question, and tells a cohesive story (e.g., a list of interpretations will not receive full credit).",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#footnotes",
    "href": "hw/hw-01.html#footnotes",
    "title": "HW 01: Multiple linear regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nExercises 1 - 4 are adapted from exercises in Section 1.8 of Roback and Legler (2021).↩︎",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-02.html",
    "href": "hw/hw-02.html",
    "title": "HW 02: Poisson regression",
    "section": "",
    "text": "library(tidyverse)\nlibrary(knitr)\nlibrary(kableExtra)",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-1",
    "href": "hw/hw-02.html#exercise-1",
    "title": "HW 02: Poisson regression",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nAnswer parts a - d in the context of the following study:\nA state wildlife biologist collected data from 250 park visitors as they left at the end of their stay. Each was asked to report the number of fish they caught during their one-week stay. On average, visitors caught 21.5 fish per week.\n\nDefine the response.\nWhat are the possible values for the response?\nWhat does \\(\\lambda\\) represent?\nWould a zero-inflated model be considered here? If so, what would be a “true zero”?",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-2",
    "href": "hw/hw-02.html#exercise-2",
    "title": "HW 02: Poisson regression",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nBrockmann (1996) carried out a study of nesting female horseshoe crabs. Female horseshoe crabs often have male crabs attached to a female’s nest known as satellites. One objective of the study was to determine which characteristics of the female were associated with the number of satellites. Of particular interest is the relationship between the width of the female carapace and satellites.\nThe data can be found in crab.csv in the data folder. It includes the following variables:\n\nSatellite = number of satellites\nWidth = carapace width (cm)\nWeight = weight (kg)\nSpine = spine condition (1 = both good, 2 = one worn or broken, 3 = both worn or broken)\nColor = color (1 = light medium, 2 = medium, 3 = dark medium, 4 = dark)\n\nMake sure to convert Spine and Color to the appropriate data types in R before doing the analysis.\n\nCreate a histogram of Satellite. Is there preliminary evidence the number of satellites could be modeled as a Poisson response? Briefly explain.\nFit a Poisson regression model including Width, Weight, and Spine as predictors. Display the model with the 95% confidence interval for each coefficient.\nDescribe the effect of Spine in terms of the mean number of satellites.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-3",
    "href": "hw/hw-02.html#exercise-3",
    "title": "HW 02: Poisson regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nUse the scenario from the previous exercise to answer questions (a) - (d).\n\nWe would like to fit a quasi-Poisson regression model for this data. Briefly explain why we may want to consider fitting a quasi-Poisson regression model for this data.\nFit a quasi-Poisson regression model that corresponds with the model chosen the previous exercise. Display the model.\nWhat is the estimated dispersion parameter? Show how this value is calculated.\nHow do the estimated coefficients change compared to the model chosen in the previous exercise? How do the standard errors change?",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-4",
    "href": "hw/hw-02.html#exercise-4",
    "title": "HW 02: Poisson regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nThe goal of this exercise is to use simulation to understand the equivalency between a gamma-Poisson mixture and a negative binomial distribution.\n\n\n\n\n\n\nTip\n\n\n\nRemember to set a seed so your simulations are reproducible!\n\n\n\n\nUse the R function rpois() to generate 10,000 \\(x_i\\) from a regular Poisson distribution, \\(X \\sim \\textrm{Poisson}(\\lambda=1.5)\\). Plot a histogram of this distribution and note its mean and variance. Next, let \\(Y \\sim \\textrm{Gamma}(r = 3, \\lambda = 2)\\) and use rgamma() to generate 10,000 random \\(y_i\\) from this distribution.\nNow, consider 10,000 different Poisson distributions where \\(\\lambda_i = y_i\\). Randomly generate one \\(z_i\\) from each Poisson distribution. Plot a histogram of these \\(z_i\\) and compare it to your original histogram of \\(X\\) (where \\(X \\sim \\textrm{Poisson}(1.5)\\)). How do the means and variances compare?\nA negative binomial distribution can actually be expressed as a gamma-Poisson mixture. In Part a, you looked at a gamma-Poisson mixture \\(Z \\sim \\textrm{Poisson}(\\lambda)\\) where \\(\\lambda \\sim \\textrm{Gamma}(r = 3, \\lambda' = 2)\\).\nFind the parameters of a negative binomial distribution \\(X \\sim \\textrm{NegBinom}(r, p)\\) such that \\(X\\) is equivalent to \\(Z\\). As a hint, the means of both distributions must be the same, so \\(\\frac{r(1-p)}{p} = \\frac{3}{2}\\).\nShow through histograms and summary statistics that your negative binomial distribution is equivalent to the gamma-Poisson mixture. You can use rnbinom() in R.\nMake an argument that if you want a \\(\\textrm{NegBinom}(r, p)\\) random variable, you can instead sample from a Poisson distribution, where the \\(\\lambda\\) values are themselves sampled from a gamma distribution with parameters \\(r\\) and \\(\\lambda' = \\frac{p}{1-p}\\).",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-5",
    "href": "hw/hw-02.html#exercise-5",
    "title": "HW 02: Poisson regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nIn a 2018 study, Chapp et al. (2018) scraped every issue statement from webpages of candidates for the U.S. House of Representatives, counting the number of issues candidates commented on and scoring the level of ambiguity of each statement. We will focus on the issue counts, and determining which attributes (of both the district as a whole and the candidates themselves) are associated with candidate silence (commenting on 0 issues) and a willingness to comment on a greater number of issues. The data set is in ambiguity.csv in the data folder . This analysis will focus on the following variables:\n\nname : candidate name\ndistID : unique identification number for Congressional district\nideology : candidate left-right orientation\ndemocrat : 1 if Democrat, 0 if Republican\ntotalIssuePages : number of issues candidates commented on (response)\n\nSee Roback and Legler (2021) for the full list of variables.\nWe will use a hurdle model to analyze the data. A hurdle model is similar to a zero-inflated Poisson model, but instead of assuming that “zeros” are comprised of two distinct groups—those who would always be 0 and those who happen to be 0 on this occasion—the hurdle model assumes that “zeros” are a single entity. Therefore, in a hurdle model, cases are classified as either “zeros” or “non-zeros”, where “non-zeros” hurdle the 0 threshold—they must always have counts of 1 or above.\nWe will use the pscl package and the hurdle function in it to analyze a hurdle model. Note that coefficients in the “zero hurdle model” section of the output relate predictors to the log-odds of being a non-zero (i.e., having at least one issue statement), which is opposite of the ZIP model.\n\nVisualize the distribution of the response variable totalIssuePages. Why might we consider using a hurdle model compared to a Poisson model? Why is a zero-inflated Poisson model not appropriate in this scenario?\nCreate a plot of the empirical log odds of having at least one issue statement by ideology. You may want to group ideology values first. What can you conclude from this plot?\nCreate a hurdle model with ideology and democrat as predictors in both parts.1 Display the model. Interpret ideology in both parts of the model.\nRepeat (d), but include an interaction in both parts. Interpret the interaction in the zero hurdle part of the model.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-6",
    "href": "hw/hw-02.html#exercise-6",
    "title": "HW 02: Poisson regression",
    "section": "Exercise 6",
    "text": "Exercise 6\n\n\nAwad, Lebo, and Linden (2017) scraped 40628 Airbnb listings from New York City in March 2017 and put together the data set NYCairbnb.csv. The codebook is in the data folder of the hw-02 repo.\nPerform the EDA and build a model, considering offset and accounting for overdispersion, if needed. Then, use the model to describe the characteristics of Airbnbs that are expected to have a high number of reviews.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#footnotes",
    "href": "hw/hw-02.html#footnotes",
    "title": "HW 02: Poisson regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe R syntax in the hurlde function is similar to the syntax for the zero-inflated Poisson model. You will need to specify the distributions for the count and hurdle portions of the model, using dist = \"poisson\" and zero.dist = \"binomial\".↩︎",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "prepare/feb-26.html",
    "href": "prepare/feb-26.html",
    "title": "Prepare for Feb 26 lecture",
    "section": "",
    "text": "Read BMLR: Sections 8.5 - 8.12\nSadler, Michael E., and Christopher J. Miller. 2010. “Performance Anxiety: A Longitudinal Study of the Roles of Personality and Experience in Musicians.” Social Psychological and Personality Science 1 (3): 280–87.\n\nClick here to access the paper on Canvas"
  },
  {
    "objectID": "prepare/jan-17.html",
    "href": "prepare/jan-17.html",
    "title": "Prepare for Jan 17 lecture",
    "section": "",
    "text": "Read Beyond Multiple Linear Regression (BMLR): Sections 1.1 - 1.7\nInstall RStudio and configure git or reserve RStudio Docker container. See computing page for instructions.\nIf you have not yet done so, see Canvas announcement for links to…\n\nSign up for Slack\nComplete STA 310 Student Survey"
  },
  {
    "objectID": "prepare/jan-31.html",
    "href": "prepare/jan-31.html",
    "title": "Prepare for Jan 31 lecture",
    "section": "",
    "text": "Read Beyond Multiple Linear Regression (BMLR): Section 4.6, 4.10"
  },
  {
    "objectID": "prepare/jan-22.html",
    "href": "prepare/jan-22.html",
    "title": "Prepare for Jan 22 lecture",
    "section": "",
    "text": "Read Beyond Multiple Linear Regression (BMLR): Sections 2.1 - 2.10\nInstall RStudio and configure git or reserve RStudio Docker container. See computing page for instructions.\nIf you have not yet done so, see Canvas announcement for links to…\n\nSign up for Slack\nComplete STA 310 Student Survey"
  },
  {
    "objectID": "prepare/feb-07.html",
    "href": "prepare/feb-07.html",
    "title": "Prepare for Feb 07 lecture",
    "section": "",
    "text": "Read BMLR Section 6.1 - 6.7"
  },
  {
    "objectID": "ae/lec-05-overdisp.html",
    "href": "ae/lec-05-overdisp.html",
    "title": "Lecture 05 AE: Poisson Regression",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)\nlibrary(knitr)\n# add other packages as needed\nhh_data &lt;- read_csv(\"data/fHH1.csv\")"
  },
  {
    "objectID": "ae/lec-05-overdisp.html#household-vs.-age-age2-and-location",
    "href": "ae/lec-05-overdisp.html#household-vs.-age-age2-and-location",
    "title": "Lecture 05 AE: Poisson Regression",
    "section": "Household vs. age, age^2, and location",
    "text": "Household vs. age, age^2, and location\n\nhh_age_loc &lt;- glm(total ~ age + I(age^2) + location, \n                  data = hh_data, family = poisson)\n\ntidy(hh_age_loc, conf.int = T) |&gt; \n  kable(digits = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.3843\n0.1821\n-2.1107\n0.0348\n-0.7444\n-0.0306\n\n\nage\n0.0704\n0.0069\n10.1900\n0.0000\n0.0569\n0.0840\n\n\nI(age^2)\n-0.0007\n0.0001\n-10.9437\n0.0000\n-0.0008\n-0.0006\n\n\nlocationDavaoRegion\n-0.0194\n0.0538\n-0.3605\n0.7185\n-0.1250\n0.0859\n\n\nlocationIlocosRegion\n0.0610\n0.0527\n1.1580\n0.2468\n-0.0423\n0.1641\n\n\nlocationMetroManila\n0.0545\n0.0472\n1.1542\n0.2484\n-0.0378\n0.1473\n\n\nlocationVisayas\n0.1121\n0.0417\n2.6853\n0.0072\n0.0308\n0.1945\n\n\n\n\n\n\n\n\n\n\n\nCalculating residuals in R\n\n\n\nYou can get the residuals in two ways:\n\nresiduals function with type = \"pearson\" or type = \"deviance\".\naugment function with type.residuals = \"pearson\" or type.residuals = deviance."
  },
  {
    "objectID": "ae/lec-05-overdisp.html#calculate-model-deviance-goodness-of-fit",
    "href": "ae/lec-05-overdisp.html#calculate-model-deviance-goodness-of-fit",
    "title": "Lecture 05 AE: Poisson Regression",
    "section": "Calculate model deviance & Goodness-of-fit",
    "text": "Calculate model deviance & Goodness-of-fit\n\n\n\n\n\n\nEx 1\n\n\n\nUse the deviance residuals to calculate the model deviance.\n\n\n\n# Calculate model deviance\n\n\n\n\n\n\n\nEx 2\n\n\n\nCheck your work above using the glance function.\n\n\n\n# Get deviance using glance function\n\n\n\n\n\n\n\nEx 3\n\n\n\nConduct a goodness-of-fit test\n\n\n\n# Conduct goodness-of-fit test"
  },
  {
    "objectID": "ae/lec-05-overdisp.html#quasi-poisson",
    "href": "ae/lec-05-overdisp.html#quasi-poisson",
    "title": "Lecture 05 AE: Poisson Regression",
    "section": "Quasi-Poisson",
    "text": "Quasi-Poisson\n\nhh_age_loc_q &lt;- glm(total ~ age + I(age^2) + location, \n                    data = hh_data, family = quasipoisson)\n\n\n\n\n\n\n\nEx 4\n\n\n\nWhat do we expect the dispersion parameter to be if there is no overdispersion?\n\n\n\n\n\n\n\n\nEx 5\n\n\n\nUse the Pearson residuals to calculate the dispersion parameter.\n\n\n\n# Calculate dispersion parameter \n\n\n\n\n\n\n\nEx 6\n\n\n\nView the dispersion parameter in the model output\n\n\n\n#summary(hh_age_loc_q)"
  },
  {
    "objectID": "ae/lec-05-overdisp.html#negative-binomial-regression-model",
    "href": "ae/lec-05-overdisp.html#negative-binomial-regression-model",
    "title": "Lecture 05 AE: Poisson Regression",
    "section": "Negative binomial regression model",
    "text": "Negative binomial regression model\n\nhh_age_loc_nb &lt;- MASS::glm.nb(total ~ age + I(age^2) + location, data = hh_data)\ntidy(hh_age_loc_nb) |&gt; \n  kable(digits = 4)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.3753\n0.2076\n-1.8081\n0.0706\n\n\nage\n0.0699\n0.0079\n8.8981\n0.0000\n\n\nI(age^2)\n-0.0007\n0.0001\n-9.5756\n0.0000\n\n\nlocationDavaoRegion\n-0.0219\n0.0625\n-0.3501\n0.7262\n\n\nlocationIlocosRegion\n0.0577\n0.0615\n0.9391\n0.3477\n\n\nlocationMetroManila\n0.0562\n0.0551\n1.0213\n0.3071\n\n\nlocationVisayas\n0.1104\n0.0487\n2.2654\n0.0235"
  },
  {
    "objectID": "ae/lec-08-logistic.html",
    "href": "ae/lec-08-logistic.html",
    "title": "Lecture 08: Logistic regression",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)\nlibrary(knitr)\n\n# add other packages as needed"
  },
  {
    "objectID": "ae/lec-08-logistic.html#data-supporting-railroads-in-the-1870s",
    "href": "ae/lec-08-logistic.html#data-supporting-railroads-in-the-1870s",
    "title": "Lecture 08: Logistic regression",
    "section": "Data: Supporting railroads in the 1870s",
    "text": "Data: Supporting railroads in the 1870s\nThe data set RR_Data_Hale.csv contains information on support for referendums related to railroad subsidies for 11 communities in Hale County, Alabama in the 1870s. The data were originally collected from the US Census by historian Michael Fitzgerald and analyzed as part of a thesis project by a student at St. Olaf College. The variables in the data are\n\npctBlack: percentage of Black residents in the county\ndistance: distance the proposed railroad is from the community (in miles)\nYesVotes: number of “yes” votes in favor of the proposed railroad line\nNumVotes: number of votes cast in the election\n\n\nrr &lt;- read_csv(\"data/RR_Data_Hale.csv\")\n\nrr &lt;- rr |&gt;\n  mutate(pctYes = YesVotes/NumVotes, \n         emp_logit = log(pctYes / (1 - pctYes)), \n         inFavor = if_else(pctYes &gt; 0.5, \"Yes\", \"No\"))"
  },
  {
    "objectID": "ae/ae-02-mlr-review.html",
    "href": "ae/ae-02-mlr-review.html",
    "title": "Lecture 02 AE: Review of multiple linear regression",
    "section": "",
    "text": "Today’s data is from the Kentucky Derby, an annual 1.25-mile horse race held at the Churchill Downs race track in Louisville, KY. The data is in the file derbyplus.csv in the data folder. It contains information for races 1896 - 2017.\nResponse variable\n\nspeed: Average speed of the winner in feet per second (ft/s)\n\nAdditional variable\n\nwinner: Winning horse\n\nPredictor variables\n\nyear: Year of the race\ncondition: Condition of the track (good, fast, slow)\nstarters: Number of horses who raced\n\nGoal: Understand variability in average winner speed based on characteristics of the race.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\n\nderby &lt;- read_csv(\"data/derbyplus.csv\")"
  },
  {
    "objectID": "ae/ae-02-mlr-review.html#introduction",
    "href": "ae/ae-02-mlr-review.html#introduction",
    "title": "Lecture 02 AE: Review of multiple linear regression",
    "section": "",
    "text": "Today’s data is from the Kentucky Derby, an annual 1.25-mile horse race held at the Churchill Downs race track in Louisville, KY. The data is in the file derbyplus.csv in the data folder. It contains information for races 1896 - 2017.\nResponse variable\n\nspeed: Average speed of the winner in feet per second (ft/s)\n\nAdditional variable\n\nwinner: Winning horse\n\nPredictor variables\n\nyear: Year of the race\ncondition: Condition of the track (good, fast, slow)\nstarters: Number of horses who raced\n\nGoal: Understand variability in average winner speed based on characteristics of the race.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\n\nderby &lt;- read_csv(\"data/derbyplus.csv\")"
  },
  {
    "objectID": "ae/ae-02-mlr-review.html#model-1-main-effects-model",
    "href": "ae/ae-02-mlr-review.html#model-1-main-effects-model",
    "title": "Lecture 02 AE: Review of multiple linear regression",
    "section": "Model 1: Main effects model",
    "text": "Model 1: Main effects model\n\nmodel1 &lt;- lm(speed ~ starters + year + condition, data = derby)\n\ntidy(model1) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n8.197\n4.508\n1.818\n0.072\n\n\nstarters\n-0.005\n0.017\n-0.299\n0.766\n\n\nyear\n0.023\n0.002\n9.766\n0.000\n\n\nconditiongood\n-0.443\n0.231\n-1.921\n0.057\n\n\nconditionslow\n-1.543\n0.161\n-9.616\n0.000\n\n\n\n\n\n\n\n\n\n\n\nEx 1\n\n\n\nWrite the equation of the fitted model.\n\n\n[add response here]\n\n\n\n\n\n\nEx 2\n\n\n\nInterpret the coefficient of conditionslow in the context of the data.\n\n\n[add response here]\n\n\n\n\n\n\nEx 3\n\n\n\nDoes the intercept have a meaningful interpretation? If so, interpret it. If not…\n\nRefit the model so that the intercept has a meaningful interpretation.\nInterpret the intercept for the new model.\n\n\n\n[add response here]"
  },
  {
    "objectID": "ae/ae-02-mlr-review.html#model-2-main-effects-quadratic-effect-for-year",
    "href": "ae/ae-02-mlr-review.html#model-2-main-effects-quadratic-effect-for-year",
    "title": "Lecture 02 AE: Review of multiple linear regression",
    "section": "Model 2: Main effects + quadratic effect for year",
    "text": "Model 2: Main effects + quadratic effect for year\n\n\n\n\n\n\nEx 4\n\n\n\nFit a model that includes all main effects and a quadratic term for year. Display the model.\n\n\n[add response here]\n\n\n\n\n\n\nInterpreting quadratic effects\n\n\n\nSuppose you have the following model:\n\\[\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~ x_1  + \\hat{\\beta}_2 ~ x_2 + \\hat{\\beta}_3 ~ x_2^2\\]\nThe interpretation of a variable’s effect when there is a quadratic term in the model is\n“When \\(x_2\\) increases from a to b, \\(y\\) is expected to change by \\(\\hat{\\beta}_2(b - a) + \\hat{\\beta}_3(b^2 - a^2)\\), holding \\(x_1\\) constant.”\n\n\n\n\n\n\n\n\nEx 5\n\n\n\nInterpret the effect of year for the 5 most recent years (2013 - 2017).\n\n\n[add response here]"
  },
  {
    "objectID": "ae/ae-02-mlr-review.html#model-3-main-effects-interaction-between-year-and-condition",
    "href": "ae/ae-02-mlr-review.html#model-3-main-effects-interaction-between-year-and-condition",
    "title": "Lecture 02 AE: Review of multiple linear regression",
    "section": "Model 3: Main effects + interaction between year and condition",
    "text": "Model 3: Main effects + interaction between year and condition\n\n\n\n\n\n\nEx 6\n\n\n\nFit a model that includes all main effects and an interaction between year and condition. Do not include a quadratic term for year. Display the model.\n\n\n[add response here]\n\n\n\n\n\n\nEx 7\n\n\n\nInterpret yearnew:conditiongood.\n\n\n[add response here]\n\n\n\n\n\n\nEx 8\n\n\n\nInterpret the effect of year for slow track conditions.\n\n\n[add response here]"
  },
  {
    "objectID": "projects/final-project.html",
    "href": "projects/final-project.html",
    "title": "Final project",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Projects",
      "Final Project"
    ]
  },
  {
    "objectID": "projects/project-02.html",
    "href": "projects/project-02.html",
    "title": "Project 02",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Projects",
      "Project 02"
    ]
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Course overview",
    "section": "",
    "text": "STA 310 builds upon the content in STA 210: Regression Analysis. In STA 310 students will be introduced to generalized linear models (GLMs), a broad modeling framework that includes linear and logistic models, among others. Students will learn the basic theory of GLMs and how they can used to model a variety of response variables with non-normal distributions. Students will also learn an extension of GLMs that can be applied to modeling data with correlated observations, such as data with repeated measures.",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "course-overview.html#teaching-assistant",
    "href": "course-overview.html#teaching-assistant",
    "title": "Course overview",
    "section": "Teaching assistant",
    "text": "Teaching assistant\nThe teaching assistant for this course is Hun Kang. He is a PhD student in Statistics, and his research interests include scalable model selection, Bayesian nonparametrics and correlated and longitudinal data analysis.\n\n\n\n\nLocation\n\n\n\n\nTue 3 - 5pm\nOld Chem 203B",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "slides/05-poisson-pt2.html#announcements",
    "href": "slides/05-poisson-pt2.html#announcements",
    "title": "Poisson Regression",
    "section": "Announcements",
    "text": "Announcements\nQuiz 01: Tue, Jan 30 ~ 9am - Thu, Feb 01 at noon\n\nThe quiz is not timed and will be administered through Canvas\nCovers:\n\nSyllabus\nCovers readings & lectures: Jan 17 - 24\nOpen book, open note, open internet (not crowd-sourcing sites or AI). You may not discuss the quiz with anyone else. See policy in syllabus.\nPlease email me or send a me a direct message on Slack if you have questions."
  },
  {
    "objectID": "slides/05-poisson-pt2.html#topics",
    "href": "slides/05-poisson-pt2.html#topics",
    "title": "Poisson Regression",
    "section": "Topics",
    "text": "Topics\n\nDefine and calculate residuals for the Poisson regression model\nUse Goodness-of-fit to assess model fit\nIdentify overdispersion\nApply modeling approaches to deal with overdispersion\n\nQuasi-Poisson\nNegative binomial\n\n\n\n\nNotes based on Sections 4.4 and 4.9 of Roback and Legler (2021) unless noted otherwise."
  },
  {
    "objectID": "slides/05-poisson-pt2.html#the-data-household-size-in-the-philippines",
    "href": "slides/05-poisson-pt2.html#the-data-household-size-in-the-philippines",
    "title": "Poisson Regression",
    "section": "The data: Household size in the Philippines",
    "text": "The data: Household size in the Philippines\nThe data fHH1.csv come from the 2015 Family Income and Expenditure Survey conducted by the Philippine Statistics Authority.\nGoal: Understand the association between household size and various characteristics of the household\nResponse:\n\ntotal: Number of people in the household other than the head\n\n\n\nPredictors:\n\nlocation: Where the house is located\nage: Age of the head of household\nroof: Type of roof on the residence (proxy for wealth)\n\n\nOther variables:\n\nnumLT5: Number in the household under 5 years old"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#poisson-regression-model",
    "href": "slides/05-poisson-pt2.html#poisson-regression-model",
    "title": "Poisson Regression",
    "section": "Poisson regression model",
    "text": "Poisson regression model\nIf \\(Y_i \\sim Poisson\\) with \\(\\lambda = \\lambda_i\\) for the given values \\(x_{i1}, \\ldots, x_{ip}\\), then\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_p x_{ip}\\]\n\n\nEach observation can have a different value of \\(\\lambda\\) based on its value of the predictors \\(x_1, \\ldots, x_p\\)\n\\(\\lambda\\) determines the mean and variance, so we don’t need to estimate a separate error term"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#household-vs.-age",
    "href": "slides/05-poisson-pt2.html#household-vs.-age",
    "title": "Poisson Regression",
    "section": "Household vs. Age",
    "text": "Household vs. Age\n\nhh_age &lt;- glm(total ~ age, data = hh_data, family = poisson)\n\ntidy(hh_age) |&gt; \n  kable(digits = 4)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n1.5499\n0.0503\n30.8290\n0\n\n\nage\n-0.0047\n0.0009\n-5.0258\n0\n\n\n\n\n\n\\[\\log(\\hat{\\lambda}) = 1.5499  - 0.0047 ~ age\\]\nThe mean household size is predicted to decrease by 0.47% (multiply by a factor of \\(e^{-0.0047}\\)) for each year older the head of the household is."
  },
  {
    "objectID": "slides/05-poisson-pt2.html#household-vs.-age-and-location",
    "href": "slides/05-poisson-pt2.html#household-vs.-age-and-location",
    "title": "Poisson Regression",
    "section": "Household vs. age and location",
    "text": "Household vs. age and location\n\n\n\n\n\n\n\n\n\n\n\nVisualization recreated from Figure 4.6 in Roback and Legler (2021)."
  },
  {
    "objectID": "slides/05-poisson-pt2.html#add-age2-and-location-to-model",
    "href": "slides/05-poisson-pt2.html#add-age2-and-location-to-model",
    "title": "Poisson Regression",
    "section": "Add \\(age^2\\) and \\(location\\) to model?",
    "text": "Add \\(age^2\\) and \\(location\\) to model?\n\nhh_age_loc &lt;- glm(total ~ age + I(age^2) + location, \n                  data = hh_data, family = poisson)\n\n\n\nUse Likelihood Ratio Test\n\nanova(hh_age, hh_age_loc, test = \"LRT\") |&gt;\n  kable(digits = 3)\n\n\n\n\nResid. Df\nResid. Dev\nDf\nDeviance\nPr(&gt;Chi)\n\n\n\n\n1498\n2337.089\nNA\nNA\nNA\n\n\n1493\n2187.800\n5\n149.289\n0"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#selected-model",
    "href": "slides/05-poisson-pt2.html#selected-model",
    "title": "Poisson Regression",
    "section": "Selected model",
    "text": "Selected model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.3843\n0.1821\n-2.1107\n0.0348\n-0.7444\n-0.0306\n\n\nage\n0.0704\n0.0069\n10.1900\n0.0000\n0.0569\n0.0840\n\n\nI(age^2)\n-0.0007\n0.0001\n-10.9437\n0.0000\n-0.0008\n-0.0006\n\n\nlocationDavaoRegion\n-0.0194\n0.0538\n-0.3605\n0.7185\n-0.1250\n0.0859\n\n\nlocationIlocosRegion\n0.0610\n0.0527\n1.1580\n0.2468\n-0.0423\n0.1641\n\n\nlocationMetroManila\n0.0545\n0.0472\n1.1542\n0.2484\n-0.0378\n0.1473\n\n\nlocationVisayas\n0.1121\n0.0417\n2.6853\n0.0072\n0.0308\n0.1945\n\n\n\n\n\n\nDoes this model sufficiently explain the variability in the mean household size?"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#pearson-residuals",
    "href": "slides/05-poisson-pt2.html#pearson-residuals",
    "title": "Poisson Regression",
    "section": "Pearson residuals",
    "text": "Pearson residuals\nWe can calculate two types of residuals for Poisson regression: Pearson residuals and deviance residuals\n\n\\[\\text{Pearson residual}_i = \\frac{\\text{observed} - \\text{predicted}}{\\text{std. error}} = \\frac{Y_i - \\hat{\\lambda}_i}{\\sqrt{\\hat{\\lambda}_i}}\\]\n\n\nSimilar interpretation as standardized residuals from linear regression\nExpect most to fall between -2 and 2\nUsed to calculate overdispersion parameter (more on this soon)"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#deviance-residuals",
    "href": "slides/05-poisson-pt2.html#deviance-residuals",
    "title": "Poisson Regression",
    "section": "Deviance residuals",
    "text": "Deviance residuals\n\nThe deviance residual describes how the observed data deviates from the fitted model \\[\\text{deviance residual}_i = \\text{sign}(Y_i - \\hat{\\lambda}_i)\\sqrt{2\\Bigg[Y_i\\log\\bigg(\\frac{Y_i}{\\hat{\\lambda}_i}\\bigg) - (Y_i - \\hat{\\lambda}_i)\\Bigg]}\\]\n\nwhere\n\\[\\text{sign}(Y_i - \\hat{\\lambda}_i)  =  \\begin{cases}\n1 & \\text{ if }(Y_i - \\hat{\\lambda}_i) &gt; 0 \\\\\n-1 & \\text{ if }(Y_i - \\hat{\\lambda}_i) &lt; 0 \\\\\n0 & \\text{ if }(Y_i - \\hat{\\lambda}_i) = 0\n\\end{cases}\\]\n\nGood fitting models \\(\\Rightarrow\\) small deviances"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#selected-model-residual-plots",
    "href": "slides/05-poisson-pt2.html#selected-model-residual-plots",
    "title": "Poisson Regression",
    "section": "Selected model: Residual plots",
    "text": "Selected model: Residual plots\n\nhh_age_loc_aug_pearson &lt;- augment(hh_age_loc, type.residuals = \"pearson\") \nhh_age_loc_aug_deviance &lt;- augment(hh_age_loc, type.residuals = \"deviance\")"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#goodness-of-fit-1",
    "href": "slides/05-poisson-pt2.html#goodness-of-fit-1",
    "title": "Poisson Regression",
    "section": "Goodness-of-fit",
    "text": "Goodness-of-fit\n\nGoal: Use the (residual) deviance to assess how much the predicted values differ from the observed values.\n\\[\n\\text{deviance} = \\sum_{i=1}^{n}(\\text{deviance residual})_i^2\n\\]\nWhen a model is true, we expect\n\\[\\text{deviance} \\sim \\chi^2_{df}\\]\n\nwhere \\(df\\) is the model’s residual degrees of freedom\n\n\nQuestion to answer: What is the probability of observing a deviance larger than the one we’ve observed, given this model sufficiently fits the data?\n\n\\[P(\\chi^2_{df} &gt; \\text{ deviance})\\]"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#goodness-of-fit-calculations",
    "href": "slides/05-poisson-pt2.html#goodness-of-fit-calculations",
    "title": "Poisson Regression",
    "section": "Goodness-of-fit calculations",
    "text": "Goodness-of-fit calculations\n\nhh_age_loc$deviance\n\n[1] 2187.8\n\nhh_age_loc$df.residual\n\n[1] 1493\n\n\n\n\npchisq(hh_age_loc$deviance, hh_age_loc$df.residual, lower.tail = FALSE)\n\n[1] 3.153732e-29\n\n\n\n\n\nThe probability of observing a deviance greater than 2187.8 is \\(\\approx 0\\), so there is significant evidence of lack-of-fit."
  },
  {
    "objectID": "slides/05-poisson-pt2.html#lack-of-fit",
    "href": "slides/05-poisson-pt2.html#lack-of-fit",
    "title": "Poisson Regression",
    "section": "Lack-of-fit",
    "text": "Lack-of-fit\nThere are a few potential reasons for observing lack-of-fit:\n\nMissing important interactions or higher-order terms\nMissing important variables (perhaps this means a more comprehensive data set is required)\nThere could be extreme observations causing the deviance to be larger than expected (assess based on the residual plots)\nThere could be a problem with the Poisson model\n\nOnly one parameter \\(\\lambda\\) to describe mean and variance\nMay need more flexibility in the model to handle overdispersion"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#overdispersion",
    "href": "slides/05-poisson-pt2.html#overdispersion",
    "title": "Poisson Regression",
    "section": "Overdispersion",
    "text": "Overdispersion\nOverdispersion: There is more variability in the response than what is implied by the Poisson model\n\n\n\n\nOverall\n\n\n\n\n\n\nmean\nvar\n\n\n\n\n3.685\n5.534\n\n\n\n\n\n\n\nby Location\n\n\n\n\n\n\nlocation\nmean\nvar\n\n\n\n\nCentralLuzon\n3.402\n4.152\n\n\nDavaoRegion\n3.390\n4.723\n\n\nIlocosRegion\n3.586\n5.402\n\n\nMetroManila\n3.707\n4.863\n\n\nVisayas\n3.902\n6.602"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#why-overdispersion-matters",
    "href": "slides/05-poisson-pt2.html#why-overdispersion-matters",
    "title": "Poisson Regression",
    "section": "Why overdispersion matters",
    "text": "Why overdispersion matters\nIf there is overdispersion, then there is more variation in the response than what’s implied by a Poisson model. This means\nThe standard errors of the model coefficients are artificially small\n\\(\\Rightarrow\\) The p-values are artificially small\n\\(\\Rightarrow\\) Could lead to models that are more complex than what is needed\n\nWe can take overdispersion into account by\n\ninflating standard errors by multiplying them by a dispersion factor\nusing a negative-binomial regression model"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#dispersion-parameter",
    "href": "slides/05-poisson-pt2.html#dispersion-parameter",
    "title": "Poisson Regression",
    "section": "Dispersion parameter",
    "text": "Dispersion parameter\nThe dispersion parameter is represented by \\(\\phi\\) \\[\\hat{\\phi} = \\frac{\\sum_{i=1}^{n}(\\text{Pearson residuals})^2}{n - p}\\]\nwhere \\(p\\) is the number of terms in the model (including the intercept)\n\n\nIf there is no overdispersion \\(\\hat{\\phi} = 1\\)\nIf there is overdispersion \\(\\hat{\\phi} &gt; 1\\)"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#accounting-for-dispersion",
    "href": "slides/05-poisson-pt2.html#accounting-for-dispersion",
    "title": "Poisson Regression",
    "section": "Accounting for dispersion",
    "text": "Accounting for dispersion\n\nWe inflate the standard errors of the coefficient by multiplying the variance by \\(\\hat{\\phi}\\)\n\n\\[SE_{Q}(\\hat{\\beta}) = \\sqrt{\\hat{\\phi}}  * SE(\\hat{\\beta})\\]\n“Q” stands for quasi-Poisson, since this is an ad-hoc solution - The process for model building and model comparison is called quasilikelihood (similar to likelihood without exact underlying distributions)"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#quasi-poisson-model",
    "href": "slides/05-poisson-pt2.html#quasi-poisson-model",
    "title": "Poisson Regression",
    "section": "Quasi-Poisson model",
    "text": "Quasi-Poisson model\n\nhh_age_loc_q &lt;- glm(total ~ age + I(age^2) + location, data = hh_data, \n                family = quasipoisson) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.3843\n0.2166\n-1.7744\n0.0762\n-0.8134\n0.0358\n\n\nage\n0.0704\n0.0082\n8.5665\n0.0000\n0.0544\n0.0866\n\n\nI(age^2)\n-0.0007\n0.0001\n-9.2000\n0.0000\n-0.0009\n-0.0006\n\n\nlocationDavaoRegion\n-0.0194\n0.0640\n-0.3030\n0.7619\n-0.1451\n0.1058\n\n\nlocationIlocosRegion\n0.0610\n0.0626\n0.9735\n0.3304\n-0.0620\n0.1837\n\n\nlocationMetroManila\n0.0545\n0.0561\n0.9703\n0.3320\n-0.0552\n0.1649\n\n\nlocationVisayas\n0.1121\n0.0497\n2.2574\n0.0241\n0.0156\n0.2103"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#poisson-vs.-quasi-poisson-models",
    "href": "slides/05-poisson-pt2.html#poisson-vs.-quasi-poisson-models",
    "title": "Poisson Regression",
    "section": "Poisson vs. Quasi-Poisson models",
    "text": "Poisson vs. Quasi-Poisson models\n\n\n\nPoisson\n\n\n\n\n\n\nterm\nestimate\nstd.error\n\n\n\n\n(Intercept)\n-0.3843\n0.1821\n\n\nage\n0.0704\n0.0069\n\n\nI(age^2)\n-0.0007\n0.0001\n\n\nlocationDavaoRegion\n-0.0194\n0.0538\n\n\nlocationIlocosRegion\n0.0610\n0.0527\n\n\nlocationMetroManila\n0.0545\n0.0472\n\n\nlocationVisayas\n0.1121\n0.0417\n\n\n\n\n\n\n\nQuasi-Poisson\n\n\n\n\n\n\nestimate\nstd.error\n\n\n\n\n-0.3843\n0.2166\n\n\n0.0704\n0.0082\n\n\n-0.0007\n0.0001\n\n\n-0.0194\n0.0640\n\n\n0.0610\n0.0626\n\n\n0.0545\n0.0561\n\n\n0.1121\n0.0497"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#quasi-poisson-inference-for-coefficients",
    "href": "slides/05-poisson-pt2.html#quasi-poisson-inference-for-coefficients",
    "title": "Poisson Regression",
    "section": "Quasi-Poisson: Inference for coefficients",
    "text": "Quasi-Poisson: Inference for coefficients\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\n\n\n\n\n(Intercept)\n-0.3843\n0.2166\n\n\nage\n0.0704\n0.0082\n\n\nI(age^2)\n-0.0007\n0.0001\n\n\nlocationDavaoRegion\n-0.0194\n0.0640\n\n\nlocationIlocosRegion\n0.0610\n0.0626\n\n\nlocationMetroManila\n0.0545\n0.0561\n\n\nlocationVisayas\n0.1121\n0.0497\n\n\n\n\n\n\n\nTest statistic\n\n\\[t = \\frac{\\hat{\\beta} - 0}{SE_{Q}(\\hat{\\beta})} \\sim t_{n-p}\\]"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#quasi-poisson-model-1",
    "href": "slides/05-poisson-pt2.html#quasi-poisson-model-1",
    "title": "Poisson Regression",
    "section": "Quasi-Poisson model",
    "text": "Quasi-Poisson model\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.3843\n0.2166\n-1.7744\n0.0762\n-0.8134\n0.0358\n\n\nage\n0.0704\n0.0082\n8.5665\n0.0000\n0.0544\n0.0866\n\n\nI(age^2)\n-0.0007\n0.0001\n-9.2000\n0.0000\n-0.0009\n-0.0006\n\n\nlocationDavaoRegion\n-0.0194\n0.0640\n-0.3030\n0.7619\n-0.1451\n0.1058\n\n\nlocationIlocosRegion\n0.0610\n0.0626\n0.9735\n0.3304\n-0.0620\n0.1837\n\n\nlocationMetroManila\n0.0545\n0.0561\n0.9703\n0.3320\n-0.0552\n0.1649\n\n\nlocationVisayas\n0.1121\n0.0497\n2.2574\n0.0241\n0.0156\n0.2103"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#negative-binomial-regression-model-1",
    "href": "slides/05-poisson-pt2.html#negative-binomial-regression-model-1",
    "title": "Poisson Regression",
    "section": "Negative binomial regression model",
    "text": "Negative binomial regression model\nAnother approach to handle overdispersion is to use a negative binomial regression model\n\nThis has more flexibility than the quasi-Poisson model, because there is a new parameter in addition to \\(\\lambda\\)\n\n\n\nLet \\(Y\\) be a negative binomial random variable, \\(Y\\sim NegBinom(r, p)\\), then\n\\[\\begin{align}P(Y = y_i) = {y_i + r - 1 \\choose r - 1}(1-p)^{y_i}p^r \\hspace{5mm} y_i = 0, 1, 2, \\ldots, \\infty \\\\\nE(Y) = \\frac{r(1-p)}{p} \\hspace{8mm} SD(Y) = \\sqrt{\\frac{r(1-p)}{p^2}}\\end{align}\\]"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#negative-binomial-regression-model-2",
    "href": "slides/05-poisson-pt2.html#negative-binomial-regression-model-2",
    "title": "Poisson Regression",
    "section": "Negative binomial regression model",
    "text": "Negative binomial regression model\n\n\nMain idea: Generate a \\(\\lambda\\) for each observation (household) and generate a count using the Poisson random variable with parameter \\(\\lambda\\)\n\nMakes the counts more dispersed than with a single parameter\n\nThink of it as a Poisson model such that \\(\\lambda\\) is also random \\[\\begin{aligned} &\\text{If }\\hspace{2mm} Y|\\lambda \\sim Poisson(\\lambda)\\\\\n&\\text{ and } \\lambda \\sim Gamma\\bigg(r, \\frac{1-p}{p}\\bigg)\\\\\n&\\text{ then } Y \\sim NegBinom(r, p)\\end{aligned}\\]"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#negative-binomial-regression-in-r",
    "href": "slides/05-poisson-pt2.html#negative-binomial-regression-in-r",
    "title": "Poisson Regression",
    "section": "Negative binomial regression in R",
    "text": "Negative binomial regression in R\nUse the glm.nb function in the MASS R package.\n\n\n\n\n\n\n\nCaution\n\n\nThe MASS package has a select function that conflicts with the select function in dplyr. You can avoid this by (1) always loading tidyverse after MASS, or (2) use MASS::glm.nb instead of loading the package."
  },
  {
    "objectID": "slides/05-poisson-pt2.html#negative-binomial-regression-in-r-1",
    "href": "slides/05-poisson-pt2.html#negative-binomial-regression-in-r-1",
    "title": "Poisson Regression",
    "section": "Negative binomial regression in R",
    "text": "Negative binomial regression in R\n\nhh_age_loc_nb &lt;- MASS::glm.nb(total ~ age + I(age^2) + location, data = hh_data)\ntidy(hh_age_loc_nb) |&gt; \n  kable(digits = 4)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.3753\n0.2076\n-1.8081\n0.0706\n\n\nage\n0.0699\n0.0079\n8.8981\n0.0000\n\n\nI(age^2)\n-0.0007\n0.0001\n-9.5756\n0.0000\n\n\nlocationDavaoRegion\n-0.0219\n0.0625\n-0.3501\n0.7262\n\n\nlocationIlocosRegion\n0.0577\n0.0615\n0.9391\n0.3477\n\n\nlocationMetroManila\n0.0562\n0.0551\n1.0213\n0.3071\n\n\nlocationVisayas\n0.1104\n0.0487\n2.2654\n0.0235"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#negative-binomial-vs.-quasi-poisson",
    "href": "slides/05-poisson-pt2.html#negative-binomial-vs.-quasi-poisson",
    "title": "Poisson Regression",
    "section": "Negative binomial vs. Quasi-Poisson",
    "text": "Negative binomial vs. Quasi-Poisson\n\n\n\nQuasi-Poisson\n\n\n\n\n\n\nterm\nestimate\nstd.error\n\n\n\n\n(Intercept)\n-0.3843\n0.2166\n\n\nage\n0.0704\n0.0082\n\n\nI(age^2)\n-0.0007\n0.0001\n\n\nlocationDavaoRegion\n-0.0194\n0.0640\n\n\nlocationIlocosRegion\n0.0610\n0.0626\n\n\nlocationMetroManila\n0.0545\n0.0561\n\n\nlocationVisayas\n0.1121\n0.0497\n\n\n\n\n\n\n\n\n\nNegative binomial\n\n\n\n\n\n\nestimate\nstd.error\n\n\n\n\n-0.3753\n0.2076\n\n\n0.0699\n0.0079\n\n\n-0.0007\n0.0001\n\n\n-0.0219\n0.0625\n\n\n0.0577\n0.0615\n\n\n0.0562\n0.0551\n\n\n0.1104\n0.0487"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#references",
    "href": "slides/05-poisson-pt2.html#references",
    "title": "Poisson Regression",
    "section": "References",
    "text": "References\n\n\n\n\n🔗 STA 310 - Spring 2024\n\n\n\n\nRoback, Paul, and Julie Legler. 2021. Beyond multiple linear regression: applied generalized linear models and multilevel models in R. CRC Press."
  },
  {
    "objectID": "slides/08-logistic-pt2.html#announcements",
    "href": "slides/08-logistic-pt2.html#announcements",
    "title": "Logistic regression",
    "section": "Announcements",
    "text": "Announcements\n\nHW 02 due TODAY at 11:59pm\nProject 01\n\npresentations in class Wed, Feb 14\nwrite up due Thu, Feb 15 at noon"
  },
  {
    "objectID": "slides/08-logistic-pt2.html#learning-goals",
    "href": "slides/08-logistic-pt2.html#learning-goals",
    "title": "Logistic regression",
    "section": "Learning goals",
    "text": "Learning goals\n\nVisualizations for logistic regression\nFit and interpret logistic regression model for binomial response variable\nExplore diagnostics for logistic regression\nSummarize GLMs for independent observations\n\n\n\nNotes based on Chapter 6 Roback and Legler (2021) unless noted otherwise."
  },
  {
    "objectID": "slides/08-logistic-pt2.html#bernoulli-binomial-random-variables",
    "href": "slides/08-logistic-pt2.html#bernoulli-binomial-random-variables",
    "title": "Logistic regression",
    "section": "Bernoulli + Binomial random variables",
    "text": "Bernoulli + Binomial random variables\nLogistic regression is used to analyze data with two types of responses:\n\nBernoulli (Binary): These responses take on two values success \\((Y = 1)\\) or failure \\((Y = 0)\\), yes \\((Y = 1)\\) or no \\((Y = 0)\\), etc.\n\n\\[P(Y = y) = p^y(1-p)^{1-y} \\hspace{10mm} y = 0, 1\\]\n\nBinomial: Number of successes in a Bernoulli process, \\(n\\) independent trials with a constant probability of success \\(p\\).\n\n\\[P(Y = y) = {n \\choose y}p^{y}(1-p)^{n - y} \\hspace{10mm} y = 0, 1, \\ldots, n\\]\n\nIn both instances, the goal is to model \\(p\\) the probability of success."
  },
  {
    "objectID": "slides/08-logistic-pt2.html#logistic-regression-model",
    "href": "slides/08-logistic-pt2.html#logistic-regression-model",
    "title": "Logistic regression",
    "section": "Logistic regression model",
    "text": "Logistic regression model\n\\[\n\\log\\Big(\\frac{p}{1-p}\\Big) = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_px_p\n\\]\n\nThe response variable, \\(\\log\\Big(\\frac{p}{1-p}\\Big)\\), is the log(odds) of success, i.e. the logit\nUse the model to calculate the probability of success \\[\\hat{p} = \\frac{e^{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_px_p}}{1 + e^{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_px_p}}\\]\nWhen the response is a Bernoulli random variable, the probabilities can be used to classify each observation as a success or failure"
  },
  {
    "objectID": "slides/08-logistic-pt2.html#interpreting-coefficients",
    "href": "slides/08-logistic-pt2.html#interpreting-coefficients",
    "title": "Logistic regression",
    "section": "Interpreting coefficients",
    "text": "Interpreting coefficients\n\\[\n\\log\\Big(\\frac{\\hat{p}}{1-\\hat{p}}\\Big) = \\hat{\\beta}_0 + \\hat{\\beta}_1x_1 + \\hat{\\beta}_2x_2 + \\dots + \\hat{\\beta}_px_p\n\\]\n\n\\(\\hat{\\beta}_j\\) is predicted change in the log-odds when going from \\(x_j\\) to \\(x_j + 1\\), holding all else constant\n\\(e^{\\beta_j}\\) is the predicted change the odds when going from \\(x_j\\) to \\(x_j + 1\\), holding all else constant (odds ratio)"
  },
  {
    "objectID": "slides/08-logistic-pt2.html#covid-19-infection-prevention-practices-at-food-establishments",
    "href": "slides/08-logistic-pt2.html#covid-19-infection-prevention-practices-at-food-establishments",
    "title": "Logistic regression",
    "section": "COVID-19 infection prevention practices at food establishments",
    "text": "COVID-19 infection prevention practices at food establishments\nResearchers at Wollo Univeristy in Ethiopia conducted a study in July and August 2020 to understand factors associated with good COVID-19 infection prevention practices at food establishments. Their study is published in Andualem et al. (2022) .\n\nThey were particularly interested in the understanding implementation of prevention practices at food establishments, given the workers’ increased risk due to daily contact with customers."
  },
  {
    "objectID": "slides/08-logistic-pt2.html#results",
    "href": "slides/08-logistic-pt2.html#results",
    "title": "Logistic regression",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "slides/08-logistic-pt2.html#interpretation",
    "href": "slides/08-logistic-pt2.html#interpretation",
    "title": "Logistic regression",
    "section": "Interpretation",
    "text": "Interpretation\n\n\nThe (adjusted) odds ratio for availability of COVID-19 infection prevention guidelines is 2.68 with 95% CI (1.52, 4.75).\nThe odds ratio between workers at a restaurant with such guidelines and those at a restaurant without the guidelines is 2.68, after adjusting for the other factors.\nInterpretation: The odds a worker at a restaurant with COVID-19 infection prevention guidelines uses good infection prevention practices is 2.68 times the odds of a worker at a restaurant without the guidelines, holding all other factors constant."
  },
  {
    "objectID": "slides/08-logistic-pt2.html#access-to-personal-protective-equipment",
    "href": "slides/08-logistic-pt2.html#access-to-personal-protective-equipment",
    "title": "Logistic regression",
    "section": "Access to personal protective equipment",
    "text": "Access to personal protective equipment\nWe will use the data from Andualem et al. (2022) to explore the association between age, sex, years of service, and whether someone works at a food establishment with access to personal protective equipment (PPE) as of August 2020. We will use access to PPE as a proxy for wearing PPE.\n\n\n\n\n\nage\nsex\nyears\nppe_access\n\n\n\n\n34\nMale\n2\n1\n\n\n32\nFemale\n3\n1\n\n\n32\nFemale\n1\n1\n\n\n40\nMale\n4\n1\n\n\n32\nMale\n10\n1"
  },
  {
    "objectID": "slides/08-logistic-pt2.html#eda-for-binary-response",
    "href": "slides/08-logistic-pt2.html#eda-for-binary-response",
    "title": "Logistic regression",
    "section": "EDA for binary response",
    "text": "EDA for binary response\n\nlibrary(Stat2Data)\npar(mfrow = c(1, 2))\nemplogitplot1(ppe_access ~ age, data = covid_df, ngroups = 10)\nemplogitplot1(ppe_access ~ years, data = covid_df, ngroups = 5)"
  },
  {
    "objectID": "slides/08-logistic-pt2.html#eda-for-binary-response-1",
    "href": "slides/08-logistic-pt2.html#eda-for-binary-response-1",
    "title": "Logistic regression",
    "section": "EDA for binary response",
    "text": "EDA for binary response\n\nlibrary(viridis)\nggplot(data = covid_df, aes(x = sex, fill = factor(ppe_access))) + \n  geom_bar(position = \"fill\")  +\n  labs(x = \"Sex\", \n       fill = \"PPE Access\", \n       title = \"PPE Access by Sex\") + \n  scale_fill_viridis_d()"
  },
  {
    "objectID": "slides/08-logistic-pt2.html#model-results",
    "href": "slides/08-logistic-pt2.html#model-results",
    "title": "Logistic regression",
    "section": "Model results",
    "text": "Model results\n\nppe_model &lt;- glm(factor(ppe_access) ~ age + sex + years, \n                 data = covid_df, family = binomial)\ntidy(ppe_model, conf.int = TRUE) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-2.127\n0.458\n-4.641\n0.000\n-3.058\n-1.257\n\n\nage\n0.056\n0.017\n3.210\n0.001\n0.023\n0.091\n\n\nsexMale\n0.341\n0.224\n1.524\n0.128\n-0.098\n0.780\n\n\nyears\n0.264\n0.066\n4.010\n0.000\n0.143\n0.401"
  },
  {
    "objectID": "slides/08-logistic-pt2.html#visualizing-coefficient-estimates",
    "href": "slides/08-logistic-pt2.html#visualizing-coefficient-estimates",
    "title": "Logistic regression",
    "section": "Visualizing coefficient estimates",
    "text": "Visualizing coefficient estimates\n\nmodel_odds_ratios &lt;- tidy(ppe_model, exponentiate = TRUE, conf.int = TRUE)\n\n\nggplot(data = model_odds_ratios, aes(x = term, y = estimate)) +\n  geom_point() +\n  geom_hline(yintercept = 1, lty = 2) + \n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high))+\n  labs(title = \"Adjusted odds ratios\",\n       x = \"\",\n       y = \"Estimated AOR\") +\n  coord_flip()"
  },
  {
    "objectID": "slides/08-logistic-pt2.html#data-supporting-railroads-in-the-1870s",
    "href": "slides/08-logistic-pt2.html#data-supporting-railroads-in-the-1870s",
    "title": "Logistic regression",
    "section": "Data: Supporting railroads in the 1870s",
    "text": "Data: Supporting railroads in the 1870s\nThe data set RR_Data_Hale.csv contains information on support for referendums related to railroad subsidies for 11 communities in Hale County, Alabama in the 1870s. The data were originally collected from the US Census by historian Michael Fitzgerald and analyzed as part of a thesis project by a student at St. Olaf College. The variables in the data are\n\npctBlack: percentage of Black residents in the county\ndistance: distance the proposed railroad is from the community (in miles)\nYesVotes: number of “yes” votes in favor of the proposed railroad line\nNumVotes: number of votes cast in the election\n\n\nPrimary question: Was voting on the railroad referendum related to the distance from the proposed railroad line, after adjusting for the demographics of a county?"
  },
  {
    "objectID": "slides/08-logistic-pt2.html#the-data",
    "href": "slides/08-logistic-pt2.html#the-data",
    "title": "Logistic regression",
    "section": "The data",
    "text": "The data\n\nrr &lt;- read_csv(\"data/RR_Data_Hale.csv\")\nrr |&gt; slice(1:5) |&gt; kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCounty\npopBlack\npopWhite\npopTotal\npctBlack\ndistance\nYesVotes\nNumVotes\n\n\n\n\nCarthage\n841\n599\n1440\n58.40\n17\n61\n110\n\n\nCederville\n1774\n146\n1920\n92.40\n7\n0\n15\n\n\nFive Mile Creek\n140\n626\n766\n18.28\n15\n4\n42\n\n\nGreensboro\n1425\n975\n2400\n59.38\n0\n1790\n1804\n\n\nHarrison\n443\n355\n798\n55.51\n7\n0\n15"
  },
  {
    "objectID": "slides/08-logistic-pt2.html#exploratory-data-analysis",
    "href": "slides/08-logistic-pt2.html#exploratory-data-analysis",
    "title": "Logistic regression",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nrr &lt;- rr |&gt;\n  mutate(pctYes = YesVotes/NumVotes, \n         emp_logit = log(pctYes / (1 - pctYes)))"
  },
  {
    "objectID": "slides/08-logistic-pt2.html#exploratory-data-analysis-1",
    "href": "slides/08-logistic-pt2.html#exploratory-data-analysis-1",
    "title": "Logistic regression",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nrr &lt;- rr |&gt;\n  mutate(inFavor = if_else(pctYes &gt; 0.5, \"Yes\", \"No\"))\n\n\nCheck for potential multicollinearity and interaction effect."
  },
  {
    "objectID": "slides/08-logistic-pt2.html#model",
    "href": "slides/08-logistic-pt2.html#model",
    "title": "Logistic regression",
    "section": "Model",
    "text": "Model\nLet \\(p\\) be the percent of yes votes in a county. We’ll start by fitting the following model:\n\\[\\log\\Big(\\frac{p}{1-p}\\Big)  = \\beta_0 + \\beta_1 ~ dist + \\beta_2 ~ pctBlack\\]\n\nLikelihood\n\\[\\begin{aligned}L(p) &= \\prod_{i=1}^{n} {m_i \\choose y_i}p_i^{y_i}(1 - p_i)^{m_i - y_i} \\\\\n&= \\prod_{i=1}^{n} {m_i \\choose y_i}\\Big[\\frac{e^{\\beta_0 + \\beta_1 ~ dist_i + \\beta_2 ~ pctBlack_i}}{1 + e^{\\beta_0 + \\beta_1 ~ dist_i + \\beta_2 ~ pctBlack_i}}\\Big]^{y_i}\\Big[\\frac{1}{e^{\\beta_0 + \\beta_1 ~ dist_i + \\beta_2 ~ pctBlack_i}}\\Big]^{m_i - y_i} \\\\\\end{aligned}\\]\nUse IRLS to find \\(\\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\beta}_2\\)."
  },
  {
    "objectID": "slides/08-logistic-pt2.html#model-in-r",
    "href": "slides/08-logistic-pt2.html#model-in-r",
    "title": "Logistic regression",
    "section": "Model in R",
    "text": "Model in R\n\nrr_model &lt;- glm(cbind(YesVotes, NumVotes - YesVotes) ~ distance + pctBlack, \n                data = rr, family = binomial)\ntidy(rr_model, conf.int = TRUE) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n4.222\n0.297\n14.217\n0.000\n3.644\n4.809\n\n\ndistance\n-0.292\n0.013\n-22.270\n0.000\n-0.318\n-0.267\n\n\npctBlack\n-0.013\n0.004\n-3.394\n0.001\n-0.021\n-0.006\n\n\n\n\n\n\\[\\log\\Big(\\frac{\\hat{p}}{1-\\hat{p}}\\Big)  = 4.22 - 0.292 ~ dist - 0.013 ~ pctBlack\\]"
  },
  {
    "objectID": "slides/08-logistic-pt2.html#residuals",
    "href": "slides/08-logistic-pt2.html#residuals",
    "title": "Logistic regression",
    "section": "Residuals",
    "text": "Residuals\nSimilar to Poisson regression, there are two types of residuals: Pearson and deviance residuals\n\nPearson residuals\n\\[\n\\text{Pearson residual}_i = \\frac{\\text{actual count} - \\text{predicted count}}{\\text{SD count}} = \\frac{Y_i - m_i\\hat{p}_i}{\\sqrt{m_i\\hat{p}_i(1 - \\hat{p}_i)}}\n\\]\n\n\nDeviance residuals\n\\[\nd_i = \\text{sign}(Y_i - m_i\\hat{p}_i)\\sqrt{2\\Big[Y_i\\log\\Big(\\frac{Y_i}{m_i\\hat{p}_i}\\Big) + (m_i - Y_i)\\log\\Big(\\frac{m_i - Y_i}{m_i - m_i\\hat{p}_i}\\Big)\\Big]}\n\\]"
  },
  {
    "objectID": "slides/08-logistic-pt2.html#plot-of-deviance-residuals",
    "href": "slides/08-logistic-pt2.html#plot-of-deviance-residuals",
    "title": "Logistic regression",
    "section": "Plot of deviance residuals",
    "text": "Plot of deviance residuals\n\nrr_int_aug &lt;- augment(rr_int_model, type.predict = \"response\", \n                        type.residuals = \"deviance\")"
  },
  {
    "objectID": "slides/08-logistic-pt2.html#goodness-of-fit",
    "href": "slides/08-logistic-pt2.html#goodness-of-fit",
    "title": "Logistic regression",
    "section": "Goodness of fit",
    "text": "Goodness of fit\nSimilar to Poisson regression, the sum of the squared deviance residuals is used to assess goodness of fit.\n\\[\\begin{aligned} &H_0: \\text{ Model is a good fit} \\\\\n&H_a: \\text{ Model is not a good fit}\\end{aligned}\\]\n\n\nWhen \\(m_i\\)’s are large and the model is a good fit \\((H_0 \\text{ true})\\) the residual deviance follows a \\(\\chi^2\\) distribution with \\(n - p\\) degrees of freedom.\n\nRecall \\(n - p\\) is the residual degrees of freedom.\n\n\n\n\n\nIf the model fits, we expect the residual deviance to be approximately what value?"
  },
  {
    "objectID": "slides/08-logistic-pt2.html#adjusting-for-overdispersion",
    "href": "slides/08-logistic-pt2.html#adjusting-for-overdispersion",
    "title": "Logistic regression",
    "section": "Adjusting for overdispersion",
    "text": "Adjusting for overdispersion\n\nOverdispersion occurs when there is extra-binomial variation, i.e. the variance is greater than what we would expect, \\(np(1-p)\\).\nSimilar to Poisson regression, we can adjust for overdispersion in the binomial regression model by using a dispersion parameter \\[\\hat{\\phi} = \\sum \\frac{(\\text{Pearson residuals})^2}{n-p}\\]\n\nBy multiplying by \\(\\hat{\\phi}\\), we are accounting for the reduction in information we would expect from independent observations."
  },
  {
    "objectID": "slides/08-logistic-pt2.html#adjusting-for-overdispersion-1",
    "href": "slides/08-logistic-pt2.html#adjusting-for-overdispersion-1",
    "title": "Logistic regression",
    "section": "Adjusting for overdispersion",
    "text": "Adjusting for overdispersion\n\nWe adjust for overdispersion using a quasibinomial model.\n\n“Quasi” reflects the fact we are no longer using a binomial model with true likelihood.\n\nThe standard errors of the coefficients are \\(SE_{Q}(\\hat{\\beta}_j) = \\sqrt{\\hat{\\phi}} SE(\\hat{\\beta})\\)\n\nInference is done using the \\(t\\) distribution to account for extra variability"
  },
  {
    "objectID": "slides/08-logistic-pt2.html#references",
    "href": "slides/08-logistic-pt2.html#references",
    "title": "Logistic regression",
    "section": "References",
    "text": "References\n\n\n\n\n🔗 STA 310 - Spring 2024\n\n\n\n\nAndualem, Atsedemariam, Belachew Tegegne, Sewunet Ademe, Tarikuwa Natnael, Gete Berihun, Masresha Abebe, Yeshiwork Alemnew, et al. 2022. “COVID-19 Infection Prevention Practices Among a Sample of Food Handlers of Food and Drink Establishments in Ethiopia.” PLoS One 17 (1): e0259851.\n\n\nRoback, Paul, and Julie Legler. 2021. Beyond multiple linear regression: applied generalized linear models and multilevel models in R. CRC Press."
  },
  {
    "objectID": "slides/10-correlated-data.html#announcements",
    "href": "slides/10-correlated-data.html#announcements",
    "title": "Correlated data",
    "section": "Announcements",
    "text": "Announcements\n\nQuiz 02: Tue, Feb 20, 9am - Thu, Feb 22, 12pm (noon)\n\nCovers readings & lectures: Jan 24 - Feb 12\nPoisson regression, unifying framework for GLMs, logistic regression, proportional odds models, probit regression\n\nRead Sadler and Miller (2010) as part of Feb 26 prepare assignment"
  },
  {
    "objectID": "slides/10-correlated-data.html#learning-goals",
    "href": "slides/10-correlated-data.html#learning-goals",
    "title": "Correlated data",
    "section": "Learning goals",
    "text": "Learning goals\n\nRecognize a potential for correlation in a data set\nIdentify observational units at varying levels\nUnderstand issues correlated data may cause in modeling\nUnderstand how random effects models can be used to take correlation into account\n\n\n\nNotes based on Chapter 7 of Roback and Legler (2021) unless noted otherwise."
  },
  {
    "objectID": "slides/10-correlated-data.html#examples-of-correlated-data",
    "href": "slides/10-correlated-data.html#examples-of-correlated-data",
    "title": "Correlated data",
    "section": "Examples of correlated data",
    "text": "Examples of correlated data\n\n\nIn an education study, test scores for students from a particular teacher are typically more similar than test scores of other students with a different teacher\nIn a study measuring depression indices weekly over a month, the four measures for the same patient tend to be more similar than depression indices from other patients\nIn political polling, opinions of members from the same household tend to be more similar than opinions of members from another household\n\n\n\nCorrelation among outcomes within the same group (teacher, patient, household) is called intraclass correlation"
  },
  {
    "objectID": "slides/10-correlated-data.html#multilevel-data",
    "href": "slides/10-correlated-data.html#multilevel-data",
    "title": "Correlated data",
    "section": "Multilevel data",
    "text": "Multilevel data\n\n\nWe can think of correlated data as a multilevel structure\n\nPopulation elements are aggregated into groups\nThere are observational units and measurements at each level\n\nFor now we will focus on data with two levels:\n\nLevel one: Most basic level of observation\nLevel two: Groups formed from aggregated level-one observations"
  },
  {
    "objectID": "slides/10-correlated-data.html#multilevel-data-example",
    "href": "slides/10-correlated-data.html#multilevel-data-example",
    "title": "Correlated data",
    "section": "Multilevel data example",
    "text": "Multilevel data example\nExample: education study\n\nLevel one\n\nObservational units: students\nLevel-one covariates: test scores (response), year in school, demographics\n\nLevel two\n\nObservational units: teachers\nLevel-two covariates:years of experience"
  },
  {
    "objectID": "slides/10-correlated-data.html#two-types-of-effects-in-model",
    "href": "slides/10-correlated-data.html#two-types-of-effects-in-model",
    "title": "Correlated data",
    "section": "Two types of effects in model",
    "text": "Two types of effects in model\n\nFixed effects: Effects that are of interest in the study\n\nCan think of these as effects whose interpretations would be included in a write up of the study\n\n\n\n\nRandom effects: Not interested in studying effects of specific values in the data but we want to understand the variability\n\nCan think of these as effects whose interpretations would not necessarily be included in a write up of the study"
  },
  {
    "objectID": "slides/10-correlated-data.html#example",
    "href": "slides/10-correlated-data.html#example",
    "title": "Correlated data",
    "section": "Example",
    "text": "Example\nResearchers are interested in understanding the effect social media has on opinions about a proposed economic plan. They randomly select 1000 households. They ask each adult in the household how many minutes they spend on social media daily and whether they support the proposed economic plan.\n\n\ndaily minutes on social media is the fixed effect\nhousehold is the random effect"
  },
  {
    "objectID": "slides/10-correlated-data.html#practice",
    "href": "slides/10-correlated-data.html#practice",
    "title": "Correlated data",
    "section": "Practice",
    "text": "Practice\n\nRadon is a carcinogen – a naturally occurring radioactive gas whose decay products are also radioactive – known to cause lung cancer in high concentrations. The EPA sampled more than 80,000 homes across the U.S. Each house came from a randomly selected county and measurements were made on each level of each home. Uranium measurements at the county level were included to improve the radon estimates.1\n\n\n\nWhat are the level one and level two observational units?\nWhat is the response variable and what is its type (normal, Poisson, etc.)?\nDescribe the within-group correlation.\nWhat are the fixed effects? What are the random effects?\n\n\n\nFrom Ex. 1 in Section 7.10.1 of BMLR"
  },
  {
    "objectID": "slides/10-correlated-data.html#data-teratogen-and-rat-pups",
    "href": "slides/10-correlated-data.html#data-teratogen-and-rat-pups",
    "title": "Correlated data",
    "section": "Data: Teratogen and rat pups",
    "text": "Data: Teratogen and rat pups\nToday’s data are simulated results of an experiment with 24 dams (mother rats) randomly divided into four groups that received different doses of teratogen, a substance that could potentially cause harm to developing fetuses. The four groups are\n\nHigh dose (3 mg)\nMedium dose (2 mg)\nLow dose (1 mg)\nNo dose (Control)\n\nEach dam produced 10 rat pups and the presence of a deformity was noted for each pup.\n\nGoal: Understand the association between teratogen exposure and the probability a pup is born with a deformity."
  },
  {
    "objectID": "slides/10-correlated-data.html#sources-of-variation",
    "href": "slides/10-correlated-data.html#sources-of-variation",
    "title": "Correlated data",
    "section": "Sources of variation",
    "text": "Sources of variation\n\n\nDose effect: Studying whether different dose levels are associated with different probabilities of birth defects in the pups.\n\nDose is a fixed effect. Study is interested in defect rate at specific dose levels.\n\nDam (litter) effect: Different dams may have different propensity to produce pups with defects, i.e. pups from same litter are more likely to be similar than pups from different litters.\n\nDam is a random effect. Study is not interested in defect rate for each specific dam in the study but is interested in variability between litters.\n\nPup-to-pup variability: Within litter pup differences. This is the unexplained variability."
  },
  {
    "objectID": "slides/10-correlated-data.html#scenario-1-no-dose-effect",
    "href": "slides/10-correlated-data.html#scenario-1-no-dose-effect",
    "title": "Correlated data",
    "section": "Scenario 1: No dose effect",
    "text": "Scenario 1: No dose effect\nAssume dose has no effect on, \\(p\\), the probability of a pup born with a deformity.\n\nScenario 1a.: \\(p = 0.5\\) for each dam\nScenario 1b.: \\(p \\sim Beta(0.5, 0.5)\\) (expected value = 0.5)"
  },
  {
    "objectID": "slides/10-correlated-data.html#scenario-2-dose-effect-1",
    "href": "slides/10-correlated-data.html#scenario-2-dose-effect-1",
    "title": "Correlated data",
    "section": "Scenario 2: Dose effect",
    "text": "Scenario 2: Dose effect\nNow we will consider the effect of the dose of teratogen on the probability of a pup born with a deformity. The 24 pups have been randomly divided into four groups:\n\nHigh dose (dose = 3)\nMedium dose (dose = 2)\nLow dose (dose = 1)\nNo dose (dose = 0)\n\n\nWe will assume the true relationship between \\(p\\) and dose is the following:\n\\[\\log\\Big(\\frac{p}{1-p}\\Big) = -2 + 1.33 ~ dose\\]"
  },
  {
    "objectID": "slides/10-correlated-data.html#scenario-2",
    "href": "slides/10-correlated-data.html#scenario-2",
    "title": "Correlated data",
    "section": "Scenario 2",
    "text": "Scenario 2\nScenario 2a.\n\\[p = \\frac{e^{-2 + 1.33 ~ dose}}{1 + e^{-2 + 1.33 ~ dose}}\\]\n\nScenario 2b.\n\\[p \\sim Beta\\Big(\\frac{2p}{(1-p)}, 2\\Big)\\]\n\n\nOn average, dams who receive dose \\(x\\) have the same probability of pup born with deformity as dams with dose \\(x\\) under Scenario 2a.\n\ne.g., If dose = 1, the probability of a pup born with deformity is 0.338 in Scenario 2a and the mean is 0.338 in Scenario 2b."
  },
  {
    "objectID": "slides/10-correlated-data.html#distributions-under-scenario-2",
    "href": "slides/10-correlated-data.html#distributions-under-scenario-2",
    "title": "Correlated data",
    "section": "Distributions under Scenario 2",
    "text": "Distributions under Scenario 2"
  },
  {
    "objectID": "slides/10-correlated-data.html#scenario-2-summary-statistics",
    "href": "slides/10-correlated-data.html#scenario-2-summary-statistics",
    "title": "Correlated data",
    "section": "Scenario 2 summary statistics",
    "text": "Scenario 2 summary statistics\n\n\n\nSummary statistics of Scenario 2 by dose.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScenario 2a\n\n\nScenario 2b\n\n\n\nDosage\nMean p\nSD p\nMean Count\nSD Count\nMean p\nSD p\nMean Count\nSD Count\n\n\n\n\n0\n0.119\n0\n1.333\n1.366\n0.061\n0.069\n0.500\n0.837\n\n\n1\n0.339\n0\n3.167\n1.835\n0.239\n0.208\n3.500\n2.881\n\n\n2\n0.661\n0\n5.833\n1.472\n0.615\n0.195\n5.833\n1.941\n\n\n3\n0.881\n0\n8.833\n1.169\n0.872\n0.079\n8.833\n1.169\n\n\n\n\n\n\n\n\n\nFrom Table 7.2 in BMLR"
  },
  {
    "objectID": "slides/10-correlated-data.html#scenario-2-estimated-odds-ratio",
    "href": "slides/10-correlated-data.html#scenario-2-estimated-odds-ratio",
    "title": "Correlated data",
    "section": "Scenario 2: Estimated odds ratio",
    "text": "Scenario 2: Estimated odds ratio\nThe estimated effect of dose and the 95% CI from the binomial and quasibinomial models are below:\nScenario 2a\n\n\n\n\nOdds Ratio\n95% CI\n\n\n\n\nBinomial\n3.536\n(2.604, 4.958)\n\n\nQuasibinomial\n3.536\n(2.512, 5.186)\n\n\n\nScenario 2b\n\n\n\n\nOdds Ratio\n95% CI\n\n\n\n\nBinomial\n4.311\n(3.086, 6.271)\n\n\nQuasibinomial\n4.311\n(2.735, 7.352)"
  },
  {
    "objectID": "slides/10-correlated-data.html#data-structure",
    "href": "slides/10-correlated-data.html#data-structure",
    "title": "Correlated data",
    "section": "Data structure",
    "text": "Data structure\n\nFrom Figure 7.4 in BMLR"
  },
  {
    "objectID": "slides/10-correlated-data.html#preview-fit-model-with-random-effect",
    "href": "slides/10-correlated-data.html#preview-fit-model-with-random-effect",
    "title": "Correlated data",
    "section": "Preview: Fit model with random effect",
    "text": "Preview: Fit model with random effect\n\nlibrary(lme4)\nlibrary(broom.mixed)\nrandom_effect_model &lt;- glmer(deformity ~ dose + (1|dam), \n                          family = binomial, data = scenario2_raw)\ntidy(random_effect_model, conf.int = TRUE) |&gt; \n  kable(digits = 3)\n\n\n\n\neffect\ngroup\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\nfixed\nNA\n(Intercept)\n-2.819\n0.528\n-5.343\n0\n-3.853\n-1.785\n\n\nfixed\nNA\ndose\n1.691\n0.282\n5.992\n0\n1.138\n2.244\n\n\nran_pars\ndam\nsd__(Intercept)\n0.834\nNA\nNA\nNA\nNA\nNA"
  },
  {
    "objectID": "slides/10-correlated-data.html#summary",
    "href": "slides/10-correlated-data.html#summary",
    "title": "Correlated data",
    "section": "Summary",
    "text": "Summary\n\nThe structure of the data set may imply correlation between observations.\nCorrelated observations provide less information than independent observations; we need to account for this reduction in information.\nFailing to account for this reduction could result in underestimating standard error, thus resulting in overstating significance and the precision of the estimates.\nWe showed how we can account for this by incorporating the dispersion parameter or a random effect."
  },
  {
    "objectID": "slides/10-correlated-data.html#references",
    "href": "slides/10-correlated-data.html#references",
    "title": "Correlated data",
    "section": "References",
    "text": "References\n\n\n\n\n🔗 STA 310 - Spring 2024\n\n\n\n\nRoback, Paul, and Julie Legler. 2021. Beyond multiple linear regression: applied generalized linear models and multilevel models in R. CRC Press."
  },
  {
    "objectID": "slides/02-big-picture.html#announcements",
    "href": "slides/02-big-picture.html#announcements",
    "title": "The big picture",
    "section": "Announcements",
    "text": "Announcements\n\nResources for extra R review\n\nLearn R: An interactive introduction to data analysis R (focus on Chapters 4 - 6)\nDuke Library Center for Data and Visualization Sciences workshops\n\nR for Lunch: data wrangling with dplyr (Fri, Sep 1, 12:30 - 1:30)\nR for Lunch: visualization with ggplot2 (Fri, Sep 8, 12:30 - 1:30)\nSee the CDVS website for more information and to register.\n\n\nLast day of in-person work for this class is Dec 7\nLecture recordings request policy\nReadings for next week will be posted later this week"
  },
  {
    "objectID": "slides/02-big-picture.html#topics",
    "href": "slides/02-big-picture.html#topics",
    "title": "The big picture",
    "section": "Topics",
    "text": "Topics\n\nData analysis life cycle\nReproducible data analysis\nAnalyzing multivariable relationships"
  },
  {
    "objectID": "slides/02-big-picture.html#reproducibility-checklist",
    "href": "slides/02-big-picture.html#reproducibility-checklist",
    "title": "The big picture",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for an analysis to be reproducible?\n\n\nNear term goals:\n✔️ Can the tables and figures be exactly reproduced from the code and data?\n✔️ Does the code actually do what you think it does?\n✔️ In addition to what was done, is it clear why it was done?\n\n\nLong term goals:\n✔️ Can the code be used for other data?\n✔️ Can you extend the code to do other things?"
  },
  {
    "objectID": "slides/02-big-picture.html#why-is-reproducibility-important",
    "href": "slides/02-big-picture.html#why-is-reproducibility-important",
    "title": "The big picture",
    "section": "Why is reproducibility important?",
    "text": "Why is reproducibility important?\n\nResults produced are more reliable and trustworthy (Ostblom and Timbers 2022)\nFacilitates more effective collaboration (Ostblom and Timbers 2022)\nContributing to science, which builds and organizes knowledge in terms of testable hypotheses (Alexander 2023)\nPossible to identify and correct errors or biases in the analysis process (Alexander 2023)"
  },
  {
    "objectID": "slides/02-big-picture.html#when-things-go-wrong",
    "href": "slides/02-big-picture.html#when-things-go-wrong",
    "title": "The big picture",
    "section": "When things go wrong",
    "text": "When things go wrong\n\n\n\nReproducibility error\nConsequence\nSource(s)\n\n\n\n\nLimitations in Excel data formats\nLoss of 16,000 COVID case records in the UK\n(Kelion 2020)\n\n\nAutomatic formatting in Excel\nImportant genes disregarded in scientific studies\n(Ziemann, Eren, and El-Osta 2016)\n\n\nDeletion of a cell caused rows to shift\nMix-up of which patient group received the treatment\n(Wallensteen et al. 2018)\n\n\nUsing binary instead of explanatory labels\nMix-up of the intervention with the control group\n(Aboumatar and Wise 2019)\n\n\nUsing the same notation for missing data and zero values\nPaper retraction\n(Whitehouse et al. 2021)\n\n\nIncorrectly copying data in a spreadsheet\nDelay in the opening of a hospital\n(Picken 2020)\n\n\n\nSource: Ostblom and Timbers (2022)"
  },
  {
    "objectID": "slides/02-big-picture.html#toolkit",
    "href": "slides/02-big-picture.html#toolkit",
    "title": "The big picture",
    "section": "Toolkit",
    "text": "Toolkit\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub\n\n\n\n\n\n\n\nNote\n\n\nYou will start using these computing tools in Lab 01."
  },
  {
    "objectID": "slides/02-big-picture.html#r-and-rstudio",
    "href": "slides/02-big-picture.html#r-and-rstudio",
    "title": "The big picture",
    "section": "R and RStudio",
    "text": "R and RStudio\n\nR is a statistical programming language\nRStudio is a convenient interface for R (an integrated development environment, IDE)\n\n\nSource: Statistical Inference via Data Science"
  },
  {
    "objectID": "slides/02-big-picture.html#rstudio-ide",
    "href": "slides/02-big-picture.html#rstudio-ide",
    "title": "The big picture",
    "section": "RStudio IDE",
    "text": "RStudio IDE"
  },
  {
    "objectID": "slides/02-big-picture.html#quarto",
    "href": "slides/02-big-picture.html#quarto",
    "title": "The big picture",
    "section": "Quarto",
    "text": "Quarto\n\nFully reproducible reports – the analysis is run from the beginning each time you render\nCode goes in chunks and narrative goes outside of chunks\nVisual editor to make document editing experience similar to a word processor (Google docs, Word, Pages, etc.)"
  },
  {
    "objectID": "slides/02-big-picture.html#quarto-1",
    "href": "slides/02-big-picture.html#quarto-1",
    "title": "The big picture",
    "section": "Quarto",
    "text": "Quarto"
  },
  {
    "objectID": "slides/02-big-picture.html#how-will-we-use-quarto",
    "href": "slides/02-big-picture.html#how-will-we-use-quarto",
    "title": "The big picture",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise and assignment is written in a Quarto document\nYou’ll have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/02-big-picture.html#what-is-versioning",
    "href": "slides/02-big-picture.html#what-is-versioning",
    "title": "The big picture",
    "section": "What is versioning?",
    "text": "What is versioning?"
  },
  {
    "objectID": "slides/02-big-picture.html#what-is-versioning-1",
    "href": "slides/02-big-picture.html#what-is-versioning-1",
    "title": "The big picture",
    "section": "What is versioning?",
    "text": "What is versioning?\nwith human readable messages"
  },
  {
    "objectID": "slides/02-big-picture.html#why-do-we-need-version-control",
    "href": "slides/02-big-picture.html#why-do-we-need-version-control",
    "title": "The big picture",
    "section": "Why do we need version control?",
    "text": "Why do we need version control?\n\n\n\n\n\n\n\n\nProvides a clear record of how the analysis methods evolved. This makes analysis auditable and thus more trustworthy and reliable. (Ostblom and Timbers 2022)"
  },
  {
    "objectID": "slides/02-big-picture.html#git-and-github",
    "href": "slides/02-big-picture.html#git-and-github",
    "title": "The big picture",
    "section": "git and GitHub",
    "text": "git and GitHub\n\n\ngit is a version control system – like “Track Changes” features from Microsoft Word.\nGitHub is the home for your git-based projects on the internet (like DropBox but much better).\nThere are a lot of git commands and very few people know them all. 99% of the time you will use git to add, commit, push, and pull."
  },
  {
    "objectID": "slides/02-big-picture.html#carbohydrates-in-starbucks-food",
    "href": "slides/02-big-picture.html#carbohydrates-in-starbucks-food",
    "title": "The big picture",
    "section": "Carbohydrates in Starbucks food",
    "text": "Carbohydrates in Starbucks food\n\nStarbucks often displays the total calories in their food items but not the other nutritional information.\nCarbohydrates are a body’s main fuel source. The Dietary Guidelines for America recommend that carbohydrates make up 45% to 65% of total daily calories.1\nOur goal is to understand the relationship between the amount of carbohydrates and calories in Starbucks food items. We’d also like to assess if the relationship differs based on the type of food item (bakery, salad, sandwich, etc.)\n\nSource: Mayo Clinic"
  },
  {
    "objectID": "slides/02-big-picture.html#starbucks-data",
    "href": "slides/02-big-picture.html#starbucks-data",
    "title": "The big picture",
    "section": "Starbucks data",
    "text": "Starbucks data\n\n\nObservations: 77 Starbucks food items\nVariables:\n\ncarb: Total carbohydrates (in grams)\ncalories: Total calories\nbakery: 1: bakery food item, 0: other food type"
  },
  {
    "objectID": "slides/02-big-picture.html#terminology",
    "href": "slides/02-big-picture.html#terminology",
    "title": "The big picture",
    "section": "Terminology",
    "text": "Terminology\n\ncarb is the response variable\n\nvariable whose variation we want to understand / variable we wish to predict\nalso known as outcome or dependent variable\n\n\n\n\ncalories, bakery are the predictor variables\n\nvariables used to account for variation in the response\nalso known as explanatory, independent, or input variables"
  },
  {
    "objectID": "slides/02-big-picture.html#univariate-exploratory-data-analysis",
    "href": "slides/02-big-picture.html#univariate-exploratory-data-analysis",
    "title": "The big picture",
    "section": "Univariate exploratory data analysis",
    "text": "Univariate exploratory data analysis\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "slides/02-big-picture.html#bivariate-exploratory-data-analysis",
    "href": "slides/02-big-picture.html#bivariate-exploratory-data-analysis",
    "title": "The big picture",
    "section": "Bivariate exploratory data analysis",
    "text": "Bivariate exploratory data analysis\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "slides/02-big-picture.html#function-between-response-and-predictors",
    "href": "slides/02-big-picture.html#function-between-response-and-predictors",
    "title": "The big picture",
    "section": "Function between response and predictors",
    "text": "Function between response and predictors\n\n\\[\\text{carb} = f(\\text{calories}, \\text{bakery}) + \\epsilon\\]\n\n\nGoal: Determine \\(f\\)\nHow do we determine \\(f\\)?\n\nMake an assumption about the functional form \\(f\\) (parametric model)\nUse the data to fit a model based on that form"
  },
  {
    "objectID": "slides/02-big-picture.html#determine-f",
    "href": "slides/02-big-picture.html#determine-f",
    "title": "The big picture",
    "section": "Determine \\(f\\)",
    "text": "Determine \\(f\\)\n\nChoose the functional form of \\(f\\), i.e., choose the appropriate model given the response variable\n\n\nSuppose \\(f\\) takes the form of a linear model\n\\[y = f(\\mathbf{X}) = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p + \\epsilon\\]\n\n\n\nUse the data to fit (or train) the model, i.e, estimate the model parameters, \\(\\beta_0, \\beta_1, \\ldots, \\beta_p\\)"
  },
  {
    "objectID": "slides/02-big-picture.html#carb-vs.-calories",
    "href": "slides/02-big-picture.html#carb-vs.-calories",
    "title": "The big picture",
    "section": "Carb vs. Calories",
    "text": "Carb vs. Calories\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\\[\\text{carb} = \\beta_0 + \\beta_1 ~\\text{calories} + \\epsilon\\]"
  },
  {
    "objectID": "slides/02-big-picture.html#carb-vs.-calories-bakery",
    "href": "slides/02-big-picture.html#carb-vs.-calories-bakery",
    "title": "The big picture",
    "section": "Carb vs. Calories + Bakery",
    "text": "Carb vs. Calories + Bakery\n\n\\[\\text{carb} = \\beta_0 + \\beta_1 ~\\text{calories} + \\beta_2 ~\\text{bakery} + \\epsilon\\]"
  },
  {
    "objectID": "slides/02-big-picture.html#carb-vs.-calories-bakery-with-interaction",
    "href": "slides/02-big-picture.html#carb-vs.-calories-bakery-with-interaction",
    "title": "The big picture",
    "section": "Carb vs. Calories + Bakery (with interaction)",
    "text": "Carb vs. Calories + Bakery (with interaction)\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\\[{\\small \\text{carb} = \\beta_0 + \\beta_1 ~\\text{calories} + \\beta_2 ~\\text{bakery} + \\beta_3 ~ \\text{calories} \\times \\text{bakery}  + \\epsilon}\\]"
  },
  {
    "objectID": "slides/02-big-picture.html#statistical-model-vs.-regression-equation",
    "href": "slides/02-big-picture.html#statistical-model-vs.-regression-equation",
    "title": "The big picture",
    "section": "Statistical model vs. regression equation",
    "text": "Statistical model vs. regression equation\nStatistical model (also known as data-generating model)\n\\[{\\small \\text{carb} = \\beta_0 + \\beta_1 ~\\text{calories} + \\beta_2 ~\\text{bakery} + \\beta_3 ~ \\text{calories} \\times \\text{bakery}  + \\epsilon}\\]\nModels the process for generating values of the response in the population (function + error)\n\n\nRegression equation\nEstimate of the function using the sample data\n\\[{\\small \\hat{\\text{carb}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~\\text{calories} + \\hat{\\beta}_2 ~\\text{bakery} + \\hat{\\beta}_3 ~ \\text{calories} \\times \\text{bakery}}\\]"
  },
  {
    "objectID": "slides/02-big-picture.html#why-fit-a-model",
    "href": "slides/02-big-picture.html#why-fit-a-model",
    "title": "The big picture",
    "section": "Why fit a model?",
    "text": "Why fit a model?\n\nPrediction: Expected value of the response variable for given values of the predictor variables\nInference: Conclusion about the relationship between the response and predictor variables\n\n\n\nWhat is an example of a prediction question that can be answered using the model of carb vs. calories and bakery?\nWhat is an example of an inference question that can be answered using the model of carb vs. calories and bakery?"
  },
  {
    "objectID": "slides/02-big-picture.html#recap",
    "href": "slides/02-big-picture.html#recap",
    "title": "The big picture",
    "section": "Recap",
    "text": "Recap\n\nReproducibility\n\nIt is best practice conduct all data analysis in a reproducible way\nWe will implement a reproducible workflow using R, Quarto, and git/GitHub\n\n\n\n\nMultivariable relationships\n\nWe can use exploratory data analysis to describe the relationship between two variables\nWe make an assumption about the relationship between variables when doing linear regression\nThe two main objectives for fitting a linear regression model are (1) prediction and (2) inference"
  },
  {
    "objectID": "slides/02-big-picture.html#references",
    "href": "slides/02-big-picture.html#references",
    "title": "The big picture",
    "section": "References",
    "text": "References\n\n\n\n\n🔗 STA 210 - Fall 2023 - Schedule\n\n\n\n\nAlexander, Rohan. 2023. “Telling Stories with Data,” June. https://doi.org/10.1201/9781003229407.\n\n\nOstblom, Joel, and Tiffany Timbers. 2022. “Opinionated Practices for Teaching Reproducibility: Motivation, Guided Instruction and Practice.” Journal of Statistics and Data Science Education 30 (3): 241–50. https://doi.org/10.1080/26939169.2022.2074922."
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#announcements",
    "href": "slides/09-prop-odds-probit.html#announcements",
    "title": "Proportional odds + Probit regression",
    "section": "Announcements",
    "text": "Announcements\n\nProject 01\n\npresentations in class Wed, Feb 14\nwrite up due Thu, Feb 15 at 9pm\n\nQuiz 02: Tue, Feb 20 - Thu, Feb 22\n\nCovers readings & lectures: Jan 24 - Feb 12\nPoisson regression, unifying framework for GLMs, logistic regression, proportional odds models, probit regression"
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#learning-goals",
    "href": "slides/09-prop-odds-probit.html#learning-goals",
    "title": "Proportional odds + Probit regression",
    "section": "Learning goals",
    "text": "Learning goals\n\nIntroduce proportional odds and probit regression models\nUnderstand how these models are related to logistic regression models\nInterpret coefficients in context of the data\nSee how these models are applied in research contexts\n\n\n\nNotes based on Chapters 6 and 7 of McNulty (2021) unless stated otherwise."
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#predicting-ed-wait-and-treatment-times",
    "href": "slides/09-prop-odds-probit.html#predicting-ed-wait-and-treatment-times",
    "title": "Proportional odds + Probit regression",
    "section": "Predicting ED wait and treatment times",
    "text": "Predicting ED wait and treatment times\nAtaman and Sarıyer (2021) use ordinal logistic regression to predict patient wait and treatment times in an emergency department (ED). The goal is to identify relevant factors that can be used to inform recommendations for reducing wait and treatment times, thus improving the quality of care in the ED.\nData: Daily records for ED arrivals in August 2018 at a public hospital in Izmir, Turkey.\n\n\n\nClick here to access the article on Canvas."
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#predicting-ed-wait-and-treatment-times-1",
    "href": "slides/09-prop-odds-probit.html#predicting-ed-wait-and-treatment-times-1",
    "title": "Proportional odds + Probit regression",
    "section": "Predicting ED wait and treatment times",
    "text": "Predicting ED wait and treatment times\nResponse variables:\n\nWait time:\n\nPatients who wait less than 10 minutes\nPatients whose waiting time is in the range of 10 - 60 minutes\nPatients who wait more than 60 minutes\n\nTreatment time:\n\nPatients who are treated for up to 10 minutes\nPatients whose treatment time is in the range of 10 - 120 minutes\nPatients who are treated for longer than 120 minutes"
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#predicting-ed-wait-and-treatment-times-2",
    "href": "slides/09-prop-odds-probit.html#predicting-ed-wait-and-treatment-times-2",
    "title": "Proportional odds + Probit regression",
    "section": "Predicting ED wait and treatment times",
    "text": "Predicting ED wait and treatment times\nPredictor variables:\n\n\n\nGender:\n\nMale\nFemale\n\nAge:\n\n0 - 14\n15 - 64\n65 - 84\n\\(\\geq\\) 85\n\nArrival mode:\n\nWalk-in\nAmbulance\n\n\n\n\nTriage level:\n\nRed (urgent)\nGreen (non-urgent)\n\nICD-10 diagnosis: Codes specifying patient’s diagnosis"
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#ordered-vs.-unordered-variables",
    "href": "slides/09-prop-odds-probit.html#ordered-vs.-unordered-variables",
    "title": "Proportional odds + Probit regression",
    "section": "Ordered vs. unordered variables",
    "text": "Ordered vs. unordered variables\nCategorical variables with 3+ levels\n\n\nUnordered (Nominal)\n\nVoting choice in election with multiple candidates\nType of cell phone owned by adults in the U.S.\nFavorite social media platform among undergraduate students\n\n\nOrdered (Ordinal)\n\nWait and treatment times in the emergency department\nLikert scale ratings on a survey\nEmployee job performance ratings"
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#proportional-odds-model",
    "href": "slides/09-prop-odds-probit.html#proportional-odds-model",
    "title": "Proportional odds + Probit regression",
    "section": "Proportional odds model",
    "text": "Proportional odds model\nLet \\(Y\\) be an ordinal response variable that takes levels \\(1, 2, \\ldots, J\\) with associated probabilities \\(p_1, p_2, \\ldots, p_J\\)\n\nThe proportional odds model can be written as the following:\n\\[\\begin{aligned}&\\log\\Big(\\frac{P(Y\n\\leq 1)}{P(Y &gt; 1)}\\Big) = \\beta_{01} - \\beta_1x_1 - \\dots -  \\beta_px_p \\\\\n& \\log\\Big(\\frac{P(Y\\leq 2)}{P(Y &gt; 2)}\\Big) = \\beta_{02} -\\beta_1x_1 - \\dots -  \\beta_px_p \\\\\n& \\dots \\\\\n& \\log\\Big(\\frac{P(Y\\leq J-1)}{P(Y &gt; J-1)}\\Big) = \\beta_{0{J-1}} - \\beta_1x_1 - \\dots - \\beta_px_p\\end{aligned}\\]\n\nWhat does \\(\\beta_{01}\\) mean? What does \\(\\beta_1\\) mean?"
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#proportional-odds-model-1",
    "href": "slides/09-prop-odds-probit.html#proportional-odds-model-1",
    "title": "Proportional odds + Probit regression",
    "section": "Proportional odds model",
    "text": "Proportional odds model\nLet’s consider one portion of the model:\n\\[\n\\log\\Big(\\frac{P(Y\\leq k)}{P(Y &gt; k)}\\Big) = \\beta_{0k} - \\beta_1x_1 - \\dots -  \\beta_px_p\n\\]\n\n\n\nThe response variable is \\(logit(Y\\leq k)\\), the log-odds of observing an outcome less than or equal to category \\(k\\).\n\\(\\beta_j &gt; 0\\) is associated with increased log-odds of being in a higher category of \\(Y\\)\n\n\\(e^{\\beta_j}\\) associated with an increased odds of being in a higher category of \\(Y\\)\n\nEffect of one unit increase in \\(x_j\\) the same regardless of which category of \\(Y\\)"
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#effect-of-arrival-mode-on-waiting-time",
    "href": "slides/09-prop-odds-probit.html#effect-of-arrival-mode-on-waiting-time",
    "title": "Proportional odds + Probit regression",
    "section": "Effect of arrival mode on waiting time",
    "text": "Effect of arrival mode on waiting time\n\nWaiting time model output from Ataman and Sarıyer (2021)\nThe variable arrival mode has two possible values: ambulance and walk-in. Describe the effect of arrival mode on waiting time. Note: The baseline category is walk-in."
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#effect-of-triage-level",
    "href": "slides/09-prop-odds-probit.html#effect-of-triage-level",
    "title": "Proportional odds + Probit regression",
    "section": "Effect of triage level",
    "text": "Effect of triage level\nConsider the full output with the ordinal logistic models for wait and treatment times.\n\nWaiting and treatment time model output from Ataman and Sarıyer (2021).\nUse the results from both models to describe the effect of triage level on waiting and treatment times. Note: The baseline category is green.\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#fitting-proportional-odds-models-in-r",
    "href": "slides/09-prop-odds-probit.html#fitting-proportional-odds-models-in-r",
    "title": "Proportional odds + Probit regression",
    "section": "Fitting proportional odds models in R",
    "text": "Fitting proportional odds models in R\nFit proportional odds models using the polr function in the MASS package:\n\nproportional_model &lt;- polr(Y ~ x1 + x2 + x3, data = my_data)"
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#multinomial-logistic-model",
    "href": "slides/09-prop-odds-probit.html#multinomial-logistic-model",
    "title": "Proportional odds + Probit regression",
    "section": "Multinomial logistic model",
    "text": "Multinomial logistic model\nSuppose the outcome variable \\(Y\\) is categorical and can take values \\(1, 2, \\ldots, K\\) such that\n\\[\nP(Y = 1) = p_1, \\ldots , P(Y = K) = p_K  \\hspace{5mm} \\text{ and } \\hspace{5mm}  \\sum_{k = 1}^{K} p_k = 1\n\\]\n\nChoose baseline category. Let’s choose \\(Y = 1\\) . Then\n\n\n\\[\\begin{aligned}&\\log\\Big(\\frac{P(Y = 2)}{P(Y = 1)}\\Big) = \\beta_{02} - \\beta_{12}x_1 - \\dots -  \\beta_{p2}x_p \\\\\n& \\log\\Big(\\frac{P(Y = 3)}{P(Y =1)}\\Big) = \\beta_{03} -\\beta_{13}x_1 - \\dots -  \\beta_{p3}x_p \\\\\n& \\dots \\\\\n& \\log\\Big(\\frac{P(Y = K)}{P(Y = 1)}\\Big) = \\beta_{0{K}} - \\beta_{1K}x_1 - \\dots - \\beta_{pK}x_{p}\\end{aligned}\\]"
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#multinomial-logistic-vs.-proportional-odds",
    "href": "slides/09-prop-odds-probit.html#multinomial-logistic-vs.-proportional-odds",
    "title": "Proportional odds + Probit regression",
    "section": "Multinomial logistic vs. proportional odds",
    "text": "Multinomial logistic vs. proportional odds\n\nHow is the proportional odds model similar to the multinomial logistic model? How is it different? What is an advantage of each model? What is a disadvantage?\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#impact-of-nature-documentary-on-recycling",
    "href": "slides/09-prop-odds-probit.html#impact-of-nature-documentary-on-recycling",
    "title": "Proportional odds + Probit regression",
    "section": "Impact of nature documentary on recycling",
    "text": "Impact of nature documentary on recycling\nIbanez and Roussel (2022) conducted an experiment to understand the impact of watching a nature documentary on pro-environmental behavior. The researchers randomly assigned the 113 participants to watch an video about architecture in NYC (control) or a video about Yellowstone National Park (treatment). As part of the experiment, participants were asked to dispose of their headphone coverings in a recycle bin available at the end of the experiment.\n\n\nClick here to access the article on Canvas."
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#impact-of-nature-documentary-on-recycling-1",
    "href": "slides/09-prop-odds-probit.html#impact-of-nature-documentary-on-recycling-1",
    "title": "Proportional odds + Probit regression",
    "section": "Impact of nature documentary on recycling",
    "text": "Impact of nature documentary on recycling\nResponse variable: Recycle headphone coverings vs. not\nPredictor variables:\n\nAge\nGender\nStudent\nMade donation to environmental organization in previous part of experiment\nEnvironmental beliefs measured by the new ecological paradigm scale (NEP)"
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#probit-regression-1",
    "href": "slides/09-prop-odds-probit.html#probit-regression-1",
    "title": "Proportional odds + Probit regression",
    "section": "Probit regression",
    "text": "Probit regression\nLet \\(Y\\) be a binary response variable that takes values 0 or 1, and let \\(p = P(Y = 1 | x_1, \\ldots, x_p)\\)\n\\[\nprobit(p) = \\Phi^{-1}(p) = \\beta_0 + \\beta_1 x_1+ \\dots + \\beta_px_p\n\\]\nwhere \\(\\Phi^{-1}\\) is the inverse normal distribution function.\n\n\nThe outcome is the z-score at which the cumulative probability is equal to \\(p\\)\n\ne.g. \\(probit(0.975) = \\Phi^{-1}(0.975) = 1.96\\)"
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#interpretation",
    "href": "slides/09-prop-odds-probit.html#interpretation",
    "title": "Proportional odds + Probit regression",
    "section": "Interpretation",
    "text": "Interpretation\n\n\\(\\hat{\\beta}_j\\) is the estimated change in z-score for each unit increase in \\(x_j\\), holding all other factors constant.\nThis is a fairly clunky interpretation, so the (average) marginal effect of \\(x_j\\) is often interpreted instead\nThe marginal effect of \\(x_j\\) is essentially the change the probability from variable \\(x_j\\)"
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#impact-of-nature-documentary",
    "href": "slides/09-prop-odds-probit.html#impact-of-nature-documentary",
    "title": "Proportional odds + Probit regression",
    "section": "Impact of nature documentary",
    "text": "Impact of nature documentary\n\n\n\n\n\nRecycling model from Ibanez and Roussel (2022)\n\n\n\n\nInterpret the effect of watching the nature documentary Nature (T2) on recycling. Assume NEP is low, NEP-High = 0."
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#probit-vs.-logistic-regression",
    "href": "slides/09-prop-odds-probit.html#probit-vs.-logistic-regression",
    "title": "Proportional odds + Probit regression",
    "section": "Probit vs. logistic regression",
    "text": "Probit vs. logistic regression\nPros of probit regression:\n\nSome statisticians like assuming the normal distribution over the logistic distribution.\nEasier to work with in more advanced settings, such as multivariate and Bayesian modeling\n\n\nCons of probit regression:\n\nZ-scores are not as straightforward to interpret as the outcomes of a logistic model.\nWe can’t use odds ratios to describe findings.\nIt’s more mathematically complicated than logistic regression.\nIt does not work well for response variable with 3+ categories\n\n\n\n\nList adapted from Categorical Regression."
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#fitting-probit-regression-models-in-r",
    "href": "slides/09-prop-odds-probit.html#fitting-probit-regression-models-in-r",
    "title": "Proportional odds + Probit regression",
    "section": "Fitting probit regression models in R",
    "text": "Fitting probit regression models in R\nFit probit regression models using the glm function with family = binomial(link = probit).\n\nCalculate marginal effects using the margins function from the margins R package.\n\nmargins(my_model, variables = \"my_variables\")"
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#ideology-vs.-issue-statements",
    "href": "slides/09-prop-odds-probit.html#ideology-vs.-issue-statements",
    "title": "Proportional odds + Probit regression",
    "section": "Ideology vs. issue statements",
    "text": "Ideology vs. issue statements\nLet’s look at the model using ideology and party ID to explain the number of issue statements by politicians. We will use probit regression for the “hurdle” part of the model - the likelihood a candidate comments on at least one issue (has_issue_stmt)\n\n\nhurdle_probit &lt;- glm(has_issue_stmt ~ ideology + democrat, \n             data = politics, \n             family = binomial(link = probit))\n\n\n\n\nSee Section 4.11.2 of Roback and Legler (2021) for more detail about the data."
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#hurdle-using-probit-regression",
    "href": "slides/09-prop-odds-probit.html#hurdle-using-probit-regression",
    "title": "Proportional odds + Probit regression",
    "section": "Hurdle (using probit regression)",
    "text": "Hurdle (using probit regression)\n\ntidy(hurdle_probit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n1.272\n0.117\n10.829\n0.000\n\n\nideology\n0.262\n0.089\n2.926\n0.003\n\n\ndemocrat1\n0.149\n0.180\n0.827\n0.408\n\n\n\n\nmargins(hurdle_probit)\n\n ideology democrat1\n  0.04071   0.02333\n\n\n\nInterpret the effect of democrat on commenting on at least one issue."
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#hurdle-using-logistic-regression",
    "href": "slides/09-prop-odds-probit.html#hurdle-using-logistic-regression",
    "title": "Proportional odds + Probit regression",
    "section": "Hurdle (using logistic regression)",
    "text": "Hurdle (using logistic regression)\n\nhurdle_logistic &lt;- glm(has_issue_stmt ~ ideology + democrat, \n             data = politics, \n             family = binomial)\n\ntidy(hurdle_logistic) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n2.127\n0.225\n9.465\n0.000\n\n\nideology\n0.575\n0.167\n3.446\n0.001\n\n\ndemocrat1\n0.428\n0.349\n1.225\n0.221"
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#probit-vs.-logistic-models",
    "href": "slides/09-prop-odds-probit.html#probit-vs.-logistic-models",
    "title": "Proportional odds + Probit regression",
    "section": "Probit vs. logistic models",
    "text": "Probit vs. logistic models\n\n\nProbit model\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n1.272\n\n\nideology\n0.262\n\n\ndemocrat1\n0.149\n\n\n\n\n\n\nLogistic model\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n2.127\n\n\nideology\n0.575\n\n\ndemocrat1\n0.428\n\n\n\n\n\n\n\n\n\nSuppose there is democratic representative with ideology score -2.5. Based on the probit model, what is the probability they will comment on at least one issue? What is the probability based on the logistic model?\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#wrap-up",
    "href": "slides/09-prop-odds-probit.html#wrap-up",
    "title": "Proportional odds + Probit regression",
    "section": "Wrap up",
    "text": "Wrap up\n\nCovered fitting, interpreting, and drawing conclusions from GLMs\n\nLooked at Poisson, Negative Binomial, and Logistic, Proportional odds, and Probit models in detail\n\nUsed Pearson and deviance residuals to assess model fit and determine if new variables should be added to the model\nAddressed issues of overdispersion and zero-inflation\nUsed the properties of the one-parameter exponential family to identify the best link function for any GLM\n\n\nEverything we’ve done thus far as been under the assumption that the observations are independent. Looking ahead we will consider models for data with dependent (correlated) observations."
  },
  {
    "objectID": "slides/09-prop-odds-probit.html#references",
    "href": "slides/09-prop-odds-probit.html#references",
    "title": "Proportional odds + Probit regression",
    "section": "References",
    "text": "References\n\n\n\n\n🔗 STA 310 - Spring 2024\n\n\n\n\nAtaman, Mustafa Gökalp, and Görkem Sarıyer. 2021. “Predicting Waiting and Treatment Times in Emergency Departments Using Ordinal Logistic Regression Models.” The American Journal of Emergency Medicine 46: 45–50.\n\n\nIbanez, Lisette, and Sébastien Roussel. 2022. “The Impact of Nature Video Exposure on Pro-Environmental Behavior: An Experimental Investigation.” Plos One 17 (11): e0275806.\n\n\nMcNulty, Keith. 2021. Handbook of Regression Modeling in People Analytics: With Examples in r and Python. CRC Press.\n\n\nRoback, Paul, and Julie Legler. 2021. Beyond multiple linear regression: applied generalized linear models and multilevel models in R. CRC Press."
  },
  {
    "objectID": "slides/03-model2-mle.html",
    "href": "slides/03-model2-mle.html",
    "title": "Finding the MLEs for Model 2",
    "section": "",
    "text": "This document covers multiple ways to find the MLE for Model 2 the conditional model from Lecture 03: Using likelihoods. See the lecture notes for more details about the set up of the model.\nlibrary(tidyverse)\nrefs &lt;- read_csv(\"data/04-refs.csv\")\nThe likelihood is\n\\[\\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\\\ &(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\\end{aligned}\\]\nThe log-likelihood is\n\\[\\begin{aligned}\\log (Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias})) &= 25 \\log(p_{H| N}) + 23 \\log(1 - p_{H|N}) \\\\ & + 8 \\log(p_{H| H Bias}) + 12 \\log(1 - p_{H| H Bias})\\\\ &+ 13 \\log(p_{H| V Bias}) + 9 \\log(1-p_{H|V Bias})\\end{aligned}\\]\nWe would like to find the MLEs for \\(p_{H| N}, p_{H|H Bias}, \\text{ and }p_{H |V Bias}\\)."
  },
  {
    "objectID": "slides/03-model2-mle.html#finding-mles-using-graphs",
    "href": "slides/03-model2-mle.html#finding-mles-using-graphs",
    "title": "Finding the MLEs for Model 2",
    "section": "Finding MLEs using graphs",
    "text": "Finding MLEs using graphs\nWe need to find the MLEs for three parameters, therefore we would need to visualize a 4-dimensional object to find the MLEs from a graph. Given the difficulty of this task and the lack of precision in the estimates from this approach, we should rely on other approaches to find the MLEs in this instance."
  },
  {
    "objectID": "slides/03-model2-mle.html#finding-mles-using-calculus",
    "href": "slides/03-model2-mle.html#finding-mles-using-calculus",
    "title": "Finding the MLEs for Model 2",
    "section": "Finding MLEs using calculus",
    "text": "Finding MLEs using calculus\nWe can find the MLE for each parameter using the partial derivative of the log-likelihood with respect to each parameter.\nTo find the MLE for \\(p_{H| N}\\):\n\\[\\begin{aligned}\\frac{\\partial \\log(Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}))}{\\partial p_{H|N}} &= \\frac{25}{p_{H|N}} - \\frac{23}{1 - p_{H|N}} = 0\\\\[5pt]\n&\\Rightarrow \\frac{25}{p_{H|N}} = \\frac{23}{1 - p_{H|N}} \\\\[5pt]\n&\\Rightarrow 23p_{H|N} = 25(1 - p_{H|N}) \\\\[5pt]\n&\\Rightarrow 48p_{H|N} = 25 \\\\[5pt]\n&\\Rightarrow \\hat{p}_{H|N} = \\frac{25}{48} = 0.521\\end{aligned}\\]\nWe can use a similar approach to find the MLEs for \\(p_{H|H Bias}\\) and \\(p_{H|V Bias}\\).\n\\[\\hat{p}_{H|H Bias} = \\frac{8}{20} = 0.4\\] \\[\\hat{p}_{H|V Bias} = \\frac{13}{22} = 0.591\\]"
  },
  {
    "objectID": "slides/03-model2-mle.html#finding-the-mles-using-r",
    "href": "slides/03-model2-mle.html#finding-the-mles-using-r",
    "title": "Finding the MLEs for Model 2",
    "section": "Finding the MLEs using R",
    "text": "Finding the MLEs using R\nWe can write a function and do a grid search to find the values that maximize the log-likelihood.\n\nmaxloglik&lt;- function(nvals){\n  #nvals specifies the number of values\n  phn &lt;- seq(0, 1, length = nvals)\n  phh &lt;- seq(0, 1, length = nvals)\n  phv &lt;- seq(0, 1, length = nvals)\n  \n  loglik &lt;- expand.grid(phn, phh, phv) \n  colnames(loglik) &lt;- c(\"phn\", \"phh\", \"phv\")\n  \n  loglik &lt;- loglik %&gt;%\n    mutate(loglik  = log(phn^25 * (1 - phn)^23 * phh^8 * (1 - phh)^12 * \n                           phv^13 * (1 - phv)^9))\n  \n  loglik %&gt;%\n    arrange(desc(loglik)) %&gt;%\n    slice(1)\n}\n\n\nmaxloglik(100)\n\n        phn       phh       phv    loglik\n1 0.5252525 0.4040404 0.5858586 -61.57691\n\n\nDepending on the number of parameters, it may be hard to conduct a granular enough search to find the exact values of the MLEs. Therefore, one could use the function above to conduct a crude search to find starting values for R’s optim function. The function optim differs from optimize in that it can optimize over multiple parameter values (The optimize function can only optimize over a single parameter value).\n\n# Function to calculate log-likelihood that will be used in the optim function\nloglik &lt;- function(params){\n  phn &lt;- params[1]\n  phh &lt;- params[2]\n  phv &lt;- params[3]\n\n  log(phn^25 * (1 - phn)^23 * phh^8 * (1 - phh)^12 * \n                           phv^13 * (1 - phv)^9)\n}\n\n\n# use manual search to get starting values \nstart_vals &lt;- maxloglik(50) %&gt;% select(-loglik)\n\n\n# Use optim function in R to find the values to maximize the log-likelihood\n#set fnscale = -1 to maximize (the default is minimize)\noptim(par = start_vals, fn = loglik, control=list(fnscale=-1))\n\n$par\n      phn       phh       phv \n0.5208272 0.4000361 0.5909793 \n\n$value\n[1] -61.57319\n\n$counts\nfunction gradient \n      66       NA \n\n$convergence\n[1] 0\n\n$message\nNULL"
  },
  {
    "objectID": "slides/03-likelihoods.html#announcements",
    "href": "slides/03-likelihoods.html#announcements",
    "title": "Inference review +  using likelihoods",
    "section": "Announcements",
    "text": "Announcements\n\nHW 01 due Thursday at 6am\n\nYour access to the repo will be removed at the deadline. If you wish to submit the HW late, please email me and I will extend your access to the repo.\nYou will have access to your HW repo again when grades are returned."
  },
  {
    "objectID": "slides/03-likelihoods.html#computing-set-up",
    "href": "slides/03-likelihoods.html#computing-set-up",
    "title": "Inference review +  using likelihoods",
    "section": "Computing set up",
    "text": "Computing set up\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)\n\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\ncolors &lt;- tibble::tibble(green = \"#B5BA72\")"
  },
  {
    "objectID": "slides/03-likelihoods.html#topics",
    "href": "slides/03-likelihoods.html#topics",
    "title": "Inference review +  using likelihoods",
    "section": "Topics",
    "text": "Topics\n\nReview inference for multiple linear regression\nUsing likelihoods\n\n\n\nNotes based on Chapter 1 and 2 of Roback and Legler (2021) unless noted otherwise."
  },
  {
    "objectID": "slides/03-likelihoods.html#data-kentucky-derby-winners",
    "href": "slides/03-likelihoods.html#data-kentucky-derby-winners",
    "title": "Inference review +  using likelihoods",
    "section": "Data: Kentucky Derby Winners",
    "text": "Data: Kentucky Derby Winners\nToday’s data is from the Kentucky Derby, an annual 1.25-mile horse race held at the Churchill Downs race track in Louisville, KY. The data is in the file derbyplus.csv and contains information for races 1896 - 2017.\n\n\nResponse variable\n\nspeed: Average speed of the winner in feet per second (ft/s)\n\nAdditional variable\n\nwinner: Winning horse\n\n\nPredictor variables\n\nyear: Year of the race\ncondition: Condition of the track (good, fast, slow)\nstarters: Number of horses who raced\n\n\n\nGoal: Understand variability in average winner speed based on characteristics of the race."
  },
  {
    "objectID": "slides/03-likelihoods.html#data",
    "href": "slides/03-likelihoods.html#data",
    "title": "Inference review +  using likelihoods",
    "section": "Data",
    "text": "Data\n\nderby &lt;- read_csv(\"data/derbyplus.csv\")\n\n\nderby |&gt;\n  head(5) |&gt; kable()\n\n\n\n\nyear\nwinner\ncondition\nspeed\nstarters\n\n\n\n\n1896\nBen Brush\ngood\n51.66\n8\n\n\n1897\nTyphoon II\nslow\n49.81\n6\n\n\n1898\nPlaudit\ngood\n51.16\n4\n\n\n1899\nManuel\nfast\n50.00\n5\n\n\n1900\nLieut. Gibson\nfast\n52.28\n7"
  },
  {
    "objectID": "slides/03-likelihoods.html#candidate-models",
    "href": "slides/03-likelihoods.html#candidate-models",
    "title": "Inference review +  using likelihoods",
    "section": "Candidate models",
    "text": "Candidate models\nModel 1: Main effects model (year, condition, starters)\n\nmodel1 &lt;- lm(speed ~ starters + year + condition, data = derby)\n\n\n\nModel 2: Main effects + \\(year^2\\), the quadratic effect of year\n\nmodel2 &lt;- lm(speed ~ starters + year + I(year^2) + condition,\n             data = derby)\n\n\n\n\nModel 3: Main effects + interaction between year and condition\n\nmodel3 &lt;- lm(speed ~ starters + year + condition + year * condition, \n             data = derby)"
  },
  {
    "objectID": "slides/03-likelihoods.html#inference-for-regression",
    "href": "slides/03-likelihoods.html#inference-for-regression",
    "title": "Inference review +  using likelihoods",
    "section": "Inference for regression",
    "text": "Inference for regression\nUse statistical inference to\n\nEvaluate if predictors are statistically significant (not necessarily practically significant!)\nQuantify uncertainty in coefficient estimates\nQuantify uncertainty in model predictions\n\nIf LINE assumptions are met, we can use inferential methods based on mathematical models. If at least linearity and independence are met, we can use simulation-based inference methods."
  },
  {
    "objectID": "slides/03-likelihoods.html#inference-for-regression-1",
    "href": "slides/03-likelihoods.html#inference-for-regression-1",
    "title": "Inference review +  using likelihoods",
    "section": "Inference for regression",
    "text": "Inference for regression\nWhen LINE assumptions are met… . . .\n\n\nUse least squares regression to obtain the estimates for the model coefficients \\(\\beta_0, \\beta_1, \\ldots, \\beta_j\\) and for \\(\\sigma^2\\)\n\\(\\hat{\\sigma}\\) is the regression standard error\n\\[\n\\hat{\\sigma} = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n - p - 1}} = \\sqrt{\\frac{\\sum_{i=1}^n e_i^2}{n-p-1}}\n\\]\nwhere \\(p\\) is the number of non-intercept terms in the model (e.g., \\(p = 1\\) in simple linear regression)\nGoal is to use estimated values to draw conclusions about \\(\\beta_j\\)\n\nUse \\(\\hat{\\sigma}\\) to calculate \\(SE_{\\hat{\\beta}_j}\\) . Click here for more detail."
  },
  {
    "objectID": "slides/03-likelihoods.html#hypothesis-testing-for-beta_j",
    "href": "slides/03-likelihoods.html#hypothesis-testing-for-beta_j",
    "title": "Inference review +  using likelihoods",
    "section": "Hypothesis testing for \\(\\beta_j\\)",
    "text": "Hypothesis testing for \\(\\beta_j\\)\n\nState the hypotheses. \\(H_0: \\beta_j = 0 \\text{ vs. } H_a: \\beta_j \\neq 0\\), given the other variables in the model.\n\n\n\nCalculate the test statistic.\n\n\\[\nt = \\frac{\\hat{\\beta}_j - 0}{SE_{\\hat{\\beta}_j}}\n\\]\n\n\nCalculate the p-value. The p-value is calculated from a \\(t\\) distribution with \\(n - p - 1\\) degrees of freedom.\n\\[\n\\text{p-value} = 2P(T &gt; |t|) \\hspace{8mm} T \\sim t_{n-p-1}\n\\]\n\n\n\nState the conclusion in context of the data.\n\nReject \\(H_0\\) if p-value is sufficiently small."
  },
  {
    "objectID": "slides/03-likelihoods.html#confidence-interval-for-beta_j",
    "href": "slides/03-likelihoods.html#confidence-interval-for-beta_j",
    "title": "Inference review +  using likelihoods",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\nThe \\(C\\%\\) confidence confidence interval for \\(\\beta_j\\) is\n\\[\\hat{\\beta}_j \\pm t^* \\times SE_{\\hat{\\beta}_j}\\]\nwhere the critical value \\(t^* \\sim t_{n-p-1}\\)\n\n\nGeneral interpretation for the confidence interval [LB, UB]:\nWe are \\(C\\%\\) confident that for every one unit increase in \\(x_j\\), the response is expected to change by LB to UB units, holding all else constant."
  },
  {
    "objectID": "slides/03-likelihoods.html#measures-of-model-performance",
    "href": "slides/03-likelihoods.html#measures-of-model-performance",
    "title": "Inference review +  using likelihoods",
    "section": "Measures of model performance",
    "text": "Measures of model performance\n\n\\(R^2\\): Proportion of variability in the response explained by the model\n\nWill always increase as predictors are added, so it shouldn’t be used to compare models\n\n\\(Adj. R^2\\): Similar to \\(R^2\\) with a penalty for extra terms\n\\(AIC\\): Likelihood-based approach balancing model performance and complexity\n\\(BIC\\): Similar to AIC with stronger penalty for extra terms"
  },
  {
    "objectID": "slides/03-likelihoods.html#model-summary-statistics",
    "href": "slides/03-likelihoods.html#model-summary-statistics",
    "title": "Inference review +  using likelihoods",
    "section": "Model summary statistics",
    "text": "Model summary statistics\nUse the glance() function to get model summary statistics\n\n\n\n\n\n\nmodel\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\nModel1\n0.730\n0.721\n259.478\n276.302\n\n\nModel2\n0.827\n0.819\n207.429\n227.057\n\n\nModel3\n0.751\n0.738\n253.584\n276.016\n\n\n\n\n\n\n\nWhich model do you choose based on these statistics?"
  },
  {
    "objectID": "slides/03-likelihoods.html#characteristics-of-a-good-final-model",
    "href": "slides/03-likelihoods.html#characteristics-of-a-good-final-model",
    "title": "Inference review +  using likelihoods",
    "section": "Characteristics of a “good” final model",
    "text": "Characteristics of a “good” final model\n\nModel can be used to answer primary research questions\nPredictor variables control for important covariates\nPotential interactions have been investigated\nVariables are centered, as needed, for more meaningful interpretations\nUnnecessary terms are removed\nAssumptions are met and influential points have been addressed\nModel tells a “persuasive story parsimoniously”\n\n\n\nList from Section 1.6.7 of Roback and Legler (2021)"
  },
  {
    "objectID": "slides/03-likelihoods.html#learning-goals",
    "href": "slides/03-likelihoods.html#learning-goals",
    "title": "Inference review +  using likelihoods",
    "section": "Learning goals",
    "text": "Learning goals\n\nDescribe the concept of a likelihood\nConstruct the likelihood for a simple model\nDefine the Maximum Likelihood Estimate (MLE) and use it to answer an analysis question\nIdentify three ways to calculate or approximate the MLE and apply these methods to find the MLE for a simple model"
  },
  {
    "objectID": "slides/03-likelihoods.html#what-is-the-likelihood",
    "href": "slides/03-likelihoods.html#what-is-the-likelihood",
    "title": "Inference review +  using likelihoods",
    "section": "What is the likelihood?",
    "text": "What is the likelihood?\nA likelihood is a function that tells us how likely we are to observe our data for a given parameter value (or values).\n\nUnlike with Ordinary Least Squares (OLS) estimates, they do not require the responses be independent, identically distributed, and normal\nThey are not the same as probability functions"
  },
  {
    "objectID": "slides/03-likelihoods.html#probability-function-vs.-likelihood",
    "href": "slides/03-likelihoods.html#probability-function-vs.-likelihood",
    "title": "Inference review +  using likelihoods",
    "section": "Probability function vs. likelihood",
    "text": "Probability function vs. likelihood\n\n\nProbability function: Fixed parameter value(s) + input possible outcomes \\(\\Rightarrow\\) probability of seeing the different outcomes given the parameter value(s)\nLikelihood: Fixed data + input possible parameter values \\(\\Rightarrow\\) probability of seeing the fixed data for each parameter value"
  },
  {
    "objectID": "slides/03-likelihoods.html#data-fouls-in-college-basketball-games",
    "href": "slides/03-likelihoods.html#data-fouls-in-college-basketball-games",
    "title": "Inference review +  using likelihoods",
    "section": "Data: Fouls in college basketball games",
    "text": "Data: Fouls in college basketball games\nThe data set 04-refs.csv includes 30 randomly selected NCAA men’s basketball games played in the 2009 - 2010 season.1\nWe will focus on the variables foul1, foul2, and foul3, which indicate which team had a foul called them for the 1st, 2nd, and 3rd fouls, respectively.\n\nH: Foul was called on the home team\nV: Foul was called on the visiting team\n\nWe are focusing on the first three fouls for this analysis, but this could easily be extended to include all fouls in a game.\nThe dataset was derived from basektball0910.csv used in BMLR Section 11.2"
  },
  {
    "objectID": "slides/03-likelihoods.html#fouls-in-college-basketball-games",
    "href": "slides/03-likelihoods.html#fouls-in-college-basketball-games",
    "title": "Inference review +  using likelihoods",
    "section": "Fouls in college basketball games",
    "text": "Fouls in college basketball games\n\nrefs &lt;- read_csv(\"data/04-refs.csv\")\nrefs |&gt; slice(1:5) |&gt; kable()\n\n\n\n\ngame\ndate\nvisitor\nhometeam\nfoul1\nfoul2\nfoul3\n\n\n\n\n166\n20100126\nCLEM\nBC\nV\nV\nV\n\n\n224\n20100224\nDEPAUL\nCIN\nH\nH\nV\n\n\n317\n20100109\nMARQET\nNOVA\nH\nH\nH\n\n\n214\n20100228\nMARQET\nSETON\nV\nV\nH\n\n\n278\n20100128\nSETON\nSFL\nH\nV\nV\n\n\n\n\n\nWe will treat the games as independent in this analysis."
  },
  {
    "objectID": "slides/03-likelihoods.html#different-likelihood-models",
    "href": "slides/03-likelihoods.html#different-likelihood-models",
    "title": "Inference review +  using likelihoods",
    "section": "Different likelihood models",
    "text": "Different likelihood models\nModel 1 (Unconditional Model):\n\nWhat is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?\n\n\nModel 2 (Conditional Model):\n\nIs there a tendency for the referees to call more fouls on the visiting team or home team?\nIs there a tendency for referees to call a foul on the team that already has more fouls?\n\n\n\nUltimately we want to decide which model is better."
  },
  {
    "objectID": "slides/03-likelihoods.html#exploratory-data-analysis",
    "href": "slides/03-likelihoods.html#exploratory-data-analysis",
    "title": "Inference review +  using likelihoods",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\n\nrefs |&gt;\ncount(foul1, foul2, foul3) |&gt; kable()\n\n\n\n\nfoul1\nfoul2\nfoul3\nn\n\n\n\n\nH\nH\nH\n3\n\n\nH\nH\nV\n2\n\n\nH\nV\nH\n3\n\n\nH\nV\nV\n7\n\n\nV\nH\nH\n7\n\n\nV\nH\nV\n1\n\n\nV\nV\nH\n5\n\n\nV\nV\nV\n2\n\n\n\n\n\n\nThere are\n\n46 total fouls on the home team\n44 total fouls on the visiting team"
  },
  {
    "objectID": "slides/03-likelihoods.html#likelihood",
    "href": "slides/03-likelihoods.html#likelihood",
    "title": "Inference review +  using likelihoods",
    "section": "Likelihood",
    "text": "Likelihood\nLet \\(p_H\\) be the probability the referees call a foul on the home team. The likelihood for a single observation \\[Lik(p_H) = p_H^{y_i}(1 - p_H)^{n_i - y_i}\\]Where \\(y_i\\) is the number of fouls called on the home team. (In this example, we know \\(n_i = 3\\) for all observations.)\n\nExample\nFor a single game where the first three fouls are \\(H, H, V\\), then \\[Lik(p_H) = p_H^{2}(1 - p_H)^{3 - 2} = p_H^{2}(1 - p_H)\\]"
  },
  {
    "objectID": "slides/03-likelihoods.html#model-1-likelihood-contribution",
    "href": "slides/03-likelihoods.html#model-1-likelihood-contribution",
    "title": "Inference review +  using likelihoods",
    "section": "Model 1: Likelihood contribution",
    "text": "Model 1: Likelihood contribution\n\n\n\nFoul 1\nFoul 2\nFoul 3\nn\nLikelihood contribution\n\n\n\n\nH\nH\nH\n3\n\\(p_H^3\\)\n\n\nH\nH\nV\n2\n\\(p_H^2(1 - p_H)\\)\n\n\nH\nV\nH\n3\n\\(p_H^2(1 - p_H)\\)\n\n\nH\nV\nV\n7\nA\n\n\nV\nH\nH\n7\nB\n\n\nV\nH\nV\n1\n\\(p_H(1 - p_H)^2\\)\n\n\nV\nV\nH\n5\n\\(p_H(1 - p_H)^2\\)\n\n\nV\nV\nV\n2\n\\((1 - p_H)^3\\)\n\n\n\n\nFill in A and B.\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/03-likelihoods.html#model-1-likelihood-function",
    "href": "slides/03-likelihoods.html#model-1-likelihood-function",
    "title": "Inference review +  using likelihoods",
    "section": "Model 1: Likelihood function",
    "text": "Model 1: Likelihood function\nBecause the observations (the games) are independent, the likelihood is\n\\[Lik(p_H) = \\prod_{i=1}^{n}p_H^{y_i}(1 - p_H)^{3 - y_i}\\]\n\nWe will use this function to find the maximum likelihood estimate (MLE). The MLE is the value between 0 and 1 where we are most likely to see the observed data."
  },
  {
    "objectID": "slides/03-likelihoods.html#visualizing-the-likelihood",
    "href": "slides/03-likelihoods.html#visualizing-the-likelihood",
    "title": "Inference review +  using likelihoods",
    "section": "Visualizing the likelihood",
    "text": "Visualizing the likelihood\n\n\n\n\n\n\n\n\n\n\n\n\n\np &lt;- seq(0,1, length.out = 100) #sequence of 100 values between 0 and 100\nlik &lt;- p^46 *(1 -p)^44\nx &lt;- tibble(p = p, lik = lik)\nggplot(data = x, aes(x = p, y = lik)) + \n  geom_point() + \n  geom_line() +\n  labs(y = \"Likelihood\",\n       title = \"Likelihood of p_H\")"
  },
  {
    "objectID": "slides/03-likelihoods.html#finding-the-maximum-likelihood-estimate",
    "href": "slides/03-likelihoods.html#finding-the-maximum-likelihood-estimate",
    "title": "Inference review +  using likelihoods",
    "section": "Finding the maximum likelihood estimate",
    "text": "Finding the maximum likelihood estimate\nThere are three primary ways to find the MLE\n✅ Approximate using a graph\n✅ Numerical approximation\n✅ Using calculus"
  },
  {
    "objectID": "slides/03-likelihoods.html#approximate-mle-from-a-graph",
    "href": "slides/03-likelihoods.html#approximate-mle-from-a-graph",
    "title": "Inference review +  using likelihoods",
    "section": "Approximate MLE from a graph",
    "text": "Approximate MLE from a graph"
  },
  {
    "objectID": "slides/03-likelihoods.html#mle-using-numerical-approximation",
    "href": "slides/03-likelihoods.html#mle-using-numerical-approximation",
    "title": "Inference review +  using likelihoods",
    "section": "MLE using numerical approximation",
    "text": "MLE using numerical approximation\nSpecify a finite set of possible values the for \\(p_H\\) and calculate the likelihood for each value\n\n\n# write an R function for the likelihood\nref_lik &lt;- function(ph) {\n  ph^46 *(1 - ph)^44\n}\n\n# search possible values for p and return max\nnGrid = 1000\nph &lt;- seq(0, 1, length = nGrid)\nlik &lt;- ref_lik(ph)\nph[lik == max(lik)]\n\n[1] 0.5115115"
  },
  {
    "objectID": "slides/03-likelihoods.html#find-mle-using-calculus",
    "href": "slides/03-likelihoods.html#find-mle-using-calculus",
    "title": "Inference review +  using likelihoods",
    "section": "Find MLE using calculus",
    "text": "Find MLE using calculus\n\nFind the MLE by taking the first derivative of the likelihood function.\nThis can be tricky because of the Product Rule, so we can maximize the log(Likelihood) instead. The same value maximizes the likelihood and log(Likelihood)"
  },
  {
    "objectID": "slides/03-likelihoods.html#find-mle-using-calculus-1",
    "href": "slides/03-likelihoods.html#find-mle-using-calculus-1",
    "title": "Inference review +  using likelihoods",
    "section": "Find MLE using calculus",
    "text": "Find MLE using calculus\n\\[Lik(p_H) = \\prod_{i=1}^{n}p_H^{y_i}(1 - p_H)^{3 - y_i}\\]\n\n\\[\n\\begin{aligned}\\log(Lik(p_H)) &= \\sum_{i=1}^{n}y_i\\log(p_H) + (3 - y_i)\\log(1 - p_H)\\\\[10pt] &= 46\\log(p_H) + 44\\log(1 - p_H)\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/03-likelihoods.html#find-mle-using-calculus-2",
    "href": "slides/03-likelihoods.html#find-mle-using-calculus-2",
    "title": "Inference review +  using likelihoods",
    "section": "Find MLE using calculus",
    "text": "Find MLE using calculus\n\\[\\frac{d}{d p_H} \\log(Lik(p_H)) = \\frac{46}{p_H} - \\frac{44}{1-p_H} = 0\\]\n\n\\[\\Rightarrow \\frac{46}{p_H} = \\frac{44}{1-p_H}\\]\n\n\n\\[\\Rightarrow 46(1-p_H) = 44p_H\\]\n\n\n\\[\\Rightarrow 46 = 90p_H\\]\n\n\n\\[\n\\hat{p}_H = \\frac{46}{90} = 0.511\n\\]\n\n\n\n😐"
  },
  {
    "objectID": "slides/03-likelihoods.html#model-2-conditional-model-1",
    "href": "slides/03-likelihoods.html#model-2-conditional-model-1",
    "title": "Inference review +  using likelihoods",
    "section": "Model 2: Conditional model",
    "text": "Model 2: Conditional model\nNow let’s assume fouls are not independent within each game. We will specify this dependence using conditional probabilities.\n\nConditional probability: \\(P(A|B) =\\) Probability of \\(A\\) given \\(B\\) has occurred\n\n\nDefine new parameters:\n\n\n\\(p_{H|N}\\): Probability referees call foul on home team given there are equal numbers of fouls on the home and visiting teams\n\\(p_{H|H Bias}\\): Probability referees call foul on home team given there are more prior fouls on the home team\n\\(p_{H|V Bias}\\): Probability referees call foul on home team given there are more prior fouls on the visiting team"
  },
  {
    "objectID": "slides/03-likelihoods.html#model-2-likelihood-contributions",
    "href": "slides/03-likelihoods.html#model-2-likelihood-contributions",
    "title": "Inference review +  using likelihoods",
    "section": "Model 2: Likelihood contributions",
    "text": "Model 2: Likelihood contributions\n\n\n\n\n\n\n\n\n\n\nFoul 1\nFoul 2\nFoul 3\nn\nLikelihood contribution\n\n\n\n\nH\nH\nH\n3\n\\((p_{H\\vert N})(p_{H\\vert H Bias})(p_{H\\vert H Bias}) = (p_{H\\vert N})(p_{H\\vert H Bias})^2\\)\n\n\nH\nH\nV\n2\n\\((p_{H\\vert N})(p_{H\\vert H Bias})(1-p_{H\\vert H Bias})\\)\n\n\nH\nV\nH\n3\n\\((p_{H\\vert N})(1 - p_{H \\vert HBias})(p_{H \\vert N}) = (p_{H \\vert N})^2(1 - p_{H \\vert HBias})\\)\n\n\nH\nV\nV\n7\nA\n\n\nV\nH\nH\n7\nB\n\n\nV\nH\nV\n1\n\\((1 - p_{H\\vert N})(p_{H\\vert V Bias})(1 - p_{H\\vert N}) = (1 - p_{H\\vert N})^2(p_{H\\vert V Bias})\\)\n\n\nV\nV\nH\n5\n\\((1 - p_{H\\vert N})(1-p_{H\\vert V Bias})(p_{H\\vert V Bias})\\)\n\n\nV\nV\nV\n2\n\\(\\begin{aligned}&(1 - p_{H\\vert N})(1-p_{H\\vert V Bias})(1-p_{H\\vert V Bias})\\\\ &=(1 - p_{H\\vert N})(1-p_{H\\vert V Bias})^2\\end{aligned}\\)"
  },
  {
    "objectID": "slides/03-likelihoods.html#likelihood-function",
    "href": "slides/03-likelihoods.html#likelihood-function",
    "title": "Inference review +  using likelihoods",
    "section": "Likelihood function",
    "text": "Likelihood function\n\\[\\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\\\ &(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\\end{aligned}\\]\n(Note: The exponents sum to 90, the total number of fouls in the data)\n\n\n\\[\\begin{aligned}\\log (Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias})) &= 25 \\log(p_{H| N}) + 23 \\log(1 - p_{H|N}) \\\\ & + 8 \\log(p_{H| H Bias}) + 12 \\log(1 - p_{H| H Bias})\\\\ &+ 13 \\log(p_{H| V Bias}) + 9 \\log(1-p_{H|V Bias})\\end{aligned}\\]"
  },
  {
    "objectID": "slides/03-likelihoods.html#mles-for-model-2",
    "href": "slides/03-likelihoods.html#mles-for-model-2",
    "title": "Inference review +  using likelihoods",
    "section": "MLEs for Model 2",
    "text": "MLEs for Model 2\nClick here for details on finding MLEs for Model2."
  },
  {
    "objectID": "slides/03-likelihoods.html#next-time",
    "href": "slides/03-likelihoods.html#next-time",
    "title": "Inference review +  using likelihoods",
    "section": "Next time",
    "text": "Next time\n\nPoisson regression"
  },
  {
    "objectID": "slides/03-likelihoods.html#references",
    "href": "slides/03-likelihoods.html#references",
    "title": "Inference review +  using likelihoods",
    "section": "References",
    "text": "References\n\n\n\n\n🔗 STA 310 - Spring 2024\n\n\n\n\nRoback, Paul, and Julie Legler. 2021. Beyond multiple linear regression: applied generalized linear models and multilevel models in R. CRC Press."
  },
  {
    "objectID": "slides/06-poisson-pt3.html#announcements",
    "href": "slides/06-poisson-pt3.html#announcements",
    "title": "Poisson Regression",
    "section": "Announcements",
    "text": "Announcements"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#topics",
    "href": "slides/06-poisson-pt3.html#topics",
    "title": "Poisson Regression",
    "section": "Topics",
    "text": "Topics\n\nOffsets in Poisson regression\nZero-inflated Poisson regression"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#data-airbnbs-in-nyc",
    "href": "slides/06-poisson-pt3.html#data-airbnbs-in-nyc",
    "title": "Poisson Regression",
    "section": "Data: Airbnbs in NYC",
    "text": "Data: Airbnbs in NYC\nThe data set NYCairbnb-sample.csv contains information about a random sample of 1000 Airbnbs in New York City. It is a subset of the data on 40628 Airbnbs scraped by Awad, Lebo, and Linden (2017).1\nVariables\n\nnumber_of_reviews: Number of reviews for the unit on Airbnb (proxy for number of rentals)\nprice: price per night in US dollars\nroom_type: Entire home/apartment, private room, or shared room\ndays: Number of days the unit has been listed (date when info scraped - date when unit first listed on Airbnb)\n\nGoal: Use the price and room type of Airbnbs to describe variation in the number of reviews (a proxy for number of rentals).\nData set pulled from BMLR Section 4.11."
  },
  {
    "objectID": "slides/06-poisson-pt3.html#data-airbnbs-in-nyc-1",
    "href": "slides/06-poisson-pt3.html#data-airbnbs-in-nyc-1",
    "title": "Poisson Regression",
    "section": "Data: Airbnbs in NYC",
    "text": "Data: Airbnbs in NYC\n\nairbnb &lt;- read_csv(\"data/NYCairbnb.csv\") \n\n#|&gt;\n#  select(id, number_of_reviews, days, room_type, price)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ndays\nlast_scraped\nhost_since\nroom_type\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\n\n\n\n\n16859979\n74\n4/3/2017\n1/19/2017\nPrivate room\n1.0\n1\n67\n7\n10\n10\n10\nFALSE\n\n\n16083673\n913\n4/3/2017\n10/3/2014\nPrivate room\n0.5\n1\n49\n7\n8\n9\n9\nTRUE\n\n\n12870344\n333\n4/2/2017\n5/4/2016\nPrivate room\n1.0\n1\n145\n0\nNA\nNA\nNA\nFALSE\n\n\n6561509\n677\n4/2/2017\n5/26/2015\nPrivate room\n1.0\n1\n65\n7\n10\n10\n10\nFALSE\n\n\n1940534\n1503\n4/3/2017\n2/20/2013\nPrivate room\n1.0\n1\n60\n11\n5\n6\n7\nFALSE"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#eda",
    "href": "slides/06-poisson-pt3.html#eda",
    "title": "Poisson Regression",
    "section": "EDA",
    "text": "EDA"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#eda-1",
    "href": "slides/06-poisson-pt3.html#eda-1",
    "title": "Poisson Regression",
    "section": "EDA",
    "text": "EDA\n\n\n\nOverall\n\n\n\n\n\n\nmean\nvar\n\n\n\n\n15.904\n855.329\n\n\n\n\n\n\n\nby room type\n\n\n\n\n\n\nroom_type\nmean\nvar\n\n\n\n\nEntire home/apt\n16.824\n820.289\n\n\nPrivate room\n15.223\n909.915\n\n\nShared room\n11.858\n516.557"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#considerations-for-modeling",
    "href": "slides/06-poisson-pt3.html#considerations-for-modeling",
    "title": "Poisson Regression",
    "section": "Considerations for modeling",
    "text": "Considerations for modeling\nWe would like to fit the Poisson regression model\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1 ~ price_i + \\beta_2 ~ room\\_type1_i + \\beta_3 ~ room\\_type2_i\\]\n\n\n\nBased on the EDA, what are some potential issues we may want to address in the model building?\nSuppose any model fit issues are addressed. What are some potential limitations to the conclusions and interpretations from the model?\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#offset-1",
    "href": "slides/06-poisson-pt3.html#offset-1",
    "title": "Poisson Regression",
    "section": "Offset",
    "text": "Offset\n\nSometimes counts are not directly comparable because the observations differ based on some characteristic directly related to the counts, i.e. the sampling effort.\nAn offset can be used to adjust for differences in sampling effort.\n\n\n\nLet \\(x_{offset}\\) be the variable that accounts for differences in sampling effort, then \\(\\log(x_{offset})\\) will be added to the model.\n\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1 ~ x_{i1} + \\beta_2 ~ x_{i2} + ... + \\beta_p ~ x_{ip} + \\log(x_{offset_i})\\]\n\nThe offset is a term in the model with coefficient always equal to 1."
  },
  {
    "objectID": "slides/06-poisson-pt3.html#adding-an-offset-to-the-airbnb-model",
    "href": "slides/06-poisson-pt3.html#adding-an-offset-to-the-airbnb-model",
    "title": "Poisson Regression",
    "section": "Adding an offset to the Airbnb model",
    "text": "Adding an offset to the Airbnb model\nWe will add the offset \\(\\log(days)\\) to the model. This accounts for the fact that we would expect Airbnbs that have been listed longer to have more reviews.\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1 ~ price_i + \\beta_2 ~ room\\_type1_i + \\beta_3 ~ room\\_type2_i + \\log(days_i)\\] \nNote: The response variable for the model is still \\(\\log(\\lambda_i)\\), the log mean number of reviews"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#detail-on-the-offset",
    "href": "slides/06-poisson-pt3.html#detail-on-the-offset",
    "title": "Poisson Regression",
    "section": "Detail on the offset",
    "text": "Detail on the offset\nWe want to adjust for the number of days, so we are interested in \\(\\frac{reviews}{days}\\).\n\nGiven \\(\\lambda\\) is the mean number of reviews\n\\[\\log\\Big(\\frac{\\lambda_i}{days_i}\\Big) = \\beta_0 + \\beta_1 ~ price_i + \\beta_2 ~ room\\_type1_i + \\beta_3 ~ room\\_type2_i\\]\n\n\n\n\\[\\Rightarrow \\log({\\lambda_i}) - \\log(days_i) = \\beta_0 + \\beta_1 ~ price_i + \\beta_2 ~ room\\_type1_i + \\beta_3 ~ room\\_type2_i\\]\n\n\n\n\\[\\Rightarrow \\log({\\lambda_i}) = \\beta_0 + \\beta_1 ~ price_i + \\beta_2 ~ room\\_type1_i + \\beta_3 ~ room\\_type2_i + \\log(days_i)\\]"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#airbnb-model-in-r",
    "href": "slides/06-poisson-pt3.html#airbnb-model-in-r",
    "title": "Poisson Regression",
    "section": "Airbnb model in R",
    "text": "Airbnb model in R\n\nairbnb_model &lt;- glm(number_of_reviews ~ price + room_type, \n                    data = airbnb, family = poisson, \n                    offset = log(days)) \n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-4.1528\n0.0027\n-1523.1520\n0\n\n\nprice\n-0.0004\n0.0000\n-38.5904\n0\n\n\nroom_typePrivate room\n-0.0469\n0.0028\n-16.8612\n0\n\n\nroom_typeShared room\n-0.1468\n0.0086\n-17.0990\n0\n\n\n\n\n\n\n\nThe coefficient for \\(\\log(days)\\) is fixed at 1, so it is not in the model output."
  },
  {
    "objectID": "slides/06-poisson-pt3.html#interpretations",
    "href": "slides/06-poisson-pt3.html#interpretations",
    "title": "Poisson Regression",
    "section": "Interpretations",
    "text": "Interpretations\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-4.1528\n0.0027\n-1523.1520\n0\n\n\nprice\n-0.0004\n0.0000\n-38.5904\n0\n\n\nroom_typePrivate room\n-0.0469\n0.0028\n-16.8612\n0\n\n\nroom_typeShared room\n-0.1468\n0.0086\n-17.0990\n0\n\n\n\n\n\n\n\n\nInterpret the coefficient of price\nInterpret the coefficient of room_typePrivate room\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#quasi-poisson-model",
    "href": "slides/06-poisson-pt3.html#quasi-poisson-model",
    "title": "Poisson Regression",
    "section": "Quasi-Poisson model",
    "text": "Quasi-Poisson model\n\nairbnb_model_q &lt;- glm(number_of_reviews ~ price + room_type, \n                    data = airbnb, family = quasipoisson, \n                    offset = log(days)) \n\ntidy(airbnb_model_q)\n\n# A tibble: 4 × 5\n  term                   estimate std.error statistic      p.value\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept)           -4.15     0.0192      -216.   0           \n2 price                 -0.000426 0.0000777     -5.48 0.0000000434\n3 room_typePrivate room -0.0469   0.0196        -2.39 0.0167      \n4 room_typeShared room  -0.147    0.0605        -2.43 0.0152"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#data-weekend-drinking",
    "href": "slides/06-poisson-pt3.html#data-weekend-drinking",
    "title": "Poisson Regression",
    "section": "Data: Weekend drinking",
    "text": "Data: Weekend drinking\nThe data weekend-drinks.csv contains information from a survey of 77 students in a introductory statistics course on a dry campus.1\nVariables\n\ndrinks: Number of drinks they had in the past weekend\noff_campus: 1 - lives off campus, 0 otherwise\nfirst_year: 1 - student is a first-year, 0 otherwise\nsex: f - student identifies as female, m - student identifies as male\n\nGoal: The goal is explore factors related to drinking behavior on a dry campus.\nData from case study in BMLR Section 4.10."
  },
  {
    "objectID": "slides/06-poisson-pt3.html#eda-response-variable",
    "href": "slides/06-poisson-pt3.html#eda-response-variable",
    "title": "Poisson Regression",
    "section": "EDA: Response variable",
    "text": "EDA: Response variable"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#observed-vs.-expected-response",
    "href": "slides/06-poisson-pt3.html#observed-vs.-expected-response",
    "title": "Poisson Regression",
    "section": "Observed vs. expected response",
    "text": "Observed vs. expected response\n\n\n\nWhat does it mean to be a “zero” in this data?"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#two-types-of-zeros",
    "href": "slides/06-poisson-pt3.html#two-types-of-zeros",
    "title": "Poisson Regression",
    "section": "Two types of zeros",
    "text": "Two types of zeros\nThere are two types of zeros\n\nThose who happen to have a zero in the data set (people who drink but happened to not drink last weekend)\nThose who will always report a value of zero (non-drinkers)\n\nThese are called true zeros\n\n\n\nWe introduce a new parameter \\(\\alpha\\) for the proportion of true zeros, then fit a model that has two components:\n\n\n1️⃣ The association between mean number of drinks and various characteristics among those who drink\n2️⃣ The estimated proportion of non-drinkers"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#zero-inflated-poisson-model-1",
    "href": "slides/06-poisson-pt3.html#zero-inflated-poisson-model-1",
    "title": "Poisson Regression",
    "section": "Zero-inflated Poisson model",
    "text": "Zero-inflated Poisson model\nZero-inflated Poisson (ZIP) model has two parts\n1️⃣ Association, among those who drink, between the mean number of drinks and predictors sex and off campus residence\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1 ~ off\\_campus_i + \\beta_2 ~ sex_i\\] where \\(\\lambda\\) is the mean number of drinks among those who drink\n\n2️⃣ Probability that a student does not drink\n\\[\\text{logit}(\\alpha_i) = \\log\\Big(\\frac{\\alpha_i}{1- \\alpha_i}\\Big) = \\beta_0 + \\beta_1 ~ first\\_year_i\\]\nwhere \\(\\alpha\\) is the proportion of non-drinkers\n\n\nNote: The same variables can be used in each component"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#details-of-the-zip-model",
    "href": "slides/06-poisson-pt3.html#details-of-the-zip-model",
    "title": "Poisson Regression",
    "section": "Details of the ZIP model",
    "text": "Details of the ZIP model\n\nThe ZIP model is a special case of a latent variable model\n\nA type of mixture model where observations for one or more groups occur together but the group membership unknown\n\nZero-inflated models are a common type of mixture model; they apply beyond Poisson regression"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#zip-model-in-r",
    "href": "slides/06-poisson-pt3.html#zip-model-in-r",
    "title": "Poisson Regression",
    "section": "ZIP model in R",
    "text": "ZIP model in R\nFit ZIP models using the zeroinfl function from the pscl R package.\n\nlibrary(pscl)\n\ndrinks_zip &lt;- zeroinfl(drinks ~ off_campus + sex | first_year,\n                data = drinks)\ndrinks_zip\n\n\nCall:\nzeroinfl(formula = drinks ~ off_campus + sex | first_year, data = drinks)\n\nCount model coefficients (poisson with log link):\n(Intercept)   off_campus         sexm  \n     0.7543       0.4159       1.0209  \n\nZero-inflation model coefficients (binomial with logit link):\n(Intercept)   first_year  \n    -0.6036       1.1364"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#tidy-output",
    "href": "slides/06-poisson-pt3.html#tidy-output",
    "title": "Poisson Regression",
    "section": "Tidy output",
    "text": "Tidy output\nUse the tidy function from the poissonreg package for tidy model output.\n\nlibrary(poissonreg)\n\n\n\nMean number of drinks among those who drink\n\ntidy(drinks_zip, type = \"count\") |&gt; kable(digits = 3)\n\n\n\n\nterm\ntype\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\ncount\n0.754\n0.144\n5.238\n0.000\n\n\noff_campus\ncount\n0.416\n0.206\n2.020\n0.043\n\n\nsexm\ncount\n1.021\n0.175\n5.827\n0.000"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#tidy-output-1",
    "href": "slides/06-poisson-pt3.html#tidy-output-1",
    "title": "Poisson Regression",
    "section": "Tidy output",
    "text": "Tidy output\nProportion of non-drinkers\n\ntidy(drinks_zip, type = \"zero\") |&gt; kable(digits = 3)\n\n\n\n\nterm\ntype\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\nzero\n-0.604\n0.311\n-1.938\n0.053\n\n\nfirst_year\nzero\n1.136\n0.610\n1.864\n0.062"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#interpreting-the-model-coefficients",
    "href": "slides/06-poisson-pt3.html#interpreting-the-model-coefficients",
    "title": "Poisson Regression",
    "section": "Interpreting the model coefficients",
    "text": "Interpreting the model coefficients\n\n\n\n\n\nterm\ntype\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\ncount\n0.754\n0.144\n5.238\n0.000\n\n\noff_campus\ncount\n0.416\n0.206\n2.020\n0.043\n\n\nsexm\ncount\n1.021\n0.175\n5.827\n0.000\n\n\n\n\n\n\n\n\nInterpret the intercept.\nInterpret the coefficients off_campus and sexm.\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#estimated-proportion-zeros",
    "href": "slides/06-poisson-pt3.html#estimated-proportion-zeros",
    "title": "Poisson Regression",
    "section": "Estimated proportion zeros",
    "text": "Estimated proportion zeros\n\n\n\n\n\nterm\ntype\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\nzero\n-0.604\n0.311\n-1.938\n0.053\n\n\nfirst_year\nzero\n1.136\n0.610\n1.864\n0.062\n\n\n\n\n\n\nBased on the model…\n\nWhat is the probability a first-year student is a non-drinker?\nWhat is the probability a upperclass student (sophomore, junior, senior) is a non-drinker?\n\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#comparing-poisson-and-zip-models",
    "href": "slides/06-poisson-pt3.html#comparing-poisson-and-zip-models",
    "title": "Poisson Regression",
    "section": "Comparing Poisson and ZIP Models",
    "text": "Comparing Poisson and ZIP Models\n\nSuppose we want to compare our ZIP model to a Poisson model \\(\\log(\\lambda_i) = \\beta_0 + \\beta_1 ~ off_campus_i + \\beta_2 ~ sex_i\\)\nWhich of the following methods can we use to compare these models?\n\nAIC\nBIC\nLikelihood ratio test"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#likelihoods-for-zip-model",
    "href": "slides/06-poisson-pt3.html#likelihoods-for-zip-model",
    "title": "Poisson Regression",
    "section": "Likelihoods for ZIP model",
    "text": "Likelihoods for ZIP model"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#probabilities-under-zip-model",
    "href": "slides/06-poisson-pt3.html#probabilities-under-zip-model",
    "title": "Poisson Regression",
    "section": "Probabilities under ZIP model",
    "text": "Probabilities under ZIP model\nThere are three different types of observations in the data:\n\nObserved zero and will always be 0 (true zeros)\nObserved 0 but will not always be 0\nObserved non-zero count and will not always be 0"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#probabilities-under-zip-model-1",
    "href": "slides/06-poisson-pt3.html#probabilities-under-zip-model-1",
    "title": "Poisson Regression",
    "section": "Probabilities under ZIP model",
    "text": "Probabilities under ZIP model\nTrue zeros \\[P(0 | \\text{true zero})= \\alpha\\]\n\nObserved 0 but will not always be 0\n\\[P(0 | \\text{not always zero}) = (1 - \\alpha)\\frac{e^{-\\lambda}\\lambda^0}{0!}\\]\n\n\nDid not observe 0 and will not always be 0\n\\[P(z_i | \\text{not always zero}) = (1 - \\alpha)\\frac{e^{-\\lambda}\\lambda^{z_i}}{z_i!}\\]"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#probabilities-under-zip-model-2",
    "href": "slides/06-poisson-pt3.html#probabilities-under-zip-model-2",
    "title": "Poisson Regression",
    "section": "Probabilities under ZIP model",
    "text": "Probabilities under ZIP model\nPutting this all together. Let \\(y_i\\) be an observed response then\n\\[P(Y_i = y_i | x_i) = \\begin{cases}\n\\alpha + (1 - \\alpha)e^{-\\lambda_i} && \\text{ if } y_i = 0 \\\\\n(1 - \\alpha)\\frac{e^{-\\lambda_i}\\lambda_i^{y_i}}{y_i!} && \\text{ if } y_i &gt; 0\n\\end{cases}\\]\n\nRecall from our example,\n\\[\\lambda_i = e^{\\beta_0 + \\beta_1~off\\_campus_i + \\beta_2 ~ sex_i}\\]\n\\[\\alpha_i = \\frac{e^{\\beta_{0\\alpha} + \\beta_{1\\alpha} ~ first\\_year_i}}{1 + e^{\\beta_{0\\alpha} + \\beta_{1\\alpha} ~ first\\_year_i}}\\]\n\nPlug in \\(\\lambda_i\\) and \\(\\alpha_i\\) into the above equation obtain the likelihood function"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#references",
    "href": "slides/06-poisson-pt3.html#references",
    "title": "Poisson Regression",
    "section": "References",
    "text": "References\n\n\n\n\n🔗 STA 310 - Spring 2024\n\n\n\n\nAwad, Annika, Evan Lebo, and Anna Linden. 2017. “Intercontinental Comparative Analysis of Airbnb Booking Factors.”"
  },
  {
    "objectID": "slides/11-multilevel-models.html#announcements",
    "href": "slides/11-multilevel-models.html#announcements",
    "title": "Multilevel models",
    "section": "Announcements",
    "text": "Announcements\n\nQuiz 02: due Thu, Feb 22, 12pm (noon)\n\nCovers readings & lectures: Jan 24 - Feb 12\nPoisson regression, unifying framework for GLMs, logistic regression, proportional odds models, probit regression\n\nHW 02 returned\n\nClose issue in your GitHub after you’ve reviewed feedback\n\nHW 03 released tomorrow and due Wed, Feb 28\nRead Sadler and Miller (2010) as part of Feb 26 prepare assignment"
  },
  {
    "objectID": "slides/11-multilevel-models.html#topics",
    "href": "slides/11-multilevel-models.html#topics",
    "title": "Multilevel models",
    "section": "Topics",
    "text": "Topics\n\nUnderstand how multilevel models can be used to take correlation into account\nConduct univariate and bivariate EDA for multilevel models\nWrite multilevel model, including assumptions about variance components\n\nIn by-level and composite forms\n\nInterpret the model parameters, fixed effects, and variance components\n\n\n\nNotes based on Chapter 8 of Roback and Legler (2021) unless noted otherwise."
  },
  {
    "objectID": "slides/11-multilevel-models.html#multilevel-data",
    "href": "slides/11-multilevel-models.html#multilevel-data",
    "title": "Multilevel models",
    "section": "Multilevel data",
    "text": "Multilevel data\n\nWe can think of correlated data as a multilevel structure\n\nPopulation elements are aggregated into groups\nThere are observational units and measurements at each level\n\nFor now we will focus on data with two levels:\n\nLevel one: Most basic level of observation\nLevel two: Groups formed from aggregated level-one observations"
  },
  {
    "objectID": "slides/11-multilevel-models.html#two-types-of-effects",
    "href": "slides/11-multilevel-models.html#two-types-of-effects",
    "title": "Multilevel models",
    "section": "Two types of effects",
    "text": "Two types of effects\n\nFixed effects: Effects that are of interest in the study\n\nCan think of these as effects whose interpretations would be included in a write up of the study\n\n\n\n\nRandom effects: Not interested in studying effects of specific values in the data but we want to understand the variability\n\nCan think of these as effects whose interpretations would not necessarily be included in a write up of the study"
  },
  {
    "objectID": "slides/11-multilevel-models.html#data-music-performance-anxiety",
    "href": "slides/11-multilevel-models.html#data-music-performance-anxiety",
    "title": "Multilevel models",
    "section": "Data: Music performance anxiety",
    "text": "Data: Music performance anxiety\nThe data musicdata.csv come from the study by Sadler and Miller (2010) of the emotional state of musicians before performances. The dataset contains information collected from 37 undergraduate music majors who completed the Positive Affect Negative Affect Schedule (PANAS), an instrument produces a measure of anxiety (negative affect) and a measure of happiness (positive affect). This analysis will focus on negative affect as a measure of performance anxiety.\n\nThe primary variables we’ll use are\n\nna: negative affect score on PANAS (the response variable)\nperform_type: type of performance (Solo, Large Ensemble, Small Ensemble)\ninstrument: type of instrument (Voice, Orchestral, Piano)"
  },
  {
    "objectID": "slides/11-multilevel-models.html#look-at-data",
    "href": "slides/11-multilevel-models.html#look-at-data",
    "title": "Multilevel models",
    "section": "Look at data",
    "text": "Look at data\n\n\n\n\n\nid\ndiary\nperform_type\nna\ngender\ninstrument\n\n\n\n\n1\n1\nSolo\n11\nFemale\nvoice\n\n\n1\n2\nLarge Ensemble\n19\nFemale\nvoice\n\n\n1\n3\nLarge Ensemble\n14\nFemale\nvoice\n\n\n12\n1\nSolo\n23\nFemale\norchestral instrument\n\n\n12\n2\nSolo\n17\nFemale\norchestral instrument\n\n\n12\n3\nSmall Ensemble\n25\nFemale\norchestral instrument\n\n\n\n\n\n\n\nWhat are the Level One and Level Two observational units?\nWhat variables are measured at each level?"
  },
  {
    "objectID": "slides/11-multilevel-models.html#univariate-exploratory-data-analysis",
    "href": "slides/11-multilevel-models.html#univariate-exploratory-data-analysis",
    "title": "Multilevel models",
    "section": "Univariate exploratory data analysis",
    "text": "Univariate exploratory data analysis\nLevel One variables\nTwo ways to approach univariate EDA (visualizations and summary statistics) for Level One variables:\n\nUse individual observations (i.e., treat observations as independent)\nUse aggregated values for each Level Two observation\n\n\nLevel Two variables\n\nUse a data set that contains one row per Level Two observation"
  },
  {
    "objectID": "slides/11-multilevel-models.html#bivariate-exploratory-data-analysis",
    "href": "slides/11-multilevel-models.html#bivariate-exploratory-data-analysis",
    "title": "Multilevel models",
    "section": "Bivariate exploratory data analysis",
    "text": "Bivariate exploratory data analysis\nGoals\n\nExplore general association between the predictor and response variable\nExplore whether subjects at a given level of the predictor tend to have similar mean responses\nExplore whether variation in response differs at different levels of a predictor\n\nThere are two ways to visualize these associations:\n\nOne plot of individual observations (i.e., treat observations as independent)\nSeparate plots of responses vs. predictor for each Level Two observation (lattice plots)"
  },
  {
    "objectID": "slides/11-multilevel-models.html#questions-we-want-to-answer",
    "href": "slides/11-multilevel-models.html#questions-we-want-to-answer",
    "title": "Multilevel models",
    "section": "Questions we want to answer",
    "text": "Questions we want to answer\nWhat is the association between performance type (large ensemble or not) and performance anxiety? Does the association differ based on instrument type (orchestral or not)?\n\n\nWhat is the problem with an ordinary least squares model to draw conclusions?\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n15.721\n0.359\n43.778\n0.000\n\n\norchestra\n1.789\n0.552\n3.243\n0.001\n\n\nlarge_ensemble\n-0.277\n0.791\n-0.350\n0.727\n\n\norchestra:large_ensemble\n-1.709\n1.062\n-1.609\n0.108"
  },
  {
    "objectID": "slides/11-multilevel-models.html#other-modeling-approaches",
    "href": "slides/11-multilevel-models.html#other-modeling-approaches",
    "title": "Multilevel models",
    "section": "Other modeling approaches",
    "text": "Other modeling approaches\n1️⃣ Condense each musician’s set of responses into a single outcome (e.g., mean max, last observation, etc.) and fit a linear model on these condensed observations\n\nLeaves few observations (37) to fit the model\nIgnoring a lot of information in the multiple observations for each musician\n\n\n2️⃣ Fit a separate model for each musician understand the association between performance type (Level One models). Then fit a system of Level Two models to predict the fitted coefficients in the Level One model for each subject based on instrument type (Level Two model).\n\n\nLet’s look at approach #2"
  },
  {
    "objectID": "slides/11-multilevel-models.html#level-one-model",
    "href": "slides/11-multilevel-models.html#level-one-model",
    "title": "Multilevel models",
    "section": "Level One model",
    "text": "Level One model\nWe’ll start with the Level One model to understand the association between performance type and performance anxiety for the \\(i^{th}\\) musician and the \\(j^{th}\\) perfromance \\[na_{ij} = a_i + b_i ~ LargeEnsemble_{ij} + \\epsilon_i, \\hspace{5mm} \\epsilon_{ij} \\sim N(0,\\sigma^2)\\]\n\nWhy is it more meaningful to use performance type for the Level One model than instrument?\n\nFor now, estimate \\(a_i\\) and \\(b_i\\) using least-squares regression."
  },
  {
    "objectID": "slides/11-multilevel-models.html#example-level-one-model",
    "href": "slides/11-multilevel-models.html#example-level-one-model",
    "title": "Multilevel models",
    "section": "Example Level One model",
    "text": "Example Level One model\nBelow is data for id #22\n\n\n\n\n\nid\ndiary\nperform_type\ninstrument\nna\n\n\n\n\n22\n1\nSolo\norchestral instrument\n24\n\n\n22\n2\nLarge Ensemble\norchestral instrument\n21\n\n\n22\n3\nLarge Ensemble\norchestral instrument\n14\n\n\n22\n4\nLarge Ensemble\norchestral instrument\n15\n\n\n22\n5\nLarge Ensemble\norchestral instrument\n10\n\n\n22\n6\nSolo\norchestral instrument\n24\n\n\n22\n7\nSolo\norchestral instrument\n24\n\n\n22\n8\nSolo\norchestral instrument\n16\n\n\n22\n9\nSmall Ensemble\norchestral instrument\n34\n\n\n22\n10\nLarge Ensemble\norchestral instrument\n22\n\n\n22\n11\nLarge Ensemble\norchestral instrument\n19\n\n\n22\n12\nLarge Ensemble\norchestral instrument\n18\n\n\n22\n13\nLarge Ensemble\norchestral instrument\n12\n\n\n22\n14\nLarge Ensemble\norchestral instrument\n19\n\n\n22\n15\nSolo\norchestral instrument\n25"
  },
  {
    "objectID": "slides/11-multilevel-models.html#level-one-model-1",
    "href": "slides/11-multilevel-models.html#level-one-model-1",
    "title": "Multilevel models",
    "section": "Level One model",
    "text": "Level One model\n\nmusic |&gt;\n  filter(id == 22) |&gt;\n  lm(na ~ large_ensemble, data = _) |&gt;\n  tidy() |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n24.500\n1.96\n12.503\n0.000\n\n\nlarge_ensemble\n-7.833\n2.53\n-3.097\n0.009\n\n\n\n\n\n\n\n\nRepeat for all 37 musicians. See Part 3: Level One Models in AE."
  },
  {
    "objectID": "slides/11-multilevel-models.html#level-one-models",
    "href": "slides/11-multilevel-models.html#level-one-models",
    "title": "Multilevel models",
    "section": "Level One models",
    "text": "Level One models\n\nRecreated from BMLR Figure 8.9\nNow let’s consider if there is an association between the estimated slopes, estimated intercepts, and the type of instrument"
  },
  {
    "objectID": "slides/11-multilevel-models.html#level-two-model",
    "href": "slides/11-multilevel-models.html#level-two-model",
    "title": "Multilevel models",
    "section": "Level Two Model",
    "text": "Level Two Model\nThe slope and intercept for the \\(i^{th}\\) musician can be modeled as \\[\\begin{aligned}&a_i = \\alpha_0 + \\alpha_1 ~ Orchestra_i + u_i \\\\\n&b_i = \\beta_0 + \\beta_1 ~ Orchestra_i + v_i\\end{aligned}\\]\nNote the response variable in the Level Two models are not observed outcomes but the (fitted) slope and intercept from each musician\nSee Part 4: Level Two Models in AE."
  },
  {
    "objectID": "slides/11-multilevel-models.html#estimated-coefficients-by-instrument",
    "href": "slides/11-multilevel-models.html#estimated-coefficients-by-instrument",
    "title": "Multilevel models",
    "section": "Estimated coefficients by instrument",
    "text": "Estimated coefficients by instrument"
  },
  {
    "objectID": "slides/11-multilevel-models.html#level-two-model-1",
    "href": "slides/11-multilevel-models.html#level-two-model-1",
    "title": "Multilevel models",
    "section": "Level Two model",
    "text": "Level Two model\nModel for intercepts\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n16.283\n0.671\n24.249\n0.000\n\n\norchestra\n1.411\n0.991\n1.424\n0.163\n\n\n\n\n\n\nModel for slopes\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.771\n0.851\n-0.906\n0.373\n\n\norchestra\n-1.406\n1.203\n-1.168\n0.253"
  },
  {
    "objectID": "slides/11-multilevel-models.html#writing-out-the-models",
    "href": "slides/11-multilevel-models.html#writing-out-the-models",
    "title": "Multilevel models",
    "section": "Writing out the models",
    "text": "Writing out the models\nLevel One\n\\[\\hat{na}_{ij}  = \\hat{a}_i + \\hat{b}_i ~ LargeEnsemble_{ij}\\]\n\n\nLevel Two\n\\[\\begin{aligned}&\\hat{a}_i = 16.283 + 1.441 ~ Orchestra_i \\\\\n&\\hat{b}_i = -0.771 - 1.406 ~ Orchestra_i\\end{aligned}\\]"
  },
  {
    "objectID": "slides/11-multilevel-models.html#estimated-composite-model",
    "href": "slides/11-multilevel-models.html#estimated-composite-model",
    "title": "Multilevel models",
    "section": "Estimated composite model",
    "text": "Estimated composite model\n\\[\n\\begin{aligned}\\hat{na}_{ij} &= 16.283 + 1.441 ~ Orchestra_i - 0.771 ~ LargeEnsemble_{ij} \\\\\n&- 1.406 ~ Orchestra:LargeEnsemble_{ij}\\end{aligned}\n\\]\n(Note that we also have the error terms \\(\\epsilon_{ij}, u_i, v_i\\) that we will discuss later)\n\n\n\nWhat is the predicted average performance anxiety before solos and small ensemble performances for vocalists and keyboardists? For those who place orchestral instruments?\nWhat is the predicted average performance anxiety before large ensemble performances for those who play orchestral instruments?"
  },
  {
    "objectID": "slides/11-multilevel-models.html#disadvantages-to-this-approach",
    "href": "slides/11-multilevel-models.html#disadvantages-to-this-approach",
    "title": "Multilevel models",
    "section": "Disadvantages to this approach",
    "text": "Disadvantages to this approach\n⚠️ Weighs each musician the same regardless of number of diary entries\n⚠️ Drops subjects who have missing values for slope (7 individuals who didn’t play a large ensemble performance)\n⚠️ Does not share strength effectively across individuals (look at \\(R^2\\) values in Part 3: Level One Models of AE)\n\n\nWe will use a unified approach that utilizes likelihood-based methods to address some of these drawbacks."
  },
  {
    "objectID": "slides/11-multilevel-models.html#framework",
    "href": "slides/11-multilevel-models.html#framework",
    "title": "Multilevel models",
    "section": "Framework",
    "text": "Framework\nLet \\(Y_{ij}\\) be the performance anxiety for the \\(i^{th}\\) musician before performance \\(j\\).\nLevel One\n\\[Y_{ij} = a_i + b_i ~ LargeEnsemble + \\epsilon_{ij}\\]\n\nLevel Two\n\\[\\begin{aligned}&a_i = \\alpha_0 + \\alpha_1 ~ Orchestra_i+ u_i\\\\\n&b_i = \\beta_0 + \\beta_1~Orchestra_i + v_i\\end{aligned}\\]\n\n\n\nThis approach uses likelihood-based methods (instead of least squares) to address the previously mentioned disadvantages"
  },
  {
    "objectID": "slides/11-multilevel-models.html#composite-model",
    "href": "slides/11-multilevel-models.html#composite-model",
    "title": "Multilevel models",
    "section": "Composite model",
    "text": "Composite model\nPlug in the equations for \\(a_i\\) and \\(b_i\\) to get the composite model \\[\\begin{aligned}Y_{ij} &= (\\alpha_0 + \\alpha_1 ~ Orchestra_i + \\beta_0 ~ LargeEnsemble_{ij} \\\\\n&+ \\beta_1 ~ Orchestra_i:LargeEnsemble_{ij})\\\\\n&+ (u_i + v_i ~ LargeEnsemble_{ij} + \\epsilon_{ij})\\end{aligned}\\]\n\n\nThe fixed effects to estimate are \\(\\alpha_0, \\alpha_1, \\beta_0, \\beta_1\\)\nThe error terms are \\(u_i, v_i, \\epsilon_{ij}\\)\n\n\\(u_i\\) and \\(v_i\\) are associated with student random effect\n\\(\\epsilon_{ij}\\) is what’s left unexplained\n\n\n\n\n\nNote that we no longer need to estimate \\(a_i\\) and \\(b_i\\) directly as we did earlier. They conceptually connect the Level One and Level Two models."
  },
  {
    "objectID": "slides/11-multilevel-models.html#notation",
    "href": "slides/11-multilevel-models.html#notation",
    "title": "Multilevel models",
    "section": "Notation",
    "text": "Notation\n\n\nGreek letters denote the fixed effect model parameters to be estimated\n\ne.g., \\(\\alpha_0, \\alpha_1, \\beta_0, \\beta_1\\)\n\nRoman letters denote the preliminary fixed effects at lower levels (not directly estimated)\n\ne.g. \\(a_i, b_i\\)\n\n\\(\\sigma\\) and \\(\\rho\\) denote variance components that will be estimated\n\\(\\epsilon_{ij}, u_i, v_i\\) denote error terms (not directly estimated)"
  },
  {
    "objectID": "slides/11-multilevel-models.html#error-terms",
    "href": "slides/11-multilevel-models.html#error-terms",
    "title": "Multilevel models",
    "section": "Error terms",
    "text": "Error terms\n\n\nWe generally assume that the error terms are normally distributed, e.g. error associated with each performance of a given musician is \\(\\epsilon_{ij} \\sim N(0, \\sigma^2)\\)\nFor the Level Two models, the errors are\n\n\\(u_i\\): deviation of musician \\(i\\) from the mean performance anxiety before solos and small ensembles after accounting for the instrument\n\\(v_i\\): deviance of musician \\(i\\) from the mean difference in performance anxiety between large ensembles and other performance types after accounting for instrument\n\nNeed to account for fact that \\(u_i\\) and \\(v_i\\) are correlated for the \\(i^{th}\\) musician"
  },
  {
    "objectID": "slides/11-multilevel-models.html#distribution-of-level-two-errors",
    "href": "slides/11-multilevel-models.html#distribution-of-level-two-errors",
    "title": "Multilevel models",
    "section": "Distribution of Level Two errors",
    "text": "Distribution of Level Two errors\nUse a multivariate normal distribution for the Level Two error terms \\[\\left[ \\begin{array}{c}\n            u_{i} \\\\ v_{i}\n          \\end{array}  \\right] \\sim N \\left( \\left[\n          \\begin{array}{c}\n            0 \\\\ 0\n          \\end{array} \\right], \\left[\n          \\begin{array}{cc}\n            \\sigma_{u}^{2} & \\rho_{uv}\\sigma_{u}\\sigma_v \\\\\n            \\rho_{uv}\\sigma_{u}\\sigma_v & \\sigma_{v}^{2}\n          \\end{array} \\right] \\right)\\]\nwhere \\(\\sigma^2_u\\) and \\(\\sigma^2_v\\) are the variance of \\(u_i\\)’s and \\(v_i\\)’s respectively, and \\(\\sigma_{uv} = \\rho_{uv}\\sigma_u\\sigma_v\\) is covariance between \\(u_i\\) and \\(v_i\\)\n\n\nWhat does it mean for \\(\\rho_{uv} &gt; 0\\)?\nWhat does it mean for \\(\\rho_{uv} &lt; 0\\)?"
  },
  {
    "objectID": "slides/11-multilevel-models.html#visualizing-multivariate-normal-distribution",
    "href": "slides/11-multilevel-models.html#visualizing-multivariate-normal-distribution",
    "title": "Multilevel models",
    "section": "Visualizing multivariate normal distribution",
    "text": "Visualizing multivariate normal distribution\n\nRecreated from Figure 8.12"
  },
  {
    "objectID": "slides/11-multilevel-models.html#fit-the-model",
    "href": "slides/11-multilevel-models.html#fit-the-model",
    "title": "Multilevel models",
    "section": "Fit the model",
    "text": "Fit the model\nFit multilevel model using the lmer function from the lme4 package. Display results using the tidy() function from the broom.mixed package.\n\nlibrary(lme4)\nlibrary(broom.mixed)\n\nmusic_model &lt;- lmer(na ~ orchestra + large_ensemble + \n                      orchestra:large_ensemble +\n                      (large_ensemble|id), \n                    REML = TRUE, data = music)\n\ntidy(music_model) |&gt; kable(digits = 3)"
  },
  {
    "objectID": "slides/11-multilevel-models.html#fitted-model",
    "href": "slides/11-multilevel-models.html#fitted-model",
    "title": "Multilevel models",
    "section": "Fitted model",
    "text": "Fitted model\n\n\n\n\n\n\n\n\n\n\n\n\n\neffect\ngroup\nterm\nestimate\nstd.error\nstatistic\n\n\n\n\nfixed\nNA\n(Intercept)\n15.930\n0.641\n24.833\n\n\nfixed\nNA\norchestra\n1.693\n0.945\n1.791\n\n\nfixed\nNA\nlarge_ensemble\n-0.911\n0.845\n-1.077\n\n\nfixed\nNA\norchestra:large_ensemble\n-1.424\n1.099\n-1.295\n\n\nran_pars\nid\nsd__(Intercept)\n2.378\nNA\nNA\n\n\nran_pars\nid\ncor__(Intercept).large_ensemble\n-0.635\nNA\nNA\n\n\nran_pars\nid\nsd__large_ensemble\n0.672\nNA\nNA\n\n\nran_pars\nResidual\nsd__Observation\n4.670\nNA\nNA"
  },
  {
    "objectID": "slides/11-multilevel-models.html#fitted-model-1",
    "href": "slides/11-multilevel-models.html#fitted-model-1",
    "title": "Multilevel models",
    "section": "Fitted model",
    "text": "Fitted model\n\\[\n\\begin{aligned}\n\\hat{na}_{ij} &= 15.930 + 1.693 ~ Orchestra_i - 0.911 ~ LargeEnsemble_{ij} \\\\\n&- 1.424 ~ Orchestra_i:LargeEnsemble_{ij} \\\\[30pt]&\\left[ \\begin{array}{c}\n            u_{i} \\\\ v_{i}\n          \\end{array}  \\right] \\sim N \\left( \\left[\n          \\begin{array}{c}\n            0 \\\\ 0\n          \\end{array} \\right], \\left[\n          \\begin{array}{cc}\n            2.378^{2} & -0.635 *2.378 *0.672 \\\\\n            -0.635 *2.378 *0.672 & 0.672^{2}\n          \\end{array} \\right] \\right) \\\\[30pt]\n&\\epsilon_{ij} \\sim N(0, 4.670^2)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/11-multilevel-models.html#references",
    "href": "slides/11-multilevel-models.html#references",
    "title": "Multilevel models",
    "section": "References",
    "text": "References\n\n\n\n\n🔗 STA 310 - Spring 2024\n\n\n\n\nRoback, Paul, and Julie Legler. 2021. Beyond multiple linear regression: applied generalized linear models and multilevel models in R. CRC Press.\n\n\nSadler, Michael E, and Christopher J Miller. 2010. “Performance Anxiety: A Longitudinal Study of the Roles of Personality and Experience in Musicians.” Social Psychological and Personality Science 1 (3): 280–87."
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio containers (optional)\n🔗 on Duke Container Manager\n\n\nCourse GitHub organization\n🔗 on GitHub\n\n\nGradebook\n🔗 on Canvas\n\n\nTextbooks\n🔗 Beyond Multiple Linear Regression\n\n\n\n🔗 R for Data Science\n\n\n\n🔗 Tidy Modeling with R",
    "crumbs": [
      "Course information",
      "Useful links"
    ]
  }
]