[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Role\nName\nOffice hours\nLocation\n\n\n\n\nInstructor\nProf. Maria Tackett\nMon 10:30 - 11:30am\nWed 1:30 - 2:30pm\nOld Chem 118B\n\n\n\n\nor by appointment\nOld Chem 118B or Zoom\n\n\nTeaching Assistant\nHun Kang\nTue 3 - 5pm\nOld Chem 203B"
  },
  {
    "objectID": "syllabus.html#teaching-team-office-hours",
    "href": "syllabus.html#teaching-team-office-hours",
    "title": "Syllabus",
    "section": "",
    "text": "Role\nName\nOffice hours\nLocation\n\n\n\n\nInstructor\nProf. Maria Tackett\nMon 10:30 - 11:30am\nWed 1:30 - 2:30pm\nOld Chem 118B\n\n\n\n\nor by appointment\nOld Chem 118B or Zoom\n\n\nTeaching Assistant\nHun Kang\nTue 3 - 5pm\nOld Chem 203B"
  },
  {
    "objectID": "syllabus.html#course-info",
    "href": "syllabus.html#course-info",
    "title": "Syllabus",
    "section": "Course info",
    "text": "Course info\n\n\n\n\nDay\nTime\nLocation\n\n\n\n\nLectures\nMon & Wed\n3:05 - 4:20pm\nPhysics 205\n\n\nLab 01\nThu\n3:05 - 4:20pm\nPerkins 071 (Link #5)\n\n\nLab 02\nThu\n4:40 - 5:55pm\nPerkins 087 (Link #3)"
  },
  {
    "objectID": "syllabus.html#textbooks",
    "href": "syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nAll books are freely available online. Print copies are also available for purchase.\n\n\n\nBeyond Multiple Linear Regression\nRoback, Legler\nCRC Press, 1st edition, 2020\n\n\nR for Data Science\nWickham, Cetinkaya-Rundel, Grolemund\nO’Reilly, 2nd edition, 2023\n\n\nTidy Modeling with R\nKuhn, Silge\nO’Reilly, 1st edition, 2022"
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus",
    "section": "Course description",
    "text": "Course description\nSTA 310 builds upon the content in STA 210: Regression Analysis. In STA 310 students will be introduced to generalized linear models (GLMs), a broad modeling framework that includes linear and logistic models, among others. Students will learn the basic theory of GLMs and how they can used to model a variety of response variables with non-normal distributions. Students will also learn an extension of GLMs that can be applied to modeling data with correlated observations, such as data with repeated measures."
  },
  {
    "objectID": "syllabus.html#prerequisites",
    "href": "syllabus.html#prerequisites",
    "title": "Syllabus",
    "section": "Prerequisites",
    "text": "Prerequisites\nThe prerequisites for the course are STA 210 and one of STA 230/STA 231/STA 240. This course assumes students have some familiarity with linear regression, analyzing data using RStudio, using version control with Git and collaborating using GitHub. The semester will start with a short review of linear regression and computing."
  },
  {
    "objectID": "syllabus.html#course-learning-objectives",
    "href": "syllabus.html#course-learning-objectives",
    "title": "Syllabus",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to …\n\ndescribe generalized linear models (GLMs) as a unified framework.\nexplain how specific models fit into the GLM framework, including extensions for correlated data.\nidentify the appropriate model given the data and analysis objective.\nanalyze real-world data by fitting and interpreting GLMs.\nuse R for analysis, Quarto to write reports, git for version control, and GitHub for collaboration.\neffectively communicate results from statistical analyses to a general audience in writing and oral presentations."
  },
  {
    "objectID": "syllabus.html#course-community",
    "href": "syllabus.html#course-community",
    "title": "Syllabus",
    "section": "Course community",
    "text": "Course community\n\nDuke Community Standard\nAs a student in this course, you have agreed to uphold the Duke Community Standard as well as the practices specific to this course.\n\n\n\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know! You’ll be able to note this in the Getting to know you survey.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nPronouns\nPronouns are meaningful tools to communicate identities and experiences, and using pronouns supports a campus environment where all community members can thrive. Please update your gender pronouns in Duke Hub. You can learn more at the Center for Sexual and Gender Diversity’s website.\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website, sta310-sp24.netlify.app\nAnnouncements will be sent through Canvas and email. Please check your email regularly to ensure you have the latest announcements for the course.\n\n\nWhere to get help\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours1 to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the course Slack. There is a chance another student has already asked a similar question, so please check the other posts on Slack before adding a new question. If you know the answer to a question posted on Slack, I encourage you to respond!\n\nCheck out the Support page for more resources.\n\n\nEmail\nIf there is a question that’s not appropriate for Slack, please email directly with “STA 310” in the subject line. Barring extenuating circumstances, I will respond to STA 310 emails within 48 hours Monday - Thursday. Response time may be slower for emails received Friday - Sunday."
  },
  {
    "objectID": "syllabus.html#activities-assessment",
    "href": "syllabus.html#activities-assessment",
    "title": "Syllabus",
    "section": "Activities & Assessment",
    "text": "Activities & Assessment\nThe activities and assessments in this course are designed to help you successfully achieve the course learning objectives. Each activity and assessment is part of the prepare, practice, perform cycle for each topic.\n\nPrepare: Includes reading assignments and occasional videos to introduce new concepts and ensure a basic comprehension of the material.\nPractice: Includes in-class activities and application exercises to explore the topics new topics in more depth. These activities will be completed during lecture. As they are intended for practice, they will not be graded.\nPerform: Includes homework, quizzes, and the projects. These assignments are an opportunity for you to demonstrate your understanding of the course material and how it is applied to the analysis of real-world data.\n\n\nReadings\nThere will be reading assignments to accompany each topic. Readings will primarily come from the course textbook Beyond Multiple Linear Regression, but they may periodically include articles and other resources. It is strongly recommended that you complete the readings before lectures, so you have an introduction to the topic before class.\n\n\nLectures\nLectures will be interactive with a mix of presenting lecture notes, short in-class activities, and application exercises. The activities and application exercises will give you an opportunity to explore concepts in more depth and get practice applying them to real-world data.\n\n\nHomework\nThere will be 6 homework assignments during the semester. In these assignments, you will apply what you’ve learned as you answer conceptual questions and complete guided and open-ended analyses. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Homework will be submitted in your private GitHub repo.\nThe lowest homework grade is dropped.\n\n\nQuizzes\nThere will be 6 quizzes during the semester. Quizzes will cover the readings, lecture notes and activities, and any assignments since the previous quiz.\nThe lowest quiz grade is dropped.\n\n\nProjects\nThere will be 2 short group projects and 1 final individual project in this course. Teams will be randomly assigned for each of the mini projects. More details about each project will be available as they are assigned."
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n40%\n\n\nProject 01\n10%\n\n\nProject 02\n10%\n\n\nFinal project\n20%\n\n\nQuizzes\n20%\n\n\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n&gt;= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n&lt; 60\n\n\n\nThese are upper bounds for grade cutoffs, depending on the class performance the cutoffs may be lowered but they won’t be increased."
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nAcademic honesty\nBy participating in this course, you agree to abide by the following when completing assignments:\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what’s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the teaching assistants.\nYou may not discuss or otherwise work with others on quizzes. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved.\nFor the projects collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project across teams.\nReusing code: Unless explicitly stated otherwise, you may make use of online resources (e.g. StackOverflow) for coding examples on assignments. If you directly use code from an outside source (or use it as inspiration), you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nUse of artificial intelligence (AI): You should treat AI tools, such as ChatGPT, the same as other online resources. There are two guiding principles that govern how you can use AI in this course:2 (1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning. (2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\nAI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. You may use these guidelines for citing AI-generated content.\nNo AI tools for narrative: Unless instructed otherwise, AI is not permitted for writing narrative on assignments. In general, you may use AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content.\n\n\nIf you are unsure if the use of a particular resource complies with the academic honesty policy, please ask me or a teaching assistant.\nRegardless of course delivery format, it is the responsibility of all students to understand and follow all Duke policies, including academic integrity (e.g., completing one’s own work, following proper citation of sources, adhering to guidance around group work projects,and more). Ignoring these requirements is a violation of the Duke Community Standard. Any questions and/or concerns regarding academic integrity can be directed to the Office of Student Conduct and Community Standards at conduct@duke.edu.\nAny violations in academic honesty standards as outlined in the Duke Community Standard and those specific to this course will automatically result in a 0 for the assignment and will be reported to the Office of Student Conduct for further action.\n\n\nLate work & extensions\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback within a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline.\n\nHomework will be accepted up to 48 hours after the deadline. There will be a 5% deduction for each 24-hour period the assignment is late.\nNo late work is accepted on quizzes, and there are no makeups for missed quizzes.\nLate policy for the projects:\n\nPresentation: Late presentations are not accepted and there are no make ups for missed presentations.\nWrite up: GitHub repositories will be closed to contributions at the deadline. If you need to submit your work late, please send me a message via Slack or email to reopen your repository. There will be a 5% deduction for write ups submitted late but the same day (by 11:59pm). There will be a 10% deduction for write ups submitted the next day (by 11:59pm). There will be a 15% deduction for write ups submitted two days late (by 11:59pm). No credit given for write ups submitted more than 2 days after the deadline.\nPeer evaluation: No late work is accepted on peer evaluations. If you do not turn in your peer evaluation, you get 0 points for your own peer score as well, regardless of how your teammates have evaluated you. There are no make ups for peer evaluations.\n\n\n\n\nLate waiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a homework assignment by the deadline, you may email me before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used for once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let me know if you need help contacting your academic dean.\n\n\nRegrade requests\nRegrade requests must be submitted via email to me within a week of when an assignment is returned. Regrade requests will only be considered if points were tallied incorrectly or a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. If a regrade request is submitted, the entire question will be regraded, so your score could increase, decrease, or remain unchanged.\n\n\nAttendance\nYou are expected to attend all lectures and labs with a fully-charged laptop or tablet with access to RStudio. We understand there may be times when you are unable to attend a class meeting; in such instances it is your responsibility to make up the missed material. Labs will primarily be used to work on homework and the projects. If you miss a lab meeting dedicated to group work, please communicate with your teammates to make a plan to contribute to the assignment. Click here for more information on the Trinity attendance policies.\n\n\nAttendance Policy Related to COVID Symptoms, Exposure, or Infection\nStudent health, safety, and well-being are the university’s top priorities. To help ensure your well-being and the well-being of those around you, please do not come to class if you have tested positive for COVID-19 or have possible symptoms and have not yet been tested. If any of these situations apply to you, you must follow university guidance related to the ongoing COVID-19 pandemic and current health and safety protocols. If you are experiencing any COVID-19 symptoms, contact student health (dshcheckin@duke.edu, 919-681-9355). Learn more about current university policy related to COVID-19 at coronavirus.duke.edu.\nTo keep the university community as safe and healthy as possible, you will be expected to follow these guidelines. Please reach out to me and your academic dean as soon as possible if you need to quarantine or isolate so that we can discuss arrangements for your continued participation in class."
  },
  {
    "objectID": "syllabus.html#accommodations",
    "href": "syllabus.html#accommodations",
    "title": "Syllabus",
    "section": "Accommodations",
    "text": "Accommodations\n\nAcademic accommodations\nIf you are a student with a disability and need accommodations for this class, it is your responsibility to register with the Student Disability Access Office (SDAO) and provide them with documentation of your disability. SDAO will work with you to determine what accommodations are appropriate for your situation. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu.\n\n\nReligious accommodations\nStudents are permitted by university policy to be absent from class to observe a religious holiday. Accordingly, Trinity College of Arts & Sciences and the Pratt School of Engineering have established procedures to be followed by students for notifying their instructors of an absence necessitated by the observance of a religious holiday. Please submit requests for religious accommodations at the beginning of the semester so that we can work to make suitable arrangements well ahead of time. You can find the policy and relevant notification form here: trinity.duke.edu/undergraduate/academic-policies/religious-holidays"
  },
  {
    "objectID": "syllabus.html#additional-support",
    "href": "syllabus.html#additional-support",
    "title": "Syllabus",
    "section": "Additional support",
    "text": "Additional support\n\nAcademic Resource Center\nThe Academic Resource Center (the ARC) offers services to support students academically during their undergraduate careers at Duke. The ARC can provide support with time management, academic skills and strategies, unique learning styles, peer tutoring, learning consultations, learning communities, and more. ARC services are available free to any Duke undergraduate student, in any year, studying in any discipline.\nContact ARC@duke.edu, 919-684-5917.\n\n\nMental health and wellness resources\nStudent mental health and wellness is of primary importance at Duke, and the university offers resources to support students in managing daily stress and self-care. Duke offers several resources for students to seek assistance on coursework and to nurture daily habits that support overall well-being, some of which are listed below\n\nDuWell: (919) 681-8421, provides Moments of Mindfulness (stress management and resilience building) and Koru (meditation) programming to assist students in developing a daily emotional well-being practice. Click here to see schedules for programs please see. All are welcome and no experience necessary. duwell@studentaffairs.duke.edu, or studentaffairs.duke.edu/duwell\n\nIf your mental health concerns and/or stressful events negatively affect your daily emotional state, academic performance, or ability to participate in your daily activities, many resources are available to help you through difficult times. Duke encourages all students to access these resources.\n\nDukeReach: Provides comprehensive outreach services to identify and support students in managing all aspects of well-being. If you have concerns about a student’s behavior or health visit the website for resources and assistance. studentaffairs.duke.edu/dukereach\nCounseling and Psychological Services (CAPS): CAPS services include individual, group, and couples counseling services, health coaching, psychiatric services, and workshops and discussions. CAPS also provides referral to off-campus resources for specialized care. (919) 660-1000. studentaffairs.duke.edu/caps\nBlue Devils Care: A convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling. bluedevilscare.duke.edu\nTwo-Click Support: Duke Student Government and DukeReach partnership that connects students to help in just two clicks. bit.ly/TwoClickSupport\n\n\n\nTechnology Accommodations\nStudents with demonstrated high financial need who have limited access to computers may request assistance in the form of loaner laptops. For new Spring 2024 technology assistance requests, please go here. Please note that supplies are limited.\nSee the Support page for a more comprehensive list of academic and mental health wellness resources."
  },
  {
    "objectID": "syllabus.html#important-dates",
    "href": "syllabus.html#important-dates",
    "title": "Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nJan 10: Classes begin\nJan 15: Martin Luther King, Jr. Holiday - No classes\nJan 24: Drop/add ends\nMar 11 - 15: Spring break - No classes\nMar 27 :Last day to withdraw with W\nApr 24: LDOC\nApr 25 - 28: Reading period\nApr 19 - May 04: Final exams\n\nClick here for the full academic calendar."
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "Syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOffice hours are times the teaching team set aside each week to meet with students. Click here to learn more about how to effectively use office hours.↩︎"
  },
  {
    "objectID": "stats-experience.html",
    "href": "stats-experience.html",
    "title": "Statistics Experience",
    "section": "",
    "text": "The world of statistics and data science is vast and continually growing! The goal of the statistics experience assignments is to help you engage with the statistics and data science communities outside of the classroom.\nYou may submit the statistics experience assignment anytime between now and the deadline.\nEach experience has two parts:\n1️⃣ Have a statistics experience.\n2️⃣ Make a slide reflecting on your experience.\nYou must complete both parts to receive credit. The statistics experience will count as a homework grade."
  },
  {
    "objectID": "stats-experience.html#part-1-experience-statistics-outside-of-the-classroom",
    "href": "stats-experience.html#part-1-experience-statistics-outside-of-the-classroom",
    "title": "Statistics Experience",
    "section": "Part 1: Experience statistics outside of the classroom",
    "text": "Part 1: Experience statistics outside of the classroom\nComplete an activity in one of the categories below. Under each category are suggested activities. You do not have to do one these suggested activities. You are welcome to find other activities as long as they are related to statistics/data science and they fit in one of the six categories. If there is an activity you’d like to do but you’re not sure if it qualifies for the statistics experience, just ask!\n\nCategory 1: Attend a talk or conference\nAttend an talk, panel, or conference related to statistics or data science. If you are attending a single talk or panel, it must be at least 30 minutes to count towards the statistics experience. The event can be in-person or online.\n\n\nCategory 2: Talk with a statistician/ data scientist\nTalk with someone who uses statistics in their daily work. This could include a professor, professional in industry, graduate student, etc.\n\n\nCategory 3: Listen to a podcast / watch video\nListen to a podcast or watch a video about statistics and data science. The podcast or video must be at least 30 minutes to count towards the statistics experience. A few suggestions are below:\n\nStats + Stories Podcast\nCausal Inference Podcast\nFiveThirtyEight Model Talk\nrstudio::conf talks\n\n2022 conference\n2021 conference\n2020 conference\n\n\nThis list is not exhaustive. You may listen to other podcasts or watch other statistics/data science videos not included on this list. Ask Professor Tackett if you are unsure whether a particular podcast or video will count towards the statistics experience.\n\n\nCategory 4: Participate in a data science competition or challenge\nParticipate in a statistics or data science competition. You can participate individually or with a team.\n\n\nCategory 5: Read a book on statistics/data science\nThere are a lot of books about statistics, data science, and related topics. A few suggestions are below. If you decide to read a book that isn’t on this list, ask Professor Tackett to make sure it counts toward the experience. Many of these books are available through Duke library.\n\nWeapons of Math Destruction by Cathy O’Neil\nHow Charts Lie: Getting Smarter about Visual Information by Alberto Cairo\nThe Theory that Would Not Die by Sharon Bertsch McGrayne\nThe Art of Statistics: How to learn from data by David Spiegelhalter\nThe Signal and the Noise: Why so many predictions fail - but some don’t by Nate Silver\nList of books about data science ethics\n\nThis list is not exhaustive.\n\n\nCategory 6: TidyTuesday\nYou may also participate in a TidyTuesday challenge. New data sets are announced on Monday afternoons.You can find more information about TidyTuesday and see the data in the TidyTuesday GitHub repo.\nA few guidelines:\n✅ Create a GitHub repo for your TidyTuesday submission. Your repo should include\n\nThe R Markdown file with all the code needed to reproduce your visualization.\nA README that includes an image of your final visualization and a short summary (~ 1 paragraph) about your visualization.\n\n✅ The visualization should include features or customization that are beyond what we’ve done in class .\n✅ Include the link to your GitHub repo in the slide summarizing your experience.\n\n\nCategory 7: CURV - connecting, uplifting, and recognizing voices\nCURV is a project by Dr. Jo Hardin at Pomona College to highlight statisticians and data scientists from groups who have been historically marginalized in the discipline. We will highlight some of the scholars in the CURV data base through the “Statistician of the Day” during lecture each week.\nThere are two options for this statistics experience:\n1️⃣. Present the Statistician of the Day. Learn about one of the scholars in the CURV data base and present what you learn in class.\nA few guidelines:\n\nLet Professor Tackett know at least one week in advance of when you’d like to present a Statistician of the Day. They will take place at the beginning of lectures on Mondays.\nCreate 1 - 2 slides about the scholar.\nPresent at the beginning of lecture for both lectures. If you are unable to attend the beginning of both lectures, you can present in-person during your lecture period and provide a short video for the other lecture period.\n\n2️⃣ Contribute to the CURV data base. If there is a scholar you would like to suggest for the data base, submit your suggestion as an issue or pull request on the CURV GitHub repo and create a sample CURV page.\nA few guidelines:\n✅ Create a draft of the CURV page for your suggested scholar. For reference, click here for the CURV page for W.E.B. Du Bois. The page must be created in a Quarto document.\n\n\n\n\n\n\nTip\n\n\n\nYou can find the Quarto documents for current scholars in the data base in the CURV GitHub repo. You can use one of these as a template to format your page.\n\n\n✅ Make a pull request to the CURV GitHub repo to add the .qmd file for your suggested scholar, OR open an issue with a link to the .qmd file for your suggested scholar. You can ask a member of the teaching team if you have questions about how to do this.\n✅ Include the URL to your pull request or issue in your one-slide reflection."
  },
  {
    "objectID": "stats-experience.html#part-2-reflect-on-your-experience",
    "href": "stats-experience.html#part-2-reflect-on-your-experience",
    "title": "Statistics Experience",
    "section": "Part 2: Reflect on your experience",
    "text": "Part 2: Reflect on your experience\nMake one slide summarizing and reflecting on your experience. Submit the slide as a PDF on Gradescope.\nInclude the following on your slide:\n\nName and brief description of the event/podcast/competition/etc.\nSomething you found new, interesting, or unexpected\nHow the event/podcast/competition/etc. connects to something we’ve done in class.\nCitation or link to web page for event/competition/etc.\n\nClick here to see a template to help you get started on your slide. Your slide does not have to follow this exact format; it just needs to include the information mentioned above and be easily readable (i.e. use a reasonable font size!). Creativity is encouraged!"
  },
  {
    "objectID": "stats-experience.html#submission",
    "href": "stats-experience.html#submission",
    "title": "Statistics Experience",
    "section": "Submission",
    "text": "Submission\nSubmit the reflection as a PDF under the Statistics Experience assignment on Gradescope by Mon, Nov 20 at 11:59pm. Standard homework late policy applies."
  },
  {
    "objectID": "computing.html",
    "href": "computing.html",
    "title": "Computing",
    "section": "",
    "text": "You will need access to R/ RStudio and git for this course. There are two options to access the software:"
  },
  {
    "objectID": "computing.html#step-1-install-rrstudio-and-git",
    "href": "computing.html#step-1-install-rrstudio-and-git",
    "title": "Computing",
    "section": "Step 1: Install R/RStudio and git",
    "text": "Step 1: Install R/RStudio and git\nYou can install R/RStudio on your local machine and configure it to work with git and GitHub. The text Happy Git and GitHub for the useR is a great resource for working with RStudio and git. The steps are outlined below. Click on each link for more detail.\n\nInstall R and RStudio Desktop: posit.co/download/rstudio-desktop\n\nI recommend installing the desktop version not the preview release of RStudio\n\nInstall git: happygitwithr.com/install-git"
  },
  {
    "objectID": "computing.html#step-2-install-r-packages",
    "href": "computing.html#step-2-install-r-packages",
    "title": "Computing",
    "section": "Step 2: Install R packages",
    "text": "Step 2: Install R packages\nBelow is a set of R packages we will use throughout the semester. This list is just to get you started; we will let you know as new R packages are required.\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"knitr\")\ninstall.packages(\"lme4\")\ninstall.packages(\"tidymodels\")\ninstall.packages(\"usethis\")\ninstall.packages(\"credentials\")"
  },
  {
    "objectID": "computing.html#step-3-install-quarto",
    "href": "computing.html#step-3-install-quarto",
    "title": "Computing",
    "section": "Step 3: Install Quarto",
    "text": "Step 3: Install Quarto\nWe will use Quarto (similar to R Markdown) to write up analyses. Download and install Quarto at quarto.org/docs/get-started"
  },
  {
    "objectID": "computing.html#step-4-set-up-git-authentication",
    "href": "computing.html#step-4-set-up-git-authentication",
    "title": "Computing",
    "section": "Step 4: Set up git authentication",
    "text": "Step 4: Set up git authentication\nYou will authenticate GitHub using SSH.\n\nType credentials::ssh_setup_github() into your console.\nR will ask “No SSH key found. Generate one now?” Click 1 for yes.\nYou will generate a key. It will begin with “ssh-rsa….” R will then ask “Would you like to open a browser now?” Click 1 for yes.\nYou may be asked to provide your username and password to log into GitHub. This would be the ones associated with your account that you set up. After entering this information, paste the key in and give it a name. You might name it in a way that indicates where the key will be used, e.g., sta310)\n\nYou can find more detailed instructions here if you’re interested."
  },
  {
    "objectID": "computing.html#step-5-configure-git",
    "href": "computing.html#step-5-configure-git",
    "title": "Computing",
    "section": "Step 5: Configure git",
    "text": "Step 5: Configure git\nWe need to configure your git so that RStudio can communicate with GitHub. This requires two pieces of information: your name and email address.\nTo do so, you will use the use_git_config() function from the usethis package.\nType the following lines of code in the console in RStudio filling in your name and the email address associated with your GitHub account.\n\nusethis::use_git_config(\n  user.name = \"Your name\", \n  user.email = \"Email associated with your GitHub account\")\n\nFor example, mine would be\n\nusethis::use_git_config(\n  user.name = \"Maria Tackett\",\n  user.email = \"maria.tackett@duke.edu\")\n\nYou are now ready to conduct reproducible data analyses!"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#announcements",
    "href": "slides/06-poisson-pt3.html#announcements",
    "title": "Poisson Regression",
    "section": "Announcements",
    "text": "Announcements\n\nQuiz 01 on Canvas due Thu, Feb 01 at noon\nHW 02 due Wed, Feb 07 at 11:59pm (grace period until Thu, Feb 08 noon)\n\nReleased tomorrow morning\n\nThis week’s lab: Project 01 article evaluation"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#topics",
    "href": "slides/06-poisson-pt3.html#topics",
    "title": "Poisson Regression",
    "section": "Topics",
    "text": "Topics\n\nOffset in Poisson regression\nZero-inflated Poisson regression"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#data-airbnbs-in-nyc",
    "href": "slides/06-poisson-pt3.html#data-airbnbs-in-nyc",
    "title": "Poisson Regression",
    "section": "Data: Airbnbs in NYC",
    "text": "Data: Airbnbs in NYC\nThe data set NYCairbnb-sample.csv contains information about a random sample of 1000 Airbnbs in New York City. It is a subset of the data on 40628 Airbnbs scraped by Awad, Lebo, and Linden (2017).1\nVariables\n\nnumber_of_reviews: Number of reviews for the unit on Airbnb (proxy for number of rentals)\nprice: price per night in US dollars\nroom_type: Entire home/apartment, private room, or shared room\ndays: Number of days the unit has been listed (date when info scraped - date when unit first listed on Airbnb)\n\nGoal: Use the price and room type of Airbnbs to describe variation in the number of reviews (a proxy for number of rentals).\nData set pulled from BMLR Section 4.11."
  },
  {
    "objectID": "slides/06-poisson-pt3.html#data-airbnbs-in-nyc-1",
    "href": "slides/06-poisson-pt3.html#data-airbnbs-in-nyc-1",
    "title": "Poisson Regression",
    "section": "Data: Airbnbs in NYC",
    "text": "Data: Airbnbs in NYC\n\nairbnb &lt;- read_csv(\"data/NYCairbnb-sample.csv\") \n\n\n\n\n\n\n\n\nid\nnumber_of_reviews\ndays\nroom_type\nprice\n\n\n\n\n15756544\n16\n1144\nPrivate room\n120\n\n\n14218251\n15\n471\nPrivate room\n89\n\n\n21644\n0\n2600\nPrivate room\n89\n\n\n13667835\n1\n283\nEntire home/apt\n150\n\n\n265912\n0\n1970\nEntire home/apt\n89"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#eda",
    "href": "slides/06-poisson-pt3.html#eda",
    "title": "Poisson Regression",
    "section": "EDA",
    "text": "EDA"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#eda-1",
    "href": "slides/06-poisson-pt3.html#eda-1",
    "title": "Poisson Regression",
    "section": "EDA",
    "text": "EDA\n\n\n\nOverall\n\n\n\n\n\n\nmean\nvar\n\n\n\n\n15.916\n765.969\n\n\n\n\n\n\n\nby room type\n\n\n\n\n\n\nroom_type\nmean\nvar\n\n\n\n\nEntire home/apt\n16.283\n760.348\n\n\nPrivate room\n15.608\n786.399\n\n\nShared room\n15.028\n605.971"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#considerations-for-modeling",
    "href": "slides/06-poisson-pt3.html#considerations-for-modeling",
    "title": "Poisson Regression",
    "section": "Considerations for modeling",
    "text": "Considerations for modeling\nWe would like to fit the Poisson regression model\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1 ~ price_i + \\beta_2 ~ room\\_type1_i + \\beta_3 ~ room\\_type2_i\\]\n\n\n\nBased on the EDA, what are some potential issues we may want to address in the model building?\nSuppose any model fit issues are addressed. What are some potential limitations to the conclusions and interpretations from the model?\n\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#offset-1",
    "href": "slides/06-poisson-pt3.html#offset-1",
    "title": "Poisson Regression",
    "section": "Offset",
    "text": "Offset\n\nSometimes counts are not directly comparable because the observations differ based on some characteristic directly related to the counts, i.e. the sampling effort.\nAn offset can be used to adjust for differences in sampling effort.\n\n\n\nLet \\(x_{offset}\\) be the variable that accounts for differences in sampling effort, then \\(\\log(x_{offset})\\) will be added to the model.\n\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1 ~ x_{i1} + \\beta_2 ~ x_{i2} + ... + \\beta_p ~ x_{ip} + \\log(x_{offset_i})\\]\n\nThe offset is a term in the model with coefficient always equal to 1."
  },
  {
    "objectID": "slides/06-poisson-pt3.html#adding-an-offset-to-the-airbnb-model",
    "href": "slides/06-poisson-pt3.html#adding-an-offset-to-the-airbnb-model",
    "title": "Poisson Regression",
    "section": "Adding an offset to the Airbnb model",
    "text": "Adding an offset to the Airbnb model\nWe will add the offset \\(\\log(days)\\) to the model. This accounts for the fact that we would expect Airbnbs that have been listed longer to have more reviews.\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1 ~ price_i + \\beta_2 ~ room\\_type1_i + \\beta_3 ~ room\\_type2_i + \\log(days_i)\\] \nNote: The response variable for the model is still \\(\\log(\\lambda_i)\\), the log mean number of reviews"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#detail-on-the-offset",
    "href": "slides/06-poisson-pt3.html#detail-on-the-offset",
    "title": "Poisson Regression",
    "section": "Detail on the offset",
    "text": "Detail on the offset\nWe want to adjust for the number of days, so we are interested in \\(\\frac{reviews}{days}\\).\n\nGiven \\(\\lambda\\) is the mean number of reviews\n\\[\\log\\Big(\\frac{\\lambda_i}{days_i}\\Big) = \\beta_0 + \\beta_1 ~ price_i + \\beta_2 ~ room\\_type1_i + \\beta_3 ~ room\\_type2_i\\]\n\n\n\n\\[\\Rightarrow \\log({\\lambda_i}) - \\log(days_i) = \\beta_0 + \\beta_1 ~ price_i + \\beta_2 ~ room\\_type1_i + \\beta_3 ~ room\\_type2_i\\]\n\n\n\n\\[\\Rightarrow \\log({\\lambda_i}) = \\beta_0 + \\beta_1 ~ price_i + \\beta_2 ~ room\\_type1_i + \\beta_3 ~ room\\_type2_i + \\log(days_i)\\]"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#airbnb-model-in-r",
    "href": "slides/06-poisson-pt3.html#airbnb-model-in-r",
    "title": "Poisson Regression",
    "section": "Airbnb model in R",
    "text": "Airbnb model in R\n\nairbnb_model &lt;- glm(number_of_reviews ~ price + room_type, \n                    data = airbnb, family = poisson, \n                    offset = log(days)) \n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-4.1351\n0.0170\n-243.1397\n0\n\n\nprice\n-0.0005\n0.0001\n-7.0952\n0\n\n\nroom_typePrivate room\n-0.0994\n0.0174\n-5.6986\n0\n\n\nroom_typeShared room\n0.2436\n0.0452\n5.3841\n0\n\n\n\n\n\n\n\nThe coefficient for \\(\\log(days)\\) is fixed at 1, so it is not in the model output."
  },
  {
    "objectID": "slides/06-poisson-pt3.html#interpretations",
    "href": "slides/06-poisson-pt3.html#interpretations",
    "title": "Poisson Regression",
    "section": "Interpretations",
    "text": "Interpretations\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-4.1351\n0.0170\n-243.1397\n0\n\n\nprice\n-0.0005\n0.0001\n-7.0952\n0\n\n\nroom_typePrivate room\n-0.0994\n0.0174\n-5.6986\n0\n\n\nroom_typeShared room\n0.2436\n0.0452\n5.3841\n0\n\n\n\n\n\n\n\n\nInterpret the coefficient of price\nInterpret the coefficient of room_typePrivate room\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#quasi-poisson-model",
    "href": "slides/06-poisson-pt3.html#quasi-poisson-model",
    "title": "Poisson Regression",
    "section": "Quasi-Poisson model",
    "text": "Quasi-Poisson model\n\nairbnb_model_q &lt;- glm(number_of_reviews ~ price + room_type, \n                    data = airbnb, family = quasipoisson, \n                    offset = log(days)) \n\nsummary(airbnb_model_q)\n\n\nCall:\nglm(formula = number_of_reviews ~ price + room_type, family = quasipoisson, \n    data = airbnb, offset = log(days))\n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           -4.1350727  0.1159506 -35.662   &lt;2e-16 ***\nprice                 -0.0004914  0.0004722  -1.041    0.298    \nroom_typePrivate room -0.0993582  0.1188728  -0.836    0.403    \nroom_typeShared room   0.2435939  0.3084581   0.790    0.430    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 46.48268)\n\n    Null deviance: 31550  on 999  degrees of freedom\nResidual deviance: 31379  on 996  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 6"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#quasi-poisson-model-1",
    "href": "slides/06-poisson-pt3.html#quasi-poisson-model-1",
    "title": "Poisson Regression",
    "section": "Quasi-Poisson model",
    "text": "Quasi-Poisson model\n\ntidy(airbnb_model_q) |&gt;\n  kable(digits = 4)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-4.1351\n0.1160\n-35.6624\n0.0000\n\n\nprice\n-0.0005\n0.0005\n-1.0407\n0.2983\n\n\nroom_typePrivate room\n-0.0994\n0.1189\n-0.8358\n0.4034\n\n\nroom_typeShared room\n0.2436\n0.3085\n0.7897\n0.4299"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#data-weekend-drinking",
    "href": "slides/06-poisson-pt3.html#data-weekend-drinking",
    "title": "Poisson Regression",
    "section": "Data: Weekend drinking",
    "text": "Data: Weekend drinking\nThe data weekend-drinks.csv contains information from a survey of 77 students in a introductory statistics course on a dry campus.1\nVariables\n\ndrinks: Number of drinks they had in the past weekend\noff_campus: 1 - lives off campus, 0 otherwise\nfirst_year: 1 - student is a first-year, 0 otherwise\nsex: f - student identifies as female, m - student identifies as male\n\nGoal: The goal is explore factors related to drinking behavior on a dry campus.\nData from case study in BMLR Section 4.10."
  },
  {
    "objectID": "slides/06-poisson-pt3.html#eda-response-variable",
    "href": "slides/06-poisson-pt3.html#eda-response-variable",
    "title": "Poisson Regression",
    "section": "EDA: Response variable",
    "text": "EDA: Response variable\n\n\n\n\n\n\nmean\nvar\n\n\n\n\n2.013\n10.75"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#observed-vs.-expected-response",
    "href": "slides/06-poisson-pt3.html#observed-vs.-expected-response",
    "title": "Poisson Regression",
    "section": "Observed vs. expected response",
    "text": "Observed vs. expected response\n\n\n\nWhat does it mean to be a “zero” in this data?"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#two-types-of-zeros",
    "href": "slides/06-poisson-pt3.html#two-types-of-zeros",
    "title": "Poisson Regression",
    "section": "Two types of zeros",
    "text": "Two types of zeros\nThere are two types of zeros\n\nThose who happen to have a zero in the data set (people who drink but happened to not drink last weekend)\nThose who will always report a value of zero (non-drinkers)\n\nThese are called true zeros\n\n\n\nWe introduce a new parameter \\(\\alpha\\) for the proportion of true zeros, then fit a model that has two components:\n\n\n1️⃣ The association between mean number of drinks and various characteristics among those who drink\n2️⃣ The estimated proportion of non-drinkers"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#zero-inflated-poisson-model-1",
    "href": "slides/06-poisson-pt3.html#zero-inflated-poisson-model-1",
    "title": "Poisson Regression",
    "section": "Zero-inflated Poisson model",
    "text": "Zero-inflated Poisson model\nZero-inflated Poisson (ZIP) model has two parts\n1️⃣ Association, among those who drink, between the mean number of drinks and predictors sex and off campus residence\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1 ~ off\\_campus_i + \\beta_2 ~ sex_i\\] where \\(\\lambda\\) is the mean number of drinks among those who drink\n\n2️⃣ Probability that a student does not drink\n\\[\\text{logit}(\\alpha_i) = \\log\\Big(\\frac{\\alpha_i}{1- \\alpha_i}\\Big) = \\beta_0 + \\beta_1 ~ first\\_year_i\\]\nwhere \\(\\alpha\\) is the proportion of non-drinkers\n\n\nNote: The same variables can be used in each component"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#details-of-the-zip-model",
    "href": "slides/06-poisson-pt3.html#details-of-the-zip-model",
    "title": "Poisson Regression",
    "section": "Details of the ZIP model",
    "text": "Details of the ZIP model\n\nThe ZIP model is a special case of a latent variable model\n\nA type of mixture model where observations for one or more groups occur together but the group membership unknown\n\nZero-inflated models are a common type of mixture model; they apply beyond Poisson regression"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#zip-model-in-r",
    "href": "slides/06-poisson-pt3.html#zip-model-in-r",
    "title": "Poisson Regression",
    "section": "ZIP model in R",
    "text": "ZIP model in R\nFit ZIP models using the zeroinfl function from the pscl R package.\n\nlibrary(pscl)\n\ndrinks_zip &lt;- zeroinfl(drinks ~ off_campus + sex | first_year,\n                data = drinks)\ndrinks_zip\n\n\nCall:\nzeroinfl(formula = drinks ~ off_campus + sex | first_year, data = drinks)\n\nCount model coefficients (poisson with log link):\n(Intercept)   off_campus         sexm  \n     0.7543       0.4159       1.0209  \n\nZero-inflation model coefficients (binomial with logit link):\n(Intercept)   first_year  \n    -0.6036       1.1364"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#tidy-output",
    "href": "slides/06-poisson-pt3.html#tidy-output",
    "title": "Poisson Regression",
    "section": "Tidy output",
    "text": "Tidy output\nUse the tidy function from the poissonreg package for tidy model output.\n\nlibrary(poissonreg)\n\n\n\nMean number of drinks among those who drink\n\ntidy(drinks_zip, type = \"count\") |&gt; kable(digits = 3)\n\n\n\n\nterm\ntype\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\ncount\n0.754\n0.144\n5.238\n0.000\n\n\noff_campus\ncount\n0.416\n0.206\n2.020\n0.043\n\n\nsexm\ncount\n1.021\n0.175\n5.827\n0.000"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#tidy-output-1",
    "href": "slides/06-poisson-pt3.html#tidy-output-1",
    "title": "Poisson Regression",
    "section": "Tidy output",
    "text": "Tidy output\nProportion of non-drinkers\n\ntidy(drinks_zip, type = \"zero\") |&gt; kable(digits = 3)\n\n\n\n\nterm\ntype\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\nzero\n-0.604\n0.311\n-1.938\n0.053\n\n\nfirst_year\nzero\n1.136\n0.610\n1.864\n0.062"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#interpreting-the-model-coefficients",
    "href": "slides/06-poisson-pt3.html#interpreting-the-model-coefficients",
    "title": "Poisson Regression",
    "section": "Interpreting the model coefficients",
    "text": "Interpreting the model coefficients\n\n\n\n\n\nterm\ntype\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\ncount\n0.754\n0.144\n5.238\n0.000\n\n\noff_campus\ncount\n0.416\n0.206\n2.020\n0.043\n\n\nsexm\ncount\n1.021\n0.175\n5.827\n0.000\n\n\n\n\n\n\n\n\nInterpret the intercept.\nInterpret the coefficients off_campus and sexm.\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#estimated-proportion-zeros",
    "href": "slides/06-poisson-pt3.html#estimated-proportion-zeros",
    "title": "Poisson Regression",
    "section": "Estimated proportion zeros",
    "text": "Estimated proportion zeros\n\n\n\n\n\nterm\ntype\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\nzero\n-0.604\n0.311\n-1.938\n0.053\n\n\nfirst_year\nzero\n1.136\n0.610\n1.864\n0.062\n\n\n\n\n\n\nBased on the model…\n\nWhat is the probability a first-year student is a non-drinker?\nWhat is the probability a upperclass student (sophomore, junior, senior) is a non-drinker?\n\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#comparing-poisson-and-zip-models",
    "href": "slides/06-poisson-pt3.html#comparing-poisson-and-zip-models",
    "title": "Poisson Regression",
    "section": "Comparing Poisson and ZIP Models",
    "text": "Comparing Poisson and ZIP Models\n\nSuppose we want to compare our ZIP model to a Poisson model \\(\\log(\\lambda_i) = \\beta_0 + \\beta_1 ~ off_campus_i + \\beta_2 ~ sex_i\\)\n\nWhich of the following methods can we use to compare these models?\n\nAIC\nBIC\nLikelihood ratio test"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#probabilities-under-zip-model",
    "href": "slides/06-poisson-pt3.html#probabilities-under-zip-model",
    "title": "Poisson Regression",
    "section": "Probabilities under ZIP model",
    "text": "Probabilities under ZIP model\nThere are three different types of observations in the data:\n\nObserved 0 and will always be 0 (true zeros)\nObserved 0 but will not always be 0\nObserved non-zero count and will not always be 0"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#probabilities-under-zip-model-1",
    "href": "slides/06-poisson-pt3.html#probabilities-under-zip-model-1",
    "title": "Poisson Regression",
    "section": "Probabilities under ZIP model",
    "text": "Probabilities under ZIP model\nTrue zeros \\[P(0 | \\text{true zero})= \\alpha\\]\n\nObserved 0 but will not always be 0\n\\[P(0 | \\text{not always zero}) = (1 - \\alpha)\\frac{e^{-\\lambda}\\lambda^0}{0!}\\]\n\n\nDid not observe 0 and will not always be 0\n\\[P(z_i | \\text{not always zero}) = (1 - \\alpha)\\frac{e^{-\\lambda}\\lambda^{z_i}}{z_i!}\\]"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#probabilities-under-zip-model-2",
    "href": "slides/06-poisson-pt3.html#probabilities-under-zip-model-2",
    "title": "Poisson Regression",
    "section": "Probabilities under ZIP model",
    "text": "Probabilities under ZIP model\nPutting this all together. Let \\(y_i\\) be an observed response then\n\\[P(Y_i = y_i) = \\begin{cases}\n\\alpha_i + (1 - \\alpha_i)e^{-\\lambda_i} && \\text{ if } y_i = 0 \\\\\n(1 - \\alpha_i)\\frac{e^{-\\lambda_i}\\lambda_i^{y_i}}{y_i!} && \\text{ if } y_i &gt; 0\n\\end{cases}\\]\n\nRecall from our example,\n\\[\\lambda_i = e^{\\beta_0 + \\beta_1~off\\_campus_i + \\beta_2 ~ sex_i}\\]\n\\[\\alpha_i = \\frac{e^{\\beta_{0\\alpha} + \\beta_{1\\alpha} ~ first\\_year_i}}{1 + e^{\\beta_{0\\alpha} + \\beta_{1\\alpha} ~ first\\_year_i}}\\]\nPlug in \\(\\lambda_i\\) and \\(\\alpha_i\\) into the above equation obtain the likelihood function"
  },
  {
    "objectID": "slides/06-poisson-pt3.html#references",
    "href": "slides/06-poisson-pt3.html#references",
    "title": "Poisson Regression",
    "section": "References",
    "text": "References\n\n\n\n🔗 STA 310 - Spring 2024\n\n\n\nAwad, Annika, Evan Lebo, and Anna Linden. 2017. “Intercontinental Comparative Analysis of Airbnb Booking Factors.”"
  },
  {
    "objectID": "slides/03-likelihoods.html#announcements",
    "href": "slides/03-likelihoods.html#announcements",
    "title": "Inference review +  using likelihoods",
    "section": "Announcements",
    "text": "Announcements\n\nHW 01 due Thursday at 6am\n\nYour access to the repo will be removed at the deadline. If you wish to submit the HW late, please email me and I will extend your access to the repo.\nYou will have access to your HW repo again when grades are returned."
  },
  {
    "objectID": "slides/03-likelihoods.html#computing-set-up",
    "href": "slides/03-likelihoods.html#computing-set-up",
    "title": "Inference review +  using likelihoods",
    "section": "Computing set up",
    "text": "Computing set up\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)\n\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\ncolors &lt;- tibble::tibble(green = \"#B5BA72\")"
  },
  {
    "objectID": "slides/03-likelihoods.html#topics",
    "href": "slides/03-likelihoods.html#topics",
    "title": "Inference review +  using likelihoods",
    "section": "Topics",
    "text": "Topics\n\nReview inference for multiple linear regression\nUsing likelihoods\n\n\n\nNotes based on Chapter 1 and 2 of Roback and Legler (2021) unless noted otherwise."
  },
  {
    "objectID": "slides/03-likelihoods.html#data-kentucky-derby-winners",
    "href": "slides/03-likelihoods.html#data-kentucky-derby-winners",
    "title": "Inference review +  using likelihoods",
    "section": "Data: Kentucky Derby Winners",
    "text": "Data: Kentucky Derby Winners\nToday’s data is from the Kentucky Derby, an annual 1.25-mile horse race held at the Churchill Downs race track in Louisville, KY. The data is in the file derbyplus.csv and contains information for races 1896 - 2017.\n\n\nResponse variable\n\nspeed: Average speed of the winner in feet per second (ft/s)\n\nAdditional variable\n\nwinner: Winning horse\n\n\nPredictor variables\n\nyear: Year of the race\ncondition: Condition of the track (good, fast, slow)\nstarters: Number of horses who raced\n\n\n\nGoal: Understand variability in average winner speed based on characteristics of the race."
  },
  {
    "objectID": "slides/03-likelihoods.html#data",
    "href": "slides/03-likelihoods.html#data",
    "title": "Inference review +  using likelihoods",
    "section": "Data",
    "text": "Data\n\nderby &lt;- read_csv(\"data/derbyplus.csv\")\n\n\nderby |&gt;\n  head(5) |&gt; kable()\n\n\n\n\nyear\nwinner\ncondition\nspeed\nstarters\n\n\n\n\n1896\nBen Brush\ngood\n51.66\n8\n\n\n1897\nTyphoon II\nslow\n49.81\n6\n\n\n1898\nPlaudit\ngood\n51.16\n4\n\n\n1899\nManuel\nfast\n50.00\n5\n\n\n1900\nLieut. Gibson\nfast\n52.28\n7"
  },
  {
    "objectID": "slides/03-likelihoods.html#candidate-models",
    "href": "slides/03-likelihoods.html#candidate-models",
    "title": "Inference review +  using likelihoods",
    "section": "Candidate models",
    "text": "Candidate models\nModel 1: Main effects model (year, condition, starters)\n\nmodel1 &lt;- lm(speed ~ starters + year + condition, data = derby)\n\n\n\nModel 2: Main effects + \\(year^2\\), the quadratic effect of year\n\nmodel2 &lt;- lm(speed ~ starters + year + I(year^2) + condition,\n             data = derby)\n\n\n\n\nModel 3: Main effects + interaction between year and condition\n\nmodel3 &lt;- lm(speed ~ starters + year + condition + year * condition, \n             data = derby)"
  },
  {
    "objectID": "slides/03-likelihoods.html#inference-for-regression",
    "href": "slides/03-likelihoods.html#inference-for-regression",
    "title": "Inference review +  using likelihoods",
    "section": "Inference for regression",
    "text": "Inference for regression\nUse statistical inference to\n\nEvaluate if predictors are statistically significant (not necessarily practically significant!)\nQuantify uncertainty in coefficient estimates\nQuantify uncertainty in model predictions\n\nIf LINE assumptions are met, we can use inferential methods based on mathematical models. If at least linearity and independence are met, we can use simulation-based inference methods."
  },
  {
    "objectID": "slides/03-likelihoods.html#inference-for-regression-1",
    "href": "slides/03-likelihoods.html#inference-for-regression-1",
    "title": "Inference review +  using likelihoods",
    "section": "Inference for regression",
    "text": "Inference for regression\nWhen LINE assumptions are met… . . .\n\n\nUse least squares regression to obtain the estimates for the model coefficients \\(\\beta_0, \\beta_1, \\ldots, \\beta_j\\) and for \\(\\sigma^2\\)\n\\(\\hat{\\sigma}\\) is the regression standard error\n\\[\n\\hat{\\sigma} = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n - p - 1}} = \\sqrt{\\frac{\\sum_{i=1}^n e_i^2}{n-p-1}}\n\\]\nwhere \\(p\\) is the number of non-intercept terms in the model (e.g., \\(p = 1\\) in simple linear regression)\nGoal is to use estimated values to draw conclusions about \\(\\beta_j\\)\n\nUse \\(\\hat{\\sigma}\\) to calculate \\(SE_{\\hat{\\beta}_j}\\) . Click here for more detail."
  },
  {
    "objectID": "slides/03-likelihoods.html#hypothesis-testing-for-beta_j",
    "href": "slides/03-likelihoods.html#hypothesis-testing-for-beta_j",
    "title": "Inference review +  using likelihoods",
    "section": "Hypothesis testing for \\(\\beta_j\\)",
    "text": "Hypothesis testing for \\(\\beta_j\\)\n\nState the hypotheses. \\(H_0: \\beta_j = 0 \\text{ vs. } H_a: \\beta_j \\neq 0\\), given the other variables in the model.\n\n\n\nCalculate the test statistic.\n\n\\[\nt = \\frac{\\hat{\\beta}_j - 0}{SE_{\\hat{\\beta}_j}}\n\\]\n\n\nCalculate the p-value. The p-value is calculated from a \\(t\\) distribution with \\(n - p - 1\\) degrees of freedom.\n\\[\n\\text{p-value} = 2P(T &gt; |t|) \\hspace{8mm} T \\sim t_{n-p-1}\n\\]\n\n\n\nState the conclusion in context of the data.\n\nReject \\(H_0\\) if p-value is sufficiently small."
  },
  {
    "objectID": "slides/03-likelihoods.html#confidence-interval-for-beta_j",
    "href": "slides/03-likelihoods.html#confidence-interval-for-beta_j",
    "title": "Inference review +  using likelihoods",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\nThe \\(C\\%\\) confidence confidence interval for \\(\\beta_j\\) is\n\\[\\hat{\\beta}_j \\pm t^* \\times SE_{\\hat{\\beta}_j}\\]\nwhere the critical value \\(t^* \\sim t_{n-p-1}\\)\n\n\nGeneral interpretation for the confidence interval [LB, UB]:\nWe are \\(C\\%\\) confident that for every one unit increase in \\(x_j\\), the response is expected to change by LB to UB units, holding all else constant."
  },
  {
    "objectID": "slides/03-likelihoods.html#measures-of-model-performance",
    "href": "slides/03-likelihoods.html#measures-of-model-performance",
    "title": "Inference review +  using likelihoods",
    "section": "Measures of model performance",
    "text": "Measures of model performance\n\n\\(R^2\\): Proportion of variability in the response explained by the model\n\nWill always increase as predictors are added, so it shouldn’t be used to compare models\n\n\\(Adj. R^2\\): Similar to \\(R^2\\) with a penalty for extra terms\n\\(AIC\\): Likelihood-based approach balancing model performance and complexity\n\\(BIC\\): Similar to AIC with stronger penalty for extra terms"
  },
  {
    "objectID": "slides/03-likelihoods.html#model-summary-statistics",
    "href": "slides/03-likelihoods.html#model-summary-statistics",
    "title": "Inference review +  using likelihoods",
    "section": "Model summary statistics",
    "text": "Model summary statistics\nUse the glance() function to get model summary statistics\n\n\n\n\n\n\nmodel\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\nModel1\n0.730\n0.721\n259.478\n276.302\n\n\nModel2\n0.827\n0.819\n207.429\n227.057\n\n\nModel3\n0.751\n0.738\n253.584\n276.016\n\n\n\n\n\n\n\nWhich model do you choose based on these statistics?"
  },
  {
    "objectID": "slides/03-likelihoods.html#characteristics-of-a-good-final-model",
    "href": "slides/03-likelihoods.html#characteristics-of-a-good-final-model",
    "title": "Inference review +  using likelihoods",
    "section": "Characteristics of a “good” final model",
    "text": "Characteristics of a “good” final model\n\nModel can be used to answer primary research questions\nPredictor variables control for important covariates\nPotential interactions have been investigated\nVariables are centered, as needed, for more meaningful interpretations\nUnnecessary terms are removed\nAssumptions are met and influential points have been addressed\nModel tells a “persuasive story parsimoniously”\n\n\n\nList from Section 1.6.7 of Roback and Legler (2021)"
  },
  {
    "objectID": "slides/03-likelihoods.html#learning-goals",
    "href": "slides/03-likelihoods.html#learning-goals",
    "title": "Inference review +  using likelihoods",
    "section": "Learning goals",
    "text": "Learning goals\n\nDescribe the concept of a likelihood\nConstruct the likelihood for a simple model\nDefine the Maximum Likelihood Estimate (MLE) and use it to answer an analysis question\nIdentify three ways to calculate or approximate the MLE and apply these methods to find the MLE for a simple model"
  },
  {
    "objectID": "slides/03-likelihoods.html#what-is-the-likelihood",
    "href": "slides/03-likelihoods.html#what-is-the-likelihood",
    "title": "Inference review +  using likelihoods",
    "section": "What is the likelihood?",
    "text": "What is the likelihood?\nA likelihood is a function that tells us how likely we are to observe our data for a given parameter value (or values).\n\nUnlike with Ordinary Least Squares (OLS) estimates, they do not require the responses be independent, identically distributed, and normal\nThey are not the same as probability functions"
  },
  {
    "objectID": "slides/03-likelihoods.html#probability-function-vs.-likelihood",
    "href": "slides/03-likelihoods.html#probability-function-vs.-likelihood",
    "title": "Inference review +  using likelihoods",
    "section": "Probability function vs. likelihood",
    "text": "Probability function vs. likelihood\n\n\nProbability function: Fixed parameter value(s) + input possible outcomes \\(\\Rightarrow\\) probability of seeing the different outcomes given the parameter value(s)\nLikelihood: Fixed data + input possible parameter values \\(\\Rightarrow\\) probability of seeing the fixed data for each parameter value"
  },
  {
    "objectID": "slides/03-likelihoods.html#data-fouls-in-college-basketball-games",
    "href": "slides/03-likelihoods.html#data-fouls-in-college-basketball-games",
    "title": "Inference review +  using likelihoods",
    "section": "Data: Fouls in college basketball games",
    "text": "Data: Fouls in college basketball games\nThe data set 04-refs.csv includes 30 randomly selected NCAA men’s basketball games played in the 2009 - 2010 season.1\nWe will focus on the variables foul1, foul2, and foul3, which indicate which team had a foul called them for the 1st, 2nd, and 3rd fouls, respectively.\n\nH: Foul was called on the home team\nV: Foul was called on the visiting team\n\nWe are focusing on the first three fouls for this analysis, but this could easily be extended to include all fouls in a game.\nThe dataset was derived from basektball0910.csv used in BMLR Section 11.2"
  },
  {
    "objectID": "slides/03-likelihoods.html#fouls-in-college-basketball-games",
    "href": "slides/03-likelihoods.html#fouls-in-college-basketball-games",
    "title": "Inference review +  using likelihoods",
    "section": "Fouls in college basketball games",
    "text": "Fouls in college basketball games\n\nrefs &lt;- read_csv(\"data/04-refs.csv\")\nrefs |&gt; slice(1:5) |&gt; kable()\n\n\n\n\ngame\ndate\nvisitor\nhometeam\nfoul1\nfoul2\nfoul3\n\n\n\n\n166\n20100126\nCLEM\nBC\nV\nV\nV\n\n\n224\n20100224\nDEPAUL\nCIN\nH\nH\nV\n\n\n317\n20100109\nMARQET\nNOVA\nH\nH\nH\n\n\n214\n20100228\nMARQET\nSETON\nV\nV\nH\n\n\n278\n20100128\nSETON\nSFL\nH\nV\nV\n\n\n\n\n\nWe will treat the games as independent in this analysis."
  },
  {
    "objectID": "slides/03-likelihoods.html#different-likelihood-models",
    "href": "slides/03-likelihoods.html#different-likelihood-models",
    "title": "Inference review +  using likelihoods",
    "section": "Different likelihood models",
    "text": "Different likelihood models\nModel 1 (Unconditional Model):\n\nWhat is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?\n\n\nModel 2 (Conditional Model):\n\nIs there a tendency for the referees to call more fouls on the visiting team or home team?\nIs there a tendency for referees to call a foul on the team that already has more fouls?\n\n\n\nUltimately we want to decide which model is better."
  },
  {
    "objectID": "slides/03-likelihoods.html#exploratory-data-analysis",
    "href": "slides/03-likelihoods.html#exploratory-data-analysis",
    "title": "Inference review +  using likelihoods",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\n\nrefs |&gt;\ncount(foul1, foul2, foul3) |&gt; kable()\n\n\n\n\nfoul1\nfoul2\nfoul3\nn\n\n\n\n\nH\nH\nH\n3\n\n\nH\nH\nV\n2\n\n\nH\nV\nH\n3\n\n\nH\nV\nV\n7\n\n\nV\nH\nH\n7\n\n\nV\nH\nV\n1\n\n\nV\nV\nH\n5\n\n\nV\nV\nV\n2\n\n\n\n\n\n\nThere are\n\n46 total fouls on the home team\n44 total fouls on the visiting team"
  },
  {
    "objectID": "slides/03-likelihoods.html#likelihood",
    "href": "slides/03-likelihoods.html#likelihood",
    "title": "Inference review +  using likelihoods",
    "section": "Likelihood",
    "text": "Likelihood\nLet \\(p_H\\) be the probability the referees call a foul on the home team. The likelihood for a single observation \\[Lik(p_H) = p_H^{y_i}(1 - p_H)^{n_i - y_i}\\]Where \\(y_i\\) is the number of fouls called on the home team. (In this example, we know \\(n_i = 3\\) for all observations.)\n\nExample\nFor a single game where the first three fouls are \\(H, H, V\\), then \\[Lik(p_H) = p_H^{2}(1 - p_H)^{3 - 2} = p_H^{2}(1 - p_H)\\]"
  },
  {
    "objectID": "slides/03-likelihoods.html#model-1-likelihood-contribution",
    "href": "slides/03-likelihoods.html#model-1-likelihood-contribution",
    "title": "Inference review +  using likelihoods",
    "section": "Model 1: Likelihood contribution",
    "text": "Model 1: Likelihood contribution\n\n\n\nFoul 1\nFoul 2\nFoul 3\nn\nLikelihood contribution\n\n\n\n\nH\nH\nH\n3\n\\(p_H^3\\)\n\n\nH\nH\nV\n2\n\\(p_H^2(1 - p_H)\\)\n\n\nH\nV\nH\n3\n\\(p_H^2(1 - p_H)\\)\n\n\nH\nV\nV\n7\nA\n\n\nV\nH\nH\n7\nB\n\n\nV\nH\nV\n1\n\\(p_H(1 - p_H)^2\\)\n\n\nV\nV\nH\n5\n\\(p_H(1 - p_H)^2\\)\n\n\nV\nV\nV\n2\n\\((1 - p_H)^3\\)\n\n\n\n\nFill in A and B.\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/03-likelihoods.html#model-1-likelihood-function",
    "href": "slides/03-likelihoods.html#model-1-likelihood-function",
    "title": "Inference review +  using likelihoods",
    "section": "Model 1: Likelihood function",
    "text": "Model 1: Likelihood function\nBecause the observations (the games) are independent, the likelihood is\n\\[Lik(p_H) = \\prod_{i=1}^{n}p_H^{y_i}(1 - p_H)^{3 - y_i}\\]\n\nWe will use this function to find the maximum likelihood estimate (MLE). The MLE is the value between 0 and 1 where we are most likely to see the observed data."
  },
  {
    "objectID": "slides/03-likelihoods.html#visualizing-the-likelihood",
    "href": "slides/03-likelihoods.html#visualizing-the-likelihood",
    "title": "Inference review +  using likelihoods",
    "section": "Visualizing the likelihood",
    "text": "Visualizing the likelihood\n\n\n\n\n\n\n\n\n\n\n\n\n\np &lt;- seq(0,1, length.out = 100) #sequence of 100 values between 0 and 100\nlik &lt;- p^46 *(1 -p)^44\nx &lt;- tibble(p = p, lik = lik)\nggplot(data = x, aes(x = p, y = lik)) + \n  geom_point() + \n  geom_line() +\n  labs(y = \"Likelihood\",\n       title = \"Likelihood of p_H\")"
  },
  {
    "objectID": "slides/03-likelihoods.html#finding-the-maximum-likelihood-estimate",
    "href": "slides/03-likelihoods.html#finding-the-maximum-likelihood-estimate",
    "title": "Inference review +  using likelihoods",
    "section": "Finding the maximum likelihood estimate",
    "text": "Finding the maximum likelihood estimate\nThere are three primary ways to find the MLE\n✅ Approximate using a graph\n✅ Numerical approximation\n✅ Using calculus"
  },
  {
    "objectID": "slides/03-likelihoods.html#approximate-mle-from-a-graph",
    "href": "slides/03-likelihoods.html#approximate-mle-from-a-graph",
    "title": "Inference review +  using likelihoods",
    "section": "Approximate MLE from a graph",
    "text": "Approximate MLE from a graph"
  },
  {
    "objectID": "slides/03-likelihoods.html#mle-using-numerical-approximation",
    "href": "slides/03-likelihoods.html#mle-using-numerical-approximation",
    "title": "Inference review +  using likelihoods",
    "section": "MLE using numerical approximation",
    "text": "MLE using numerical approximation\nSpecify a finite set of possible values the for \\(p_H\\) and calculate the likelihood for each value\n\n\n# write an R function for the likelihood\nref_lik &lt;- function(ph) {\n  ph^46 *(1 - ph)^44\n}\n\n# search possible values for p and return max\nnGrid = 1000\nph &lt;- seq(0, 1, length = nGrid)\nlik &lt;- ref_lik(ph)\nph[lik == max(lik)]\n\n[1] 0.5115115"
  },
  {
    "objectID": "slides/03-likelihoods.html#find-mle-using-calculus",
    "href": "slides/03-likelihoods.html#find-mle-using-calculus",
    "title": "Inference review +  using likelihoods",
    "section": "Find MLE using calculus",
    "text": "Find MLE using calculus\n\nFind the MLE by taking the first derivative of the likelihood function.\nThis can be tricky because of the Product Rule, so we can maximize the log(Likelihood) instead. The same value maximizes the likelihood and log(Likelihood)"
  },
  {
    "objectID": "slides/03-likelihoods.html#find-mle-using-calculus-1",
    "href": "slides/03-likelihoods.html#find-mle-using-calculus-1",
    "title": "Inference review +  using likelihoods",
    "section": "Find MLE using calculus",
    "text": "Find MLE using calculus\n\\[Lik(p_H) = \\prod_{i=1}^{n}p_H^{y_i}(1 - p_H)^{3 - y_i}\\]\n\n\\[\n\\begin{aligned}\\log(Lik(p_H)) &= \\sum_{i=1}^{n}y_i\\log(p_H) + (3 - y_i)\\log(1 - p_H)\\\\[10pt] &= 46\\log(p_H) + 44\\log(1 - p_H)\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/03-likelihoods.html#find-mle-using-calculus-2",
    "href": "slides/03-likelihoods.html#find-mle-using-calculus-2",
    "title": "Inference review +  using likelihoods",
    "section": "Find MLE using calculus",
    "text": "Find MLE using calculus\n\\[\\frac{d}{d p_H} \\log(Lik(p_H)) = \\frac{46}{p_H} - \\frac{44}{1-p_H} = 0\\]\n\n\\[\\Rightarrow \\frac{46}{p_H} = \\frac{44}{1-p_H}\\]\n\n\n\\[\\Rightarrow 46(1-p_H) = 44p_H\\]\n\n\n\\[\\Rightarrow 46 = 90p_H\\]\n\n\n\\[\n\\hat{p}_H = \\frac{46}{90} = 0.511\n\\]\n\n\n\n😐"
  },
  {
    "objectID": "slides/03-likelihoods.html#model-2-conditional-model-1",
    "href": "slides/03-likelihoods.html#model-2-conditional-model-1",
    "title": "Inference review +  using likelihoods",
    "section": "Model 2: Conditional model",
    "text": "Model 2: Conditional model\nNow let’s assume fouls are not independent within each game. We will specify this dependence using conditional probabilities.\n\nConditional probability: \\(P(A|B) =\\) Probability of \\(A\\) given \\(B\\) has occurred\n\n\nDefine new parameters:\n\n\n\\(p_{H|N}\\): Probability referees call foul on home team given there are equal numbers of fouls on the home and visiting teams\n\\(p_{H|H Bias}\\): Probability referees call foul on home team given there are more prior fouls on the home team\n\\(p_{H|V Bias}\\): Probability referees call foul on home team given there are more prior fouls on the visiting team"
  },
  {
    "objectID": "slides/03-likelihoods.html#model-2-likelihood-contributions",
    "href": "slides/03-likelihoods.html#model-2-likelihood-contributions",
    "title": "Inference review +  using likelihoods",
    "section": "Model 2: Likelihood contributions",
    "text": "Model 2: Likelihood contributions\n\n\n\n\n\n\n\n\n\n\nFoul 1\nFoul 2\nFoul 3\nn\nLikelihood contribution\n\n\n\n\nH\nH\nH\n3\n\\((p_{H\\vert N})(p_{H\\vert H Bias})(p_{H\\vert H Bias}) = (p_{H\\vert N})(p_{H\\vert H Bias})^2\\)\n\n\nH\nH\nV\n2\n\\((p_{H\\vert N})(p_{H\\vert H Bias})(1-p_{H\\vert H Bias})\\)\n\n\nH\nV\nH\n3\n\\((p_{H\\vert N})(1 - p_{H \\vert HBias})(p_{H \\vert N}) = (p_{H \\vert N})^2(1 - p_{H \\vert HBias})\\)\n\n\nH\nV\nV\n7\nA\n\n\nV\nH\nH\n7\nB\n\n\nV\nH\nV\n1\n\\((1 - p_{H\\vert N})(p_{H\\vert V Bias})(1 - p_{H\\vert N}) = (1 - p_{H\\vert N})^2(p_{H\\vert V Bias})\\)\n\n\nV\nV\nH\n5\n\\((1 - p_{H\\vert N})(1-p_{H\\vert V Bias})(p_{H\\vert V Bias})\\)\n\n\nV\nV\nV\n2\n\\(\\begin{aligned}&(1 - p_{H\\vert N})(1-p_{H\\vert V Bias})(1-p_{H\\vert V Bias})\\\\ &=(1 - p_{H\\vert N})(1-p_{H\\vert V Bias})^2\\end{aligned}\\)"
  },
  {
    "objectID": "slides/03-likelihoods.html#likelihood-function",
    "href": "slides/03-likelihoods.html#likelihood-function",
    "title": "Inference review +  using likelihoods",
    "section": "Likelihood function",
    "text": "Likelihood function\n\\[\\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\\\ &(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\\end{aligned}\\]\n(Note: The exponents sum to 90, the total number of fouls in the data)\n\n\n\\[\\begin{aligned}\\log (Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias})) &= 25 \\log(p_{H| N}) + 23 \\log(1 - p_{H|N}) \\\\ & + 8 \\log(p_{H| H Bias}) + 12 \\log(1 - p_{H| H Bias})\\\\ &+ 13 \\log(p_{H| V Bias}) + 9 \\log(1-p_{H|V Bias})\\end{aligned}\\]"
  },
  {
    "objectID": "slides/03-likelihoods.html#mles-for-model-2",
    "href": "slides/03-likelihoods.html#mles-for-model-2",
    "title": "Inference review +  using likelihoods",
    "section": "MLEs for Model 2",
    "text": "MLEs for Model 2\nClick here for details on finding MLEs for Model2."
  },
  {
    "objectID": "slides/03-likelihoods.html#next-time",
    "href": "slides/03-likelihoods.html#next-time",
    "title": "Inference review +  using likelihoods",
    "section": "Next time",
    "text": "Next time\n\nPoisson regression"
  },
  {
    "objectID": "slides/03-likelihoods.html#references",
    "href": "slides/03-likelihoods.html#references",
    "title": "Inference review +  using likelihoods",
    "section": "References",
    "text": "References\n\n\n\n🔗 STA 310 - Spring 2024\n\n\n\nRoback, Paul, and Julie Legler. 2021. Beyond multiple linear regression: applied generalized linear models and multilevel models in R. CRC Press."
  },
  {
    "objectID": "slides/03-model2-mle.html",
    "href": "slides/03-model2-mle.html",
    "title": "Finding the MLEs for Model 2",
    "section": "",
    "text": "This document covers multiple ways to find the MLE for Model 2 the conditional model from Lecture 03: Using likelihoods. See the lecture notes for more details about the set up of the model.\nlibrary(tidyverse)\nrefs &lt;- read_csv(\"data/04-refs.csv\")\nThe likelihood is\n\\[\\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\\\ &(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\\end{aligned}\\]\nThe log-likelihood is\n\\[\\begin{aligned}\\log (Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias})) &= 25 \\log(p_{H| N}) + 23 \\log(1 - p_{H|N}) \\\\ & + 8 \\log(p_{H| H Bias}) + 12 \\log(1 - p_{H| H Bias})\\\\ &+ 13 \\log(p_{H| V Bias}) + 9 \\log(1-p_{H|V Bias})\\end{aligned}\\]\nWe would like to find the MLEs for \\(p_{H| N}, p_{H|H Bias}, \\text{ and }p_{H |V Bias}\\)."
  },
  {
    "objectID": "slides/03-model2-mle.html#finding-mles-using-graphs",
    "href": "slides/03-model2-mle.html#finding-mles-using-graphs",
    "title": "Finding the MLEs for Model 2",
    "section": "Finding MLEs using graphs",
    "text": "Finding MLEs using graphs\nWe need to find the MLEs for three parameters, therefore we would need to visualize a 4-dimensional object to find the MLEs from a graph. Given the difficulty of this task and the lack of precision in the estimates from this approach, we should rely on other approaches to find the MLEs in this instance."
  },
  {
    "objectID": "slides/03-model2-mle.html#finding-mles-using-calculus",
    "href": "slides/03-model2-mle.html#finding-mles-using-calculus",
    "title": "Finding the MLEs for Model 2",
    "section": "Finding MLEs using calculus",
    "text": "Finding MLEs using calculus\nWe can find the MLE for each parameter using the partial derivative of the log-likelihood with respect to each parameter.\nTo find the MLE for \\(p_{H| N}\\):\n\\[\\begin{aligned}\\frac{\\partial \\log(Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}))}{\\partial p_{H|N}} &= \\frac{25}{p_{H|N}} - \\frac{23}{1 - p_{H|N}} = 0\\\\[5pt]\n&\\Rightarrow \\frac{25}{p_{H|N}} = \\frac{23}{1 - p_{H|N}} \\\\[5pt]\n&\\Rightarrow 23p_{H|N} = 25(1 - p_{H|N}) \\\\[5pt]\n&\\Rightarrow 48p_{H|N} = 25 \\\\[5pt]\n&\\Rightarrow \\hat{p}_{H|N} = \\frac{25}{48} = 0.521\\end{aligned}\\]\nWe can use a similar approach to find the MLEs for \\(p_{H|H Bias}\\) and \\(p_{H|V Bias}\\).\n\\[\\hat{p}_{H|H Bias} = \\frac{8}{20} = 0.4\\] \\[\\hat{p}_{H|V Bias} = \\frac{13}{22} = 0.591\\]"
  },
  {
    "objectID": "slides/03-model2-mle.html#finding-the-mles-using-r",
    "href": "slides/03-model2-mle.html#finding-the-mles-using-r",
    "title": "Finding the MLEs for Model 2",
    "section": "Finding the MLEs using R",
    "text": "Finding the MLEs using R\nWe can write a function and do a grid search to find the values that maximize the log-likelihood.\n\nmaxloglik&lt;- function(nvals){\n  #nvals specifies the number of values\n  phn &lt;- seq(0, 1, length = nvals)\n  phh &lt;- seq(0, 1, length = nvals)\n  phv &lt;- seq(0, 1, length = nvals)\n  \n  loglik &lt;- expand.grid(phn, phh, phv) \n  colnames(loglik) &lt;- c(\"phn\", \"phh\", \"phv\")\n  \n  loglik &lt;- loglik %&gt;%\n    mutate(loglik  = log(phn^25 * (1 - phn)^23 * phh^8 * (1 - phh)^12 * \n                           phv^13 * (1 - phv)^9))\n  \n  loglik %&gt;%\n    arrange(desc(loglik)) %&gt;%\n    slice(1)\n}\n\n\nmaxloglik(100)\n\n        phn       phh       phv    loglik\n1 0.5252525 0.4040404 0.5858586 -61.57691\n\n\nDepending on the number of parameters, it may be hard to conduct a granular enough search to find the exact values of the MLEs. Therefore, one could use the function above to conduct a crude search to find starting values for R’s optim function. The function optim differs from optimize in that it can optimize over multiple parameter values (The optimize function can only optimize over a single parameter value).\n\n# Function to calculate log-likelihood that will be used in the optim function\nloglik &lt;- function(params){\n  phn &lt;- params[1]\n  phh &lt;- params[2]\n  phv &lt;- params[3]\n\n  log(phn^25 * (1 - phn)^23 * phh^8 * (1 - phh)^12 * \n                           phv^13 * (1 - phv)^9)\n}\n\n\n# use manual search to get starting values \nstart_vals &lt;- maxloglik(50) %&gt;% select(-loglik)\n\n\n# Use optim function in R to find the values to maximize the log-likelihood\n#set fnscale = -1 to maximize (the default is minimize)\noptim(par = start_vals, fn = loglik, control=list(fnscale=-1))\n\n$par\n      phn       phh       phv \n0.5208272 0.4000361 0.5909793 \n\n$value\n[1] -61.57319\n\n$counts\nfunction gradient \n      66       NA \n\n$convergence\n[1] 0\n\n$message\nNULL"
  },
  {
    "objectID": "slides/lab-01.html#meet-your-ta",
    "href": "slides/lab-01.html#meet-your-ta",
    "title": "Welcome to STA 310 Labs!",
    "section": "Meet your TA!",
    "text": "Meet your TA!"
  },
  {
    "objectID": "slides/lab-01.html#what-to-expect-in-lab",
    "href": "slides/lab-01.html#what-to-expect-in-lab",
    "title": "Welcome to STA 310 Labs!",
    "section": "What to expect in lab",
    "text": "What to expect in lab\n\nIntroduction to the week’s lab\nAnswer questions about lectures and cover additional content, as needed\nWork on homework or projects"
  },
  {
    "objectID": "slides/lab-01.html#lecture-02-ae",
    "href": "slides/lab-01.html#lecture-02-ae",
    "title": "Welcome to STA 310 Labs!",
    "section": "Lecture 02 AE",
    "text": "Lecture 02 AE\n\nOpen the Lecture 02 AE from yesterday’s class.\nAre there any questions about Exercises 1 - 5?\nWe will go over Exercises 6 - 8 about Model 3 today. You will do Part 2 in Monday’s lecture."
  },
  {
    "objectID": "slides/lab-01.html#icebreaker",
    "href": "slides/lab-01.html#icebreaker",
    "title": "Welcome to STA 310 Labs!",
    "section": "Icebreaker",
    "text": "Icebreaker\n\n\nGet into groups of 3 - 5.\nIntroduce yourself if you haven’t met\nChoose a reporter\n\nNeed help choosing? Person with birthday closest to today’s date.\n\nIdentify 8 things everyone in the group has in common\n\nNot being a Duke student\nNot clothes (e.g., we’re all wearing socks)\nNot body parts (e.g., we all have a nose)\n\nReporter will share list with the class.\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/lab-01.html#todays-lab",
    "href": "slides/lab-01.html#todays-lab",
    "title": "Welcome to STA 310 Labs!",
    "section": "Today’s lab",
    "text": "Today’s lab\nThe rest of the today’s lab is focused on working on HW 01. You are encouraged to discuss homework with each other but everyone must turn in their own assignment. See the syllabus for policy on homework collaboration.\n\n🔗 sta310-sp24.netlify.app/hw/hw-01\n\n\n\n🔗 STA 310 - Spring 2024"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 310: Generalized Linear Models",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\n\n  \n    \n    \n      week\n      dow\n      date\n      topic\n      prepare\n      lectures\n      ae\n      hw\n      quiz\n      project\n      notes\n    \n  \n  \n    1\nW\nJan 10\nWelcome\n\n\n\n\n\n\n\n    \nTh\nJan 11\nNo lab: Labs start 1/18\n\n\n\n\n\n\n\n    2\nM\nJan 15\nNo lecture: Martin Luther King Jr. Day\n\n\n\n\n\n\n\n    \nW\nJan 17\nReview: Multiple linear regression\n\n\n\n\n\n\n\n    \nTh\nJan 18\nLab 01: Welcome + HW 01\n\n\n\n\n\n\n\n    3\nM\nJan 22\nInference review + Using likelihoods\n\n\n\n\n\n\n\n    \nW\nJan 24\nComparing models using likelihoods\n\n\n\n\n\n\nHW 01 due\n    \n\n\nPoisson regression\n\n\n\n\n\n\n\n    \nTh\nJan 25\nLab: Start Project 01\n\n\n\n\n\n\n\n    4\nM\nJan 29\nPoisson: Goodness of fit + overdispersion\n\n\n\n\n\n\n\n    \nW\nJan 31\nPoisson: offset + ZIP models\n\n\n\n\n\n\n\n    \nTh\nFeb 1\nLab: Project 01 Article Evaluation\n\n\n\n\n\n\nQuiz 01 due at 12pm\n    5\nM\nFeb 5\nUnifying framework for GLMs\n\n\n\n\n\n\n\n    \nW\nFeb 7\nLogistic regression\n\n\n\n\n\n\nHW 02 due\n    \nTh\nFeb 8\nLab: Project 01 Write up + Presentation\n\n\n\n\n\n\n\n    6\nM\nFeb 12\nBinomial + ordinal regression\n\n\n\n\n\n\n\n    \nW\nFeb 14\nProject 01 presentations\n\n\n\n\n\n\n\n    \nTh\nFeb 15\n\n\n\n\n\n\n\n\n    7\nM\nFeb 19\nModeling correlated observations\n\n\n\n\n\n\n\n    \nW\nFeb 21\nFixed + random effects\n\n\n\n\n\n\n\n    \nTh\nFeb 22\n\n\n\n\n\n\n\nQuiz 02 due at 12pm\n    8\nM\nFeb 26\nFixed + random effects\n\n\n\n\n\n\n\n    \nW\nFeb 27\nMultilevel models\n\n\n\n\n\n\nHW 03 due\n    \nTh\nFeb 28\n\n\n\n\n\n\n\n\n    9\nM\nMar 4\nMultilevel models cont'd\n\n\n\n\n\n\n\n    \nW\nMar 6\nMultilevel models cont'd\n\n\n\n\n\n\n\n    \nTh\nMar 7\n\n\n\n\n\n\n\nQuiz 03 due at 12pm\n    10\nM\nMar 11\nNo lecture: Spring break!\n\n\n\n\n\n\n\n    \nW\nMar 13\nNo lecture: Spring break!\n\n\n\n\n\n\n\n    \nTh\nMar 14\nNo lab: Spring break!\n\n\n\n\n\n\n\n    11\nM\nMar 18\nModeling longitudinal data\n\n\n\n\n\n\n\n    \nW\nMar 20\nModeling longitudinal data cont'd\n\n\n\n\n\n\nHW 04 due\n    \nTh\nMar 21\n\n\n\n\n\n\n\n\n    12\nM\nMar 25\nModeling longitudinal data cont'd\n\n\n\n\n\n\n\n    \nW\nMar 27\nProject 02 presentations\n\n\n\n\n\n\n\n    \nTh\nMar 28\n\n\n\n\n\n\n\nQuiz 04 due at 12pm\n    13\nM\nApr 1\nMultilevel models with 3+ levels\n\n\n\n\n\n\n\n    \nW\nApr 3\nMultilevel models with 3+ levels\n\n\n\n\n\n\nHW 05 due\n    \nTh\nApr 4\n\n\n\n\n\n\n\n\n    14\nM\nApr 8\nNo lecture\n\n\n\n\n\n\n\n    \nW\nApr 10\nCovariance structures\n\n\n\n\n\n\n\n    \nTh\nApr 11\n\n\n\n\n\n\n\nQuiz 05 due at 12pm\n    15\nM\nApr 15\nMultilevel GLMs\n\n\n\n\n\n\n\n    \nW\nApr 17\nMultilevel GLMs cont'd\n\n\n\n\n\n\nHW 06 due\n    \nTh\nApr 18\n\n\n\n\n\n\n\n\n    16\nM\nApr 22\nMultilevel GLMs cont'd\n\n\n\n\n\n\n\n    \nW\nApr 24\nFinal project meetings\n\n\n\n\n\n\nQuiz 06 due at 12pm\n    Exam period"
  },
  {
    "objectID": "projects/project-02.html",
    "href": "projects/project-02.html",
    "title": "Project 02",
    "section": "",
    "text": "To be posted."
  },
  {
    "objectID": "projects/final-project.html",
    "href": "projects/final-project.html",
    "title": "Final project",
    "section": "",
    "text": "To be posted."
  },
  {
    "objectID": "ae/ae-02-mlr-review.html",
    "href": "ae/ae-02-mlr-review.html",
    "title": "Lecture 02 AE: Review of multiple linear regression",
    "section": "",
    "text": "Today’s data is from the Kentucky Derby, an annual 1.25-mile horse race held at the Churchill Downs race track in Louisville, KY. The data is in the file derbyplus.csv in the data folder. It contains information for races 1896 - 2017.\nResponse variable\n\nspeed: Average speed of the winner in feet per second (ft/s)\n\nAdditional variable\n\nwinner: Winning horse\n\nPredictor variables\n\nyear: Year of the race\ncondition: Condition of the track (good, fast, slow)\nstarters: Number of horses who raced\n\nGoal: Understand variability in average winner speed based on characteristics of the race.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\n\nderby &lt;- read_csv(\"data/derbyplus.csv\")"
  },
  {
    "objectID": "ae/ae-02-mlr-review.html#introduction",
    "href": "ae/ae-02-mlr-review.html#introduction",
    "title": "Lecture 02 AE: Review of multiple linear regression",
    "section": "",
    "text": "Today’s data is from the Kentucky Derby, an annual 1.25-mile horse race held at the Churchill Downs race track in Louisville, KY. The data is in the file derbyplus.csv in the data folder. It contains information for races 1896 - 2017.\nResponse variable\n\nspeed: Average speed of the winner in feet per second (ft/s)\n\nAdditional variable\n\nwinner: Winning horse\n\nPredictor variables\n\nyear: Year of the race\ncondition: Condition of the track (good, fast, slow)\nstarters: Number of horses who raced\n\nGoal: Understand variability in average winner speed based on characteristics of the race.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\n\nderby &lt;- read_csv(\"data/derbyplus.csv\")"
  },
  {
    "objectID": "ae/ae-02-mlr-review.html#model-1-main-effects-model",
    "href": "ae/ae-02-mlr-review.html#model-1-main-effects-model",
    "title": "Lecture 02 AE: Review of multiple linear regression",
    "section": "Model 1: Main effects model",
    "text": "Model 1: Main effects model\n\nmodel1 &lt;- lm(speed ~ starters + year + condition, data = derby)\n\ntidy(model1) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n8.197\n4.508\n1.818\n0.072\n\n\nstarters\n-0.005\n0.017\n-0.299\n0.766\n\n\nyear\n0.023\n0.002\n9.766\n0.000\n\n\nconditiongood\n-0.443\n0.231\n-1.921\n0.057\n\n\nconditionslow\n-1.543\n0.161\n-9.616\n0.000\n\n\n\n\n\n\n\n\n\n\n\nEx 1\n\n\n\nWrite the equation of the fitted model.\n\n\n[add response here]\n\n\n\n\n\n\nEx 2\n\n\n\nInterpret the coefficient of conditionslow in the context of the data.\n\n\n[add response here]\n\n\n\n\n\n\nEx 3\n\n\n\nDoes the intercept have a meaningful interpretation? If so, interpret it. If not…\n\nRefit the model so that the intercept has a meaningful interpretation.\nInterpret the intercept for the new model.\n\n\n\n[add response here]"
  },
  {
    "objectID": "ae/ae-02-mlr-review.html#model-2-main-effects-quadratic-effect-for-year",
    "href": "ae/ae-02-mlr-review.html#model-2-main-effects-quadratic-effect-for-year",
    "title": "Lecture 02 AE: Review of multiple linear regression",
    "section": "Model 2: Main effects + quadratic effect for year",
    "text": "Model 2: Main effects + quadratic effect for year\n\n\n\n\n\n\nEx 4\n\n\n\nFit a model that includes all main effects and a quadratic term for year. Display the model.\n\n\n[add response here]\n\n\n\n\n\n\nInterpreting quadratic effects\n\n\n\nSuppose you have the following model:\n\\[\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~ x_1  + \\hat{\\beta}_2 ~ x_2 + \\hat{\\beta}_3 ~ x_2^2\\]\nThe interpretation of a variable’s effect when there is a quadratic term in the model is\n“When \\(x_2\\) increases from a to b, \\(y\\) is expected to change by \\(\\hat{\\beta}_2(b - a) + \\hat{\\beta}_3(b^2 - a^2)\\), holding \\(x_1\\) constant.”\n\n\n\n\n\n\n\n\nEx 5\n\n\n\nInterpret the effect of year for the 5 most recent years (2013 - 2017).\n\n\n[add response here]"
  },
  {
    "objectID": "ae/ae-02-mlr-review.html#model-3-main-effects-interaction-between-year-and-condition",
    "href": "ae/ae-02-mlr-review.html#model-3-main-effects-interaction-between-year-and-condition",
    "title": "Lecture 02 AE: Review of multiple linear regression",
    "section": "Model 3: Main effects + interaction between year and condition",
    "text": "Model 3: Main effects + interaction between year and condition\n\n\n\n\n\n\nEx 6\n\n\n\nFit a model that includes all main effects and an interaction between year and condition. Do not include a quadratic term for year. Display the model.\n\n\n[add response here]\n\n\n\n\n\n\nEx 7\n\n\n\nInterpret yearnew:conditiongood.\n\n\n[add response here]\n\n\n\n\n\n\nEx 8\n\n\n\nInterpret the effect of year for slow track conditions.\n\n\n[add response here]"
  },
  {
    "objectID": "ae/lec-05-overdisp.html",
    "href": "ae/lec-05-overdisp.html",
    "title": "Lecture 05 AE: Poisson Regression",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)\nlibrary(knitr)\n# add other packages as needed\nhh_data &lt;- read_csv(\"data/fHH1.csv\")"
  },
  {
    "objectID": "ae/lec-05-overdisp.html#household-vs.-age-age2-and-location",
    "href": "ae/lec-05-overdisp.html#household-vs.-age-age2-and-location",
    "title": "Lecture 05 AE: Poisson Regression",
    "section": "Household vs. age, age^2, and location",
    "text": "Household vs. age, age^2, and location\n\nhh_age_loc &lt;- glm(total ~ age + I(age^2) + location, \n                  data = hh_data, family = poisson)\n\ntidy(hh_age_loc, conf.int = T) |&gt; \n  kable(digits = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.3843\n0.1821\n-2.1107\n0.0348\n-0.7444\n-0.0306\n\n\nage\n0.0704\n0.0069\n10.1900\n0.0000\n0.0569\n0.0840\n\n\nI(age^2)\n-0.0007\n0.0001\n-10.9437\n0.0000\n-0.0008\n-0.0006\n\n\nlocationDavaoRegion\n-0.0194\n0.0538\n-0.3605\n0.7185\n-0.1250\n0.0859\n\n\nlocationIlocosRegion\n0.0610\n0.0527\n1.1580\n0.2468\n-0.0423\n0.1641\n\n\nlocationMetroManila\n0.0545\n0.0472\n1.1542\n0.2484\n-0.0378\n0.1473\n\n\nlocationVisayas\n0.1121\n0.0417\n2.6853\n0.0072\n0.0308\n0.1945\n\n\n\n\n\n\n\n\n\n\n\nCalculating residuals in R\n\n\n\nYou can get the residuals in two ways:\n\nresiduals function with type = \"pearson\" or type = \"deviance\".\naugment function with type.residuals = \"pearson\" or type.residuals = deviance."
  },
  {
    "objectID": "ae/lec-05-overdisp.html#calculate-model-deviance-goodness-of-fit",
    "href": "ae/lec-05-overdisp.html#calculate-model-deviance-goodness-of-fit",
    "title": "Lecture 05 AE: Poisson Regression",
    "section": "Calculate model deviance & Goodness-of-fit",
    "text": "Calculate model deviance & Goodness-of-fit\n\n\n\n\n\n\nEx 1\n\n\n\nUse the deviance residuals to calculate the model deviance.\n\n\n\n# Calculate model deviance\n\n\n\n\n\n\n\nEx 2\n\n\n\nCheck your work above using the glance function.\n\n\n\n# Get deviance using glance function\n\n\n\n\n\n\n\nEx 3\n\n\n\nConduct a goodness-of-fit test\n\n\n\n# Conduct goodness-of-fit test"
  },
  {
    "objectID": "ae/lec-05-overdisp.html#quasi-poisson",
    "href": "ae/lec-05-overdisp.html#quasi-poisson",
    "title": "Lecture 05 AE: Poisson Regression",
    "section": "Quasi-Poisson",
    "text": "Quasi-Poisson\n\nhh_age_loc_q &lt;- glm(total ~ age + I(age^2) + location, \n                    data = hh_data, family = quasipoisson)\n\n\n\n\n\n\n\nEx 4\n\n\n\nWhat do we expect the dispersion parameter to be if there is no overdispersion?\n\n\n\n\n\n\n\n\nEx 5\n\n\n\nUse the Pearson residuals to calculate the dispersion parameter.\n\n\n\n# Calculate dispersion parameter \n\n\n\n\n\n\n\nEx 6\n\n\n\nView the dispersion parameter in the model output\n\n\n\n#summary(hh_age_loc_q)"
  },
  {
    "objectID": "ae/lec-05-overdisp.html#negative-binomial-regression-model",
    "href": "ae/lec-05-overdisp.html#negative-binomial-regression-model",
    "title": "Lecture 05 AE: Poisson Regression",
    "section": "Negative binomial regression model",
    "text": "Negative binomial regression model\n\nhh_age_loc_nb &lt;- MASS::glm.nb(total ~ age + I(age^2) + location, data = hh_data)\ntidy(hh_age_loc_nb) |&gt; \n  kable(digits = 4)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.3753\n0.2076\n-1.8081\n0.0706\n\n\nage\n0.0699\n0.0079\n8.8981\n0.0000\n\n\nI(age^2)\n-0.0007\n0.0001\n-9.5756\n0.0000\n\n\nlocationDavaoRegion\n-0.0219\n0.0625\n-0.3501\n0.7262\n\n\nlocationIlocosRegion\n0.0577\n0.0615\n0.9391\n0.3477\n\n\nlocationMetroManila\n0.0562\n0.0551\n1.0213\n0.3071\n\n\nlocationVisayas\n0.1104\n0.0487\n2.2654\n0.0235"
  },
  {
    "objectID": "prepare/feb-07.html",
    "href": "prepare/feb-07.html",
    "title": "Prepare for Feb 07 lecture",
    "section": "",
    "text": "Read BMLR Section 6.1 - 6.7"
  },
  {
    "objectID": "prepare/jan-22.html",
    "href": "prepare/jan-22.html",
    "title": "Prepare for Jan 22 lecture",
    "section": "",
    "text": "Read Beyond Multiple Linear Regression (BMLR): Sections 2.1 - 2.10\nInstall RStudio and configure git or reserve RStudio Docker container. See computing page for instructions.\nIf you have not yet done so, see Canvas announcement for links to…\n\nSign up for Slack\nComplete STA 310 Student Survey"
  },
  {
    "objectID": "prepare/jan-31.html",
    "href": "prepare/jan-31.html",
    "title": "Prepare for Jan 31 lecture",
    "section": "",
    "text": "Read Beyond Multiple Linear Regression (BMLR): Section 4.6, 4.10"
  },
  {
    "objectID": "prepare/jan-17.html",
    "href": "prepare/jan-17.html",
    "title": "Prepare for Jan 17 lecture",
    "section": "",
    "text": "Read Beyond Multiple Linear Regression (BMLR): Sections 1.1 - 1.7\nInstall RStudio and configure git or reserve RStudio Docker container. See computing page for instructions.\nIf you have not yet done so, see Canvas announcement for links to…\n\nSign up for Slack\nComplete STA 310 Student Survey"
  },
  {
    "objectID": "hw/hw-03.html",
    "href": "hw/hw-03.html",
    "title": "HW 03",
    "section": "",
    "text": "To be posted."
  },
  {
    "objectID": "hw/hw-04.html",
    "href": "hw/hw-04.html",
    "title": "HW 04",
    "section": "",
    "text": "To be posted."
  },
  {
    "objectID": "hw/hw-06.html",
    "href": "hw/hw-06.html",
    "title": "HW 06",
    "section": "",
    "text": "To be posted."
  },
  {
    "objectID": "hw/hw-05.html",
    "href": "hw/hw-05.html",
    "title": "HW 05",
    "section": "",
    "text": "To be posted."
  },
  {
    "objectID": "hw/hw-01.html",
    "href": "hw/hw-01.html",
    "title": "HW 01: Multiple linear regression",
    "section": "",
    "text": "Important\n\n\n\n\nThis assignment is due on Wednesday, January 24 at 11:59pm with a grace period (i.e., no late penalty) until Thursday, January 25 at 6am.\n\nYour access to the repo will be removed at the end of the grace period. If you wish to submit the HW late, please email me and I will extend your access to the repo.\nYou will have access to your HW repo again when grades are returned."
  },
  {
    "objectID": "hw/hw-01.html#exercise-1",
    "href": "hw/hw-01.html#exercise-1",
    "title": "HW 01: Multiple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nConsider the following scenario:\n\nResearchers record the number of cricket chirps per minute and temperature during that time. They use linear regression to investigate whether the number of chirps varies with temperature.\n\n\nIdentify the response and predictor variable.\nWrite the complete specification of the statistical model.\nWrite the assumptions for linear regression in the context of the problem."
  },
  {
    "objectID": "hw/hw-01.html#exercise-2",
    "href": "hw/hw-01.html#exercise-2",
    "title": "HW 01: Multiple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nConsider the following scenario:\n\nA randomized clinical trial investigated postnatal depression and the use of an estrogen patch. Patients were randomly assigned to either use the patch or not. Depression scores were recorded on 6 different visits.\n\n\nIdentify the response and predictor variables.\nIdentify which model assumption(s) are violated. Briefly explain your choice."
  },
  {
    "objectID": "hw/hw-01.html#exercise-3",
    "href": "hw/hw-01.html#exercise-3",
    "title": "HW 01: Multiple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nUse the Kentucky Derby case study in Chapter 1 of Beyond Multiple Linear Regression.\n\nConsider Equation (1.3) in Section 1.6.3. Show why we have to be sure to say “holding year constant”, “after adjusting for year”, or an equivalent statement, when interpreting \\(\\beta_2\\).\nBriefly explain why there is no error (random variation) term \\(\\epsilon_i\\) in Equation (1.4) in Section 1.6.6?"
  },
  {
    "objectID": "hw/hw-01.html#exercise-4",
    "href": "hw/hw-01.html#exercise-4",
    "title": "HW 01: Multiple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nThe data set kingCountyHouses.csv in the data folder contains data on over 20,000 houses sold in King County, Washington (Kaggle (2018)).\nWe will use the following variables:\n\nprice = selling price of the house\nsqft = interior square footage\n\nSee Section 1.8 of Beyond Multiple Linear Regression for the full list of variables.\n\nFit a linear regression model with price as the response variable and sqft as the predictor variable (Model 1). Interpret the slope coefficient in terms of the expected change in price when sqft increases by 100.\nFit Model 2, where logprice (the natural log of price) is now the response variable and sqft is still the predictor variable. How is the logprice expected to change when sqft increases by 100?\nRecall that \\(log(a) - log(b) = log(\\frac{a}{b})\\). Use this to derive how the price is expected to change when sqft increases by 100 based on Model 2.\nFit Model 3, where price and logsqft (the natural log of sqft) are the response and predictor variables, respectively. How is the price expected to change when sqft increases by 10%? As a hint, this is the same as multiplying sqft by 1.10.\n\n\n\n\n\n\n\nTip\n\n\n\nClick here for notes on interpreting model effects for log-transformed response and/or predictor variables."
  },
  {
    "objectID": "hw/hw-01.html#exercise-5",
    "href": "hw/hw-01.html#exercise-5",
    "title": "HW 01: Multiple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nThe goal of this analysis is to use characteristics of 593 colleges and universities in the United States to understand variability in the early career pay, defined as the median salary for alumni with 0 - 5 years of experience. The data was obtained from TidyTuesday College tuition, diversity, and pay, and was originaly collected from the PayScale College Salary Report.\nThe data set is located in college-data.csv in the data folder. We will focus on the following variables:\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\nname\ncharacter\nName of school\n\n\nstate_name\ncharacter\nstate name\n\n\ntype\ncharacter\nPublic or private\n\n\nearly_career_pay\ndouble\nMedian salary for alumni with 0 - 5 years experience (in US dollars)\n\n\nstem_percent\ndouble\nPercent of degrees awarded in science, technology, engineering, or math subjects\n\n\nout_of_state_total\ndouble\nTotal cost for in-state residents in USD (sum of room & board + out of state tuition)\n\n\n\n\nVisualize the distribution of the response variable early_career_pay. Write 1 - 2 observations from the plot.\nVisualize the relationship between (i) early_career_pay and type and (ii) early_career_pay and stem_percent. Write an observation from each plot.\nBelow is the specification of the statistical model for this analysis. Fit the model and neatly display the results using 3 digits. Display the 95% confidence interval for the coefficients.\n\n\\[\n\\begin{align}\nearly\\_career\\_pay_{i} = \\beta_0 &+ \\beta_1~out\\_of\\_state\\_total_{i} \\\\ &+ \\beta_2 ~ type_i\\\\&+ \\beta_3 ~ stem\\_percent_{i}\\\\ &+ \\beta_4 ~ type_i * stem\\_percent_{i} \\\\ &+ \\epsilon_{i}, \\hspace{5mm} \\text{where } \\epsilon_i \\sim N(0, \\sigma^2)\n\\end{align}\n\\]\n\nHow many degrees of freedom are there in the estimate of the regression standard error \\(\\sigma\\) for the model from part c?\nWhat is the 95% confidence interval for the amount in which the intercept for public institutions differs from private institutions?"
  },
  {
    "objectID": "hw/hw-01.html#exercise-6",
    "href": "hw/hw-01.html#exercise-6",
    "title": "HW 01: Multiple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nUse the analysis from the previous exercise to write a paragraph (~ 3 - 5 sentences) describing the differences in early career pay based on the institution characteristics. The summary should be consistent with the results from the previous exercise, comprehensive, answers the primary analysis question, and tells a cohesive story (e.g., a list of interpretations will not receive full credit)."
  },
  {
    "objectID": "hw/hw-01.html#footnotes",
    "href": "hw/hw-01.html#footnotes",
    "title": "HW 01: Multiple linear regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nExercises 1 - 4 are adapted from exercises in Section 1.8 of Roback and Legler (2021).↩︎"
  },
  {
    "objectID": "hw/hw-02.html",
    "href": "hw/hw-02.html",
    "title": "HW 02: Poisson regression",
    "section": "",
    "text": "library(tidyverse)\nlibrary(knitr)\nlibrary(kableExtra)"
  },
  {
    "objectID": "hw/hw-02.html#exercise-1",
    "href": "hw/hw-02.html#exercise-1",
    "title": "HW 02: Poisson regression",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nAnswer parts a - d in the context of the following study:\nA state wildlife biologist collected data from 250 park visitors as they left at the end of their stay. Each was asked to report the number of fish they caught during their one-week stay. On average, visitors caught 21.5 fish per week.\n\nDefine the response.\nWhat are the possible values for the response?\nWhat does \\(\\lambda\\) represent?\nWould a zero-inflated model be considered here? If so, what would be a “true zero”?"
  },
  {
    "objectID": "hw/hw-02.html#exercise-2",
    "href": "hw/hw-02.html#exercise-2",
    "title": "HW 02: Poisson regression",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nBrockmann (1996) carried out a study of nesting female horseshoe crabs. Female horseshoe crabs often have male crabs attached to a female’s nest known as satellites. One objective of the study was to determine which characteristics of the female were associated with the number of satellites. Of particular interest is the relationship between the width of the female carapace and satellites.\nThe data can be found in crab.csv in the data folder. It includes the following variables:\n\nSatellite = number of satellites\nWidth = carapace width (cm)\nWeight = weight (kg)\nSpine = spine condition (1 = both good, 2 = one worn or broken, 3 = both worn or broken)\nColor = color (1 = light medium, 2 = medium, 3 = dark medium, 4 = dark)\n\nMake sure to convert Spine and Color to the appropriate data types in R before doing the analysis.\n\nCreate a histogram of Satellite. Is there preliminary evidence the number of satellites could be modeled as a Poisson response? Briefly explain.\nFit a Poisson regression model including Width, Weight, and Spine as predictors. Display the model with the 95% confidence interval for each coefficient.\nDescribe the effect of Spine in terms of the mean number of satellites."
  },
  {
    "objectID": "hw/hw-02.html#exercise-3",
    "href": "hw/hw-02.html#exercise-3",
    "title": "HW 02: Poisson regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nUse the scenario from the previous exercise to answer questions (a) - (d).\n\nWe would like to fit a quasi-Poisson regression model for this data. Briefly explain why we may want to consider fitting a quasi-Poisson regression model for this data.\nFit a quasi-Poisson regression model that corresponds with the model chosen the previous exercise. Display the model.\nWhat is the estimated dispersion parameter? Show how this value is calculated.\nHow do the estimated coefficients change compared to the model chosen in the previous exercise? How do the standard errors change?"
  },
  {
    "objectID": "hw/hw-02.html#exercise-4",
    "href": "hw/hw-02.html#exercise-4",
    "title": "HW 02: Poisson regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nThe goal of this exercise is to use simulation to understand the equivalency between a gamma-Poisson mixture and a negative binomial distribution.\n\n\n\n\n\n\nTip\n\n\n\nRemember to set a seed so your simulations are reproducible!\n\n\n\n\nUse the R function rpois() to generate 10,000 \\(x_i\\) from a regular Poisson distribution, \\(X \\sim \\textrm{Poisson}(\\lambda=1.5)\\). Plot a histogram of this distribution and note its mean and variance. Next, let \\(Y \\sim \\textrm{Gamma}(r = 3, \\lambda = 2)\\) and use rgamma() to generate 10,000 random \\(y_i\\) from this distribution.\nNow, consider 10,000 different Poisson distributions where \\(\\lambda_i = y_i\\). Randomly generate one \\(z_i\\) from each Poisson distribution. Plot a histogram of these \\(z_i\\) and compare it to your original histogram of \\(X\\) (where \\(X \\sim \\textrm{Poisson}(1.5)\\)). How do the means and variances compare?\nA negative binomial distribution can actually be expressed as a gamma-Poisson mixture. In Part a, you looked at a gamma-Poisson mixture \\(Z \\sim \\textrm{Poisson}(\\lambda)\\) where \\(\\lambda \\sim \\textrm{Gamma}(r = 3, \\lambda' = 2)\\).\nFind the parameters of a negative binomial distribution \\(X \\sim \\textrm{NegBinom}(r, p)\\) such that \\(X\\) is equivalent to \\(Z\\). As a hint, the means of both distributions must be the same, so \\(\\frac{r(1-p)}{p} = \\frac{3}{2}\\).\nShow through histograms and summary statistics that your negative binomial distribution is equivalent to the gamma-Poisson mixture. You can use rnbinom() in R.\nMake an argument that if you want a \\(\\textrm{NegBinom}(r, p)\\) random variable, you can instead sample from a Poisson distribution, where the \\(\\lambda\\) values are themselves sampled from a gamma distribution with parameters \\(r\\) and \\(\\lambda' = \\frac{p}{1-p}\\)."
  },
  {
    "objectID": "hw/hw-02.html#exercise-5",
    "href": "hw/hw-02.html#exercise-5",
    "title": "HW 02: Poisson regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nIn a 2018 study, Chapp et al. (2018) scraped every issue statement from webpages of candidates for the U.S. House of Representatives, counting the number of issues candidates commented on and scoring the level of ambiguity of each statement. We will focus on the issue counts, and determining which attributes (of both the district as a whole and the candidates themselves) are associated with candidate silence (commenting on 0 issues) and a willingness to comment on a greater number of issues. The data set is in ambiguity.csv in the data folder . This analysis will focus on the following variables:\n\nname : candidate name\ndistID : unique identification number for Congressional district\nideology : candidate left-right orientation\ndemocrat : 1 if Democrat, 0 if Republican\ntotalIssuePages : number of issues candidates commented on (response)\n\nSee Roback and Legler (2021) for the full list of variables.\nWe will use a hurdle model to analyze the data. A hurdle model is similar to a zero-inflated Poisson model, but instead of assuming that “zeros” are comprised of two distinct groups—those who would always be 0 and those who happen to be 0 on this occasion—the hurdle model assumes that “zeros” are a single entity. Therefore, in a hurdle model, cases are classified as either “zeros” or “non-zeros”, where “non-zeros” hurdle the 0 threshold—they must always have counts of 1 or above.\nWe will use the pscl package and the hurdle function in it to analyze a hurdle model. Note that coefficients in the “zero hurdle model” section of the output relate predictors to the log-odds of being a non-zero (i.e., having at least one issue statement), which is opposite of the ZIP model.\n\nVisualize the distribution of the response variable totalIssuePages. Why might we consider using a hurdle model compared to a Poisson model? Why is a zero-inflated Poisson model not appropriate in this scenario?\nCreate a plot of the empirical log odds of having at least one issue statement by ideology. You may want to group ideology values first. What can you conclude from this plot?\nCreate a hurdle model with ideology and democrat as predictors in both parts.1 Display the model. Interpret ideology in both parts of the model.\nRepeat (d), but include an interaction in both parts. Interpret the interaction in the zero hurdle part of the model."
  },
  {
    "objectID": "hw/hw-02.html#exercise-6",
    "href": "hw/hw-02.html#exercise-6",
    "title": "HW 02: Poisson regression",
    "section": "Exercise 6",
    "text": "Exercise 6\n\n\nAwad, Lebo, and Linden (2017) scraped 40628 Airbnb listings from New York City in March 2017 and put together the data set NYCairbnb.csv. The codebook is in the data folder of the hw-02 repo.\nPerform the EDA and build a model, considering offset and accounting for overdispersion, if needed. Then, use the model to describe the characteristics of Airbnbs that are expected to have a high number of reviews."
  },
  {
    "objectID": "hw/hw-02.html#footnotes",
    "href": "hw/hw-02.html#footnotes",
    "title": "HW 02: Poisson regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe R syntax in the hurlde function is similar to the syntax for the zero-inflated Poisson model. You will need to specify the distributions for the count and hurdle portions of the model, using dist = \"poisson\" and zero.dist = \"binomial\".↩︎"
  },
  {
    "objectID": "prepare/jan-29.html",
    "href": "prepare/jan-29.html",
    "title": "Prepare for Jan 29 lecture",
    "section": "",
    "text": "Read Beyond Multiple Linear Regression (BMLR): Section 4.9"
  },
  {
    "objectID": "prepare/jan-24.html",
    "href": "prepare/jan-24.html",
    "title": "Prepare for Jan 24 lecture",
    "section": "",
    "text": "Read Beyond Multiple Linear Regression (BMLR): Sections 4.1 - 4.8"
  },
  {
    "objectID": "prepare/feb-12.html",
    "href": "prepare/feb-12.html",
    "title": "Prepare for Feb 12 lecture",
    "section": "",
    "text": "Read BMLR Section 6.1 - 6.7"
  },
  {
    "objectID": "prepare/feb-05.html",
    "href": "prepare/feb-05.html",
    "title": "Prepare for Feb 05 lecture",
    "section": "",
    "text": "Read BMLR Section 5.1 - 5.3"
  },
  {
    "objectID": "ae/lec-04-poisson-estimate.html",
    "href": "ae/lec-04-poisson-estimate.html",
    "title": "Lecture 04 AE: Estimating coefficients for Poisson Regression",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\n\nhh_data &lt;- read_csv(\"data/fHH1.csv\")"
  },
  {
    "objectID": "ae/lec-04-poisson-estimate.html#step-1.-initial-estimates-of-lambda",
    "href": "ae/lec-04-poisson-estimate.html#step-1.-initial-estimates-of-lambda",
    "title": "Lecture 04 AE: Estimating coefficients for Poisson Regression",
    "section": "Step 1. Initial estimates of lambda",
    "text": "Step 1. Initial estimates of lambda\nUsing total + 0.1 instead of total as initial starting values to avoid dividing by 0 or taking the log of 0.\n\nhh_data &lt;- hh_data |&gt;\n  mutate(lambda = hh_data$total + 5)"
  },
  {
    "objectID": "ae/lec-04-poisson-estimate.html#step-2.-calculate-the-working-response-values-z_i.",
    "href": "ae/lec-04-poisson-estimate.html#step-2.-calculate-the-working-response-values-z_i.",
    "title": "Lecture 04 AE: Estimating coefficients for Poisson Regression",
    "section": "Step 2. Calculate the working response values \\(z_i\\).",
    "text": "Step 2. Calculate the working response values \\(z_i\\).\nFor Poisson regression, \\(z_i = \\log(\\lambda) + \\frac{(y_i - \\lambda_i)}{\\lambda_i}\\)\n\nhh_data &lt;- hh_data |&gt;\n  mutate(z = log(lambda) + (hh_data$total - lambda) / lambda)"
  },
  {
    "objectID": "ae/lec-04-poisson-estimate.html#step-3.-calculate-the-working-weights-w_i",
    "href": "ae/lec-04-poisson-estimate.html#step-3.-calculate-the-working-weights-w_i",
    "title": "Lecture 04 AE: Estimating coefficients for Poisson Regression",
    "section": "Step 3. Calculate the working weights \\(W_i\\)",
    "text": "Step 3. Calculate the working weights \\(W_i\\)\nFor Poisson regression, \\(W_i = \\lambda_i\\) .\n\nhh_data &lt;- hh_data |&gt;\n  mutate(w = lambda)\n\n\nhh_data |&gt;\n  select(total, lambda, z, w) |&gt;\n  slice(1:5)\n\n# A tibble: 5 × 4\n  total lambda     z     w\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0      5 0.609     5\n2     3      8 1.45      8\n3     4      9 1.64      9\n4     3      8 1.45      8\n5     3      8 1.45      8"
  },
  {
    "objectID": "ae/lec-04-poisson-estimate.html#step-4.-find-the-coefficient-estimates-of-the-weighted-least-squares-model",
    "href": "ae/lec-04-poisson-estimate.html#step-4.-find-the-coefficient-estimates-of-the-weighted-least-squares-model",
    "title": "Lecture 04 AE: Estimating coefficients for Poisson Regression",
    "section": "Step 4. Find the coefficient estimates of the weighted least squares model",
    "text": "Step 4. Find the coefficient estimates of the weighted least squares model\n\nwls &lt;- lm(z ~ age, weight = w, data = hh_data)\ntidy(wls) |&gt;\n  kable(digits = 4)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n1.7594\n0.0419\n41.9664\n0e+00\n\n\nage\n-0.0026\n0.0008\n-3.4172\n6e-04"
  },
  {
    "objectID": "ae/lec-04-poisson-estimate.html#use-this-model-to-get-new-estimates-of-lambda",
    "href": "ae/lec-04-poisson-estimate.html#use-this-model-to-get-new-estimates-of-lambda",
    "title": "Lecture 04 AE: Estimating coefficients for Poisson Regression",
    "section": "Use this model to get new estimates of lambda",
    "text": "Use this model to get new estimates of lambda\n\nhh_data &lt;- hh_data |&gt;\n  mutate(lambda = exp(predict(wls)))\n\nRepeat steps 2 - 4 until the estimates \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) converge to their respective values."
  },
  {
    "objectID": "ae/lec-04-poisson-estimate.html#irls-automated",
    "href": "ae/lec-04-poisson-estimate.html#irls-automated",
    "title": "Lecture 04 AE: Estimating coefficients for Poisson Regression",
    "section": "IRLS automated",
    "text": "IRLS automated\n\nnreps &lt;- 10\nhh_data &lt;- hh_data %&gt;%\n  mutate(lambda = hh_data$total + 5)\n\n\nbetas &lt;- tibble(beta0 = rep(0, nreps), \n                beta1 = rep(0, nreps))\n\nfor(i in 1:nreps){\n  hh_data &lt;- hh_data %&gt;%\n    mutate(z = log(lambda) + (hh_data$total - lambda)/ lambda, \n         w = lambda)\n  wls &lt;- lm(z ~ age, weight = w, data = hh_data)\n  betas$beta0[i] = tidy(wls)$estimate[1]\n  betas$beta1[i] = tidy(wls)$estimate[2]\n  \n  hh_data &lt;- hh_data %&gt;% \n    mutate(lambda = exp(predict(wls)))\n}\n  \nbetas\n\n# A tibble: 10 × 2\n   beta0    beta1\n   &lt;dbl&gt;    &lt;dbl&gt;\n 1  1.76 -0.00265\n 2  1.57 -0.00414\n 3  1.55 -0.00468\n 4  1.55 -0.00471\n 5  1.55 -0.00471\n 6  1.55 -0.00471\n 7  1.55 -0.00471\n 8  1.55 -0.00471\n 9  1.55 -0.00471\n10  1.55 -0.00471"
  },
  {
    "objectID": "ae/lec-04-poisson-estimate.html#fit-using-the-glm-function",
    "href": "ae/lec-04-poisson-estimate.html#fit-using-the-glm-function",
    "title": "Lecture 04 AE: Estimating coefficients for Poisson Regression",
    "section": "Fit using the glm function",
    "text": "Fit using the glm function\n\n## add code here"
  },
  {
    "objectID": "support.html",
    "href": "support.html",
    "title": "Course support",
    "section": "",
    "text": "We expect everyone will have questions at some point in the semester, so we want to make sure you can identify when that is and feel comfortable seeking help."
  },
  {
    "objectID": "support.html#lectures-and-labs",
    "href": "support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone."
  },
  {
    "objectID": "support.html#office-hours",
    "href": "support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage you to take advantage of them!\nMake a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself."
  },
  {
    "objectID": "support.html#slack",
    "href": "support.html#slack",
    "title": "Course support",
    "section": "Slack",
    "text": "Slack\nOutside of class and office hours, any general questions about course content or assignments should be posted on the classrom Slack. There is a chance another student has already asked a similar question, so please check the other posts on Slack before adding a new question. If you know the answer to a question that is posted, I encourage you to respond!"
  },
  {
    "objectID": "support.html#email",
    "href": "support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nIf you have questions about personal matters that are not appropriate for the class discussion forum (e.g. illness, accommodations, etc.), you may email Professor Tackett at maria.tackett@duke.edu. If you email me, please include “STA 310” in the subject line. Barring extenuating circumstances, I will respond to STA 310 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday."
  },
  {
    "objectID": "support.html#academic-support",
    "href": "support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917."
  },
  {
    "objectID": "support.html#mental-health-and-wellness",
    "href": "support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\n\nDukeReach: Provides comprehensive outreach services to identify and support students in managing all aspects of well being. If you have concerns about a student’s behavior or health visit the website for resources and assistance. Go to studentaffairs.duke.edu/dukereach\nCounseling and Psychological Services (CAPS): CAPS services include individual, group, and couples counseling services, health coaching, psychiatric services, and workshops and discussions. (919) 660-1000 or students.duke.edu/wellness/caps\nTimelyCare (formerly known as Blue Devils Care): An online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling. bluedevilscare.duke.edu"
  },
  {
    "objectID": "support.html#technology-accommodations",
    "href": "support.html#technology-accommodations",
    "title": "Course support",
    "section": "Technology accommodations",
    "text": "Technology accommodations\nHighly aided students who have limited access to computers may request loaner laptops through the DukeLIFE Technology Assistance Program. Please note that supplies are limited.\nNote that we will be using Duke’s computational resources in this course. These resources are freely available to you. As long as your computer can connect to the internet and open a browser window, you can perform the necessary computing for this course. All software we use is open-source and/or freely available."
  },
  {
    "objectID": "support.html#course-materials-costs",
    "href": "support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.)."
  },
  {
    "objectID": "projects/project-01.html",
    "href": "projects/project-01.html",
    "title": "Project 01: Generalized Linear Models",
    "section": "",
    "text": "For this project you and your team will be reading and evaluating a scholarly article that incorporates generalized linear models (GLMs) in the analysis.\nThe learning objectives of the project are to"
  },
  {
    "objectID": "projects/project-01.html#team-assignments",
    "href": "projects/project-01.html#team-assignments",
    "title": "Project 01: Generalized Linear Models",
    "section": "Team assignments",
    "text": "Team assignments\nYou will work in small teams for this project. You will find the team assignments in the #project-01 channel in Slack.\nBefore getting started, I encourage you to discuss the following as a group:\n\nCome up with a plan to communicate and work together outside of lab.\nCome up with a plan for remote work if some team members are unable to attend lab or other in-person team meetings."
  },
  {
    "objectID": "projects/project-01.html#workflow",
    "href": "projects/project-01.html#workflow",
    "title": "Project 01: Generalized Linear Models",
    "section": "Workflow",
    "text": "Workflow\n\nProject Week 01 (week of Mon, Jan 22): Select article and submit proposal.\nProject Week 02 (week of Mon, Jan 29): Read article and complete article evaluation.\nProject Week 03 (week of Mon, Feb 05 ): Work on draft reports and presentations.\nProject Week 04 (week of Mon, Feb 12): Presentations and submit report."
  },
  {
    "objectID": "projects/project-01.html#due-dates",
    "href": "projects/project-01.html#due-dates",
    "title": "Project 01: Generalized Linear Models",
    "section": "Due dates",
    "text": "Due dates\n\n\n\n\n\n\nNote\n\n\n\nAll work will be submitted in your team’s project GitHub repo.\n\n\n\nProposal: due Fri, Jan 26 at noon\nArticle evaluation: due Sun, Feb 04 at noon\nPresentation: due Wed, Feb 14 at 3:05pm\nWritten report: due Thu, Feb 15 at noon"
  },
  {
    "objectID": "projects/project-01.html#article",
    "href": "projects/project-01.html#article",
    "title": "Project 01: Generalized Linear Models",
    "section": "Article",
    "text": "Article\nThe article for this project must be published in a scholarly journal. Please ask a member of the teaching team if you are unsure whether the article is published in a scholarly journal. The article must incorporate the use one or more generalized linear models, that is not a linear regression model, in the analysis.\n\nCommon GLMs are Poisson regression, Logistic regression, Probit regression, and Negative binomial regression.\nYou can also look for models based on the distribution of the response variable: Binary, Binomial, Poisson, Exponential, Gamma, Geometric.\nSee Section 3.6 in Beyond Multiple Linear Regression for a list of types of GLMs.\n\nThe model used in the paper does not have to be one we discuss in class. I’d encourage you to explore articles that use modeling beyond the scope of the class!\nBelow are a few useful places to search for articles:\n\nDuke Library\nPLOS One\nPubMed.gov\n\nSee the Tips on finding articles for tips on searching journal databases to find an article."
  },
  {
    "objectID": "projects/project-01.html#proposal",
    "href": "projects/project-01.html#proposal",
    "title": "Project 01: Generalized Linear Models",
    "section": "Proposal",
    "text": "Proposal\nThe main goal of the proposal is to ensure you have an article that will set you up for a successful project. Include the following in the proposal.\n\nThe citation for the article. If you’re using a .bib file you can use the default citation format in Quarto (Chicago author-date format). Otherwise, use MLA format.\nBrief summary about why you chose this article.\nBrief summary of the article’s primary research objective.\nName of the GLM(s) used in the article and a short description of the response variable for each model.\n\nYou are only required to write the proposal for one article. Write the proposal in the file proposal.qmd, then push the .qmd and rendered PDF to the GitHub repo for submission.\n\n\n\n\n\n\nImportant\n\n\n\nThe proposal is due on Fri, Jan 25 at noon.\n\nYou will not be able to commit new work to your GitHub repo after the deadline until we have completed grading. If your group needs to submit your work late, please send me a message on Slack or email to reopen the repo.\n\n\n\nGrading criteria\nThe proposal will be graded based on the following:\n\nAll required components of the proposal are included and accurate (8 pts)\nAll team members have made meaningful contribution, as determined by Git commit history (2 pts)"
  },
  {
    "objectID": "projects/project-01.html#article-evaluation",
    "href": "projects/project-01.html#article-evaluation",
    "title": "Project 01: Generalized Linear Models",
    "section": "Article evaluation",
    "text": "Article evaluation\nThe purpose of the article evaluation is for you to begin describing and evaluating the statistical analysis and argument in the article. Write your responses to the following questions in article-evaluation.qmd. The anticipated length is about 1 - 2 pages and should be no more than 4 pages. There is no minimum page requirement, as long as each section is comprehensively addressed.\n\nAudience and purpose\n\nWho is the primary audience for this article, i.e., for what type of readers are the authors writing?\nWhat is the general purpose of the article, e.g., to persuade the reader to do something, to prove something, to inform the reader, etc.?\n\nData\n\nHow were the data generated - from an experiment, online survey, interviews, etc?\nUnder what conditions were the data collected, e.g., the time period, location, how subjects were selected, response rate / drop-out rate, etc.?\n\nGraphs and tables\n\nDescribe the types of visualizations and tables used in the article.\nHow are they primarily used - for exploratory data analysis, to support a candidatee, etc.?\nWhat visualizations or tables might you add to the article? Briefly explain.\n\nGeneralized Linear Model\nIf your paper has multiple, GLMs you only have to write this section up for one model.\n\nWhat is the response variable, and what is its distribution?\nWhat are the predictor variables? Which predictor(s) are of particularl interest in the research?\nWrite the statistical model in mathematical notation.\n\nOverall argument\n\nAre there limitations or difficulties with generalizing beyond the data? Briefly explain.\nWhen was the article published? Are the findings up-to-date, out-dated, or timeless? Briefly explain.\nHow does the study advance knowledge in the field?\n\n\n\nGrading criteria\nThe article evaluation will be graded based on the following\n\nAll required components of the article evaulation are included and accurate (15 pts)\nThe team has worked collaboratively using GitHub and all all team members have made a meaningful contribution, as determined by Git commit history (5 pts)\n\n\n\n\n\n\n\nImportant\n\n\n\nThe article evaluation is due on Sun, Feb 04 at noon.\n\nYou will not be able to commit new work to your GitHub repo after the deadline until we have completed grading. If your group needs to submit your work late, please send me a message on Slack or email to reopen the repo."
  },
  {
    "objectID": "projects/project-01.html#write-up",
    "href": "projects/project-01.html#write-up",
    "title": "Project 01: Generalized Linear Models",
    "section": "Write up",
    "text": "Write up\nThe anticipated length is about 5 pages. There is no minimum or maximum page requirement as long as each section is accurately and comprehensively addressed.\n\nIntroduction\nBriefly summarize the article, the research objective and purpose, and key conclusions. Also include a description of the data used for the analysis.\n\n\nMethods\nDescribe the GLM used for the analysis. Describe the response variable and and its distribution. Describe predictor variables. Write the equation of the statistical models using mathematical notation.\n\n\nResults\nInterpret the results form the model. Write the interpretations / conclusions from the mode, using estimates from the article when possible. If the article does not include estimates for some or all of the estimated effects effects, you can write general interpretations using the appropriate mathematical symbol (e.g., \\(\\hat{\\beta}_1\\)) in place of the estimated value.\n\n\nCommunication\nThe objective of this section of the written report is to assess the authors’ argument and communication. Reading and identifying how others communicate statistical results is a key way to develop your statistical writing skills. This section will include an assessment of the following:\n\nAudience: Describe the primary audience for the article.\nMethods: Consider the detail in the data and methods sections. What aspects of the analysis are mentioned in detail? What aspects are mentioned without detail? How does the level of detail correlate to the statistical background of the primary audience?\nGraphs and figures: How are the graphs, figures, and tables used to support the findings? How are they used for exploratory data analysis? How how are they used to assess or support modeling results? Would additional graphs, figures, or tables be helpful? If so, what kind?\n\nIdentify one key graph. Where is it located in the article? What message does it convey with respect to the objective and conclusion of the study? If there are no graphs in the article, describe one key graph you would include and how it would be used in the article (e.g., support conclusions, provide clarity, etc.).\n\nLimitations: Are there limitations or difficulties in generalizing beyond the data? How are these limitations noted, if at all? Do you have any other concerns about the study?\nImpact: According to the author, how does the study advance knowledge in the field? Taking into account the year the article was published, do the author’s claims seem adequately justified, overblown, or unduly cautious?\n\nYou can use these questions as a guide to shape the narrative. This section should still be written in narrative form, not as a list of questions and answers.\nThe questions in this section are adapted from Communicating with Data: The Art of Writing for Data Science by Deborah Nolan and Sara Stoudt. Click here for more details about the questions and how to read scientific articles. You can borrow a copy of the book from Duke Libraries.\n\n\nGrading criteria\nEach section will assessed on whether the components of the section are clearly, comprehensively, and accurately discussed in the report. (30 pts total)\nThe report will also be assessed based on the following:\n\nFormatting: 3 pts\n\nThis is an assessment of the overall presentation and formatting of the written report. This includes neatly formatted text and tables, appropriate labels on figures, suppressing all code and extraneous output, properly rendered LaTex, etc.\n\nReproducibility: 2 pts\n\nThis is an assessment of the reproducibility of the report. Is the PDF produced by rendering the Quarto document?\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe written report is due on Thu, Feb 15 at noon.\nYou will not be able to commit new work to your GitHub repo after the deadline until we have completed grading. If your group needs to submit your work late, please send me a message on Slack or email to reopen the repo."
  },
  {
    "objectID": "projects/project-01.html#presentation",
    "href": "projects/project-01.html#presentation",
    "title": "Project 01: Generalized Linear Models",
    "section": "Presentation",
    "text": "Presentation\nYou will present on Wed, Feb 14 during lecture. Each team will have up to 10 minutes for the presentation along with a few minutes for questions, and every team member should speak about an equal amount of time during the presentation.\nYou can make the presentation slides using the software of your choice. You can use as many slide as you wish, just be mindful of what can reasonably be presented in the timeframe. A suggested outline is\n\n1 slide to introduce article\n1 - 2 slides to describe the model\n1 - 2 slides for key interpretations and results\n1 slide for key highlights about the communication and writing (e.g., what the authors did particularly well or areas of improvement)\n\nYou will be assigned two presentations to peer review. You must submit the peer review scores for both presentations to have the “Peers” scores for your team’s presentation included in your presentation grade.\nThe presentation order and peer review assignments will be given closer to the presentation date.\n\nGrading criteria - Teaching Team (16 pts)\nThis portion of the grade will the average of the scores from the members of the teaching team.\n\nProfessionalism (5 pts)\n\nWas the team prepared for the presentation? Did each team member have a meaningful contribution to the presentation?\nWas the time reasonably divided among team members? Was the presentation within the time limit?\nDid the team present a unified story?\n\nContent (6 pts): The content is presented in a clear and accurate way. This includes clearly and accurately describing\n\nthe primary research objective and intended audience for the article.\nthe data used in the analysis.\nthe observations and units at every level.\nthe model and primary conclusions\nthe effectiveness of tables, figures, and graphs in the article and argument of the contribution of the work (optional).\n\nSlides (10 pts)\n\nAre the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.?\n\n\n\n\nGrading criteria - Peers (4 pts)\nThis portion of the grade will the average of the scores from the peer reviewers. Peer review assignments will be posted on Slack.\n\nIntroduction (1 pt)\n\nDid the team clearly describe the primary research objective and intended audience for the article?\n\nData (1 pt)\n\nDid the team clearly describe the data used in the analysis?\n\nModel (1 pt)\n\nDid the team clearly describe the observational units and variables at each level? Did they clearly describe the model?\n\nSlides (1 pt)\n\nAre the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.?"
  },
  {
    "objectID": "projects/project-01.html#github-repo-organization",
    "href": "projects/project-01.html#github-repo-organization",
    "title": "Project 01: Generalized Linear Models",
    "section": "GitHub repo organization",
    "text": "GitHub repo organization\nYou should have the following files and folders in the project repo. The repo and brief summary in the README should be updated by Thu, Feb 15 at noon. README.md: 3 - 5 sentence summary of the project and citation for the article.\n\nproposal.qmd\nproposal.pdf\narticle-evaluation.qmd\narticle-evaluation.pdf\nwriteup.qmd\nwriteup.pdf\n/presentation\n\n/presentation/*: Presentation file (if not linked in README)\n/presentation/README.md: Link to project (if not in presentation folder)\n\n\nOptional\n\n*.bib: BibTex file for references\n/data/: Folder containing data"
  },
  {
    "objectID": "projects/project-01.html#grading-100-points",
    "href": "projects/project-01.html#grading-100-points",
    "title": "Project 01: Generalized Linear Models",
    "section": "Grading (100 points)",
    "text": "Grading (100 points)\n\n\n\nComponent\nPoints\n\n\n\n\nProposal\n10 pts\n\n\nArticle evaluation\n20 pts\n\n\nWritten report\n35 pts\n\n\nPresentation + Slides\n25 pts\n\n\nRepo organization\n5 pts\n\n\nTeamwork evaluation (individually assessed)\n5 pts"
  },
  {
    "objectID": "projects/project-01.html#tips-on-finding-articles",
    "href": "projects/project-01.html#tips-on-finding-articles",
    "title": "Project 01: Generalized Linear Models",
    "section": "Tips on finding articles",
    "text": "Tips on finding articles\nBelow are tips to help you find articles based on information from Jodi Psoter, the former Librarian for Chemistry and Statistical Science at Duke Libraries and current Head Librarian for the Marine Lab Library.\n\nPubMed\nArticles in health-related fields\nThe PubMed heading tree lets you search by topic. The link will direct you to the results under the category of “Statistics as a Topic”.\n\nClick on the model or distribution of interest, e.g. “Logistic Models”.\nClick “Add to search builder” under the PubMed Search Builder in the top right corner. You should now see the model/analysis type you chose in the search box.\nClick “Search PubMed”, and a page of search results will appear.\nThere are options to narrow your results on the left-hand side based on your team’s interest.\n\n\n\nPsycInfo\nArticles in psychology\nPsycInfo will allow users to search by analysis type.\n\nPut the name of the model in the search bar, e.g., “Poisson Regression”. Then, in the drop down menu next to the search bar, select “DE Subjects [exact]”. Click Search.\nYou can use the options on the left-hand size to narrow down the search results.\n\n\n\nWeb of Science\nArticles on all topics\nWeb of Science Data Citation Index lets you search for data sets based on the topic of interest.\n\nUse the search bar to search based on a topic of interest. You can also search for the model or distribution name.\nOn the left-hand side, check “Data Set” under Content Type and check “Dataset” under Data Types. Click “Refine” to limit the results.\n\n3.Click on the article of interest.\n\nYou can use the options on the left-hand size to narrow down the search results.\n\n\n\nAcknowledgements\n\nGrading criteria and the repo organization for this project were adapted from Project 1 on vizdata.org.\nSome questions for the Article Evaluation adapted from “How to Evaluate Journal Articles”.\nQuestions in the “Communication” section of the Written Report are adapted from Communicating with Data: The Art of Writing for Data Science by Deborah Nolan and Sara Stoudt."
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Course overview",
    "section": "",
    "text": "STA 310 builds upon the content in STA 210: Regression Analysis. In STA 310 students will be introduced to generalized linear models (GLMs), a broad modeling framework that includes linear and logistic models, among others. Students will learn the basic theory of GLMs and how they can used to model a variety of response variables with non-normal distributions. Students will also learn an extension of GLMs that can be applied to modeling data with correlated observations, such as data with repeated measures."
  },
  {
    "objectID": "course-overview.html#teaching-assistant",
    "href": "course-overview.html#teaching-assistant",
    "title": "Course overview",
    "section": "Teaching assistant",
    "text": "Teaching assistant\nThe teaching assistant for this course is Hun Kang. He is a PhD student in Statistics, and his research interests include scalable model selection, Bayesian nonparametrics and correlated and longitudinal data analysis.\n\n\n\n\nLocation\n\n\n\n\nTue 3 - 5pm\nOld Chem 203B"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#announcements",
    "href": "slides/05-poisson-pt2.html#announcements",
    "title": "Poisson Regression",
    "section": "Announcements",
    "text": "Announcements\nQuiz 01: Tue, Jan 30 ~ 9am - Thu, Feb 01 at noon\n\nThe quiz is not timed and will be administered through Canvas\nCovers:\n\nSyllabus\nCovers readings & lectures: Jan 17 - 24\nOpen book, open note, open internet (not crowd-sourcing sites or AI). You may not discuss the quiz with anyone else. See policy in syllabus.\nPlease email me or send a me a direct message on Slack if you have questions."
  },
  {
    "objectID": "slides/05-poisson-pt2.html#topics",
    "href": "slides/05-poisson-pt2.html#topics",
    "title": "Poisson Regression",
    "section": "Topics",
    "text": "Topics\n\nDefine and calculate residuals for the Poisson regression model\nUse Goodness-of-fit to assess model fit\nIdentify overdispersion\nApply modeling approaches to deal with overdispersion\n\nQuasi-Poisson\nNegative binomial\n\n\n\n\nNotes based on Sections 4.4 and 4.9 of Roback and Legler (2021) unless noted otherwise."
  },
  {
    "objectID": "slides/05-poisson-pt2.html#the-data-household-size-in-the-philippines",
    "href": "slides/05-poisson-pt2.html#the-data-household-size-in-the-philippines",
    "title": "Poisson Regression",
    "section": "The data: Household size in the Philippines",
    "text": "The data: Household size in the Philippines\nThe data fHH1.csv come from the 2015 Family Income and Expenditure Survey conducted by the Philippine Statistics Authority.\nGoal: Understand the association between household size and various characteristics of the household\nResponse:\n\ntotal: Number of people in the household other than the head\n\n\n\nPredictors:\n\nlocation: Where the house is located\nage: Age of the head of household\nroof: Type of roof on the residence (proxy for wealth)\n\n\nOther variables:\n\nnumLT5: Number in the household under 5 years old"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#poisson-regression-model",
    "href": "slides/05-poisson-pt2.html#poisson-regression-model",
    "title": "Poisson Regression",
    "section": "Poisson regression model",
    "text": "Poisson regression model\nIf \\(Y_i \\sim Poisson\\) with \\(\\lambda = \\lambda_i\\) for the given values \\(x_{i1}, \\ldots, x_{ip}\\), then\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_p x_{ip}\\]\n\n\nEach observation can have a different value of \\(\\lambda\\) based on its value of the predictors \\(x_1, \\ldots, x_p\\)\n\\(\\lambda\\) determines the mean and variance, so we don’t need to estimate a separate error term"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#household-vs.-age",
    "href": "slides/05-poisson-pt2.html#household-vs.-age",
    "title": "Poisson Regression",
    "section": "Household vs. Age",
    "text": "Household vs. Age\n\nhh_age &lt;- glm(total ~ age, data = hh_data, family = poisson)\n\ntidy(hh_age) |&gt; \n  kable(digits = 4)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n1.5499\n0.0503\n30.8290\n0\n\n\nage\n-0.0047\n0.0009\n-5.0258\n0\n\n\n\n\n\n\\[\\log(\\hat{\\lambda}) = 1.5499  - 0.0047 ~ age\\]\nThe mean household size is predicted to decrease by 0.47% (multiply by a factor of \\(e^{-0.0047}\\)) for each year older the head of the household is."
  },
  {
    "objectID": "slides/05-poisson-pt2.html#household-vs.-age-and-location",
    "href": "slides/05-poisson-pt2.html#household-vs.-age-and-location",
    "title": "Poisson Regression",
    "section": "Household vs. age and location",
    "text": "Household vs. age and location\n\n\n\n\n\n\n\n\n\n\n\nVisualization recreated from Figure 4.6 in Roback and Legler (2021)."
  },
  {
    "objectID": "slides/05-poisson-pt2.html#add-age2-and-location-to-model",
    "href": "slides/05-poisson-pt2.html#add-age2-and-location-to-model",
    "title": "Poisson Regression",
    "section": "Add \\(age^2\\) and \\(location\\) to model?",
    "text": "Add \\(age^2\\) and \\(location\\) to model?\n\nhh_age_loc &lt;- glm(total ~ age + I(age^2) + location, \n                  data = hh_data, family = poisson)\n\n\n\nUse Likelihood Ratio Test\n\nanova(hh_age, hh_age_loc, test = \"LRT\") |&gt;\n  kable(digits = 3)\n\n\n\n\nResid. Df\nResid. Dev\nDf\nDeviance\nPr(&gt;Chi)\n\n\n\n\n1498\n2337.089\nNA\nNA\nNA\n\n\n1493\n2187.800\n5\n149.289\n0"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#selected-model",
    "href": "slides/05-poisson-pt2.html#selected-model",
    "title": "Poisson Regression",
    "section": "Selected model",
    "text": "Selected model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.3843\n0.1821\n-2.1107\n0.0348\n-0.7444\n-0.0306\n\n\nage\n0.0704\n0.0069\n10.1900\n0.0000\n0.0569\n0.0840\n\n\nI(age^2)\n-0.0007\n0.0001\n-10.9437\n0.0000\n-0.0008\n-0.0006\n\n\nlocationDavaoRegion\n-0.0194\n0.0538\n-0.3605\n0.7185\n-0.1250\n0.0859\n\n\nlocationIlocosRegion\n0.0610\n0.0527\n1.1580\n0.2468\n-0.0423\n0.1641\n\n\nlocationMetroManila\n0.0545\n0.0472\n1.1542\n0.2484\n-0.0378\n0.1473\n\n\nlocationVisayas\n0.1121\n0.0417\n2.6853\n0.0072\n0.0308\n0.1945\n\n\n\n\n\n\nDoes this model sufficiently explain the variability in the mean household size?"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#pearson-residuals",
    "href": "slides/05-poisson-pt2.html#pearson-residuals",
    "title": "Poisson Regression",
    "section": "Pearson residuals",
    "text": "Pearson residuals\nWe can calculate two types of residuals for Poisson regression: Pearson residuals and deviance residuals\n\n\\[\\text{Pearson residual}_i = \\frac{\\text{observed} - \\text{predicted}}{\\text{std. error}} = \\frac{Y_i - \\hat{\\lambda}_i}{\\sqrt{\\hat{\\lambda}_i}}\\]\n\n\nSimilar interpretation as standardized residuals from linear regression\nExpect most to fall between -2 and 2\nUsed to calculate overdispersion parameter (more on this soon)"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#deviance-residuals",
    "href": "slides/05-poisson-pt2.html#deviance-residuals",
    "title": "Poisson Regression",
    "section": "Deviance residuals",
    "text": "Deviance residuals\n\nThe deviance residual describes how the observed data deviates from the fitted model \\[\\text{deviance residual}_i = \\text{sign}(Y_i - \\hat{\\lambda}_i)\\sqrt{2\\Bigg[Y_i\\log\\bigg(\\frac{Y_i}{\\hat{\\lambda}_i}\\bigg) - (Y_i - \\hat{\\lambda}_i)\\Bigg]}\\]\n\nwhere\n\\[\\text{sign}(Y_i - \\hat{\\lambda}_i)  =  \\begin{cases}\n1 & \\text{ if }(Y_i - \\hat{\\lambda}_i) &gt; 0 \\\\\n-1 & \\text{ if }(Y_i - \\hat{\\lambda}_i) &lt; 0 \\\\\n0 & \\text{ if }(Y_i - \\hat{\\lambda}_i) = 0\n\\end{cases}\\]\n\nGood fitting models \\(\\Rightarrow\\) small deviances"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#selected-model-residual-plots",
    "href": "slides/05-poisson-pt2.html#selected-model-residual-plots",
    "title": "Poisson Regression",
    "section": "Selected model: Residual plots",
    "text": "Selected model: Residual plots\n\nhh_age_loc_aug_pearson &lt;- augment(hh_age_loc, type.residuals = \"pearson\") \nhh_age_loc_aug_deviance &lt;- augment(hh_age_loc, type.residuals = \"deviance\")"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#goodness-of-fit-1",
    "href": "slides/05-poisson-pt2.html#goodness-of-fit-1",
    "title": "Poisson Regression",
    "section": "Goodness-of-fit",
    "text": "Goodness-of-fit\n\nGoal: Use the (residual) deviance to assess how much the predicted values differ from the observed values.\n\\[\n\\text{deviance} = \\sum_{i=1}^{n}(\\text{deviance residual})_i^2\n\\]\nWhen a model is true, we expect\n\\[\\text{deviance} \\sim \\chi^2_{df}\\]\n\nwhere \\(df\\) is the model’s residual degrees of freedom\n\n\nQuestion to answer: What is the probability of observing a deviance larger than the one we’ve observed, given this model sufficiently fits the data?\n\n\\[P(\\chi^2_{df} &gt; \\text{ deviance})\\]"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#goodness-of-fit-calculations",
    "href": "slides/05-poisson-pt2.html#goodness-of-fit-calculations",
    "title": "Poisson Regression",
    "section": "Goodness-of-fit calculations",
    "text": "Goodness-of-fit calculations\n\nhh_age_loc$deviance\n\n[1] 2187.8\n\nhh_age_loc$df.residual\n\n[1] 1493\n\n\n\n\npchisq(hh_age_loc$deviance, hh_age_loc$df.residual, lower.tail = FALSE)\n\n[1] 3.153732e-29\n\n\n\n\n\nThe probability of observing a deviance greater than 2187.8 is \\(\\approx 0\\), so there is significant evidence of lack-of-fit."
  },
  {
    "objectID": "slides/05-poisson-pt2.html#lack-of-fit",
    "href": "slides/05-poisson-pt2.html#lack-of-fit",
    "title": "Poisson Regression",
    "section": "Lack-of-fit",
    "text": "Lack-of-fit\nThere are a few potential reasons for observing lack-of-fit:\n\nMissing important interactions or higher-order terms\nMissing important variables (perhaps this means a more comprehensive data set is required)\nThere could be extreme observations causing the deviance to be larger than expected (assess based on the residual plots)\nThere could be a problem with the Poisson model\n\nOnly one parameter \\(\\lambda\\) to describe mean and variance\nMay need more flexibility in the model to handle overdispersion"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#overdispersion",
    "href": "slides/05-poisson-pt2.html#overdispersion",
    "title": "Poisson Regression",
    "section": "Overdispersion",
    "text": "Overdispersion\nOverdispersion: There is more variability in the response than what is implied by the Poisson model\n\n\n\n\nOverall\n\n\n\n\n\n\nmean\nvar\n\n\n\n\n3.685\n5.534\n\n\n\n\n\n\n\nby Location\n\n\n\n\n\n\nlocation\nmean\nvar\n\n\n\n\nCentralLuzon\n3.402\n4.152\n\n\nDavaoRegion\n3.390\n4.723\n\n\nIlocosRegion\n3.586\n5.402\n\n\nMetroManila\n3.707\n4.863\n\n\nVisayas\n3.902\n6.602"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#why-overdispersion-matters",
    "href": "slides/05-poisson-pt2.html#why-overdispersion-matters",
    "title": "Poisson Regression",
    "section": "Why overdispersion matters",
    "text": "Why overdispersion matters\nIf there is overdispersion, then there is more variation in the response than what’s implied by a Poisson model. This means\nThe standard errors of the model coefficients are artificially small\n\\(\\Rightarrow\\) The p-values are artificially small\n\\(\\Rightarrow\\) Could lead to models that are more complex than what is needed\n\nWe can take overdispersion into account by\n\ninflating standard errors by multiplying them by a dispersion factor\nusing a negative-binomial regression model"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#dispersion-parameter",
    "href": "slides/05-poisson-pt2.html#dispersion-parameter",
    "title": "Poisson Regression",
    "section": "Dispersion parameter",
    "text": "Dispersion parameter\nThe dispersion parameter is represented by \\(\\phi\\) \\[\\hat{\\phi} = \\frac{\\sum_{i=1}^{n}(\\text{Pearson residuals})^2}{n - p}\\]\nwhere \\(p\\) is the number of terms in the model (including the intercept)\n\n\nIf there is no overdispersion \\(\\hat{\\phi} = 1\\)\nIf there is overdispersion \\(\\hat{\\phi} &gt; 1\\)"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#accounting-for-dispersion",
    "href": "slides/05-poisson-pt2.html#accounting-for-dispersion",
    "title": "Poisson Regression",
    "section": "Accounting for dispersion",
    "text": "Accounting for dispersion\n\nWe inflate the standard errors of the coefficient by multiplying the variance by \\(\\hat{\\phi}\\)\n\n\\[SE_{Q}(\\hat{\\beta}) = \\sqrt{\\hat{\\phi}}  * SE(\\hat{\\beta})\\]\n“Q” stands for quasi-Poisson, since this is an ad-hoc solution - The process for model building and model comparison is called quasilikelihood (similar to likelihood without exact underlying distributions)"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#quasi-poisson-model",
    "href": "slides/05-poisson-pt2.html#quasi-poisson-model",
    "title": "Poisson Regression",
    "section": "Quasi-Poisson model",
    "text": "Quasi-Poisson model\n\nhh_age_loc_q &lt;- glm(total ~ age + I(age^2) + location, data = hh_data, \n                family = quasipoisson) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.3843\n0.2166\n-1.7744\n0.0762\n-0.8134\n0.0358\n\n\nage\n0.0704\n0.0082\n8.5665\n0.0000\n0.0544\n0.0866\n\n\nI(age^2)\n-0.0007\n0.0001\n-9.2000\n0.0000\n-0.0009\n-0.0006\n\n\nlocationDavaoRegion\n-0.0194\n0.0640\n-0.3030\n0.7619\n-0.1451\n0.1058\n\n\nlocationIlocosRegion\n0.0610\n0.0626\n0.9735\n0.3304\n-0.0620\n0.1837\n\n\nlocationMetroManila\n0.0545\n0.0561\n0.9703\n0.3320\n-0.0552\n0.1649\n\n\nlocationVisayas\n0.1121\n0.0497\n2.2574\n0.0241\n0.0156\n0.2103"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#poisson-vs.-quasi-poisson-models",
    "href": "slides/05-poisson-pt2.html#poisson-vs.-quasi-poisson-models",
    "title": "Poisson Regression",
    "section": "Poisson vs. Quasi-Poisson models",
    "text": "Poisson vs. Quasi-Poisson models\n\n\n\nPoisson\n\n\n\n\n\n\nterm\nestimate\nstd.error\n\n\n\n\n(Intercept)\n-0.3843\n0.1821\n\n\nage\n0.0704\n0.0069\n\n\nI(age^2)\n-0.0007\n0.0001\n\n\nlocationDavaoRegion\n-0.0194\n0.0538\n\n\nlocationIlocosRegion\n0.0610\n0.0527\n\n\nlocationMetroManila\n0.0545\n0.0472\n\n\nlocationVisayas\n0.1121\n0.0417\n\n\n\n\n\n\n\nQuasi-Poisson\n\n\n\n\n\n\nestimate\nstd.error\n\n\n\n\n-0.3843\n0.2166\n\n\n0.0704\n0.0082\n\n\n-0.0007\n0.0001\n\n\n-0.0194\n0.0640\n\n\n0.0610\n0.0626\n\n\n0.0545\n0.0561\n\n\n0.1121\n0.0497"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#quasi-poisson-inference-for-coefficients",
    "href": "slides/05-poisson-pt2.html#quasi-poisson-inference-for-coefficients",
    "title": "Poisson Regression",
    "section": "Quasi-Poisson: Inference for coefficients",
    "text": "Quasi-Poisson: Inference for coefficients\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\n\n\n\n\n(Intercept)\n-0.3843\n0.2166\n\n\nage\n0.0704\n0.0082\n\n\nI(age^2)\n-0.0007\n0.0001\n\n\nlocationDavaoRegion\n-0.0194\n0.0640\n\n\nlocationIlocosRegion\n0.0610\n0.0626\n\n\nlocationMetroManila\n0.0545\n0.0561\n\n\nlocationVisayas\n0.1121\n0.0497\n\n\n\n\n\n\n\nTest statistic\n\n\\[t = \\frac{\\hat{\\beta} - 0}{SE_{Q}(\\hat{\\beta})} \\sim t_{n-p}\\]"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#quasi-poisson-model-1",
    "href": "slides/05-poisson-pt2.html#quasi-poisson-model-1",
    "title": "Poisson Regression",
    "section": "Quasi-Poisson model",
    "text": "Quasi-Poisson model\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.3843\n0.2166\n-1.7744\n0.0762\n-0.8134\n0.0358\n\n\nage\n0.0704\n0.0082\n8.5665\n0.0000\n0.0544\n0.0866\n\n\nI(age^2)\n-0.0007\n0.0001\n-9.2000\n0.0000\n-0.0009\n-0.0006\n\n\nlocationDavaoRegion\n-0.0194\n0.0640\n-0.3030\n0.7619\n-0.1451\n0.1058\n\n\nlocationIlocosRegion\n0.0610\n0.0626\n0.9735\n0.3304\n-0.0620\n0.1837\n\n\nlocationMetroManila\n0.0545\n0.0561\n0.9703\n0.3320\n-0.0552\n0.1649\n\n\nlocationVisayas\n0.1121\n0.0497\n2.2574\n0.0241\n0.0156\n0.2103"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#negative-binomial-regression-model-1",
    "href": "slides/05-poisson-pt2.html#negative-binomial-regression-model-1",
    "title": "Poisson Regression",
    "section": "Negative binomial regression model",
    "text": "Negative binomial regression model\nAnother approach to handle overdispersion is to use a negative binomial regression model\n\nThis has more flexibility than the quasi-Poisson model, because there is a new parameter in addition to \\(\\lambda\\)\n\n\n\nLet \\(Y\\) be a negative binomial random variable, \\(Y\\sim NegBinom(r, p)\\), then\n\\[\\begin{align}P(Y = y_i) = {y_i + r - 1 \\choose r - 1}(1-p)^{y_i}p^r \\hspace{5mm} y_i = 0, 1, 2, \\ldots, \\infty \\\\\nE(Y) = \\frac{r(1-p)}{p} \\hspace{8mm} SD(Y) = \\sqrt{\\frac{r(1-p)}{p^2}}\\end{align}\\]"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#negative-binomial-regression-model-2",
    "href": "slides/05-poisson-pt2.html#negative-binomial-regression-model-2",
    "title": "Poisson Regression",
    "section": "Negative binomial regression model",
    "text": "Negative binomial regression model\n\n\nMain idea: Generate a \\(\\lambda\\) for each observation (household) and generate a count using the Poisson random variable with parameter \\(\\lambda\\)\n\nMakes the counts more dispersed than with a single parameter\n\nThink of it as a Poisson model such that \\(\\lambda\\) is also random \\[\\begin{aligned} &\\text{If }\\hspace{2mm} Y|\\lambda \\sim Poisson(\\lambda)\\\\\n&\\text{ and } \\lambda \\sim Gamma\\bigg(r, \\frac{1-p}{p}\\bigg)\\\\\n&\\text{ then } Y \\sim NegBinom(r, p)\\end{aligned}\\]"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#negative-binomial-regression-in-r",
    "href": "slides/05-poisson-pt2.html#negative-binomial-regression-in-r",
    "title": "Poisson Regression",
    "section": "Negative binomial regression in R",
    "text": "Negative binomial regression in R\nUse the glm.nb function in the MASS R package.\n\n\n\n\n\n\n\nCaution\n\n\nThe MASS package has a select function that conflicts with the select function in dplyr. You can avoid this by (1) always loading tidyverse after MASS, or (2) use MASS::glm.nb instead of loading the package."
  },
  {
    "objectID": "slides/05-poisson-pt2.html#negative-binomial-regression-in-r-1",
    "href": "slides/05-poisson-pt2.html#negative-binomial-regression-in-r-1",
    "title": "Poisson Regression",
    "section": "Negative binomial regression in R",
    "text": "Negative binomial regression in R\n\nhh_age_loc_nb &lt;- MASS::glm.nb(total ~ age + I(age^2) + location, data = hh_data)\ntidy(hh_age_loc_nb) |&gt; \n  kable(digits = 4)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.3753\n0.2076\n-1.8081\n0.0706\n\n\nage\n0.0699\n0.0079\n8.8981\n0.0000\n\n\nI(age^2)\n-0.0007\n0.0001\n-9.5756\n0.0000\n\n\nlocationDavaoRegion\n-0.0219\n0.0625\n-0.3501\n0.7262\n\n\nlocationIlocosRegion\n0.0577\n0.0615\n0.9391\n0.3477\n\n\nlocationMetroManila\n0.0562\n0.0551\n1.0213\n0.3071\n\n\nlocationVisayas\n0.1104\n0.0487\n2.2654\n0.0235"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#negative-binomial-vs.-quasi-poisson",
    "href": "slides/05-poisson-pt2.html#negative-binomial-vs.-quasi-poisson",
    "title": "Poisson Regression",
    "section": "Negative binomial vs. Quasi-Poisson",
    "text": "Negative binomial vs. Quasi-Poisson\n\n\n\nQuasi-Poisson\n\n\n\n\n\n\nterm\nestimate\nstd.error\n\n\n\n\n(Intercept)\n-0.3843\n0.2166\n\n\nage\n0.0704\n0.0082\n\n\nI(age^2)\n-0.0007\n0.0001\n\n\nlocationDavaoRegion\n-0.0194\n0.0640\n\n\nlocationIlocosRegion\n0.0610\n0.0626\n\n\nlocationMetroManila\n0.0545\n0.0561\n\n\nlocationVisayas\n0.1121\n0.0497\n\n\n\n\n\n\n\n\n\nNegative binomial\n\n\n\n\n\n\nestimate\nstd.error\n\n\n\n\n-0.3753\n0.2076\n\n\n0.0699\n0.0079\n\n\n-0.0007\n0.0001\n\n\n-0.0219\n0.0625\n\n\n0.0577\n0.0615\n\n\n0.0562\n0.0551\n\n\n0.1104\n0.0487"
  },
  {
    "objectID": "slides/05-poisson-pt2.html#references",
    "href": "slides/05-poisson-pt2.html#references",
    "title": "Poisson Regression",
    "section": "References",
    "text": "References\n\n\n\n🔗 STA 310 - Spring 2024\n\n\n\nRoback, Paul, and Julie Legler. 2021. Beyond multiple linear regression: applied generalized linear models and multilevel models in R. CRC Press."
  },
  {
    "objectID": "slides/01-welcome.html#teaching-team",
    "href": "slides/01-welcome.html#teaching-team",
    "title": "Welcome to STA 310!",
    "section": "Teaching Team",
    "text": "Teaching Team\n\n\nInstructor:\nProfessor Maria Tackett\nOld Chem 118B\nmaria.tackett@duke.edu\n\nTeaching assistant\nHun Kang\nPhD student in statistics"
  },
  {
    "objectID": "slides/01-welcome.html#course-logistics",
    "href": "slides/01-welcome.html#course-logistics",
    "title": "Welcome to STA 310!",
    "section": "Course logistics",
    "text": "Course logistics\nLectures\nMondays and Wednesdays, 3:05 - 4:20pm, Physics 205\n\nLabs\nLab 01: Thursdays, 3:05 - 4:20pm, Link #5\nLab 02: Thursdays, 4:45- 5:55pm, Link #5"
  },
  {
    "objectID": "slides/01-welcome.html#generalized-linear-models",
    "href": "slides/01-welcome.html#generalized-linear-models",
    "title": "Welcome to STA 310!",
    "section": "Generalized Linear Models",
    "text": "Generalized Linear Models\nIn statistics, a generalized linear model (GLM) is a flexible generalization of ordinary linear regression. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.1\n\nExample: Logistic regression\n\\[\\begin{aligned}\\pi = P(y = 1 | x) \\hspace{2mm} &\\Rightarrow \\hspace{2mm} \\text{Link function: } \\log\\big(\\frac{\\pi}{1-\\pi}\\big) \\\\\n&\\Rightarrow \\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1~x\\end{aligned}\\]\n\nSouce: Generalized linear model"
  },
  {
    "objectID": "slides/01-welcome.html#course-learning-objectives",
    "href": "slides/01-welcome.html#course-learning-objectives",
    "title": "Welcome to STA 310!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to …\n\n\ndescribe generalized linear models (GLMs) as a unified framework.\nexplain how specific models fit into the GLM framework, including extensions for correlated data.\nidentify the appropriate model given the data and analysis objective.\nanalyze real-world data by fitting and interpreting GLMs.\nuse R for analysis, Quarto to write reports, git for version control, and GitHub for collaboration.\neffectively communicate results from statistical analyses to a general audience in writing and oral presentations."
  },
  {
    "objectID": "slides/01-welcome.html#course-topics",
    "href": "slides/01-welcome.html#course-topics",
    "title": "Welcome to STA 310!",
    "section": "Course topics",
    "text": "Course topics\nGeneralized Linear Models\n\nIntroduce models for non-normal response variables\nEstimation, interpretation, and inference\nMathematical details of GLMs as a unified framework\n\n\nModeling correlated data\n\nIntroduce multilevel models for correlated and longitudinal data\nEstimation, interpretation, and inference\nMathematical details, particularly diving into covariance structures"
  },
  {
    "objectID": "slides/01-welcome.html#glms-in-practice",
    "href": "slides/01-welcome.html#glms-in-practice",
    "title": "Welcome to STA 310!",
    "section": "GLMs in practice",
    "text": "GLMs in practice\n\n\n\n\n\n“…we used negative binomial regression to model the association between the number of questions produced, race, and group after adjusting for the additional covariates age and years of education. Poisson and zero-inflated Poisson regression models were also considered…the negative binomial model was a good fit for the data given the overdispersion in the distribution of number of questions asked.”1\nFannin, D. K., Elleby, J., Tackett, M., & Minga, J. (2023). Intersectionality of Race and Question-Asking in Women After Right Hemisphere Brain Damage. Journal of Speech, Language, and Hearing Research, 66(1), 314-324."
  },
  {
    "objectID": "slides/01-welcome.html#glms-in-practice-1",
    "href": "slides/01-welcome.html#glms-in-practice-1",
    "title": "Welcome to STA 310!",
    "section": "GLMs in practice",
    "text": "GLMs in practice\n\n\n\n\n\n” …a logistic regression model is used to test how the likelihood of a foul is affected by which team is the home team, the foul differential, and the score differential…The logistic regression was run under several specifications … using clustered observation standard errors, with each game as a cluster. This is done as an attempt to adjust for the fact that observations may not be independent as required under the logistic specification.1\n\n\n\n\nAnderson, K. J., & Pierce, D. A. (2009). Officiating bias: The effect of foul differential on foul calls in NCAA basketball. Journal of sports sciences, 27(7), 687-694."
  },
  {
    "objectID": "slides/01-welcome.html#meet-your-classmates-1",
    "href": "slides/01-welcome.html#meet-your-classmates-1",
    "title": "Welcome to STA 310!",
    "section": "Meet your classmates!",
    "text": "Meet your classmates!\n\nGet in groups of 2 - 3\nEach person in the group…\n\nIntroduce yourself\nShare a boring fact about yourself\n\nEveryone will introduce one person from your group to the class"
  },
  {
    "objectID": "slides/01-welcome.html#pre-reqs",
    "href": "slides/01-welcome.html#pre-reqs",
    "title": "Welcome to STA 310!",
    "section": "Pre-reqs",
    "text": "Pre-reqs\nPre-reqs\nSTA 210 and STA 230 / STA 240\n\nBackground knowledge\n\n\nStatistical methods\n\nLinear and logistic regression\nStatistical inference\nBasic understanding of random variables\n\n\nComputing\n\nUsing R for data analysis\nWriting reports using Quarto\nVersion control and collaboration using GitHub"
  },
  {
    "objectID": "slides/01-welcome.html#course-toolkit",
    "href": "slides/01-welcome.html#course-toolkit",
    "title": "Welcome to STA 310!",
    "section": "Course toolkit",
    "text": "Course toolkit\n\n\nsta310-sp24.netlify.app"
  },
  {
    "objectID": "slides/01-welcome.html#course-toolkit-1",
    "href": "slides/01-welcome.html#course-toolkit-1",
    "title": "Welcome to STA 310!",
    "section": "Course toolkit",
    "text": "Course toolkit\nCanvas: canvas.duke.edu/courses/25310\n\nAnnouncements\nGradebook\n\nGitHub: github.com/sta310-sp24\n\nHomework and projects\n\nSlack (link in Canvas)\n\nClass discussion forum"
  },
  {
    "objectID": "slides/01-welcome.html#class-meetings",
    "href": "slides/01-welcome.html#class-meetings",
    "title": "Welcome to STA 310!",
    "section": "Class Meetings",
    "text": "Class Meetings\n\n\nLectures\n\nSome traditional lecture\nShort individual and group activities\nBring fully-charged laptop / tablet to use R\n\n\nLabs (start January 18)\n\nWork on class assignments with TA support\nWork on projects with teammates\n\n\n\n\n\nAttendance is strongly expected (if you are healthy!)"
  },
  {
    "objectID": "slides/01-welcome.html#readings",
    "href": "slides/01-welcome.html#readings",
    "title": "Welcome to STA 310!",
    "section": "Readings",
    "text": "Readings\n\n\n\n\n\n\n\n\n\nPrimary textbook: Beyond Multiple Linear Regression by Roback and Legler\nOther texts:\n\nR for Data Science (2nd edition) by Wickham, Çetinkaya-Rundel, and Grolemund\nTidy Modeling with R by Kuhn and Silge\n\nArticles and videos periodically assigned"
  },
  {
    "objectID": "slides/01-welcome.html#r-and-rstudio",
    "href": "slides/01-welcome.html#r-and-rstudio",
    "title": "Welcome to STA 310!",
    "section": "R and RStudio",
    "text": "R and RStudio\n1️⃣ Install R and RStudio on your laptop\n\nClick here for instructions to install RStudio and configure git\n\n\nor\n\n2️⃣ Access RStudio through Docker container provided by Duke OIT\n\nReserve a generic RStudio container (there is no course specific container)"
  },
  {
    "objectID": "slides/01-welcome.html#github",
    "href": "slides/01-welcome.html#github",
    "title": "Welcome to STA 310!",
    "section": "GitHub",
    "text": "GitHub\n\nGitHub course organization: github.com/sta310-sp24\nWill receive and submit assignments through a private GitHub repo in the course Github organization\nWill receive assignment feedback as a GitHub issue. Final grades on each assignment will be available in Canvas\nAll work and feedback are private"
  },
  {
    "objectID": "slides/01-welcome.html#slack",
    "href": "slides/01-welcome.html#slack",
    "title": "Welcome to STA 310!",
    "section": "Slack",
    "text": "Slack\n\nOnline discussion forum (like Piazza, Ed Discussion, etc.)\nPlatform to ask questions about course content, logistics, assignments, etc.\nContent organized by channels. Before posting, please browse previous posts to see if your question has already been answered. If not, please post your question in the relevant channel.\nQuestions about grades, absences, and other private matters should be emailed to me with “STA 310” in the subject line."
  },
  {
    "objectID": "slides/01-welcome.html#homework-40",
    "href": "slides/01-welcome.html#homework-40",
    "title": "Welcome to STA 310!",
    "section": "Homework (40%)",
    "text": "Homework (40%)\n\n6 individual assignments\nCombination of conceptual questions, guided analyses, and open-ended analyses\nWill be submitted in your private GitHub repo\nLowest homework grade is dropped"
  },
  {
    "objectID": "slides/01-welcome.html#quizzes-20",
    "href": "slides/01-welcome.html#quizzes-20",
    "title": "Welcome to STA 310!",
    "section": "Quizzes (20%)",
    "text": "Quizzes (20%)\n\n6 individual online quizzes\nCovers content since the previous quiz, including readings, lecture notes, in-class activities, and homework\nLowest quiz grade is dropped"
  },
  {
    "objectID": "slides/01-welcome.html#projects",
    "href": "slides/01-welcome.html#projects",
    "title": "Welcome to STA 310!",
    "section": "Projects",
    "text": "Projects\n\nProject 01 (Team project, 10%)\n\nTeam project to read and evaluate academic article that includes model for non-normal response variable\nIncludes in-class presentation and short write up\n\nProject 02 (Team project, 10%)\n\nTeam project to evaluate article and conduct analysis focused on models for correlated data\nIncludes in-class presentation and short write up\n\nFinal project (20%)\n\nIndividual project to apply what you’ve learned to analyze correlated data\nIncludes write up"
  },
  {
    "objectID": "slides/01-welcome.html#grading",
    "href": "slides/01-welcome.html#grading",
    "title": "Welcome to STA 310!",
    "section": "Grading",
    "text": "Grading\nFinal grades will be calculated as follows\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n40%\n\n\nProject 01\n10%\n\n\nProject 02\n10%\n\n\nFinal project\n20%\n\n\nQuizzes\n20%\n\n\n\n\nSee syllabus for letter grade thresholds."
  },
  {
    "objectID": "slides/01-welcome.html#course-community-1",
    "href": "slides/01-welcome.html#course-community-1",
    "title": "Welcome to STA 310!",
    "section": "Course community",
    "text": "Course community\n\nUphold the Duke Community Standard:\n\n\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors;\nI will act if the Standard is compromised.\n\n\n\n\n\n\nCommit to respect, honor, and celebrate our diverse community\nCommit to being part of a learning environment that is welcoming and accessible to everyone"
  },
  {
    "objectID": "slides/01-welcome.html#accessibility",
    "href": "slides/01-welcome.html#accessibility",
    "title": "Welcome to STA 310!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nIf you have documented accommodations from SDAO, please send the documentation as soon as possible.\nI am committed to making all course activities and materials accessible. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "slides/01-welcome.html#support",
    "href": "slides/01-welcome.html#support",
    "title": "Welcome to STA 310!",
    "section": "Support",
    "text": "Support\n\nOffice hours to meet with a member of the teaching team.\n\nFind the schedule in the syllabus and course webpage\nOffice hours begin January 16\nPlease email me if you’d like to meet before then\n\nSlack for questions about course logistics, content, and assignments\nEmail for questions not appropriate for Slack, e.g., regarding personal matters or grades\n\nPlease put STA 310 in the subject line\n\n\nSee the syllabus and support page for additional academic and mental health and wellness resources"
  },
  {
    "objectID": "slides/01-welcome.html#covid-19-and-other-illness",
    "href": "slides/01-welcome.html#covid-19-and-other-illness",
    "title": "Welcome to STA 310!",
    "section": "COVID-19 and other illness",
    "text": "COVID-19 and other illness\n\nPlease do not come to class if you have tested positive for COVID-19, have possible symptoms and have not yet been tested, or have other illness.\nRead and follow the university guidelines regarding COVID-19 at coronavirus.duke.edu."
  },
  {
    "objectID": "slides/01-welcome.html#late-work",
    "href": "slides/01-welcome.html#late-work",
    "title": "Welcome to STA 310!",
    "section": "Late work",
    "text": "Late work\n\nHomework will be accepted up to 48 hours after the deadline. There will be a 5% deduction for each 24-hour period the assignment is late.\nNo late work is accepted on quizzes, and there are no makeups for missed quizzes.\nLate policy for projects:\n\nPresentation: Late presentations are not accepted and there are no make ups for missed presentations.\nWrite up: There will be a 5% deduction for write ups submitted late but the same day, a 10% deduction for write ups submitted the next day, and a 15% deduction for write ups submitted two days late (by 11:59pm). No credit given for write ups submitted more than 2 days after the deadline.\nPeer evaluation: No late work is accepted on peer evaluations."
  },
  {
    "objectID": "slides/01-welcome.html#academic-integrity-and-collaboration",
    "href": "slides/01-welcome.html#academic-integrity-and-collaboration",
    "title": "Welcome to STA 310!",
    "section": "Academic integrity and collaboration",
    "text": "Academic integrity and collaboration\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level.\nYou may not discuss or otherwise work with others on quizzes.\nFor the projects collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project across teams.\nReusing code: Unless explicitly stated otherwise, you may make use of online resources (e.g. StackOverflow) for coding examples on assignments. If you directly use code from an outside source (or use it as inspiration), you must explicitly cite where you obtained the code."
  },
  {
    "objectID": "slides/01-welcome.html#use-of-artificial-intelligence-ai",
    "href": "slides/01-welcome.html#use-of-artificial-intelligence-ai",
    "title": "Welcome to STA 310!",
    "section": "Use of artificial intelligence (AI)",
    "text": "Use of artificial intelligence (AI)\n\nYou should treat AI tools, such as ChatGPT, the same as other online resources.\nThere are two guiding principles that govern how you can use AI in this course:1\n\n(1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning.\n(2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\n\nThese guiding principles are based on Course Policies related to ChatGPT and other AI Tools developed by Joel Gladd, Ph.D.↩︎"
  },
  {
    "objectID": "slides/01-welcome.html#use-of-artificial-intelligence-ai-1",
    "href": "slides/01-welcome.html#use-of-artificial-intelligence-ai-1",
    "title": "Welcome to STA 310!",
    "section": "Use of artificial intelligence (AI)",
    "text": "Use of artificial intelligence (AI)\n✅ AI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code.\n❌ No AI tools for narrative: Unless instructed otherwise, AI is not permitted for writing narrative on assignments.\n\n\n\n\n\n\n\nImportant\n\n\nIn general, you may use AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content."
  },
  {
    "objectID": "slides/01-welcome.html#set-up-course-toolkit",
    "href": "slides/01-welcome.html#set-up-course-toolkit",
    "title": "Welcome to STA 310!",
    "section": "Set up course toolkit",
    "text": "Set up course toolkit\nSee announcement on Canvas and complete the following:\n\nSign up for Slack\nComplete STA 310 Student Survey\n\nNeed to provide GitHub username. If you do not have a GitHub username, go to github.com to sign up and click here for advice on making a username."
  },
  {
    "objectID": "slides/01-welcome.html#next-class",
    "href": "slides/01-welcome.html#next-class",
    "title": "Welcome to STA 310!",
    "section": "Next Class",
    "text": "Next Class\n(Wednesday, January 17)\n\nUnderstand statistical models\nReview multiple linear regression"
  },
  {
    "objectID": "slides/01-welcome.html#to-do-before-next-time",
    "href": "slides/01-welcome.html#to-do-before-next-time",
    "title": "Welcome to STA 310!",
    "section": "To do before next time",
    "text": "To do before next time\n\nInstall RStudio and configure git (or reserve container). See computing page for instructions.\n\nWill do application exercise next class\n\nRead syllabus and let me know if you have any questions\nSee Prepare for Jan 17 lecture\n\n\n\n\n🔗 STA 310 - Spring 2024"
  },
  {
    "objectID": "slides/04-poisson.html#computing-set-up",
    "href": "slides/04-poisson.html#computing-set-up",
    "title": "Poisson Regression",
    "section": "Computing set up",
    "text": "Computing set up\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(gridExtra)\n\n\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n\ncolors &lt;- tibble::tibble(green = \"#B5BA72\")"
  },
  {
    "objectID": "slides/04-poisson.html#topics",
    "href": "slides/04-poisson.html#topics",
    "title": "Poisson Regression",
    "section": "Topics",
    "text": "Topics\n\nDescribe properties of the Poisson random variable\nWrite the mathematical equation of the Poisson regression model\nDescribe how the Poisson regression differs from least-squares regression\nInterpret the coefficients for the Poisson regression model\nCompare two Poisson regression models\n\n\n\nNotes based on Section 4.4 - 4.5 of Roback and Legler (2021) unless noted otherwise."
  },
  {
    "objectID": "slides/04-poisson.html#scenarios-to-use-poisson-regression",
    "href": "slides/04-poisson.html#scenarios-to-use-poisson-regression",
    "title": "Poisson Regression",
    "section": "Scenarios to use Poisson regression",
    "text": "Scenarios to use Poisson regression\n\nDoes the number of employers conducting on-campus interviews during a year differ for public and private colleges?\nDoes the daily number of asthma-related visits to an Emergency Room differ depending on air pollution indices?\nDoes the number of paint defects per square foot of wall differ based on the years of experience of the painter?"
  },
  {
    "objectID": "slides/04-poisson.html#scenarios-to-use-poisson-regression-1",
    "href": "slides/04-poisson.html#scenarios-to-use-poisson-regression-1",
    "title": "Poisson Regression",
    "section": "Scenarios to use Poisson regression",
    "text": "Scenarios to use Poisson regression\n\nDoes the number of employers conducting on-campus interviews during a year differ for public and private colleges?\nDoes the daily number of asthma-related visits to an Emergency Room differ depending on air pollution indices?\nDoes the number of paint defects per square foot of wall differ based on the years of experience of the painter?\n\n\n\nEach response variable is a count per a unit of time or space."
  },
  {
    "objectID": "slides/04-poisson.html#poisson-distribution",
    "href": "slides/04-poisson.html#poisson-distribution",
    "title": "Poisson Regression",
    "section": "Poisson distribution",
    "text": "Poisson distribution\nLet \\(Y\\) be the number of events in a given unit of time or space. Then \\(Y\\) can be modeled using a Poisson distribution\n\\[P(Y=y) = \\frac{e^{-\\lambda}\\lambda^y}{y!} \\hspace{10mm} y=0,1,2,\\ldots, \\infty\\]\n\nFeatures\n\n\\(E(Y) = Var(Y) = \\lambda\\)\nThe distribution is typically skewed right, particularly if \\(\\lambda\\) is small\nThe distribution becomes more symmetric as \\(\\lambda\\) increases\n\nIf \\(\\lambda\\) is sufficiently large, it can be approximated using a normal distribution (Click here for an example.)"
  },
  {
    "objectID": "slides/04-poisson.html#example1",
    "href": "slides/04-poisson.html#example1",
    "title": "Poisson Regression",
    "section": "Example1",
    "text": "Example1\nThe annual number of earthquakes registering at least 2.5 on the Richter Scale and having an epicenter within 40 miles of downtown Memphis follows a Poisson distribution with mean 6.5. What is the probability there will be at 3 or fewer such earthquakes next year?\n\n\\[P(Y \\leq 3) = P(Y = 0) + P(Y = 1) + P(Y = 2) + P(Y = 3)\\]\n\n\n\\[ = \\frac{e^{-6.5}6.5^0}{0!} + \\frac{e^{-6.5}6.5^1}{1!} + \\frac{e^{-6.5}6.5^2}{2!} + \\frac{e^{-6.5}6.5^3}{3!}\\]\n\\[ = 0.112\\]\n\n\n\nppois(3, 6.5)\n\n[1] 0.1118496\n\n\n\nExample adapted from Introduction to Probability Theory Example 28-2"
  },
  {
    "objectID": "slides/04-poisson.html#the-data-household-size-in-the-philippines",
    "href": "slides/04-poisson.html#the-data-household-size-in-the-philippines",
    "title": "Poisson Regression",
    "section": "The data: Household size in the Philippines",
    "text": "The data: Household size in the Philippines\nThe data fHH1.csv come from the 2015 Family Income and Expenditure Survey conducted by the Philippine Statistics Authority.\nGoal: Understand the association between household size and various characteristics of the household\nResponse:\n\ntotal: Number of people in the household other than the head\n\n\n\nPredictors:\n\nlocation: Where the house is located\nage: Age of the head of household\nroof: Type of roof on the residence (proxy for wealth)\n\n\nOther variables:\n\nnumLT5: Number in the household under 5 years old"
  },
  {
    "objectID": "slides/04-poisson.html#the-data",
    "href": "slides/04-poisson.html#the-data",
    "title": "Poisson Regression",
    "section": "The data",
    "text": "The data\n\nhh_data &lt;- read_csv(\"data/fHH1.csv\")\nhh_data |&gt; slice(1:5) |&gt; kable()\n\n\n\n\nlocation\nage\ntotal\nnumLT5\nroof\n\n\n\n\nCentralLuzon\n65\n0\n0\nPredominantly Strong Material\n\n\nMetroManila\n75\n3\n0\nPredominantly Strong Material\n\n\nDavaoRegion\n54\n4\n0\nPredominantly Strong Material\n\n\nVisayas\n49\n3\n0\nPredominantly Strong Material\n\n\nMetroManila\n74\n3\n0\nPredominantly Strong Material"
  },
  {
    "objectID": "slides/04-poisson.html#response-variable",
    "href": "slides/04-poisson.html#response-variable",
    "title": "Poisson Regression",
    "section": "Response variable",
    "text": "Response variable\n\n\n\n\n\n\nmean\nvar\n\n\n\n\n3.685\n5.534"
  },
  {
    "objectID": "slides/04-poisson.html#why-the-least-squares-model-doesnt-work",
    "href": "slides/04-poisson.html#why-the-least-squares-model-doesnt-work",
    "title": "Poisson Regression",
    "section": "Why the least-squares model doesn’t work",
    "text": "Why the least-squares model doesn’t work\nThe goal is to model \\(\\lambda\\), the expected number of people in the household (other than the head), as a function of the predictors (covariates)\n\nWe might be tempted to try a linear model \\[\\lambda_i = \\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + \\dots + \\beta_px_{ip}\\]\n\n\nThis model won’t work because…\n\nIt could produce negative values of \\(\\lambda\\) for certain values of the predictors\nThe equal variance assumption required to conduct inference for linear regression is violated."
  },
  {
    "objectID": "slides/04-poisson.html#poisson-regression-model",
    "href": "slides/04-poisson.html#poisson-regression-model",
    "title": "Poisson Regression",
    "section": "Poisson regression model",
    "text": "Poisson regression model\nIf \\(Y_i \\sim Poisson\\) with \\(\\lambda = \\lambda_i\\) for the given values \\(x_{i1}, \\ldots, x_{ip}\\), then\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_p x_{ip}\\]\n\n\nEach observation can have a different value of \\(\\lambda\\) based on its value of the predictors \\(x_1, \\ldots, x_p\\)\n\\(\\lambda\\) determines the mean and variance, so we don’t need to estimate a separate error term"
  },
  {
    "objectID": "slides/04-poisson.html#poisson-vs.-multiple-linear-regression",
    "href": "slides/04-poisson.html#poisson-vs.-multiple-linear-regression",
    "title": "Poisson Regression",
    "section": "Poisson vs. multiple linear regression",
    "text": "Poisson vs. multiple linear regression\n\n\n\n\n\nRegression models: Linear regression (left) and Poisson regression (right).\n\n\n\n\n\n\nFigures recreated from BMLR Figure 4.1"
  },
  {
    "objectID": "slides/04-poisson.html#assumptions-for-poisson-regression",
    "href": "slides/04-poisson.html#assumptions-for-poisson-regression",
    "title": "Poisson Regression",
    "section": "Assumptions for Poisson regression",
    "text": "Assumptions for Poisson regression\n\n\nPoisson response: The response variable is a count per unit of time or space, described by a Poisson distribution, at each level of the predictor(s)\nIndependence: The observations must be independent of one another\nMean = Variance: The mean equals the variance\nLinearity: The log of the mean rate, \\(\\log(\\lambda)\\), must be a linear function of the predictor(s)"
  },
  {
    "objectID": "slides/04-poisson.html#model-1-household-vs.-age",
    "href": "slides/04-poisson.html#model-1-household-vs.-age",
    "title": "Poisson Regression",
    "section": "Model 1: Household vs. Age",
    "text": "Model 1: Household vs. Age\n\nmodel1 &lt;- glm(total ~ age, data = hh_data, family = poisson)\n\ntidy(model1) |&gt; \n  kable(digits = 4)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n1.5499\n0.0503\n30.8290\n0\n\n\nage\n-0.0047\n0.0009\n-5.0258\n0\n\n\n\n\n\n\\[\\log(\\hat{\\lambda}) = 1.5499  - 0.0047 ~ age\\]"
  },
  {
    "objectID": "slides/04-poisson.html#is-the-coefficient-of-age-statistically-significant",
    "href": "slides/04-poisson.html#is-the-coefficient-of-age-statistically-significant",
    "title": "Poisson Regression",
    "section": "Is the coefficient of age statistically significant?",
    "text": "Is the coefficient of age statistically significant?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n1.5499\n0.0503\n30.8290\n0\n1.4512\n1.6482\n\n\nage\n-0.0047\n0.0009\n-5.0258\n0\n-0.0065\n-0.0029\n\n\n\n\n\n\\[H_0: \\beta_1 = 0 \\hspace{2mm} \\text{ vs. } \\hspace{2mm} H_a: \\beta_1 \\neq 0\\]\n\nTest statistic\n\\[Z = \\frac{\\hat{\\beta}_1 - 0}{SE(\\hat{\\beta}_1)} = \\frac{-0.0047 - 0}{0.0009} = -5.026 \\text{ (using exact values)}\\]\n\n\nP-value\n\\[P(|Z| &gt; |-5.026|) = 5.01 \\times 10^{-7} \\approx 0\\]"
  },
  {
    "objectID": "slides/04-poisson.html#what-are-plausible-values-for-the-coefficient-of-age",
    "href": "slides/04-poisson.html#what-are-plausible-values-for-the-coefficient-of-age",
    "title": "Poisson Regression",
    "section": "What are plausible values for the coefficient of age?",
    "text": "What are plausible values for the coefficient of age?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n1.5499\n0.0503\n30.8290\n0\n1.4512\n1.6482\n\n\nage\n-0.0047\n0.0009\n-5.0258\n0\n-0.0065\n-0.0029\n\n\n\n\n\n95% confidence interval for the coefficient of age\n\\[\\hat{\\beta}_1 \\pm z^{*}\\times SE(\\hat{\\beta}_1)\\]\nwhere \\(z^* \\sim N(0, 1)\\) \\[-0.0047 \\pm 1.96 \\times 0.0009 = \\mathbf{(-.0065, -0.0029)}\\]\n\nInterpret the interval in terms of the change in mean household size."
  },
  {
    "objectID": "slides/04-poisson.html#estimating-beta_0-and-beta_1-1",
    "href": "slides/04-poisson.html#estimating-beta_0-and-beta_1-1",
    "title": "Poisson Regression",
    "section": "Estimating \\(\\beta_0\\) and \\(\\beta_1\\)",
    "text": "Estimating \\(\\beta_0\\) and \\(\\beta_1\\)\n\n1.5499 and -0.0047 are the estimates of \\(\\beta_0\\) and \\(\\beta_1\\) respectively.\nHow were these values determined?\nLet’s take a look at the first five rows of data:\n\n\n\n\n\n\n\nlocation\nage\ntotal\nnumLT5\nroof\n\n\n\n\nCentralLuzon\n65\n0\n0\nPredominantly Strong Material\n\n\nMetroManila\n75\n3\n0\nPredominantly Strong Material\n\n\nDavaoRegion\n54\n4\n0\nPredominantly Strong Material\n\n\nVisayas\n49\n3\n0\nPredominantly Strong Material\n\n\nMetroManila\n74\n3\n0\nPredominantly Strong Material"
  },
  {
    "objectID": "slides/04-poisson.html#likelihood",
    "href": "slides/04-poisson.html#likelihood",
    "title": "Poisson Regression",
    "section": "Likelihood",
    "text": "Likelihood\nThen the likelihood for those five observations is\n\\[Likelihood =P(Y_1 = 0)P(Y_2 = 3)P(Y_3 = 4)P(Y_4 = 3)P(Y_5 = 3)\n\\]\n\nThe Y’s follow a Poisson distribution, so this equals\n\\[\nLikelihood = \\frac{e^{-\\lambda_1}\\lambda_1^0}{0!} * \\frac{e^{-\\lambda_2}\\lambda_2^3}{3!} * \\frac{e^{-\\lambda_3}\\lambda_3^4}{4!} *\\frac{e^{-\\lambda_4}\\lambda_4^3}{3!} * \\frac{e^{-\\lambda_5}\\lambda_5^3}{3!}\n\\]\nwhere \\(\\lambda_i\\) can differ for each household based on its value of age."
  },
  {
    "objectID": "slides/04-poisson.html#log-likelihood",
    "href": "slides/04-poisson.html#log-likelihood",
    "title": "Poisson Regression",
    "section": "Log-likelihood",
    "text": "Log-likelihood\nLet’s take the log of the likelihood, as this will be easier to maximize than the likelihood itself.\n\\[\n\\begin{align}\nlogL =& -\\lambda_1 + 0\\log(\\lambda_1) - \\lambda_2 + 3\\log(\\lambda_2) - \\lambda_3 + 4\\log(\\lambda_3)\\\\ &- \\lambda_4 + 3\\log(\\lambda_4) - \\lambda_5 + 3\\log(\\lambda_5) \\\\ &+ C\n\\end{align}\n\\]\n\n\n\n\n\n\nNote\n\n\nWe are going to maximize with respect to \\(\\lambda\\), we will drop the constant term \\(C\\) moving forward."
  },
  {
    "objectID": "slides/04-poisson.html#log-likelihood-1",
    "href": "slides/04-poisson.html#log-likelihood-1",
    "title": "Poisson Regression",
    "section": "Log-likelihood",
    "text": "Log-likelihood\nBecause we’re fitting a Poisson regression model, we know\n\\[\n\\log(\\lambda_i) = \\beta_0 + \\beta_1~age_i \\hspace{6mm} and \\hspace{6mm} \\lambda_i = e^{\\beta_0 + \\beta_1~age_i}\n\\]\n\nPlugging these formulas and the respective ages into \\(logL\\), we have\n\\[\\begin{align}\nlogL \\propto& - \\e^{\\beta_0 + \\beta_1*65} + 0*(\\beta_0 + \\beta_1*65)\\\\\n&- \\e^{\\beta_0 + \\beta_1*75} + 3*(\\beta_0 + \\beta_1*75)\\\\\n&- \\e^{\\beta_0 + \\beta_1*54} + 4*(\\beta_0 + \\beta_1*54)\\\\\n& -\\e^{\\beta_0 + \\beta_1*49}  + 3*(\\beta_0 + \\beta_1*49) \\\\\n&-\\e^{\\beta_0 + \\beta_1*74} + 3*(\\beta_0 + \\beta_1*74)\n\\end{align}\\]"
  },
  {
    "objectID": "slides/04-poisson.html#log-likelihood-2",
    "href": "slides/04-poisson.html#log-likelihood-2",
    "title": "Poisson Regression",
    "section": "Log-likelihood",
    "text": "Log-likelihood\nExpanding this to the entire data set, we have\n\\[\nlogL \\propto \\sum_{i=1}^{1500} -e^{\\beta_0 + \\beta_1age_i} + total_i (\\beta_0 + \\beta_1age_i)\n\\]\n\nCan use different numerical methods to try different values of \\(\\beta_0\\) and \\(\\beta_1\\) and find the combination that maximizes \\(logL\\) ."
  },
  {
    "objectID": "slides/04-poisson.html#iteratively-reweighted-least-squares-irls",
    "href": "slides/04-poisson.html#iteratively-reweighted-least-squares-irls",
    "title": "Poisson Regression",
    "section": "Iteratively reweighted least-squares (IRLS)",
    "text": "Iteratively reweighted least-squares (IRLS)\n\nIteratively reweighted least-squares (IRLS) is used to find the MLEs\nNelder and Wedderburn (1972) show that under certain specifications of the weights and a modified response variable, the estimates found using IRLS are equivalent to the MLEs."
  },
  {
    "objectID": "slides/04-poisson.html#irls-procedure",
    "href": "slides/04-poisson.html#irls-procedure",
    "title": "Poisson Regression",
    "section": "IRLS procedure",
    "text": "IRLS procedure\n\nFind initial starting values \\(\\hat{\\theta}_i\\), the model parameter ( \\(\\hat{\\theta}_i = \\hat{\\lambda}_i\\) in the case of Poisson regression)\nCalculate the working response values \\(z_i\\).\nCalculate the working weights \\(W_i\\).\nFind the coefficient estimates of the weighted least squares model.\n\n\\[z_i = \\beta_0 + \\beta_1 x \\hspace{5mm} \\text{ with weights }W_i\\]\nThe estimates \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) are the estimates for the model coefficients.\n\nUse \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) to calculate updated values of \\(\\hat{\\theta}_i\\) and repeat steps 2 - 4 until convergence.\n\n\n\nSteps from Dunn, Smyth, et al. (2018)."
  },
  {
    "objectID": "slides/04-poisson.html#irls-set-up",
    "href": "slides/04-poisson.html#irls-set-up",
    "title": "Poisson Regression",
    "section": "IRLS Set up",
    "text": "IRLS Set up\nWorking response: Modified response variable at each step of the iteration.\n\\[z_i = g(\\theta) + g'(\\theta)(y_i - \\theta_i)\\]\nwhere \\(g(\\theta)\\) is the link function. (We will talk all about link functions in Chapter 5)\n\nFor Poisson regression \\(g(\\theta) = \\log(\\lambda)\\)\n\\[z_i = \\log(\\lambda_i) + \\frac{(y_i - \\lambda_i)}{\\lambda_i}\\]\n\n\nWorking Weights: Weights applied to the observations at each step of the iteration\n\\[W_i = \\frac{\\theta^2}{Var(Y)} \\hspace{5mm} \\Rightarrow \\hspace{5mm}  W_i = \\frac{\\lambda^2}{\\lambda} =  \\lambda \\text{ for Poisson regression}\\]"
  },
  {
    "objectID": "slides/04-poisson.html#looking-ahead",
    "href": "slides/04-poisson.html#looking-ahead",
    "title": "Poisson Regression",
    "section": "Looking ahead",
    "text": "Looking ahead\n\nFor next time - Chapter 4 - Poisson Regression\n\nSections 4.6, 4.10"
  },
  {
    "objectID": "slides/04-poisson.html#references",
    "href": "slides/04-poisson.html#references",
    "title": "Poisson Regression",
    "section": "References",
    "text": "References\n\n\n\n🔗 STA 310 - Spring 2024\n\n\n\nDunn, Peter K, Gordon K Smyth, et al. 2018. Generalized Linear Models with Examples in r. Vol. 53. Springer.\n\n\nNelder, John Ashworth, and Robert WM Wedderburn. 1972. “Generalized Linear Models.” Journal of the Royal Statistical Society Series A: Statistics in Society 135 (3): 370–84.\n\n\nRoback, Paul, and Julie Legler. 2021. Beyond multiple linear regression: applied generalized linear models and multilevel models in R. CRC Press."
  },
  {
    "objectID": "slides/02-mlr-review.html#announcements",
    "href": "slides/02-mlr-review.html#announcements",
    "title": "Review of multiple linear regression",
    "section": "Announcements",
    "text": "Announcements\n\nHW 01 due Wed, Jan 24 at 11:59pm\n\nReleased Thursday morning\n\nLabs start Thursday\nCheck website for office hours schedule\nAdded a Slack channel #internships-research-opportunities (optional)"
  },
  {
    "objectID": "slides/02-mlr-review.html#computing-set-up",
    "href": "slides/02-mlr-review.html#computing-set-up",
    "title": "Review of multiple linear regression",
    "section": "Computing set up",
    "text": "Computing set up\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\n\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n\ncolors &lt;- tibble::tibble(green = \"#B5BA72\")"
  },
  {
    "objectID": "slides/02-mlr-review.html#topics",
    "href": "slides/02-mlr-review.html#topics",
    "title": "Review of multiple linear regression",
    "section": "Topics",
    "text": "Topics\n\nDefine statistical models\nMotivate generalized linear models and multilevel models\nReview multiple linear regression\n\n\n\nNotes based on Chapter 1 of Roback and Legler (2021) unless noted otherwise."
  },
  {
    "objectID": "slides/02-mlr-review.html#models-and-statistical-models",
    "href": "slides/02-mlr-review.html#models-and-statistical-models",
    "title": "Review of multiple linear regression",
    "section": "Models and statistical models",
    "text": "Models and statistical models\nSuppose we have observations \\(y_1, \\ldots, y_n\\)\n\n\nModel: Mathematical description of the process we think generates the observations\nStatistical model: Model that includes an equation describing the impact of explanatory variables (deterministic part) and probability distributions for parts of the process that are assumed to be random variation (random part)\n\n\n\n\nDefinitions adapted from Stroup (2012)"
  },
  {
    "objectID": "slides/02-mlr-review.html#statistical-models-1",
    "href": "slides/02-mlr-review.html#statistical-models-1",
    "title": "Review of multiple linear regression",
    "section": "Statistical models",
    "text": "Statistical models\nA statistical model must include\n\nThe observations\nThe deterministic (systematic) part of the process\nThe random part of the process with a statement of the presumed probability distribution\n\n\n\nDefinitions adapted from Stroup (2012)"
  },
  {
    "objectID": "slides/02-mlr-review.html#example",
    "href": "slides/02-mlr-review.html#example",
    "title": "Review of multiple linear regression",
    "section": "Example",
    "text": "Example\nSuppose we have the model for comparing two means:\n\\[\ny_{ij} = \\mu_i + \\epsilon_{ij}\n\\]\nwhere\n\n\n\n\\(i = 1, 2\\): group\n\n\n\n\\(j = 1, \\ldots, n\\): observation number\n\\(n_i\\): number of observations in group \\(i\\)\n\\(\\mu_i\\): mean of group \\(i\\)\n\\(y_{ij}\\): \\(j^{th}\\) observation in the \\(i^{th}\\) group\n\\(\\epsilon_{ij}\\) : random error (variation) associated with \\(ij^{th}\\) observation\n\n\n\n\n\nAdapted from Stroup (2012)"
  },
  {
    "objectID": "slides/02-mlr-review.html#example-1",
    "href": "slides/02-mlr-review.html#example-1",
    "title": "Review of multiple linear regression",
    "section": "Example",
    "text": "Example\n\\[\ny_{ij} = \\mu_i + \\epsilon_{ij}\n\\]\n\n\n\\(y_{ij}\\): the observations\n\\(\\mu_i\\): deterministic part of the model, no random variability\n\\(e_{ij}\\) : random part of the model, indicating observations vary about their mean\nTypically assume \\(\\epsilon_{ij}\\) are independent and identically distributed (i.i.d.) \\(N(0, \\sigma^2)\\)\n\n\n\n\nAdapted from Stroup (2012)"
  },
  {
    "objectID": "slides/02-mlr-review.html#practice",
    "href": "slides/02-mlr-review.html#practice",
    "title": "Review of multiple linear regression",
    "section": "Practice",
    "text": "Practice\n\nSuppose \\(y_{ij}\\)’s are observed outcome data and \\(x_i\\)’s are values of the explanatory variable. Assume a linear regression model can used to describe the process of generating \\(y_{ij}\\) based on the \\(x_i\\).\n\nWrite the specification of the statistical model.\nLabel the 3 components of the model equation (observation, deterministic part, random part)\nWhat is \\(E(y_{ij})\\), the expected value of the observations?"
  },
  {
    "objectID": "slides/02-mlr-review.html#assumptions-for-linear-regression",
    "href": "slides/02-mlr-review.html#assumptions-for-linear-regression",
    "title": "Review of multiple linear regression",
    "section": "Assumptions for linear regression",
    "text": "Assumptions for linear regression\n\nLinearity: Linear relationship between mean response and predictor variable(s)\nIndependence: Residuals are independent. There is no connection between how far any two points lie above or below regression line.\nNormality: Response follows a normal distribution at each level of the predictor (or combination of predictors)\nEqual variance: Variability (variance or standard deviation) of the response is equal for all levels of the predictor (or combination of predictors)"
  },
  {
    "objectID": "slides/02-mlr-review.html#assumptions-for-linear-regression-1",
    "href": "slides/02-mlr-review.html#assumptions-for-linear-regression-1",
    "title": "Review of multiple linear regression",
    "section": "Assumptions for linear regression",
    "text": "Assumptions for linear regression\n\n\n\n\n\n\n\nModified from Figure 1.1. in BMLR\n\n\n\n\n\n\nLinearity: Linear relationship between mean of the response \\(Y\\) and the predictor \\(X\\)\nIndependence: No connection between how far any two points lie from regression line\nNormality: Response \\(Y\\) follows a normal distribution at each level of the predictor \\(X\\) (red curves)\nEqual variance: Variance of the response \\(Y\\) is equal for all levels of the predictor \\(X\\)"
  },
  {
    "objectID": "slides/02-mlr-review.html#violations-in-assumptions",
    "href": "slides/02-mlr-review.html#violations-in-assumptions",
    "title": "Review of multiple linear regression",
    "section": "Violations in assumptions",
    "text": "Violations in assumptions\nDo wealthy households tend to have fewer children compared to households with lower income? Annual income and family size are recorded for a random sample of households.\n\nThe response variable is number of children in the household.\nThe predictor variable is annual income in US dollars.\n\n\nWhich assumption(s) are obviously violated, if any?"
  },
  {
    "objectID": "slides/02-mlr-review.html#violations-in-assumptions-1",
    "href": "slides/02-mlr-review.html#violations-in-assumptions-1",
    "title": "Review of multiple linear regression",
    "section": "Violations in assumptions",
    "text": "Violations in assumptions\nMedical researchers investigated the outcome of a particular surgery for patients with comparable stages of disease but different ages. The 10 hospitals in the study had at least two surgeons performing the surgery of interest. Patients were randomly selected for each surgeon at each hospital. The surgery outcome was recorded on a scale of 1 - 10.\n\nThe response variable is surgery outcome, 1 - 10.\nThe predictor variable is patient age in years.\n\n\nWhich assumption(s) are obviously violated, if any?"
  },
  {
    "objectID": "slides/02-mlr-review.html#beyond-linear-regression",
    "href": "slides/02-mlr-review.html#beyond-linear-regression",
    "title": "Review of multiple linear regression",
    "section": "Beyond linear regression",
    "text": "Beyond linear regression\n\n\nWhen drawing conclusions from linear regression models, we do so assuming LINE are all met\nGeneralized linear models require different assumptions and can accommodate violations in LINE\n\nRelationship between response and predictor(s) can be nonlinear\nResponse variable can be non-normal\nVariance in response can differ at each level of predictor(s)\nThe independence assumption still must hold!\n\nMultilevel models are used to model data that violate the independence assumption, i.e. correlated observations"
  },
  {
    "objectID": "slides/02-mlr-review.html#data-kentucky-derby-winners",
    "href": "slides/02-mlr-review.html#data-kentucky-derby-winners",
    "title": "Review of multiple linear regression",
    "section": "Data: Kentucky Derby Winners",
    "text": "Data: Kentucky Derby Winners\nToday’s data is from the Kentucky Derby, an annual 1.25-mile horse race held at the Churchill Downs race track in Louisville, KY. The data is in the file derbyplus.csv and contains information for races 1896 - 2017.\n\n\nResponse variable\n\nspeed: Average speed of the winner in feet per second (ft/s)\n\nAdditional variable\n\nwinner: Winning horse\n\n\nPredictor variables\n\nyear: Year of the race\ncondition: Condition of the track (good, fast, slow)\nstarters: Number of horses who raced\n\n\n\nGoal: Understand variability in average winner speed based on characteristics of the race."
  },
  {
    "objectID": "slides/02-mlr-review.html#data",
    "href": "slides/02-mlr-review.html#data",
    "title": "Review of multiple linear regression",
    "section": "Data",
    "text": "Data\n\nderby &lt;- read_csv(\"data/derbyplus.csv\")\n\n\nderby |&gt;\n  head(5) |&gt; kable()\n\n\n\n\nyear\nwinner\ncondition\nspeed\nstarters\n\n\n\n\n1896\nBen Brush\ngood\n51.66\n8\n\n\n1897\nTyphoon II\nslow\n49.81\n6\n\n\n1898\nPlaudit\ngood\n51.16\n4\n\n\n1899\nManuel\nfast\n50.00\n5\n\n\n1900\nLieut. Gibson\nfast\n52.28\n7"
  },
  {
    "objectID": "slides/02-mlr-review.html#data-science-workflow",
    "href": "slides/02-mlr-review.html#data-science-workflow",
    "title": "Review of multiple linear regression",
    "section": "Data science workflow",
    "text": "Data science workflow\n\nImage source: Wickham, Çetinkaya-Rundel, and Grolemund (2023)"
  },
  {
    "objectID": "slides/02-mlr-review.html#exploratory-data-analysis-eda",
    "href": "slides/02-mlr-review.html#exploratory-data-analysis-eda",
    "title": "Review of multiple linear regression",
    "section": "Exploratory data analysis (EDA)",
    "text": "Exploratory data analysis (EDA)\n\nOnce you’re ready for the statistical analysis, the first step should always be exploratory data analysis.\nThe EDA will help you\n\nbegin to understand the variables and observations\nidentify outliers or potential data entry errors\nbegin to see relationships between variables\nidentify the appropriate model and identify a strategy\n\nThe EDA is exploratory; formal modeling and statistical inference are used to draw conclusions."
  },
  {
    "objectID": "slides/02-mlr-review.html#univariate-eda",
    "href": "slides/02-mlr-review.html#univariate-eda",
    "title": "Review of multiple linear regression",
    "section": "Univariate EDA",
    "text": "Univariate EDA"
  },
  {
    "objectID": "slides/02-mlr-review.html#univariate-eda-code",
    "href": "slides/02-mlr-review.html#univariate-eda-code",
    "title": "Review of multiple linear regression",
    "section": "Univariate EDA code",
    "text": "Univariate EDA code\n\np1 &lt;- ggplot(data = derby, aes(x = speed)) + \n  geom_histogram(fill = colors$green, color = \"black\") + \n  labs(x = \"Winning speed (ft/s)\", y = \"Count\")\n\np2 &lt;- ggplot(data = derby, aes(x = starters)) + \n  geom_histogram(fill = colors$green, color = \"black\",\n                 binwidth = 2) + \n  labs(x = \"Starters\", y = \"Count\")\n\np3 &lt;- ggplot(data = derby, aes(x = condition)) +\n   geom_bar(fill = colors$green, color = \"black\", aes(x = ))\n\np1 + (p2 / p3) + \n  plot_annotation(title = \"Univariate data analysis\")"
  },
  {
    "objectID": "slides/02-mlr-review.html#bivariate-eda",
    "href": "slides/02-mlr-review.html#bivariate-eda",
    "title": "Review of multiple linear regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA"
  },
  {
    "objectID": "slides/02-mlr-review.html#bivariate-eda-code",
    "href": "slides/02-mlr-review.html#bivariate-eda-code",
    "title": "Review of multiple linear regression",
    "section": "Bivariate EDA code",
    "text": "Bivariate EDA code\n\np4 &lt;- ggplot(data = derby, aes(x = starters, y = speed)) + \n  geom_point() + \n  labs(x = \"Starters\", y = \"Speed (ft / s)\")\n\np5 &lt;- ggplot(data = derby, aes(x = year, y = speed)) + \n  geom_point() + \n  labs(x = \"Year\", y = \"Speed (ft / s)\")\n\np6 &lt;- ggplot(data = derby, aes(x = condition, y = speed)) + \n  geom_boxplot(fill = colors$green, color = \"black\") + \n  labs(x = \"Conditions\", y = \"Speed (ft / s)\")\n\n(p4 + p5) + p6 +\n  plot_annotation(title = \"Bivariate data analysis\")"
  },
  {
    "objectID": "slides/02-mlr-review.html#scatterplot-matrix",
    "href": "slides/02-mlr-review.html#scatterplot-matrix",
    "title": "Review of multiple linear regression",
    "section": "Scatterplot matrix",
    "text": "Scatterplot matrix\nA scatterplot matrix helps quickly visualize relationships between many variable pairs. They are particularly useful to identify potentially correlated predictors."
  },
  {
    "objectID": "slides/02-mlr-review.html#scatterplot-matrix-code",
    "href": "slides/02-mlr-review.html#scatterplot-matrix-code",
    "title": "Review of multiple linear regression",
    "section": "Scatterplot matrix code",
    "text": "Scatterplot matrix code\nCreate using the ggpairs() function in the GGally package.\n\nlibrary(GGally)\nggpairs(data = derby, \n        columns = c(\"condition\", \"year\", \"starters\", \"speed\"))"
  },
  {
    "objectID": "slides/02-mlr-review.html#multivariate-eda",
    "href": "slides/02-mlr-review.html#multivariate-eda",
    "title": "Review of multiple linear regression",
    "section": "Multivariate EDA",
    "text": "Multivariate EDA\nPlot the relationship between the response and a predictor based on levels of another predictor to assess potential interactions."
  },
  {
    "objectID": "slides/02-mlr-review.html#multivariate-eda-code",
    "href": "slides/02-mlr-review.html#multivariate-eda-code",
    "title": "Review of multiple linear regression",
    "section": "Multivariate EDA code",
    "text": "Multivariate EDA code\n\nlibrary(viridis)\nggplot(data = derby, aes(x = year, y = speed, color = condition, \n                         shape = condition, linetype = condition)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE, aes(linetype = condition)) + \n  labs(x = \"Year\", y = \"Speed (ft/s)\", color = \"Condition\",\n       title = \"Speed vs. year\", \n       subtitle = \"by track condition\") +\n  guides(lty = FALSE, shape = FALSE) +\n  scale_color_viridis_d(end = 0.9)"
  },
  {
    "objectID": "slides/02-mlr-review.html#candidate-models",
    "href": "slides/02-mlr-review.html#candidate-models",
    "title": "Review of multiple linear regression",
    "section": "Candidate models",
    "text": "Candidate models\nModel 1: Main effects model (year, condition, starters)\n\nmodel1 &lt;- lm(speed ~ starters + year + condition, data = derby)\n\n\n\nModel 2: Main effects + \\(year^2\\), the quadratic effect of year\n\nmodel2 &lt;- lm(speed ~ starters + year + I(year^2) + condition,\n             data = derby)\n\n\n\n\nModel 3: Main effects + interaction between year and condition\n\nmodel3 &lt;- lm(speed ~ starters + year + condition + year * condition, \n             data = derby)"
  },
  {
    "objectID": "slides/02-mlr-review.html#inference-for-regression-1",
    "href": "slides/02-mlr-review.html#inference-for-regression-1",
    "title": "Review of multiple linear regression",
    "section": "Inference for regression",
    "text": "Inference for regression\nWhen LINE assumptions are met… . . .\n\n\nUse least squares regression to obtain the estimates for the model coefficients \\(\\beta_0, \\beta_1, \\ldots, \\beta_j\\) and for \\(\\sigma^2\\)\n\\(\\hat{\\sigma}\\) is the regression standard error\n\\[\n\\hat{\\sigma} = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n - p - 1}} = \\sqrt{\\frac{\\sum_{i=1}^n e_i^2}{n-p-1}}\n\\]\nwhere \\(p\\) is the number of non-intercept terms in the model (e.g., \\(p = 1\\) in simple linear regression)\nGoal is to use estimated values to draw conclusions about \\(\\beta_j\\)\n\nUse \\(\\hat{\\sigma}\\) to calculate \\(SE_{\\hat{\\beta}_j}\\) . Click here for more detail."
  },
  {
    "objectID": "slides/02-mlr-review.html#hypothesis-testing-for-beta_j",
    "href": "slides/02-mlr-review.html#hypothesis-testing-for-beta_j",
    "title": "Review of multiple linear regression",
    "section": "Hypothesis testing for \\(\\beta_j\\)",
    "text": "Hypothesis testing for \\(\\beta_j\\)\n\nState the hypotheses. \\(H_0: \\beta_j = 0 \\text{ vs. } H_a: \\beta_j \\neq 0\\), given the other variables in the model.\n\n\n\nCalculate the test statistic.\n\n\\[\nt = \\frac{\\hat{\\beta}_j - 0}{SE_{\\hat{\\beta}_j}}\n\\]\n\n\n\nCalculate the p-value. The p-value is calculated from a \\(t\\) distribution with \\(n - p - 1\\) degrees of freedom.\n\\[\n\\text{p-value} = 2P(T &gt; |t|) \\hspace{4mm} T \\sim t_{n-p-1}\n\\]\n\n\n\n\nState the conclusion in context of the data.\n\nReject \\(H_0\\) if p-value is sufficiently small."
  },
  {
    "objectID": "slides/02-mlr-review.html#confidence-interval-for-beta_j",
    "href": "slides/02-mlr-review.html#confidence-interval-for-beta_j",
    "title": "Review of multiple linear regression",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\nThe \\(C\\%\\) confidence confidence interval for \\(\\beta_j\\) is\n\\[\\hat{\\beta}_j \\pm t^* \\times SE_{\\hat{\\beta}_j}\\]\nwhere the critical value \\(t^* \\sim t_{n-p-1}\\)\n\n\nGeneral interpretation for the confidence interval [LB, UB]:\nWe are \\(C\\%\\) confident that for every one unit increase in \\(x_j\\), the response is expected to change by LB to UB units, holding all else constant."
  },
  {
    "objectID": "slides/02-mlr-review.html#measures-of-model-performance",
    "href": "slides/02-mlr-review.html#measures-of-model-performance",
    "title": "Review of multiple linear regression",
    "section": "Measures of model performance",
    "text": "Measures of model performance\n\n\\(R^2\\): Proportion of variability in the response explained by the model\n\nWill always increase as predictors are added, so it shouldn’t be used to compare models\n\n\\(Adj. R^2\\): Similar to \\(R^2\\) with a penalty for extra terms\n\\(AIC\\): Likelihood-based approach balancing model performance and complexity\n\\(BIC\\): Similar to AIC with stronger penalty for extra terms"
  },
  {
    "objectID": "slides/02-mlr-review.html#model-summary-statistics",
    "href": "slides/02-mlr-review.html#model-summary-statistics",
    "title": "Review of multiple linear regression",
    "section": "Model summary statistics",
    "text": "Model summary statistics\nUse the glance() function to get model summary statistics\n\n\n\n\n\n\nmodel\nr.squared\nadj.r.squared\nAIC\nBIC\n\n\n\n\nModel1\n0.730\n0.721\n259.478\n276.302\n\n\nModel2\n0.827\n0.819\n207.429\n227.057\n\n\nModel3\n0.751\n0.738\n253.584\n276.016\n\n\n\n\n\n\n\nWhich model do you choose based on these statistics?"
  },
  {
    "objectID": "slides/02-mlr-review.html#characteristics-of-a-good-final-model",
    "href": "slides/02-mlr-review.html#characteristics-of-a-good-final-model",
    "title": "Review of multiple linear regression",
    "section": "Characteristics of a “good” final model",
    "text": "Characteristics of a “good” final model\n\nModel can be used to answer primary research questions\nPredictor variables control for important covariates\nPotential interactions have been investigated\nVariables are centered, as needed, for more meaningful interpretations\nUnnecessary terms are removed\nAssumptions are met and influential points have been addressed\nModel tells a “persuasive story parsimoniously”\n\n\n\nList from Section 1.6.7 of Roback and Legler (2021)"
  },
  {
    "objectID": "slides/02-mlr-review.html#next-class",
    "href": "slides/02-mlr-review.html#next-class",
    "title": "Review of multiple linear regression",
    "section": "Next class",
    "text": "Next class\n\nUsing likelihoods\nSee Prepare for Jan 22 lecture"
  },
  {
    "objectID": "slides/04-compare-models.html#announcements",
    "href": "slides/04-compare-models.html#announcements",
    "title": "Comparing models using likelihoods",
    "section": "Announcements",
    "text": "Announcements\n\nHW 01 due Wednesday at 11:59pm. Grace period (i.e., no late penalty) until Thursday, January 25 at 6am.\n\nYour access to the repo will be removed at the end of the grace period. If you wish to submit the HW late, please email me and I will extend your access to the repo.\nYou will have access to your HW repo again when grades are returned.\n\nTomorrow’s lab: Start Project 01"
  },
  {
    "objectID": "slides/04-compare-models.html#computing-set-up",
    "href": "slides/04-compare-models.html#computing-set-up",
    "title": "Comparing models using likelihoods",
    "section": "Computing set up",
    "text": "Computing set up\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)\n\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\ncolors &lt;- tibble::tibble(green = \"#B5BA72\")"
  },
  {
    "objectID": "slides/04-compare-models.html#topics",
    "href": "slides/04-compare-models.html#topics",
    "title": "Comparing models using likelihoods",
    "section": "Topics",
    "text": "Topics\n\nComparing models using likelihood functions\n\n\n\nNotes based on Chapter 1 and 2 of Roback and Legler (2021) unless noted otherwise."
  },
  {
    "objectID": "slides/04-compare-models.html#data-fouls-in-college-basketball-games",
    "href": "slides/04-compare-models.html#data-fouls-in-college-basketball-games",
    "title": "Comparing models using likelihoods",
    "section": "Data: Fouls in college basketball games",
    "text": "Data: Fouls in college basketball games\nThe data set 04-refs.csv includes 30 randomly selected NCAA men’s basketball games played in the 2009 - 2010 season.1\nWe will focus on the variables foul1, foul2, and foul3, which indicate which team had a foul called them for the 1st, 2nd, and 3rd fouls, respectively.\n\nH: Foul was called on the home team\nV: Foul was called on the visiting team\n\nWe are focusing on the first three fouls for this analysis, but this could easily be extended to include all fouls in a game.\nThe dataset was derived from basektball0910.csv used in BMLR Section 11.2"
  },
  {
    "objectID": "slides/04-compare-models.html#fouls-in-college-basketball-games",
    "href": "slides/04-compare-models.html#fouls-in-college-basketball-games",
    "title": "Comparing models using likelihoods",
    "section": "Fouls in college basketball games",
    "text": "Fouls in college basketball games\n\nrefs &lt;- read_csv(\"data/04-refs.csv\")\nrefs |&gt; slice(1:5) |&gt; kable()\n\n\n\n\ngame\ndate\nvisitor\nhometeam\nfoul1\nfoul2\nfoul3\n\n\n\n\n166\n20100126\nCLEM\nBC\nV\nV\nV\n\n\n224\n20100224\nDEPAUL\nCIN\nH\nH\nV\n\n\n317\n20100109\nMARQET\nNOVA\nH\nH\nH\n\n\n214\n20100228\nMARQET\nSETON\nV\nV\nH\n\n\n278\n20100128\nSETON\nSFL\nH\nV\nV\n\n\n\n\n\nWe will treat the games as independent in this analysis."
  },
  {
    "objectID": "slides/04-compare-models.html#different-likelihood-models",
    "href": "slides/04-compare-models.html#different-likelihood-models",
    "title": "Comparing models using likelihoods",
    "section": "Different likelihood models",
    "text": "Different likelihood models\nModel 1 (Unconditional Model):\n\nWhat is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?\n\n\nModel 2 (Conditional Model):\n\nIs there a tendency for the referees to call more fouls on the visiting team or home team?\nIs there a tendency for referees to call a foul on the team that already has more fouls?\n\n\n\nUltimately we want to decide which model is better."
  },
  {
    "objectID": "slides/04-compare-models.html#exploratory-data-analysis",
    "href": "slides/04-compare-models.html#exploratory-data-analysis",
    "title": "Comparing models using likelihoods",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\n\nrefs |&gt;\ncount(foul1, foul2, foul3) |&gt; kable()\n\n\n\n\nfoul1\nfoul2\nfoul3\nn\n\n\n\n\nH\nH\nH\n3\n\n\nH\nH\nV\n2\n\n\nH\nV\nH\n3\n\n\nH\nV\nV\n7\n\n\nV\nH\nH\n7\n\n\nV\nH\nV\n1\n\n\nV\nV\nH\n5\n\n\nV\nV\nV\n2\n\n\n\n\n\n\nThere are\n\n46 total fouls on the home team\n44 total fouls on the visiting team"
  },
  {
    "objectID": "slides/04-compare-models.html#maximum-likelihood-estimates",
    "href": "slides/04-compare-models.html#maximum-likelihood-estimates",
    "title": "Comparing models using likelihoods",
    "section": "Maximum likelihood estimates",
    "text": "Maximum likelihood estimates\nThe maximum likelihood estimate (MLE) is the value between 0 and 1 where we are most likely to see the observed data.\n\n\n\nModel 1 (Unconditional Model)\n\n\\(\\hat{p}_H = 46/90 = 0.511\\)\n\n\nModel 2 (Conditional Model)\n\n\\(\\hat{p}_{H|N} = 25 / 48 = 0.521\\)\n\\(\\hat{p}_{H|H Bias} = 8 /20 = 0.4\\)\n\\(\\hat{p}_{H|V Bias} = 13/ 22 = 0.591\\)\n\n\n\n\n\n\nWhat is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?\nIs there a tendency for the referees to call more fouls on the visiting team or home team?\nIs there a tendency for referees to call a foul on the team that already has more fouls?"
  },
  {
    "objectID": "slides/04-compare-models.html#model-comparisons",
    "href": "slides/04-compare-models.html#model-comparisons",
    "title": "Comparing models using likelihoods",
    "section": "Model comparisons",
    "text": "Model comparisons\n\nNested models\nNon-nested models"
  },
  {
    "objectID": "slides/04-compare-models.html#nested-models",
    "href": "slides/04-compare-models.html#nested-models",
    "title": "Comparing models using likelihoods",
    "section": "Nested Models",
    "text": "Nested Models\nNested models: Models such that the parameters of the reduced model are a subset of the parameters for a larger model\nExample:\n\\[\\begin{aligned}&\\text{Model A: }y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon\\\\\n&\\text{Model B: }y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_4 x_4 + \\epsilon\\end{aligned}\\]\n\nModel A is nested in Model B. We could use likelihoods to test whether it is useful to add \\(x_3\\) and \\(x_4\\) to the model.\n\n\n\\[\\begin{aligned}&H_0: \\beta_3 = \\beta_4 = 0 \\\\\n&H_a: \\text{ at least one }\\beta_j \\text{ is not equal to 0}\\end{aligned}\\]"
  },
  {
    "objectID": "slides/04-compare-models.html#nested-models-1",
    "href": "slides/04-compare-models.html#nested-models-1",
    "title": "Comparing models using likelihoods",
    "section": "Nested models",
    "text": "Nested models\nAnother way to think about nested models: Parameters in larger model can be equated to get the simpler model or if some parameters can be set to constants\nExample:\n\\[\\begin{aligned}&\\text{Model 1: }p_H \\\\\n&\\text{Model 2: }p_{H| N}, p_{H| H Bias}, p_{H| V Bias}\\end{aligned}\\]\n\nModel 1 is nested in Model 2. The parameters \\(p_{H| N}\\), \\(p_{H|H Bias}\\), and \\(p_{H |V Bias}\\) can be set equal to \\(p_H\\) to get Model 1.\n\n\n\\[\\begin{aligned}&H_0: p_{H| N} = p_{H| H Bias} = p_{H| V Bias} = p_H \\\\\n&H_a: \\text{At least one of }p_{H| N}, p_{H| H Bias}, p_{H| V Bias} \\text{ differs from the others}\\end{aligned}\\]"
  },
  {
    "objectID": "slides/04-compare-models.html#steps-to-compare-models",
    "href": "slides/04-compare-models.html#steps-to-compare-models",
    "title": "Comparing models using likelihoods",
    "section": "Steps to compare models",
    "text": "Steps to compare models\n\nFind the MLEs for each model.\nPlug the MLEs into the log-likelihood function for each model to get the maximum value of the log-likelihood for each model.\nFind the difference in the maximum log-likelihoods\nUse the Likelihood Ratio Test to determine if the difference is statistically significant"
  },
  {
    "objectID": "slides/04-compare-models.html#steps-1---2",
    "href": "slides/04-compare-models.html#steps-1---2",
    "title": "Comparing models using likelihoods",
    "section": "Steps 1 - 2",
    "text": "Steps 1 - 2\nFind the MLEs for each model and plug them into the log-likelihood functions.\n\n\nModel 1:\n\n\\(\\hat{p}_H = 46/90 = 0.511\\)\n\n\nloglik1 &lt;- function(ph){\n log(ph^46 * (1 - ph)^44)\n}\nloglik1(46/90)\n\n[1] -62.36102\n\n\n\nModel 2\n\n\\(\\hat{p}_{H|N} = 25 / 48 = 0.521\\)\n\\(\\hat{p}_{H|H Bias} = 8 /20 = 0.4\\)\n\\(\\hat{p}_{H|V Bias} = 13/ 22 = 0.591\\)\n\n\nloglik2 &lt;- function(phn, phh, phv) {\n  log(phn^25 * (1 - phn)^23 * phh^8 * \n        (1 - phh)^12 * phv^13 * (1 - phv)^9)\n}\nloglik2(25/48, 8/20, 13/22)\n\n[1] -61.57319"
  },
  {
    "objectID": "slides/04-compare-models.html#step-3",
    "href": "slides/04-compare-models.html#step-3",
    "title": "Comparing models using likelihoods",
    "section": "Step 3",
    "text": "Step 3\nFind the difference in the log-likelihoods\n\\[\n\\log(Lik(Model 2)) - \\log(Lik(Model1))\n\\]\n\n(diff &lt;- loglik2(25/48, 8/20, 13/22) - loglik1(46/90))\n\n[1] 0.7878318\n\n\n\n\n\nIs the difference in the maximum log-likelihoods statistically significant?"
  },
  {
    "objectID": "slides/04-compare-models.html#likelihood-ratio-test",
    "href": "slides/04-compare-models.html#likelihood-ratio-test",
    "title": "Comparing models using likelihoods",
    "section": "Likelihood Ratio Test",
    "text": "Likelihood Ratio Test\nTest statistic\n\\[\\begin{aligned} LRT &= 2[\\max\\{\\log(Lik(\\text{larger model}))\\} - \\max\\{\\log(Lik(\\text{reduced model}))\\}]\\\\[10pt]\n&= 2\\log\\Bigg(\\frac{\\max\\{(Lik(\\text{larger model})\\}}{\\max\\{(Lik(\\text{reduced model})\\}}\\Bigg)\\end{aligned}\\]\n\n\nLRT follows a \\(\\chi^2\\) distribution where the degrees of freedom equal the difference in the number of parameters between the two models"
  },
  {
    "objectID": "slides/04-compare-models.html#step-4",
    "href": "slides/04-compare-models.html#step-4",
    "title": "Comparing models using likelihoods",
    "section": "Step 4",
    "text": "Step 4\n\n(LRT &lt;- 2 * (loglik2(25/48, 8/20, 13/22) - loglik1(46/90)))\n\n[1] 1.575664\n\n\n\nThe test statistic follows a \\(\\chi^2\\) distribution with 2 degrees of freedom. Therefore, the p-value is \\(P(\\chi^2 &gt; LRT)\\).\n\npchisq(LRT, 2, lower.tail = FALSE)\n\n[1] 0.4548299\n\n\n\n\nThe p-value is very large, so we fail to reject \\(H_0\\). We do not have convincing evidence that the conditional model is an improvement over the unconditional model. Therefore, we can stick with the unconditional model."
  },
  {
    "objectID": "slides/04-compare-models.html#comparing-non-nested-models-1",
    "href": "slides/04-compare-models.html#comparing-non-nested-models-1",
    "title": "Comparing models using likelihoods",
    "section": "Comparing non-nested models",
    "text": "Comparing non-nested models\n\n\nAIC = -2(max logLik) + 2p\n\n(Model1_AIC &lt;- 2 * loglik1(46/90) + 2 * 1)\n\n[1] -122.722\n\n(Model2_AIC &lt;-2 * loglik2(25/48, 8/20, 13/22) + 2 * 3)\n\n[1] -117.1464\n\n\n\nBIC = -2(max logLik) + plog(n)\n\n(Model1_BIC &lt;- 2 * loglik1(46/90) + 1 * log(30))\n\n[1] -121.3208\n\n(Model2_BIC &lt;-2 * loglik2(25/48, 8/20, 13/22) + 3 * log(30))\n\n[1] -112.9428\n\n\n\n\n\n\nChoose Model 1, the unconditional model, based on AIC and BIC"
  },
  {
    "objectID": "slides/04-compare-models.html#looking-ahead",
    "href": "slides/04-compare-models.html#looking-ahead",
    "title": "Comparing models using likelihoods",
    "section": "Looking ahead",
    "text": "Looking ahead\n\nLikelihoods help us answer the question of how likely we are to observe the data given different parameters\nIn this example, we did not consider covariates, so in practice the parameters we want to estimate will look more similar to this\n\n\\[p_H = \\frac{e^{\\beta_0 + \\beta_1x_1 + \\dots + \\beta_px_p}}{1 + e^{\\beta_0 + \\beta_1x_1 + \\dots + \\beta_px_p}}\\]\n\nFinding the MLE becomes much more complex and numerical methods may be required.\n\nWe will primarily rely on software to find the MLE, but the conceptual ideas will be the same"
  },
  {
    "objectID": "slides/04-compare-models.html#references",
    "href": "slides/04-compare-models.html#references",
    "title": "Comparing models using likelihoods",
    "section": "References",
    "text": "References\n\n\n\n🔗 STA 310 - Spring 2024\n\n\n\nRoback, Paul, and Julie Legler. 2021. Beyond multiple linear regression: applied generalized linear models and multilevel models in R. CRC Press."
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio containers (optional)\n🔗 on Duke Container Manager\n\n\nCourse GitHub organization\n🔗 on GitHub\n\n\nGradebook\n🔗 on Canvas\n\n\nTextbooks\n🔗 Beyond Multiple Linear Regression\n\n\n\n🔗 R for Data Science\n\n\n\n🔗 Tidy Modeling with R"
  },
  {
    "objectID": "project-tips.html",
    "href": "project-tips.html",
    "title": "Final project tips + resources",
    "section": "",
    "text": "Data sources\n\nSome resources that may be helpful as you find data:\n\nR Data Sources for Regression Analysis\nFiveThirtyEight data\nTidyTuesday\n\n\n\nOther data repositories\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies\n\n\n\n\nTips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your Qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works.\n\n\n\nFormatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\nAn alternative approach is to add the following code to the YAML:\n\nexecute:\n  echo: false\n  warning: false\n  message: false\n\n\n\n\nHeaders\n\nUse headers to clearly label each section. Make sure there is a space between the last # and the title, so the header renders correctly. For example, ###Section Title will not render as header, but ### Section Title will.\n\n\n\nReferences\n\nInclude all references in a section called “References” at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\n\nResize plots and figures, so you have more space for the narrative.\n\nResize individual figures: Use the code chunk header {r plot1, fig.height = 3, fig.width = 5}, replacing plot1 with a meaningful label and the height and width with values appropriate for your write up.\nResize all figures: Include the fig_width and fig_height options in your YAML header as shown below:\n\n\n\n---\ntitle: \"Your title\"\nauthor: \"Your names\"\nformat:\n  pdf:\n    fig-width: 7\n    fig-height: 5\n---\nReplace the height and width values with values appropriate for your write up.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\n\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\nIf you’re using base R function, i.e. when using the emplogit functions, put the code par(mfrow = c(rows,columns)) before the code to make the plots. For example, par(mfrow = c(2,3)) will arrange plots in a grid with 2 rows and 3 columns.\n\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\nUse coord_flip() to flip the x and y axes on the plot. This is useful if you a bar plot with an x-axis that is difficult to read due to overlapping text.\n\n❌ NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n✅ YES! Names are readable\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg |&gt;\n  count(manufacturer) |&gt;\n  mutate(manufacturer = str_to_title(manufacturer)) |&gt;\n  ggplot(aes(x = fct_reorder(manufacturer,n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  coord_flip() +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_bw() \n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel &lt;- lm(mpg ~ hp, data = mtcars)\ntidy(model) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon’t use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n❌ There is a negative linear relationship between mpg and hp.\n✅ There is a negative linear relationship between a car’s fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don’t assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the “so what”: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e. what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n❌ For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n✅ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it’s from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document.\n\n\n\n\nAdditional resources\n\nExploring RStudio’s Visual Markdown Editor\nR for Data Science\nQuarto documentation:\n\nQuarto PDF Basics\nPresentations in Quarto\n\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package"
  },
  {
    "objectID": "slides/07-glm-theory.html#announcements",
    "href": "slides/07-glm-theory.html#announcements",
    "title": "Unifying theory of GLMs",
    "section": "Announcements",
    "text": "Announcements"
  },
  {
    "objectID": "slides/07-glm-theory.html#topics",
    "href": "slides/07-glm-theory.html#topics",
    "title": "Unifying theory of GLMs",
    "section": "Topics",
    "text": "Topics\n\nIdentify the components common to all generalized linear models\nFind the canonical link based on the distribution of the response variable\nExplain how coefficients are estimated using iteratively reweighted least squares (IWLS)"
  },
  {
    "objectID": "slides/07-glm-theory.html#many-models-one-family",
    "href": "slides/07-glm-theory.html#many-models-one-family",
    "title": "Unifying theory of GLMs",
    "section": "Many models; one family",
    "text": "Many models; one family\nWe have studied models for a variety of response variables\n\nLeast squares (Normal)\nLogistic (Bernoulli, Binomial, Multinomial)\nLog-linear (Poisson, Negative Binomial)\n\nThese models are all examples of generalized linear models.\nGLMs have a similar structure for their likelihoods, MLEs, variances, so we can use a generalized approach to find the model estimates and associated uncertainty."
  },
  {
    "objectID": "slides/07-glm-theory.html#components-of-a-glm",
    "href": "slides/07-glm-theory.html#components-of-a-glm",
    "title": "Unifying theory of GLMs",
    "section": "Components of a GLM",
    "text": "Components of a GLM\nNelder and Wdderburn (1972) defines a broad class of models called generalized linear models that generalizes multiple linear regression. GLMs are characterized by three components:\n1️⃣ Response variable with parameter \\(\\theta\\) whose probability function can be written in exponential family form (random component)\n2️⃣ A linear combination of predictors, \\(\\eta = \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\) (systematic component)\n3️⃣ A link function \\(g(\\theta)\\) that connects \\(\\theta\\) to \\(\\eta\\)\n.footnote[Nelder, J. A., & Wedderburn, R. W. (1972). Generalized linear models. Journal of the Royal Statistical Society: Series A (General), 135(3), 370-384.]"
  },
  {
    "objectID": "slides/07-glm-theory.html#exponential-family-form",
    "href": "slides/07-glm-theory.html#exponential-family-form",
    "title": "Unifying theory of GLMs",
    "section": "Exponential family form",
    "text": "Exponential family form\nSuppose a probability (mass or density) function has a parameter \\(\\theta\\). It is said to have a one-parameter exponential family form if\n✅ The support (set of possible values) does not depend on \\(\\theta\\), and\n✅ The probability function can be written in the following form"
  },
  {
    "objectID": "slides/07-glm-theory.html#fytheta-eaybtheta-ctheta-dy",
    "href": "slides/07-glm-theory.html#fytheta-eaybtheta-ctheta-dy",
    "title": "Unifying theory of GLMs",
    "section": "\\[f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}\\]",
    "text": "\\[f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}\\]\nUsing this form:\n\\[E(Y) = -\\frac{c'(\\theta)}{b'(\\theta)} \\hspace{20mm} Var(Y) = \\frac{b''(\\theta)c'(\\theta) - c''(\\theta)b'(\\theta)}{[b'(\\theta)]^3}\\]"
  },
  {
    "objectID": "slides/07-glm-theory.html#poisson-in-exponential-family-form",
    "href": "slides/07-glm-theory.html#poisson-in-exponential-family-form",
    "title": "Unifying theory of GLMs",
    "section": "Poisson in exponential family form",
    "text": "Poisson in exponential family form\n\\[P(Y = y) = \\frac{e^{-\\lambda}\\lambda^y}{y!} \\hspace{10mm} y = 0, 1, 2, \\ldots, \\infty\\]\n\n\\[\\begin{aligned}P(Y = y) &= e^{-\\lambda}e^{y\\log(\\lambda)}e^{-\\log(y!)}\\\\\n& = e^{y\\log(\\lambda) - \\lambda - \\log(y!)}\\end{aligned}\\]\n\n\nRecall the form: \\(f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}\\), where the parameter \\(\\theta = \\lambda\\) for the Poisson distribution\n\n\n\n\\(a(y) = y\\)\n\\(b(\\lambda) = \\log(\\lambda)\\)\n\\(c(\\lambda) = -\\lambda\\)\n\\(d(y) = -\\log(y!)\\)"
  },
  {
    "objectID": "slides/07-glm-theory.html#poisson-in-exponential-family-form-1",
    "href": "slides/07-glm-theory.html#poisson-in-exponential-family-form-1",
    "title": "Unifying theory of GLMs",
    "section": "Poisson in exponential family form",
    "text": "Poisson in exponential family form\n\nThe support for the Poisson distribution is \\(y = 0, 1, 2, \\ldots, \\infty\\). This does not depend on the parameter \\(\\lambda\\).\nThe probability mass function can be written in the form \\(f(y;\\theta) = e^{[a(y)b(\\theta) + c(\\theta) + d(y)]}\\)\n\n\nThe Poisson distribution can be written in one-parameter exponential family form."
  },
  {
    "objectID": "slides/07-glm-theory.html#canonical-link",
    "href": "slides/07-glm-theory.html#canonical-link",
    "title": "Unifying theory of GLMs",
    "section": "Canonical link",
    "text": "Canonical link\nSuppose there is a response variable \\(Y\\) from a distribution with parameter \\(\\theta\\) and a set of predictors that can be written as a linear combination \\(\\eta = \\sum_{j=1}^{p}\\beta_jx_j = \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\)\nA link function, \\(g()\\), is a monotonic and differentiable function that connects \\(\\theta\\) to \\(\\eta\\)\nThe canonical link is a link function such that \\(g(\\theta) = \\eta\\) - When working with a member of the one-parameter exponential family, the canonical link is \\(b(\\theta)\\)"
  },
  {
    "objectID": "slides/07-glm-theory.html#canonical-link-for-poisson",
    "href": "slides/07-glm-theory.html#canonical-link-for-poisson",
    "title": "Unifying theory of GLMs",
    "section": "Canonical link for Poisson",
    "text": "Canonical link for Poisson\nRecall\n\\[P(Y = y) = e^{y\\log(\\lambda) - \\lambda - \\log(y!)}\\]\nthen the canonical link is \\(b(\\lambda) = \\log(\\lambda)\\)"
  },
  {
    "objectID": "slides/07-glm-theory.html#glm-framework-poisson-response-variable",
    "href": "slides/07-glm-theory.html#glm-framework-poisson-response-variable",
    "title": "Unifying theory of GLMs",
    "section": "GLM framework: Poisson response variable",
    "text": "GLM framework: Poisson response variable\n1️⃣ Response variable with parameter \\(\\theta\\) whose probability function can be written in exponential family form\n\\[P(Y = y) = e^{y\\log(\\lambda) - \\lambda - \\log(y!)}\\]\n\n\n\n\n\n\n2️⃣ A linear combination of predictors, \\(\\eta = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\)\n\n\n\n3️⃣ A function \\(g(\\lambda)\\) that connects \\(\\lambda\\) and \\(\\eta\\)\n\\[\\log(\\lambda) = \\eta =  \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\]"
  },
  {
    "objectID": "slides/07-glm-theory.html#activity-identifying-canonical-link",
    "href": "slides/07-glm-theory.html#activity-identifying-canonical-link",
    "title": "Unifying theory of GLMs",
    "section": "Activity: Identifying canonical link",
    "text": "Activity: Identifying canonical link\nFor the distribution\n\nDescribe an example of a setting where this random variable may be used.\nIdentify the parameter.\nWrite the pmf or pdf in one-parameter exponential form.\nIdentify the canonical link function\nOne person from each group: Write your response on the board."
  },
  {
    "objectID": "slides/07-glm-theory.html#activity",
    "href": "slides/07-glm-theory.html#activity",
    "title": "Unifying theory of GLMs",
    "section": "Activity",
    "text": "Activity\nDistributions\n\nBinary\nExponential\nNegative binomial (with fixed \\(r\\))\nGeometric\nNormal (with fixed \\(\\sigma\\))\n\n\nIf your group finishes early, try identifying the canonical link for the other distributions.\nSee BMLR - Section 3.6 for details on the distributions.\n\n\n\n\n−+\n10:00"
  },
  {
    "objectID": "slides/07-glm-theory.html#data-noisy-miners",
    "href": "slides/07-glm-theory.html#data-noisy-miners",
    "title": "Unifying theory of GLMs",
    "section": "Data: Noisy Miners",
    "text": "Data: Noisy Miners\nThe dataset nminer contains information about the number of noisy miners (small Australian bird) detected in two woodland patches within the Wimmera Plains of Victoria, Australia. It was obtained from the GLMsdata R package. We will use the following variables:\n\nMinerab: The number of noisy miners (abundance) observed in three 20 minute surveys\nEucs: The number of eucalyptus trees in each 2 hectare area (about 4.94 acres)"
  },
  {
    "objectID": "slides/07-glm-theory.html#noisy-miner-model",
    "href": "slides/07-glm-theory.html#noisy-miner-model",
    "title": "Unifying theory of GLMs",
    "section": "Noisy Miner Model",
    "text": "Noisy Miner Model\n\n\n\n\n\nEucs\nMinerab\n\n\n\n\n2\n0\n\n\n10\n0\n\n\n16\n3\n\n\n20\n2\n\n\n19\n8\n\n\n\n\n\nOur goal is to use a Poisson regression model to predict the number of noisy miners observed in three 20 minute surveys based on the number of eucalyptus trees.\n\\[\\log(\\lambda_{Minearab}) = \\beta_0 + \\beta_1 ~ Euc\\] .center[ What are the best estimates of \\(\\beta_0\\) and \\(\\beta_1\\)?]"
  },
  {
    "objectID": "slides/07-glm-theory.html#iteratively-reweighted-least-squares-iwls-1",
    "href": "slides/07-glm-theory.html#iteratively-reweighted-least-squares-iwls-1",
    "title": "Unifying theory of GLMs",
    "section": "Iteratively reweighted least squares (IWLS)",
    "text": "Iteratively reweighted least squares (IWLS)\n\nThe estimates of \\(\\beta_0\\) and \\(\\beta_1\\) are found using maximum likelihood estimation.\nIteratively reweighted least-squares (IWLS) is used to find the MLEs\n\nNelder and Wedderburn (1972) show that under certain specifications of the weights and a modified response variable, the estimates found using IWLS are equivalent to the MLEs."
  },
  {
    "objectID": "slides/07-glm-theory.html#iwls-set-up",
    "href": "slides/07-glm-theory.html#iwls-set-up",
    "title": "Unifying theory of GLMs",
    "section": "IWLS Set up",
    "text": "IWLS Set up\nWorking response: Modified response variable at each step of the iteration.\n\\[z_i = g(\\theta) + g'(\\theta)(y_i - \\theta_i)\\]\nFor Poisson regression, this is\n\\[z_i = \\log(\\lambda) + \\frac{(y_i - \\lambda_i)}{\\lambda_i}\\]\n\nWorking Weights: Weights applied to the observations at each step of the iteration\n\\[W_i = \\frac{\\theta^2}{Var(Y)} \\hspace{5mm} \\Rightarrow \\hspace{5mm}  W_i = \\frac{\\lambda^2}{\\lambda} =  \\lambda \\text{ for Poisson regression}\\]"
  },
  {
    "objectID": "slides/07-glm-theory.html#iwls-procedure",
    "href": "slides/07-glm-theory.html#iwls-procedure",
    "title": "Unifying theory of GLMs",
    "section": "IWLS procedure",
    "text": "IWLS procedure\n\nFind initial starting values \\(\\hat{\\theta}_i\\).\nCalculate the working response values \\(z_i\\).\nCalculate the working weights \\(W_i\\).\nFind the coefficient estimates of the weighted least squares model.\n\n\\[z_i = \\beta_0 + \\beta_1 x \\hspace{5mm} \\text{ with weights }W_i\\]\nThe estimates \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) are the estimates for the model coefficients.\n\nUse \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) to calculate updated values of \\(\\hat{\\theta}_i\\) and repeat steps 2 - 4 until convergence."
  },
  {
    "objectID": "slides/07-glm-theory.html#newton-raphson",
    "href": "slides/07-glm-theory.html#newton-raphson",
    "title": "Unifying theory of GLMs",
    "section": "Newton Raphson",
    "text": "Newton Raphson"
  },
  {
    "objectID": "slides/07-glm-theory.html#acknowledgements",
    "href": "slides/07-glm-theory.html#acknowledgements",
    "title": "Unifying theory of GLMs",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese slides are based on content in\n\nBMLR: Chapter 5 - Generalized Linear Models: A Unifying Theory\nNelder, J. A., & Wedderburn, R. W. (1972). Generalized linear models. Journal of the Royal Statistical Society: Series A (General), 135(3), 370-384.\nGeneralized Linear Models with Examples in R\n\nChapter 5 - Generalized Linear Models: Structure\nChapter 6 - Generalized Linear Models: Estimation\n\n\n\n\n\n🔗 STA 310 - Spring 2024"
  }
]