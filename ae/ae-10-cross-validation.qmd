---
title: "AE 10: Cross validation"
subtitle: "The Office"
date: "Oct 24, 2022"
editor: visual
---

::: callout-important
Go to the [course GitHub organization](https://github.com/sta210-fa22) and locate your `ae-10`- to get started.

The AE is due on GitHub by Thursday, October 27 at 11:59pm.
:::

## Function

```{r}
# function to calculate model fit statistics
calc_model_stats <- function(x) {
  glance(extract_fit_parsnip(x)) |>
    select(adj.r.squared, AIC, BIC)
}
```

## Packages

```{r}
#| label: load-pkgs
#| message: false
 
library(tidyverse)
library(tidymodels)
library(knitr)
```

## Load data

```{r}
#| label: load-data
#| message: false

office_episodes <- read_csv("data/office_episodes.csv")
```

## Split data into training and testing

Split your data into testing and training sets.

```{r}
#| label: initial-split

set.seed(123)
office_split <- initial_split(office_episodes)
office_train <- training(office_split)
office_test <- testing(office_split)
```

## Specify model

Specify a linear regression model. Call it `office_spec`.

```{r}
#| label: specify-model

office_spec <- linear_reg() |>
  set_engine("lm")

office_spec
```

# Model 1

## Create recipe

Create the recipe from class. Call it `office_rec1`.

```{r}
#| label: create-recipe

office_rec1 <- recipe(imdb_rating ~ ., data = office_train) |>
  update_role(episode_name, new_role = "id") |>
  step_rm(air_date, season) |>
  step_dummy(all_nominal_predictors()) |>
  step_zv(all_predictors())

office_rec1
```

## Preview recipe

```{r}
#| label: preview-recipe

prep(office_rec1) |>
  bake(office_train) |>
  glimpse()
```

## Create workflow

Create the workflow that brings together the model specification and recipe. Call it `office_wflow1`.

```{r}
#| label: create-wflow

office_wflow1 <- workflow() |>
  add_model(office_spec) |>
  add_recipe(office_rec1)

office_wflow1
```

# Cross validation

## Create folds

Create 10-folds.

```{r}
#| label: cv-tenfold

# make 10 folds
set.seed(345)
folds <- vfold_cv(office_train, v = 10)
```

## Conduct cross validation

Conduct cross validation on the 10 folds.

```{r}
#| label: conduct-cv

set.seed(456)
# Fit model and calculate statistics for each fold
office_fit_rs1 <- office_wflow1 |>
  fit_resamples(resamples = folds, 
                control = control_resamples(extract = calc_model_stats))
```

## Summarize assessment CV metrics

Summarize assessment metrics from your CV resamples.

```{r}
#| label: cv-summarize

collect_metrics(office_fit_rs1, summarize = TRUE)
```

## Summarize model fit CV metrics

```{r}
#| label: cv-model-fit
map_df(office_fit_rs1$.extracts, ~ .x[[1]][[1]]) |>
  summarise(mean_adj_rsq = mean(adj.r.squared), 
            mean_aic = mean(AIC), 
            mean_bic = mean(BIC))
```

# Another model - Model 2

Create a different (simpler, involving fewer variables) recipe and call it `office_rec2`. Conduct 10-fold cross validation and summarize metrics.

## Model 2: Recipe

```{r}
#| label: model2-recipe

# add code here
```

## Model 2: Workflow

```{r}
#| label: model2-workflow

# add code here
```

## Model 2: Conduct CV

::: callout-note
Note: We will use the same folds as the ones used for Model 1. Why should we use the same folds to evaluate and compare both models?
:::

```{r}
#| label: model2-cv

# add code here
```

## Model 2: Summarize assessment CV metrics

```{r}
#| label: model2-assessment

# add code here
```

## Model 2: Summarize model fit CV metrics

```{r}
#| label: model2-model-fit

# add code here
```

# Compare models

Describe how the two models compare to each other based on cross validation metrics.

# 
