---
title: "Inference review + <br> using likelihoods"
author: "Prof. Maria Tackett"
date: "2024-01-22"
date-format: "MMM DD, YYYY"
footer: "[🔗 STA 310 - Spring 2024](https://sta310-sp24.netlify.app)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    slide-number: true
    multiplex: false
    transition: fade
    incremental: false 
    chalkboard: true
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
execute:
  freeze: auto
  echo: true
  warning: false
  message: false
knitr:
  opts_chunk: 
    R.options:      
    width: 200
bibliography: references.bib
---

```{r setup, include = F}
knitr::opts_chunk$set(fig.width = 8,
                      fig.asp = 0.618, 
                      fig.retina = 3, 
                      dpt = 300, 
                      out.width = "90%",
                      fig.align = "center")
```

## Announcements

-   HW 01 due Wednesday at 11:59pm
    -   Your access to the repo will be removed at the deadline. If you wish to submit the HW late, please email me and I will extend your access to the repo.
    -   You will have access to your HW repo again when grades are returned.

## Computing set up

```{r}
library(tidyverse)
library(tidymodels)
library(GGally)
library(knitr)
library(patchwork)
library(viridis)
library(ggfortify)

ggplot2::theme_set(ggplot2::theme_bw(base_size = 16))
colors <- tibble::tibble(green = "#B5BA72")
```

## Topics

-   Review inference for multiple linear regression

-   Using likelihoods

::: aside
Notes based on Chapter 1 and 2 of @roback2021beyond unless noted otherwise.
:::

# Inference for multiple linear regression

## Data: Kentucky Derby Winners {.midi}

Today's data is from the Kentucky Derby, an annual 1.25-mile horse race held at the Churchill Downs race track in Louisville, KY. The data is in the file [derbyplus.csv](data/derbyplus.csv) and contains information for races 1896 - 2017.

::: columns
::: {.column width="50%"}
**Response variable**

-   `speed`: Average speed of the winner in feet per second (ft/s)

**Additional variable**

-   `winner`: Winning horse
:::

::: {.column width="50%"}
**Predictor variables**

-   `year`: Year of the race
-   `condition`: Condition of the track (good, fast, slow)
-   `starters`: Number of horses who raced
:::
:::

**Goal: Understand variability in average winner speed based on characteristics of the race.**

## Data

```{r}
derby <- read_csv("data/derbyplus.csv")
```

```{r}
derby |>
  head(5) |> kable()
```

## Candidate models

Model 1: Main effects model (`year`, `condition`, `starters`)

```{r}
model1 <- lm(speed ~ starters + year + condition, data = derby)
```

<br>

. . .

Model 2: Main effects + $year^2$, the quadratic effect of `year`

```{r}
model2 <- lm(speed ~ starters + year + I(year^2) + condition,
             data = derby)
```

<br>

. . .

Model 3: Main effects + interaction between `year` and `condition`

```{r}
model3 <- lm(speed ~ starters + year + condition + year * condition, 
             data = derby)
```

## Inference for regression

Use statistical inference to

-   Evaluate if predictors are statistically significant (not necessarily practically significant!)

-   Quantify uncertainty in coefficient estimates

-   Quantify uncertainty in model predictions

If LINE assumptions are met, we can use inferential methods based on mathematical models. If at least linearity and independence are met, we can use simulation-based inference methods.

## Inference for regression {.midi}

When LINE assumptions are met... . . .

::: incremental
-   Use least squares regression to obtain the estimates for the model coefficients $\beta_0, \beta_1, \ldots, \beta_j$ and for $\sigma^2$

-   $\hat{\sigma}$ is the **regression standard error**

    $$
    \hat{\sigma} = \sqrt{\frac{\sum_{i=1}^n(y_i - \hat{y}_i)^2}{n - p - 1}} = \sqrt{\frac{\sum_{i=1}^n e_i^2}{n-p-1}}
    $$

    where $p$ is the number of non-intercept terms in the model (e.g., $p = 1$ in simple linear regression)

-   Goal is to use estimated values to draw conclusions about $\beta_j$

    -   Use $\hat{\sigma}$ to calculate $SE_{\hat{\beta}_j}$ . [Click here](https://github.com/STA210-Sp19/supplemental-notes/blob/master/regression-basics-matrix.pdf) for more detail.
:::

## Hypothesis testing for $\beta_j$ {.small}

1.  **State the hypotheses**. $H_0: \beta_j = 0 \text{ vs. } H_a: \beta_j \neq 0$, given the other variables in the model.

. . .

2.  **Calculate the test statistic.**

$$
t = \frac{\hat{\beta}_j - 0}{SE_{\hat{\beta}_j}}
$$

. . .

**Calculate the p-value.** The p-value is calculated from a $t$ distribution with $n - p - 1$ degrees of freedom.

$$
\text{p-value} = 2P(T > |t|) \hspace{8mm} T \sim t_{n-p-1}
$$

. . .

4.  **State the conclusion in context of the data.**
    -   Reject $H_0$ if p-value is sufficiently small.

## Confidence interval for $\beta_j$

The $C\%$ confidence confidence interval for $\beta_j$ is

$$\hat{\beta}_j \pm t^* \times SE_{\hat{\beta}_j}$$

where the critical value $t^* \sim t_{n-p-1}$

<br>

. . .

**General interpretation for the confidence interval \[LB, UB\]**:

We are $C\%$ confident that for every one unit increase in $x_j$, the response is expected to change by LB to UB units, holding all else constant.

# Application exercise

::: appex
📋 [sta310-sp24.netlify.app/ae/ae-02-mlr-review](../ae/ae-02-mlr-review.html)
:::

## Measures of model performance

-   $R^2$: Proportion of variability in the response explained by the model

    -   Will always increase as predictors are added, so it shouldn't be used to compare models

-   $Adj. R^2$: Similar to $R^2$ with a penalty for extra terms

-   $AIC$: Likelihood-based approach balancing model performance and complexity

-   $BIC$: Similar to AIC with stronger penalty for extra terms

## Model summary statistics

Use the `glance()` function to get model summary statistics

<br>

```{r echo = F}
model1_glance <- glance(model1) |>
  select(r.squared, adj.r.squared, AIC, BIC)
model2_glance <- glance(model2) |>
  select(r.squared, adj.r.squared, AIC, BIC)
model3_glance <- glance(model3) |>
  select(r.squared, adj.r.squared, AIC, BIC)

model1_glance |>
  bind_rows(model2_glance) |>
  bind_rows(model3_glance) |>
  bind_cols(model = c("Model1", "Model2", "Model3")) |>
  select(model, everything()) |>
kable(digits = 3)
```

. . .

::: question
Which model do you choose based on these statistics?
:::

## Characteristics of a "good" final model {.midi}

-   Model can be used to answer primary research questions

-   Predictor variables control for important covariates

-   Potential interactions have been investigated

-   Variables are centered, as needed, for more meaningful interpretations

-   Unnecessary terms are removed

-   Assumptions are met and influential points have been addressed

-   Model tells a "persuasive story parsimoniously"

::: aside
List from Section 1.6.7 of @roback2021beyond
:::

# Using likelihoods

## Learning goals

-   Describe the concept of a likelihood

-   Construct the likelihood for a simple model

-   Define the Maximum Likelihood Estimate (MLE) and use it to answer an analysis question

-   Identify three ways to calculate or approximate the MLE and apply these methods to find the MLE for a simple model

-   Use likelihoods to compare models

## What is the likelihood?

A **likelihood** is a function that tells us how likely we are to observe our data for a given parameter value (or values).

-   Unlike with Ordinary Least Squares (OLS) estimates, they do not require the responses be independent, identically distributed, and normal

-   They are <u>not</u> the same as probability functions

## Probability function vs. likelihood {.incremental}

::: incremental
-   **Probability function:** Fixed parameter value(s) + input possible outcomes $\Rightarrow$ probability of seeing the different outcomes given the parameter value(s)

-   **Likelihood:** Fixed data + input possible parameter values $\Rightarrow$ probability of seeing the fixed data for each parameter value
:::

## Data: Fouls in college basketball games {.midi}

The data set [`04-refs.csv`](data/04-refs.csv) includes 30 randomly selected NCAA men's basketball games played in the 2009 - 2010 season.[^1]

[^1]: The dataset was derived from `basektball0910.csv` used in [BMLR Section 11.2](https://bookdown.org/roback/bookdown-BeyondMLR/ch-GLMM.html#cs:refs)

We will focus on the variables `foul1`, `foul2`, and `foul3`, which indicate which team had a foul called them for the 1st, 2nd, and 3rd fouls, respectively.

-   `H`: Foul was called on the home team
-   `V`: Foul was called on the visiting team

We are focusing on the first three fouls for this analysis, but this could easily be extended to include all fouls in a game.

------------------------------------------------------------------------

## Fouls in college basketball games

```{r}
refs <- read_csv("data/04-refs.csv")
refs |> slice(1:5) |> kable()
```

We will treat the games as independent in this analysis.

## Different likelihood models

**Model 1 (Unconditional Model)**:

-   What is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?

. . .

**Model 2 (Conditional Model)**:

-   Is there a tendency for the referees to call more fouls on the visiting team or home team?

-   Is there a tendency for referees to call a foul on the team that already has more fouls?

. . .

**Ultimately we want to decide which model is better.**

## Exploratory data analysis {.midi}

::: columns
::: {.column width="50%"}
```{r}
refs |>
count(foul1, foul2, foul3) |> kable()
```
:::

::: {.column width="50%"}
There are

-   46 total fouls on the home team
-   44 total fouls on the visiting team
:::
:::

# Model 1: Unconditional model

What is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?

## Likelihood

Let $p_H$ be the probability the referees call a foul on the home team. **The likelihood for a single observation** $$Lik(p_H) = p_H^{y_i}(1 - p_H)^{n_i - y_i}$$Where $y_i$ is the number of fouls called on the home team. (In this example, we know $n_i = 3$ for all observations.)

. . .

**Example**

For a single game where the first three fouls are $H, H, V$, then $$Lik(p_H) = p_H^{2}(1 - p_H)^{3 - 2} = p_H^{2}(1 - p_H)$$

## Model 1: Likelihood contribution {.midi}

| Foul 1 | Foul 2 | Foul 3 | n   | Likelihood contribution |
|--------|--------|--------|-----|-------------------------|
| H      | H      | H      | 3   | $p_H^3$                 |
| H      | H      | V      | 2   | $p_H^2(1 - p_H)$        |
| H      | V      | H      | 3   | $p_H^2(1 - p_H)$        |
| H      | V      | V      | 7   | **A**                   |
| V      | H      | H      | 7   | **B**                   |
| V      | H      | V      | 1   | $p_H(1 - p_H)^2$        |
| V      | V      | H      | 5   | $p_H(1 - p_H)^2$        |
| V      | V      | V      | 2   | $(1 - p_H)^3$           |

::: question
Fill in **A** and **B**.
:::

```{r echo = F}
library(countdown)
countdown(minutes = 2, seconds = 0,
          margin = "5%")
```

## Model 1: Likelihood function

Because the observations (the games) are independent, the **likelihood** is

$$Lik(p_H) = \prod_{i=1}^{n}p_H^{y_i}(1 - p_H)^{3 - y_i}$$

. . .

We will use this function to find the **maximum likelihood estimate (MLE)**. The MLE is the value between 0 and 1 where we are most likely to see the observed data.

## Visualizing the likelihood

::: columns
::: {.column width="50%"}
```{r}
#| echo: false 

p <- seq(0,1, length.out = 100) #sequence of 100 values between 0 and 100
lik <- p^46 *(1 -p)^44
x <- tibble(p = p, lik = lik)
ggplot(data = x, aes(x = p, y = lik)) + 
  geom_point() + 
  geom_line() +
  labs(y = "Likelihood",
       title = "Likelihood of p_H")
```
:::

::: {.column width="50%"}
```{r}
#| eval: false

p <- seq(0,1, length.out = 100) #sequence of 100 values between 0 and 100
lik <- p^46 *(1 -p)^44
x <- tibble(p = p, lik = lik)
ggplot(data = x, aes(x = p, y = lik)) + 
  geom_point() + 
  geom_line() +
  labs(y = "Likelihood",
       title = "Likelihood of p_H")

```
:::
:::

------------------------------------------------------------------------

::: question
What is your best guess for the MLE, $\hat{p}_H$?

a.  0.489
b.  0.500
c.  0.511
d.  0.556
:::

------------------------------------------------------------------------

## Finding the maximum likelihood estimate

There are three primary ways to find the MLE

`r emo::ji("white_check_mark")` Approximate using a graph

`r emo::ji("white_check_mark")` Numerical approximation

`r emo::ji("white_check_mark")` Using calculus

------------------------------------------------------------------------

## Approximate MLE from a graph

```{r echo = F, out.width = "80%"}
p <- seq(0,1, length.out = 100) #sequence of 100 values between 0 and 100
lik <- p^46 *(1 -p)^44

x1 <- tibble(p = p, lik = lik)

lik_plot <- ggplot(data = x1, aes(x = p, y = lik)) + 
  geom_point() + 
  geom_line() + 
  geom_vline(xintercept = 46/90, color = "red") + 
    labs(y = "Likelihood", 
       title = "Likelihood of p_H")

lik_plot
```

## MLE using numerical approximation

Specify a finite set of possible values the for $p_H$ and calculate the likelihood for each value

. . .

```{r}
# write an R function for the likelihood
ref_lik <- function(ph) {
  ph^46 *(1 - ph)^44
}

# search possible values for p and return max
nGrid = 1000
ph <- seq(0, 1, length = nGrid)
lik <- ref_lik(ph)
ph[lik == max(lik)]
```

## Find MLE using calculus

-   Find the MLE by taking the first derivative of the likelihood function.

-   This can be tricky because of the Product Rule, so we can maximize the **log(Likelihood)** instead. The same value maximizes the likelihood and log(Likelihood)

. . .

::: columns
::: {.column width="50%"}
```{r}
#| echo: false

lik_plot

```
:::

::: {.column width="50%"}
```{r}
#| echo: false

loglik_plot <- ggplot(data = x1, aes(x = p, y = log(lik))) + 
  geom_point() + 
  geom_line() + 
  geom_vline(xintercept = 46/90, color = "red") + 
    labs(y = "log(Likelihood)", 
       title = "log(Likelihood) of p_H")

loglik_plot
```
:::
:::

## Find MLE using calculus

$$Lik(p_H) = \prod_{i=1}^{n}p_H^{y_i}(1 - p_H)^{3 - y_i}$$

. . .

$$
\begin{aligned}\log(Lik(p_H)) &= \sum_{i=1}^{n}y_i\log(p_H) + (3 - y_i)\log(1 - p_H)\\[10pt] &= 46\log(p_H) + 44\log(1 - p_H)\end{aligned}
$$

## Find MLE using calculus

$$\frac{d}{d p_H} \log(Lik(p_H)) = \frac{46}{p_H} - \frac{44}{1-p_H} = 0$$

. . .

$$\Rightarrow \frac{46}{p_H} = \frac{44}{1-p_H}$$

. . .

$$\Rightarrow 46(1-p_H) = 44p_H$$

. . .

$$\Rightarrow 46 = 90p_H$$

. . .

$$
\hat{p}_H = \frac{46}{90} = 0.511
$$

. . .

<center>😐</center>

# Model 2: Conditional model

Is there a tendency for referees to call more fouls on the visiting team or home team?

Is there a tendency for referees to call a foul on the team that already has more fouls?

## Model 2: Conditional model {.midi}

Now let's assume fouls are <u>not</u> independent within each game. We will specify this dependence using conditional probabilities.

-   **Conditional probability**: $P(A|B) =$ Probability of $A$ given $B$ has occurred

. . .

Define new parameters:

::: incremental
-   $p_{H|N}$: Probability referees call foul on home team given there are equal numbers of fouls on the home and visiting teams
-   $p_{H|H Bias}$: Probability referees call foul on home team given there are more prior fouls on the home team
-   $p_{H|V Bias}$: Probability referees call foul on home team given there are more prior fouls on the visiting team
:::

## Model 2: Likelihood contributions {.small}

+--------+--------+--------+---+---------------------------------------------------------------------------------------------------------------------------------------------+
| Foul 1 | Foul 2 | Foul 3 | n | Likelihood contribution                                                                                                                     |
+========+========+========+===+=============================================================================================================================================+
| H      | H      | H      | 3 | | $(p_{H\vert N})(p_{H\vert H Bias})(p_{H\vert H Bias}) = (p_{H\vert N})(p_{H\vert H Bias})^2$                                              |
+--------+--------+--------+---+---------------------------------------------------------------------------------------------------------------------------------------------+
| H      | H      | V      | 2 | | $(p_{H\vert N})(p_{H\vert H Bias})(1-p_{H\vert H Bias})$                                                                                  |
+--------+--------+--------+---+---------------------------------------------------------------------------------------------------------------------------------------------+
| H      | V      | H      | 3 | $(p_{H\vert N})(1 - p_{H \vert HBias})(p_{H \vert N}) = (p_{H \vert N})^2(1 - p_{H \vert HBias})$                                           |
+--------+--------+--------+---+---------------------------------------------------------------------------------------------------------------------------------------------+
| H      | V      | V      | 7 | **A**                                                                                                                                       |
+--------+--------+--------+---+---------------------------------------------------------------------------------------------------------------------------------------------+
| V      | H      | H      | 7 | **B**                                                                                                                                       |
+--------+--------+--------+---+---------------------------------------------------------------------------------------------------------------------------------------------+
| V      | H      | V      | 1 | | $(1 - p_{H\vert N})(p_{H\vert V Bias})(1 - p_{H\vert N}) = (1 - p_{H\vert N})^2(p_{H\vert V Bias})$                                       |
+--------+--------+--------+---+---------------------------------------------------------------------------------------------------------------------------------------------+
| V      | V      | H      | 5 | | $(1 - p_{H\vert N})(1-p_{H\vert V Bias})(p_{H\vert V Bias})$                                                                              |
+--------+--------+--------+---+---------------------------------------------------------------------------------------------------------------------------------------------+
| V      | V      | V      | 2 | | $\begin{aligned}&(1 - p_{H\vert N})(1-p_{H\vert V Bias})(1-p_{H\vert V Bias})\\ &=(1 - p_{H\vert N})(1-p_{H\vert V Bias})^2\end{aligned}$ |
+--------+--------+--------+---+---------------------------------------------------------------------------------------------------------------------------------------------+

::: footer
:::

## Likelihood function {.midi}

$$\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\ &(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\end{aligned}$$

**(Note: The exponents sum to 90, the total number of fouls in the data)**

<br>

. . .

$$\begin{aligned}\log (Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias})) &= 25 \log(p_{H| N}) + 23 \log(1 - p_{H|N}) \\ & + 8 \log(p_{H| H Bias}) + 12 \log(1 - p_{H| H Bias})\\ &+ 13 \log(p_{H| V Bias}) + 9 \log(1-p_{H|V Bias})\end{aligned}$$

------------------------------------------------------------------------

::: question
If fouls within a game are independent, how would you expect $\hat{p}_H$, $\hat{p}_{H\vert H Bias}$ and $\hat{p}_{H\vert V Bias}$ to compare?

a.  $\hat{p}_H$ is greater than $\hat{p}_{H\vert H Bias}$ and $\hat{p}_{H \vert V Bias}$

b.  $\hat{p}_{H\vert H Bias}$ is greater than $\hat{p}_H$ and $\hat{p}_{H \vert V Bias}$

c.  $\hat{p}_{H\vert V Bias}$ is greater than $\hat{p}_H$ and $\hat{p}_{H \vert V Bias}$

d.  They are all approximately equal.
:::

## MLEs for Model 2

[Click here](03-model2-mle.html) for details on finding MLEs for Model2.

# Using likelihoods to compare models

```{r echo = F}
lik1 <- function(ph) {
 ph^46 * (1 - ph)^44
}

lik2 <- function(phn, phh, phv) {
  phn^25 * (1 - phn)^23 * phh^8 * (1 - phh)^12 * phv^13 * (1 - phv)^9
}
```

## Maximum likelihood estimates {.midi}

The **maximum likelihood estimate (MLE)** is the value between 0 and 1 where we are most likely to see the observed data.

. . .

::: columns
::: {.column width="50%"}
**Model 1 (Unconditional Model)**

-   $\hat{p}_H = 46/90 = 0.511$
:::

::: {.column width="50%"}
**Model 2 (Conditional Model)**

-   $\hat{p}_{H|N} = 25 / 48 = 0.521$
-   $\hat{p}_{H|H Bias} = 8 /20 = 0.4$
-   $\hat{p}_{H|V Bias} = 13/ 22 = 0.591$
:::
:::

. . .

-   What is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?
-   Is there a tendency for the referees to call more fouls on the visiting team or home team?
-   Is there a tendency for referees to call a foul on the team that already has more fouls?

## Model comparisons

-   Nested models

-   Non-nested models

# Comparing nested models

## Nested Models {.midi}

**Nested models**: Models such that the parameters of the reduced model are a subset of the parameters for a larger model

Example:

$$\begin{aligned}&\text{Model A: }y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \epsilon\\
&\text{Model B: }y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_4 + \epsilon\end{aligned}$$

. . .

Model A is nested in Model B. We could use likelihoods to test whether it is useful to add $x_3$ and $x_4$ to the model.

. . .

$$\begin{aligned}&H_0: \beta_3 = \beta_4 = 0 \\ 
&H_a: \text{ at least one }\beta_j \text{ is not equal to 0}\end{aligned}$$

## Nested models {.midi}

**Another way to think about nested models**: Parameters in larger model can be equated to get the simpler model or if some parameters can be set to constants

**Example:**

$$\begin{aligned}&\text{Model 1: }p_H \\
&\text{Model 2: }p_{H| N}, p_{H| H Bias}, p_{H| V Bias}\end{aligned}$$

. . .

Model 1 is nested in Model 2. The parameters $p_{H| N}$, $p_{H|H Bias}$, and $p_{H |V Bias}$ can be set equal to $p_H$ to get Model 1.

. . .

$$\begin{aligned}&H_0: p_{H| N} = p_{H| H Bias} = p_{H| V Bias} = p_H \\
&H_a: \text{At least one of }p_{H| N}, p_{H| H Bias}, p_{H| V Bias} \text{ differs from the others}\end{aligned}$$

## Steps to compare models

`r emo::ji("one")` Find the MLEs for each model.

`r emo::ji("two")` Plug the MLEs into the log-likelihood function for each model to get the maximum value of the log-likelihood for each model.

`r emo::ji("three")` Find the difference in the maximum log-likelihoods

`r emo::ji("four")` Use the Likelihood Ratio Test to determine if the difference is statistically significant

## Steps 1 - 2

Find the MLEs for each model and plug them into the log-likelihood functions.

::: columns
::: {.column width="50%"}
**Model 1:**

-   $\hat{p}_H = 46/90 = 0.511$

```{r}
loglik1 <- function(ph){
 log(ph^46 * (1 - ph)^44)
}
loglik1(46/90)
```
:::

::: {.column width="50%"}
**Model 2**

-   $\hat{p}_{H|N} = 25 / 48 = 0.521$
-   $\hat{p}_{H|H Bias} = 8 /20 = 0.4$
-   $\hat{p}_{H|V Bias} = 13/ 22 = 0.591$

```{r}
loglik2 <- function(phn, phh, phv) {
  log(phn^25 * (1 - phn)^23 * phh^8 * 
        (1 - phh)^12 * phv^13 * (1 - phv)^9)
}
loglik2(25/48, 8/20, 13/22)
```
:::
:::

## Step 3

Find the difference in the log-likelihoods

$$
\log(Lik(Model 2)) - \log(Lik(Model1))
$$

```{r}
(diff <- loglik2(25/48, 8/20, 13/22) - loglik1(46/90))
```

<br>

. . .

<center>**Is the difference in the maximum log-likelihoods statistically significant?**</center>

## Likelihood Ratio Test {.midi}

**Test statistic**

$$\begin{aligned} LRT &= 2[\max\{\log(Lik(\text{larger model}))\} - \max\{\log(Lik(\text{reduced model}))\}]\\[10pt]
&= 2\log\Bigg(\frac{\max\{(Lik(\text{larger model})\}}{\max\{(Lik(\text{reduced model})\}}\Bigg)\end{aligned}$$

<br>

. . .

LRT follows a $\chi^2$ distribution where the degrees of freedom equal the difference in the number of parameters between the two models

## Step 4

```{r}
(LRT <- 2 * (loglik2(25/48, 8/20, 13/22) - loglik1(46/90)))
```

. . .

The test statistic follows a $\chi^2$ distribution with 2 degrees of freedom. Therefore, the p-value is $P(\chi^2 > LRT)$.

```{r}
pchisq(LRT, 2, lower.tail = FALSE)
```

. . .

The p-value is very large, so we fail to reject $H_0$. We do not have convincing evidence that the conditional model is an improvement over the unconditional model. Therefore, we can stick with the unconditional model.

# Comparing non-nested models

## Comparing non-nested models {.midi}

::: columns
::: {.column width="50%"}
AIC = -2(max logLik) + 2p

```{r}
(Model1_AIC <- 2 * loglik1(46/90) + 2 * 1)
(Model2_AIC <-2 * loglik2(25/48, 8/20, 13/22) + 2 * 3)
```
:::

::: {.column width="50%"}
BIC = -2(max logLik) + plog(n)

```{r}
(Model1_BIC <- 2 * loglik1(46/90) + 1 * log(30))
(Model2_BIC <-2 * loglik2(25/48, 8/20, 13/22) + 3 * log(30))
```
:::
:::

<br>

. . .

**Choose Model 1, the unconditional model, based on AIC and BIC**

## Looking ahead {.midi}

-   Likelihoods help us answer the question of how likely we are to observe the data given different parameters

-   In this example, we did not consider covariates, so in practice the parameters we want to estimate will look more similar to this

$$p_H = \frac{e^{\beta_0 + \beta_1x_1 + \dots + \beta_px_p}}{1 + e^{\beta_0 + \beta_1x_1 + \dots + \beta_px_p}}$$

-   Finding the MLE becomes much more complex and numerical methods may be required.
    -   We will primarily rely on software to find the MLE, but the conceptual ideas will be the same

## Next time

-   Poisson regression

## References
