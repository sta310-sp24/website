---
title: "Comparing models using likelihoods"
author: "Prof. Maria Tackett"
date: "2024-01-24"
date-format: "MMM DD, YYYY"
footer: "[ðŸ”— STA 310 - Spring 2024](https://sta310-sp24.netlify.app)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    slide-number: true
    multiplex: false
    transition: fade
    incremental: false 
    chalkboard: true
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
execute:
  freeze: auto
  echo: true
  warning: false
  message: false
knitr:
  opts_chunk: 
    R.options:      
    width: 200
bibliography: references.bib
---

```{r setup, include = F}
knitr::opts_chunk$set(fig.width = 8,
                      fig.asp = 0.618, 
                      fig.retina = 3, 
                      dpt = 300, 
                      out.width = "90%",
                      fig.align = "center")
```

## Announcements

-   HW 01 due Wednesday at 11:59pm. Grace period (i.e., no late penalty) until Thursday, January 25 at 6am.
    -   Your access to the repo will be removed at the end of the grace period. If you wish to submit the HW late, please email me and I will extend your access to the repo.
    -   You will have access to your HW repo again when grades are returned.

## Computing set up

```{r}
library(tidyverse)
library(tidymodels)
library(GGally)
library(knitr)
library(patchwork)
library(viridis)
library(ggfortify)

ggplot2::theme_set(ggplot2::theme_bw(base_size = 16))
colors <- tibble::tibble(green = "#B5BA72")
```

## Topics

-   Comparing models using likelihood functions

::: aside
Notes based on Chapter 1 and 2 of @roback2021beyond unless noted otherwise.
:::

## Data: Fouls in college basketball games {.midi}

The data set [`04-refs.csv`](data/04-refs.csv) includes 30 randomly selected NCAA men's basketball games played in the 2009 - 2010 season.[^1]

[^1]: The dataset was derived from `basektball0910.csv` used in [BMLR Section 11.2](https://bookdown.org/roback/bookdown-BeyondMLR/ch-GLMM.html#cs:refs)

We will focus on the variables `foul1`, `foul2`, and `foul3`, which indicate which team had a foul called them for the 1st, 2nd, and 3rd fouls, respectively.

-   `H`: Foul was called on the home team
-   `V`: Foul was called on the visiting team

We are focusing on the first three fouls for this analysis, but this could easily be extended to include all fouls in a game.

## Fouls in college basketball games

```{r}
refs <- read_csv("data/04-refs.csv")
refs |> slice(1:5) |> kable()
```

We will treat the games as independent in this analysis.

## Different likelihood models

**Model 1 (Unconditional Model)**:

-   What is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?

. . .

**Model 2 (Conditional Model)**:

-   Is there a tendency for the referees to call more fouls on the visiting team or home team?

-   Is there a tendency for referees to call a foul on the team that already has more fouls?

. . .

**Ultimately we want to decide which model is better.**

## Exploratory data analysis {.midi}

::: columns
::: {.column width="50%"}
```{r}
refs |>
count(foul1, foul2, foul3) |> kable()
```
:::

::: {.column width="50%"}
There are

-   46 total fouls on the home team
-   44 total fouls on the visiting team
:::
:::

```{r echo = F}
lik1 <- function(ph) {
 ph^46 * (1 - ph)^44
}

lik2 <- function(phn, phh, phv) {
  phn^25 * (1 - phn)^23 * phh^8 * (1 - phh)^12 * phv^13 * (1 - phv)^9
}
```

## Maximum likelihood estimates {.midi}

The **maximum likelihood estimate (MLE)** is the value between 0 and 1 where we are most likely to see the observed data.

. . .

::: columns
::: {.column width="50%"}
**Model 1 (Unconditional Model)**

-   $\hat{p}_H = 46/90 = 0.511$
:::

::: {.column width="50%"}
**Model 2 (Conditional Model)**

-   $\hat{p}_{H|N} = 25 / 48 = 0.521$
-   $\hat{p}_{H|H Bias} = 8 /20 = 0.4$
-   $\hat{p}_{H|V Bias} = 13/ 22 = 0.591$
:::
:::

. . .

-   What is the probability the referees call a foul on the home team, assuming foul calls within a game are independent?
-   Is there a tendency for the referees to call more fouls on the visiting team or home team?
-   Is there a tendency for referees to call a foul on the team that already has more fouls?

## Model comparisons

-   Nested models

-   Non-nested models

# Comparing nested models

## Nested Models {.midi}

**Nested models**: Models such that the parameters of the reduced model are a subset of the parameters for a larger model

Example:

$$\begin{aligned}&\text{Model A: }y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \epsilon\\
&\text{Model B: }y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_4 + \epsilon\end{aligned}$$

. . .

Model A is nested in Model B. We could use likelihoods to test whether it is useful to add $x_3$ and $x_4$ to the model.

. . .

$$\begin{aligned}&H_0: \beta_3 = \beta_4 = 0 \\ 
&H_a: \text{ at least one }\beta_j \text{ is not equal to 0}\end{aligned}$$

## Nested models {.midi}

**Another way to think about nested models**: Parameters in larger model can be equated to get the simpler model or if some parameters can be set to constants

**Example:**

$$\begin{aligned}&\text{Model 1: }p_H \\
&\text{Model 2: }p_{H| N}, p_{H| H Bias}, p_{H| V Bias}\end{aligned}$$

. . .

Model 1 is nested in Model 2. The parameters $p_{H| N}$, $p_{H|H Bias}$, and $p_{H |V Bias}$ can be set equal to $p_H$ to get Model 1.

. . .

$$\begin{aligned}&H_0: p_{H| N} = p_{H| H Bias} = p_{H| V Bias} = p_H \\
&H_a: \text{At least one of }p_{H| N}, p_{H| H Bias}, p_{H| V Bias} \text{ differs from the others}\end{aligned}$$

## Steps to compare models

`r emo::ji("one")` Find the MLEs for each model.

`r emo::ji("two")` Plug the MLEs into the log-likelihood function for each model to get the maximum value of the log-likelihood for each model.

`r emo::ji("three")` Find the difference in the maximum log-likelihoods

`r emo::ji("four")` Use the Likelihood Ratio Test to determine if the difference is statistically significant

## Steps 1 - 2

Find the MLEs for each model and plug them into the log-likelihood functions.

::: columns
::: {.column width="50%"}
**Model 1:**

-   $\hat{p}_H = 46/90 = 0.511$

```{r}
loglik1 <- function(ph){
 log(ph^46 * (1 - ph)^44)
}
loglik1(46/90)
```
:::

::: {.column width="50%"}
**Model 2**

-   $\hat{p}_{H|N} = 25 / 48 = 0.521$
-   $\hat{p}_{H|H Bias} = 8 /20 = 0.4$
-   $\hat{p}_{H|V Bias} = 13/ 22 = 0.591$

```{r}
loglik2 <- function(phn, phh, phv) {
  log(phn^25 * (1 - phn)^23 * phh^8 * 
        (1 - phh)^12 * phv^13 * (1 - phv)^9)
}
loglik2(25/48, 8/20, 13/22)
```
:::
:::

## Step 3

Find the difference in the log-likelihoods

$$
\log(Lik(Model 2)) - \log(Lik(Model1))
$$

```{r}
(diff <- loglik2(25/48, 8/20, 13/22) - loglik1(46/90))
```

<br>

. . .

<center>**Is the difference in the maximum log-likelihoods statistically significant?**</center>

## Likelihood Ratio Test {.midi}

**Test statistic**

$$\begin{aligned} LRT &= 2[\max\{\log(Lik(\text{larger model}))\} - \max\{\log(Lik(\text{reduced model}))\}]\\[10pt]
&= 2\log\Bigg(\frac{\max\{(Lik(\text{larger model})\}}{\max\{(Lik(\text{reduced model})\}}\Bigg)\end{aligned}$$

<br>

. . .

LRT follows a $\chi^2$ distribution where the degrees of freedom equal the difference in the number of parameters between the two models

## Step 4

```{r}
(LRT <- 2 * (loglik2(25/48, 8/20, 13/22) - loglik1(46/90)))
```

. . .

The test statistic follows a $\chi^2$ distribution with 2 degrees of freedom. Therefore, the p-value is $P(\chi^2 > LRT)$.

```{r}
pchisq(LRT, 2, lower.tail = FALSE)
```

. . .

The p-value is very large, so we fail to reject $H_0$. We do not have convincing evidence that the conditional model is an improvement over the unconditional model. Therefore, we can stick with the unconditional model.

# Comparing non-nested models

## Comparing non-nested models {.midi}

::: columns
::: {.column width="50%"}
AIC = -2(max logLik) + 2p

```{r}
(Model1_AIC <- 2 * loglik1(46/90) + 2 * 1)
(Model2_AIC <-2 * loglik2(25/48, 8/20, 13/22) + 2 * 3)
```
:::

::: {.column width="50%"}
BIC = -2(max logLik) + plog(n)

```{r}
(Model1_BIC <- 2 * loglik1(46/90) + 1 * log(30))
(Model2_BIC <-2 * loglik2(25/48, 8/20, 13/22) + 3 * log(30))
```
:::
:::

<br>

. . .

**Choose Model 1, the unconditional model, based on AIC and BIC**

## Looking ahead {.midi}

-   Likelihoods help us answer the question of how likely we are to observe the data given different parameters

-   In this example, we did not consider covariates, so in practice the parameters we want to estimate will look more similar to this

$$p_H = \frac{e^{\beta_0 + \beta_1x_1 + \dots + \beta_px_p}}{1 + e^{\beta_0 + \beta_1x_1 + \dots + \beta_px_p}}$$

-   Finding the MLE becomes much more complex and numerical methods may be required.
    -   We will primarily rely on software to find the MLE, but the conceptual ideas will be the same

## References
