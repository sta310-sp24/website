---
title: "Variable transformations"
author: "Prof. Maria Tackett"
date: "2022-10-12"
date-format: "MMM DD, YYYY"
footer: "[ðŸ”— Week 07](https://sta210-fa22.netlify.app/weeks/week-07.html)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
execute:
  freeze: auto
  echo: true
  warning: false
  message: false
knitr:
  opts_chunk: 
    R.options:      
    width: 200
---

```{r}
#| include: false

# figure options
knitr::opts_chunk$set(
  fig.width = 10, fig.asp = 0.618, out.width = "90%",
  fig.retina = 3, dpi = 300, fig.align = "center"
)
```

## Announcements

-   [Click here](https://duke.qualtrics.com/jfe/form/SV_cwh38yvzlVjWvA2) to fill out mid-semester survey by Friday.
-   Lab 04 due:
    -   Thu, Oct 13, 11:59pm (Thu labs)
    -   Fri, Oct 14, 11:59pm (Fri labs)
-   HW 02 due Wed, Oct 19, 11:59pm (released later today)
-   Office hours resume tomorrow (Thursday)
-   Click here for [Week 07](../weeks/week-07.qmd) activities.

## Topics

-   Log transformation on the response variable

-   Log transformation on the predictor variable

## Computational set up

```{r}
#| echo: true
library(tidyverse)
library(tidymodels)
library(knitr)
library(Sleuth3) 
library(patchwork)

# set default theme and larger font size for ggplot2
ggplot2::theme_set(ggplot2::theme_bw(base_size = 20))
```

## Respiratory Rate vs. Age {.midi}

-   A high respiratory rate can potentially indicate a respiratory infection in children. In order to determine what indicates a "high" rate, we first want to understand the relationship between a child's age and their respiratory rate.

-   The data contain the respiratory rate for 618 children ages 15 days to 3 years. It was obtained from the **Sleuth3** R package and is originally form a 1994 publication "Reference Values for Respiratory Rate in the First 3 Years of Life".

-   **Variables**:

    -   `Age`: age in months
    -   `Rate`: respiratory rate (breaths per minute)

## Rate vs. Age

```{r}
#| echo: false
respiratory <- ex0824 |>
  mutate(log_rate = log(Rate), 
         log_age = log(Age))
ggplot(data=respiratory, aes(x=Age, y=Rate)) +
  geom_point(alpha = 0.7) + 
  geom_smooth() +
  labs(title  = "Respiratory Rate vs. Age", 
       x = "Age in months", 
       y = "Respiratory rate in breaths per minute")
```

::: question
What do you notice in this plot?
:::

## Training + test sets

```{r}
set.seed(101222)
# iniital split 
resp_split <- initial_split(respiratory)

# training set
resp_train <- training(resp_split)

# test set
resp_test <- testing(resp_split)

```

## Model 1: Rate vs. Age

```{r}
resp_fit <- linear_reg() |>
  set_engine("lm") |>
  fit(Rate ~ Age, data = resp_train)

tidy(resp_fit) |>
  kable(digits = 3)
```

## Model 1: Residuals

```{r echo=FALSE}
resp_aug <- augment(resp_fit$fit)

resid_orig <- ggplot(data= resp_aug, aes(x=.fitted, y=.resid)) +
  geom_point(alpha = 0.7) + 
  geom_hline(yintercept=0,color="red") + 
  labs(x = "Predicted", y = "Residuals", 
       title = "Model 1: Residuals vs. Predicted")

resid_orig
```

::: question
What do you notice in this plot?
:::

## Consider different transformations...

```{r}
#| echo: false

p1 <- ggplot(data=resp_train, aes(x=Age, y=Rate)) +
  geom_point(alpha = 0.7) + 
  geom_smooth(method = "lm")
p2 <- ggplot(data=resp_train, aes(x=Age, y=log_rate)) +
  geom_point(alpha = 0.7) + 
  geom_smooth(method = "lm") + 
    labs(y = "log(Rate)")
p3 <- ggplot(data=resp_train, aes(x=log_age, y=Rate)) +
  geom_point(alpha = 0.7) + 
  geom_smooth(method = "lm") + 
    labs(x = "log(Age)")
  
p4 <- ggplot(data=resp_train, aes(x=log_age, y=log_rate)) +
  geom_point(alpha = 0.7) + 
  geom_smooth(method = "lm") + 
    labs(x = "log(Age)", y = "log(Rate)")
  
(p1 + p2) / (p3 + p4)
```

# Log transformation on the response variable

## Identifying a need to transform $Y$ {.midi}

-   Typically, a "fan-shaped" residual plot indicates the need for a transformation of the response variable $Y$
    -   There are multiple ways to transform a variable, e.g., $\sqrt{Y}$, $1/Y$, $\log(Y)$.
    -   $\log(Y)$ the most straightforward to interpret, so we use that transformation when possible

. . .

-   When building a model:
    -   Choose a transformation and build the model on the transformed data
    -   Reassess the residual plots
    -   If the residuals plots did not sufficiently improve, try a new transformation!

## Log transformation on $Y$

-   If we apply a log transformation to the response variable, we want to estimate the parameters for the statistical model

$$
\log(Y) = \beta_0+ \beta_1 X + \epsilon, \hspace{10mm} \epsilon \sim N(0,\sigma^2_\epsilon)
$$

-   The regression equation is

$$\widehat{\log(Y)} = \hat{\beta}_0+ \hat{\beta}_1 X$$

## Log transformation on $Y$

We want to interpret the model in terms of the original variable $Y$, not $\log(Y)$, so we need to write the model in terms of $Y$

$$\hat{Y} = \exp\{\hat{\beta}_0 + \hat{\beta}_1 X\} = \exp\{\hat{\beta}_0\}\exp\{\hat{\beta}_1X\}$$<br>\
$$\widehat{\text{Median}({Y|X})} = \exp\{\hat{\beta}_0\}\exp\{\hat{\beta}_1 X\}$$

## Model interpretation

$$\hat{Y} = \exp\{\hat{\beta}_0 + \hat{\beta}_1 X\} = \exp\{\hat{\beta}_0\}\exp\{\hat{\beta}_1X\}$$

. . .

-   **Intercept**: When $X=0$, the median of $Y$ is expected to be $\exp\{\hat{\beta}_0\}$

-   **Slope:** For every one unit increase in $X$, the median of $Y$ is expected to multiply by a factor of $\exp\{\hat{\beta}_1\}$

::: question
Why is the interpretation in terms of a multiplicative change?
:::

## Why $Median(Y|X)$ instead of $\mu_{Y|X}$

Suppose we have a set of values

```{r echo = TRUE}
x <- c(3, 5, 6, 8, 10, 14, 19)
```

<br>

. . .

::: columns
::: {.column width="50%"}
Let's calculate $\overline{\log(x)}$

```{r, echo = TRUE}
log_x <- log(x)
mean(log_x)
```
:::

::: {.column width="50%"}
Let's calculate $\log(\bar{x})$

```{r, echo = TRUE}
xbar <- mean(x)
log(xbar)
```
:::
:::

<br>

. . .

Note: $\overline{\log(x)} \neq \log(\bar{x})$

## Why $Median(Y|X)$ instead of $\mu_{Y|X}$

```{r echo = TRUE}
x <- c(3, 5, 6, 8, 10, 14, 19)
```

<br>

. . .

::: columns
::: {.column width="50%"}
Let's calculate $\text{Median}(\log(x))$

```{r , echo = TRUE}
log_x <- log(x)
median(log_x)
```
:::

::: {.column width="50%"}
Let's calculate $\log(\text{Median}(x))$

```{r, echo = TRUE}
median_x <- median(x)
log(median_x)
```
:::
:::

<br>

. . .

Note: $\text{Median}(\log(x)) = \log(\text{Median}(x))$

## Mean, Median, and log

```{r}
x <- c(3, 5, 6, 8, 10, 14, 19)
```

$$\overline{\log(x)} \neq \log(\bar{x})$$

```{r echo = T}
mean(log_x) == log(xbar)
```

. . .

$$\text{Median}(\log(x)) = \log(\text{Median}(x))$$

```{r echo = T}
median(log_x) == log(median_x)
```

## Mean and median of $\log(Y)$

-   Recall that $Y = \beta_0 + \beta_1 X$ is the **mean** value of the response at the given value of the predictor $X$. This doesn't hold when we log-transform the response variable.

-   Mathematically, the mean of the logged values is **not** necessarily equal to the log of the mean value. Therefore at a given value of $X$

. . .

$$
\begin{aligned}\exp\{\text{Mean}(\log(Y|X))\} \neq \text{Mean}(Y|X) \\[5pt]
\Rightarrow \exp\{\beta_0 + \beta_1 X\} \neq \text{Mean}(Y|X) \end{aligned}
$$

## Mean and median of $\log(y)$

-   However, the median of the logged values **is** equal to the log of the median value. Therefore,

$$\exp\{\text{Median}(\log(Y|X))\} = \text{Median}(Y|X)$$

. . .

-   If the distribution of $\log(Y)$ is symmetric about the regression line, for a given value $X$, we can expect $Mean(Y)$ and $Median(Y)$ to be approximately equal.

## Model 2: log(Rate) vs. Age

```{r}
#| echo: false
#fit model
resp_logy_fit <- linear_reg() |>
  set_engine("lm") |>
  fit(log_rate ~ Age, data = resp_train)

tidy(resp_logy_fit) |>
  kable(digits = 3)
```

<br>

::: question
Interpret the slope and intercept in the context of the data.
:::

```{r}
#| echo: false
countdown::countdown(minutes = 4)
```

## Model 2: Residuals

```{r echo=F}
resp_logy_aug <- augment(resp_logy_fit$fit)

resid_logy <- ggplot(data = resp_logy_aug, aes(x = .fitted, y = .resid)) +
  geom_point(alpha = 0.7) + 
  geom_hline(yintercept=0, color="red") +
  labs(x="Predicted", y="Residuals",
       title="Model 2: Residuals vs. Predicted")

resid_logy
```

## Compare residual plots

```{r}
#| echo: false

resid_orig + resid_logy
```

# Log transformation on a predictor variable

## Log Transformation on $X$

```{r,echo=F}
set.seed(1)
s <- ggplot2::diamonds |> sample_n(100)
p1 <- ggplot(data=s,aes(x=carat,y=log(price)))+
  geom_point(color="blue")+
  ggtitle("Scatterplot")+
  xlab("X")+
  ylab("Y")
```

```{r,echo=F}
mod2 <- lm(log(price) ~ carat, data=s)
s <- s |> mutate(residuals = resid(mod2), predicted = predict(mod2))
p2 <- ggplot(data=s,aes(x=predicted, y=residuals)) + 
geom_point(alpha = 0.7)+
geom_hline(yintercept=0,color="red") +
  ggtitle("Residual vs. Predicted")+
  xlab("Predicted")+
  ylab("residuals") 
```

```{r, echo = F, fig.height = 2.5}
p1 + p2 + plot_annotation(title = "Example data")
```

Try a transformation on $X$ if the scatterplot shows some curvature but the variance is constant for all values of $X$

## Rate vs. log(Age)

```{r,echo=F}
ggplot(data= resp_train,aes(x=log_age,y=Rate)) + 
  geom_point(alpha = 0.7)  +
  ggtitle("Respiratory Rate vs. log(Age)") + 
  xlab("log(Age)")+
  ylab("Respiratory Rate")
```

## Model with Transformation on $X$ {.midi}

Suppose we have the following regression equation:

$$\hat{Y} = \hat{\beta}_0 + \hat{\beta}_1 \log(X)$$

. . .

-   **Intercept:** When $X = 1$ $(\log(X) = 0)$, $Y$ is expected to be $\hat{\beta}_0$ (i.e. the mean of $Y$ is $\hat{\beta}_0$)

-   **Slope:** When $X$ is multiplied by a factor of $\mathbf{C}$, the mean of $Y$ is expected to increase by $\boldsymbol{\hat{\beta}_1}\mathbf{\log(C)}$ units

    -   **Example**: when $X$ is multiplied by a factor of 2, $Y$ is expected to increase by $\boldsymbol{\hat{\beta}_1}\mathbf{\log(2)}$ units

## Model 3: Rate vs. log(Age)

```{r,echo=F}
resp_logx_fit <- linear_reg() |>
  set_engine("lm") |>
  fit(Rate ~ log_age, data = resp_train)

tidy(resp_logx_fit) |>
  kable(digits = 3)
```

<br>

::: question
Interpret the slope and intercept in the context of the data.
:::

```{r}
#| echo: false
countdown::countdown(minutes = 4)
```

## Model 3: Residuals

```{r}
#| echo: false
resp_logx_aug <- augment(resp_logx_fit$fit)

resid_logx <- ggplot(data = resp_logx_aug, aes(x = .fitted, y = .resid)) +
  geom_point(alpha = 0.7) + 
  geom_hline(yintercept=0, color="red") +
  labs(x="Predicted", y="Residuals",
       title="Model 3: Residuals vs. Predicted")

resid_logx
```

## Choose a model

Recall the goal of the analysis:

*In order to determine what indicates a "high" rate, we first want to understand the relationship between a child's age and their respiratory rate.*

<br>

::: question
Which is the preferred metric to compare the models - $R^2$ or RMSE?
:::

## Compare models on testing data

```{r}
#| echo: false

m1_test_aug <- predict(resp_fit, resp_test) |>
  bind_cols(resp_test) 

m2_test_aug <- predict(resp_logy_fit, resp_test) |>
  bind_cols(resp_test) 

m3_test_aug <- predict(resp_logx_fit, resp_test) |>
  bind_cols(resp_test) 
```

| Rate vs. Age                                                            | log(Rate) vs. Age                                                           | Rate vs. log(Age)                                                      |
|-------------------------------------------------------------------------|-----------------------------------------------------------------------------|------------------------------------------------------------------------|
| `r round(rsq(m1_test_aug, truth = Rate, estimate = .pred)$.estimate,3)` | `r round(rsq(m2_test_aug, truth = log_rate, estimate = .pred)$.estimate,3)` | `r round(rsq(m3_test_aug, truth = Rate, estimate =.pred)$.estimate,3)` |

<br>

::: question
Which model would you choose?
:::

## Learn more

See [Log Transformations in Linear Regression](https://github.com/sta210-sp20/supplemental-notes/blob/master/log-transformations.pdf) for more details about interpreting regression models with log-transformed variables.
