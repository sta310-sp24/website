---
title: "Modeling two-level longitudinal data"
date: "March 4, 2024"
date-format: "MMM DD, YYYY"
author: "Prof. Maria Tackett"
footer: "[ðŸ”— STA 310 - Spring 2024](https://sta310-sp24.netlify.app)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    slide-number: true
    multiplex: false
    transition: fade
    incremental: false 
    chalkboard: true
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
execute:
  freeze: auto
  echo: true
  warning: false
  message: false
knitr:
  opts_chunk: 
    R.options:      
    width: 200
bibliography: references.bib
---

```{r setup, include = F}
knitr::opts_chunk$set(fig.width = 8,
                      fig.asp = 0.618, 
                      fig.retina = 3, 
                      dpt = 300, 
                      out.width = "70%",
                      fig.align = "center")

ggplot2::theme_set(ggplot2::theme_bw(base_size = 16))

colors <- tibble::tibble(green = "#B5BA72")
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidymodels)
library(knitr)
library(patchwork)
library(viridis)
library(kableExtra)
library(lme4)
library(broom.mixed)
```

## Announcements - UPDATE

## Topics - UPDATE

-   Fit and interpret multilevel models for longitudinal data

::: aside
Notes are based on Chapter 9 of @roback2021beyond, @boedeker2019hierarchical, @faraway2016extending, and @singer2003applied.
:::

# Modeling two-level longitudinal data

## Data: Charter schools in MN {.midi}

Today's data set contains standardized test scores and demographic information for schools in Minneapolis, MN from 2008 to 2010. The data were collected by the Minnesota Department of Education. Understanding the effectiveness of charter schools is of particular interest, since they often incorporate unique methods of instruction and learning that differ from public schools.

-   **`MathAvgScore`**: Average MCA-II score for all 6th grade students in a school (response variable)
-   **`urban`**: urban (1) or rural (0) location school location
-   **`charter`**: charter school (1) or a non-charter public school (0)
-   **`schPctfree`**: proportion of students who receive free or reduced lunches in a school (based on 2010 figures).
-   **`year08`**: Years since 2008

## Data {.midi}

```{r}
#| echo: false
charter <- read_csv("data/charter-long.csv")
```

```{r echo = F}
charter |>
  select(schoolName, year08, urban, charter, schPctfree, MathAvgScore) |>
  slice(1:3, 1852:1854) |>
  kable(digits = 3)
```

## Assess missingness {.midi}

Missing data is common in longitudinal data. Before starting the analysis, it is important to understand the missing data patterns. Use the `skim` function from the **skimr** R package to get a quick view of the missingness.

```{r}
library(skimr)
charter |> skim() |> select(skim_variable, n_missing, complete_rate)
```

## Closer look at missing data pattern

```{r echo = F}
charter |>
  select(schoolid, schoolName, year08, MathAvgScore) |>
  pivot_wider(id_cols = c(schoolid, schoolName), names_from = year08,
              names_prefix = "MathAvgScore.", values_from = MathAvgScore) |> 
  mutate(MathAvgScore0_miss = if_else(is.na(MathAvgScore.0), 1, 0),
         MathAvgScore1_miss = if_else(is.na(MathAvgScore.1), 1, 0),
         MathAvgScore2_miss = if_else(is.na(MathAvgScore.2), 1, 0)) |> 
  count(MathAvgScore0_miss, MathAvgScore1_miss, MathAvgScore2_miss) |> 
  kable()
```

## Code {.midi}

```{r eval = F}
charter |>
  select(schoolid, schoolName, year08, MathAvgScore) |>
  pivot_wider(id_cols = c(schoolid, schoolName), names_from = year08,
              names_prefix = "MathAvgScore.", values_from = MathAvgScore) |> 
  mutate(MathAvgScore0_miss = if_else(is.na(MathAvgScore.0), 1, 0),
         MathAvgScore1_miss = if_else(is.na(MathAvgScore.1), 1, 0),
         MathAvgScore2_miss = if_else(is.na(MathAvgScore.2), 1, 0)) |> 
  count(MathAvgScore0_miss, MathAvgScore1_miss, MathAvgScore2_miss) |> 
  kable()
```

## Dealing with missing data {.midi}

::: incremental
-   **Complete case analysis**: Only include schools with complete data for all three years.
    -   Would remove 12.6% of observations in this data.
-   **Last observation carried forward**: Keep the last observation from each group (school) and conduct analysis for independent observations.
-   **Impute missing observations**: "Fill in" values of missing observations using the typical observed trends from groups with similar covariates.
-   **Apply multilevel methods**: Estimate patterns using available data recognizing that trends for groups with complete data are more precise than for those with fewer measurements. This is under the condition that the probability of missingness does not depend on unobserved predictors or the response.
:::

------------------------------------------------------------------------

.center\[ .question\[ What is an advantage of each method? What is a disadvantage?\]\]

```{r echo = F}
library(countdown)
countdown(minutes = 3, seconds = 00,
          margin = "1.25%")
```

## Strategy for building multilevel models

-   Conduct exploratory data analysis for Level One and Level Two variables.

-   Fit model with no covariates to assess variability at each level.

-   Create Level One models. Start with a single term, then add terms as needed.

-   Create Level Two models. Start with a single term, then add terms as needed. Start with equation for intercept term.

-   Begin with the full set of variance components, then remove variance terms as needed.

*Alternate model building strategies in BMLR Section 8.6*

## Exploratory data analysis

Given the longitudinal structure of the data, we are able to answer questions at two levels

-   **Level One (within school)**: How did average math scores for a given school change over time?

-   **Level Two (between schools)**: What is the effect of school-specific covariates on the average math scores in 2008 and the rate of change from 2008 to 2010?

We can conduct exploratory data analysis at both levels, e.g.,

-   Univariate and bivariate EDA
-   Lattice plots
-   Spaghetti plots

# Application exercise

.question\[ Conduct exploratory data analysis in `lecture-18.Rmd`.\]

See BMLR Section 9.3 for full exploratory data analysis.

## Unconditional means model

Start with the **unconditional means model**, a model with no covariates at any level. This is also called the random intercepts model.

**Level One** : $Y_{ij} = a_{i} + \epsilon_{ij}, \hspace{5mm} \epsilon_{ij} \sim N(0, \sigma^2)$

**Level Two**: $a_i = \alpha_0 + u_i, \hspace{5mm} u_{i} \sim N(0, \sigma^2_u)$

::: question
Write the composite model.
:::

## Intraclass correlation

The **intraclass correlation** is the relative variability between groups

$$\hat{\rho} = \frac{\text{Between variability}}{\text{Total variability}} = \frac{\hat{\sigma}_u^2}{\hat{\sigma}^2_u + \hat{\sigma}^2}$$

::: question
-   Fit the unconditional means model and calculate the intraclass correlation.

-   What does this mean?
:::

## Unconditional growth model

A next step in the model building is the **unconditional growth model**, a model with Level One predictors but no Level Two predictors.

**Level One**: $Y_{ij} = a_i + b_iYear08_{ij} + \epsilon_{ij}$

**Level Two**:

-   $a_i = \alpha_0 + u_i$
-   $b_i = \beta_0 + v_i$

::: question
-   Write the composite model.
-   Fit the unconditional growth model.
-   What can we learn from this model?
:::

## Pseudo $R^2$

We can use **Pseudo R**<sup>2</sup> to explain changes in variance components between two models

-   **Note**: This should only be used when the definition of the variance component is the same between the two models

$$\text{Pseudo }R^2 = \frac{\hat{\sigma}^2(\text{Model 1})  -  \hat{\sigma}^2(\text{Model 2})}{\hat{\sigma}^2(\text{Model 1})}$$

::: question
Calculate the $\text{Pseudo }R^2$ to estimate the change of within school variance between the unconditional means and unconditional growth models.
:::

## Model with school-level covariates {.midi}

Fit a model with school-level covariates that takes the following form:

**Level One**

```{=tex}
\begin{equation*}
Y_{ij}= a_{i} + b_{i}Year08_{ij} + \epsilon_{ij}
\end{equation*}
```
**Level Two**

```{=tex}
\begin{align*}
a_{i} & = \alpha_{0} + \alpha_{1}Charter_i + \alpha_{2}urban_i + \alpha_{3}schpctfree_i + u_{i} \\
b_{i} & = \beta_{0} + \beta_{1}Charter_i + \beta_{2}urban_i + v_{i}
\end{align*}
```
::: question
-   Write out the composite model.
-   Fit the model in R.
-   Use the model to describe how the average math scores differed between charter and non-charter schools.
:::

## Consider a simpler model

<center>Would a model without the effects $v_i$ and $\rho_{uv}$ be preferable?</center>

. . .

**Level One**

```{=tex}
\begin{equation*}
Y_{ij}= a_{i} + b_{i}Year08_{ij} + \epsilon_{ij}
\end{equation*}
```
**Level Two**

```{=tex}
\begin{align*}
a_{i} & = \alpha_{0} + \alpha_{1}Charter_i + \alpha_{2}urban_i + \alpha_{3}schpctfree_i + u_{i} \\
b_{i} & = \beta_{0} + \beta_{1}Charter_i + \beta_{2}urban_i 
\end{align*}
```
<br>

. . .

In this model, the effect of year is the same for all schools with a given combination of `Charter` and `urban`

## Full and reduced models

```{r}
#| code-line-numbers: "3"
full_model <- lmer(MathAvgScore ~ charter + urban + schPctfree + 
                     charter:year08  + urban:year08 + year08 + 
                     (year08|schoolid), REML = F, data = charter) 
```

<br>

```{r}
#| code-line-numbers: "3"
reduced_model <-  lmer(MathAvgScore ~ charter + urban + schPctfree + 
                     charter:year08  + urban:year08 + year08 +
                       (1 | schoolid), REML = F, data = charter) 
```

## Notes on drop-in-deviance test

```{r}
anova(full_model, reduced_model, test = "LRT") |>
  kable(digits = 3)
```

. . .

-   $\chi^2$ test is conservative, i.e., the p-values are larger than they should be, when testing random effects at the boundary ( e.g., $\sigma_v^2 = 0$) or those with bounded ranges (e.g., $\rho_{uv}$ )

-   If you observe small p-values, you can feel relatively certain the tested effects are statistically significant

-   Use bootstrap methods to obtain more accurate p-values

## References
